rows: 28, cols: 28
Number of training images: 60000
rows: 28, cols: 28
Number of test images: 10000
model layers = 0
Model created with 2 layers
Layer 0: 784 inputs, 8 neurons
Layer 1: 8 inputs, 10 neurons
Number of parameters: 6370
Batch size: 16
Error opening directory /home/rickojn/coding/cf-mlp/models/No model found, training from scratch
remainder_m = 0, remainder_n = 2
Test loss before training: 2.314452
Test accuracy before training: 0.043400


training loop:

epoch: 0
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.591746
Layer 0 weight grad [0][0] = 17.246683


Training loss: 2.294698
Training accuracy: 0.125000

epoch: 1
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.035744
Layer 0 weight grad [0][0] = 15.628881


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.464732
Layer 0 weight grad [0][0] = 15.927918


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.357338
Layer 0 weight grad [0][0] = 15.782003


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.476778
Layer 0 weight grad [0][0] = 16.604683


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.372148
Layer 0 weight grad [0][0] = 15.996270


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.035252
Layer 0 weight grad [0][0] = 16.174398


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.388083
Layer 0 weight grad [0][0] = 17.357323


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.020271
Layer 0 weight grad [0][0] = 14.911156


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.038741
Layer 0 weight grad [0][0] = 15.515544


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 10
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.042221
Layer 0 weight grad [0][0] = 16.015268


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 11
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.469506
Layer 0 weight grad [0][0] = 17.029577


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 12
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.452515
Layer 0 weight grad [0][0] = 16.548897


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 13
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.048766
Layer 0 weight grad [0][0] = 15.786231


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 14
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.051104
Layer 0 weight grad [0][0] = 16.064932


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 15
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.463250
Layer 0 weight grad [0][0] = 14.815734


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 16
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000020 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.600644
Layer 0 weight grad [0][0] = 14.944007


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 17
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.088573
Layer 0 weight grad [0][0] = 15.229445


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 18
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000021 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.081469
Layer 0 weight grad [0][0] = 15.404407


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 19
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.048816
Layer 0 weight grad [0][0] = 15.442937


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 20
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.046334
Layer 0 weight grad [0][0] = 16.280321


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 21
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.022120
Layer 0 weight grad [0][0] = 15.271311


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 22
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.079378
Layer 0 weight grad [0][0] = 14.878646


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 23
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.157916
Layer 0 weight grad [0][0] = 16.318813


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 24
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.034876
Layer 0 weight grad [0][0] = 15.513167


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 25
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.071910
Layer 0 weight grad [0][0] = 15.040145


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 26
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.442708
Layer 0 weight grad [0][0] = 15.784077


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 27
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.028477
Layer 0 weight grad [0][0] = 16.082270


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 28
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.005971
Layer 0 weight grad [0][0] = 15.191159


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 29
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.488409
Layer 0 weight grad [0][0] = 15.185506


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 30
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.024150
Layer 0 weight grad [0][0] = 15.824172


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 31
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.026368
Layer 0 weight grad [0][0] = 16.295540


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 32
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.434718
Layer 0 weight grad [0][0] = 16.058954


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 33
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.007196
Layer 0 weight grad [0][0] = 16.313524


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 34
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.066179
Layer 0 weight grad [0][0] = 15.350840


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 35
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.033679
Layer 0 weight grad [0][0] = 15.402825


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 36
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000014 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.192642
Layer 0 weight grad [0][0] = 16.605427


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 37
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.575450
Layer 0 weight grad [0][0] = 14.322599


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 38
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.027854
Layer 0 weight grad [0][0] = 15.902662


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 39
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.011099
Layer 0 weight grad [0][0] = 15.759363


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 40
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.069663
Layer 0 weight grad [0][0] = 15.791424


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 41
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.023161
Layer 0 weight grad [0][0] = 16.061954


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 42
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.064811
Layer 0 weight grad [0][0] = 14.960367


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 43
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.005829
Layer 0 weight grad [0][0] = 15.751787


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 44
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.078196
Layer 0 weight grad [0][0] = 15.668339


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 45
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.583542
Layer 0 weight grad [0][0] = 15.672911


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 46
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.568503
Layer 0 weight grad [0][0] = 15.251228


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 47
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.023028
Layer 0 weight grad [0][0] = 15.419368


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 48
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.294566
Layer 0 weight grad [0][0] = 15.241972


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 49
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.000060
Layer 0 weight grad [0][0] = 16.182056


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 50
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.022820
Layer 0 weight grad [0][0] = 14.597174


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 51
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.084333
Layer 0 weight grad [0][0] = 15.450980


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 52
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.042709
Layer 0 weight grad [0][0] = 16.015299


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 53
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.077358
Layer 0 weight grad [0][0] = 16.440746


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 54
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.039491
Layer 0 weight grad [0][0] = 16.053558


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 55
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.020306
Layer 0 weight grad [0][0] = 15.829582


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 56
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.049439
Layer 0 weight grad [0][0] = 16.426025


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 57
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.595246
Layer 0 weight grad [0][0] = 14.054403


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 58
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.329690
Layer 0 weight grad [0][0] = 16.313459


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 59
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.049171
Layer 0 weight grad [0][0] = 15.325455


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 60
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.032346
Layer 0 weight grad [0][0] = 15.937586


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 61
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.053404
Layer 0 weight grad [0][0] = 16.031893


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 62
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.037830
Layer 0 weight grad [0][0] = 16.640249


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 63
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.455031
Layer 0 weight grad [0][0] = 16.188343


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 64
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.062170
Layer 0 weight grad [0][0] = 14.258818


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 65
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.141966
Layer 0 weight grad [0][0] = 15.593708


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 66
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.091576
Layer 0 weight grad [0][0] = 15.709111


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 67
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.431748
Layer 0 weight grad [0][0] = 16.076393


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 68
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.367039
Layer 0 weight grad [0][0] = 15.139194


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 69
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.042165
Layer 0 weight grad [0][0] = 16.408470


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 70
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.043051
Layer 0 weight grad [0][0] = 16.008974


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 71
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.392763
Layer 0 weight grad [0][0] = 15.782025


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 72
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.042459
Layer 0 weight grad [0][0] = 14.803398


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 73
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.165093
Layer 0 weight grad [0][0] = 15.421940


Training loss: 2.302585
Training accuracy: 0.375000

epoch: 74
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.154431
Layer 0 weight grad [0][0] = 16.163044


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 75
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.467326
Layer 0 weight grad [0][0] = 16.105482


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 76
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.046602
Layer 0 weight grad [0][0] = 15.305834


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 77
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.045390
Layer 0 weight grad [0][0] = 15.296471


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 78
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.471727
Layer 0 weight grad [0][0] = 15.541376


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 79
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.356132
Layer 0 weight grad [0][0] = 15.394252


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 80
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.460420
Layer 0 weight grad [0][0] = 16.257986


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 81
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.025290
Layer 0 weight grad [0][0] = 15.606570


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 82
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.179573
Layer 0 weight grad [0][0] = 15.138618


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 83
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.042510
Layer 0 weight grad [0][0] = 15.997014


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 84
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.079364
Layer 0 weight grad [0][0] = 16.651299


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 85
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.473575
Layer 0 weight grad [0][0] = 16.073660


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 86
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.122359
Layer 0 weight grad [0][0] = 16.250221


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 87
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.479752
Layer 0 weight grad [0][0] = 16.304438


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 88
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.032793
Layer 0 weight grad [0][0] = 15.584317


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 89
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.452481
Layer 0 weight grad [0][0] = 15.486078


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 90
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.588530
Layer 0 weight grad [0][0] = 15.872718


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 91
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.040906
Layer 0 weight grad [0][0] = 15.272450


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 92
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.476668
Layer 0 weight grad [0][0] = 15.672459


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 93
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.023038
Layer 0 weight grad [0][0] = 15.357801


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 94
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.220580
Layer 0 weight grad [0][0] = 15.286674


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 95
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.033395
Layer 0 weight grad [0][0] = 14.164805


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 96
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.034285
Layer 0 weight grad [0][0] = 16.103270


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 97
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.483301
Layer 0 weight grad [0][0] = 15.204759


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 98
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.032786
Layer 0 weight grad [0][0] = 14.864047


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 99
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.031370
Layer 0 weight grad [0][0] = 14.592508


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 100
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.465649
Layer 0 weight grad [0][0] = 17.032730


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 101
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.039300
Layer 0 weight grad [0][0] = 16.530325


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 102
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.076521
Layer 0 weight grad [0][0] = 15.871199


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 103
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.019770
Layer 0 weight grad [0][0] = 15.894083


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 104
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.164993
Layer 0 weight grad [0][0] = 15.268082


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 105
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.037221
Layer 0 weight grad [0][0] = 15.023664


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 106
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.075465
Layer 0 weight grad [0][0] = 16.646194


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 107
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.482033
Layer 0 weight grad [0][0] = 15.496593


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 108
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.479769
Layer 0 weight grad [0][0] = 14.663327


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 109
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.466144
Layer 0 weight grad [0][0] = 17.050879


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 110
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.075943
Layer 0 weight grad [0][0] = 16.556435


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 111
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.135851
Layer 0 weight grad [0][0] = 15.986939


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 112
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.062727
Layer 0 weight grad [0][0] = 14.420409


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 113
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.061221
Layer 0 weight grad [0][0] = 16.261900


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 114
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.386915
Layer 0 weight grad [0][0] = 16.010681


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 115
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.670119
Layer 0 weight grad [0][0] = 15.448957


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 116
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.008923
Layer 0 weight grad [0][0] = 14.828651


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 117
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.348335
Layer 0 weight grad [0][0] = 16.356976


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 118
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.006385
Layer 0 weight grad [0][0] = 16.202364


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 119
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.214632
Layer 0 weight grad [0][0] = 15.833060


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 120
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.044006
Layer 0 weight grad [0][0] = 16.607441


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 121
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.555870
Layer 0 weight grad [0][0] = 15.366284


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 122
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.490721
Layer 0 weight grad [0][0] = 16.551847


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 123
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.393628
Layer 0 weight grad [0][0] = 17.254404


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 124
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.560369
Layer 0 weight grad [0][0] = 14.880488


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 125
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.012981
Layer 0 weight grad [0][0] = 16.277006


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 126
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.015352
Layer 0 weight grad [0][0] = 15.419654


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 127
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.017939
Layer 0 weight grad [0][0] = 16.689610


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 128
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.480062
Layer 0 weight grad [0][0] = 16.052608


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 129
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.059900
Layer 0 weight grad [0][0] = 15.739570


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 130
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.497355
Layer 0 weight grad [0][0] = 13.728300


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 131
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.499575
Layer 0 weight grad [0][0] = 15.903943


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 132
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.699202
Layer 0 weight grad [0][0] = 16.547447


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 133
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.560751
Layer 0 weight grad [0][0] = 14.695239


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 134
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.485667
Layer 0 weight grad [0][0] = 15.315051


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 135
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.484308
Layer 0 weight grad [0][0] = 15.368755


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 136
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.019934
Layer 0 weight grad [0][0] = 16.179453


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 137
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.057727
Layer 0 weight grad [0][0] = 16.153101


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 138
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.001538
Layer 0 weight grad [0][0] = 15.509338


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 139
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.182787
Layer 0 weight grad [0][0] = 15.947331


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 140
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.019879
Layer 0 weight grad [0][0] = 16.836491


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 141
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.379028
Layer 0 weight grad [0][0] = 15.014717


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 142
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.022150
Layer 0 weight grad [0][0] = 15.986512


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 143
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.477914
Layer 0 weight grad [0][0] = 15.494489


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 144
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.021597
Layer 0 weight grad [0][0] = 15.553550


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 145
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000014 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.020640
Layer 0 weight grad [0][0] = 17.227030


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 146
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.477337
Layer 0 weight grad [0][0] = 15.931173


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 147
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.115143
Layer 0 weight grad [0][0] = 15.482262


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 148
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.064004
Layer 0 weight grad [0][0] = 16.371923


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 149
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.174099
Layer 0 weight grad [0][0] = 16.382530


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 150
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.470903
Layer 0 weight grad [0][0] = 15.631022


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 151
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.482469
Layer 0 weight grad [0][0] = 15.844581


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 152
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.138109
Layer 0 weight grad [0][0] = 16.503069


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 153
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.006511
Layer 0 weight grad [0][0] = 14.746345


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 154
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.024362
Layer 0 weight grad [0][0] = 15.971591


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 155
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.026686
Layer 0 weight grad [0][0] = 16.331537


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 156
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000019 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.579474
Layer 0 weight grad [0][0] = 16.174700


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 157
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.137711
Layer 0 weight grad [0][0] = 15.702036


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 158
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.024673
Layer 0 weight grad [0][0] = 15.421983


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 159
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.026924
Layer 0 weight grad [0][0] = 15.225850


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 160
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.027914
Layer 0 weight grad [0][0] = 15.596230


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 161
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.469013
Layer 0 weight grad [0][0] = 17.441278


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 162
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.034563
Layer 0 weight grad [0][0] = 16.120380


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 163
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.183631
Layer 0 weight grad [0][0] = 15.494553


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 164
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.585817
Layer 0 weight grad [0][0] = 15.953906


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 165
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.476840
Layer 0 weight grad [0][0] = 14.887978


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 166
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.040805
Layer 0 weight grad [0][0] = 16.530848


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 167
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.473180
Layer 0 weight grad [0][0] = 15.062346


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 168
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.475488
Layer 0 weight grad [0][0] = 16.421724


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 169
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.038598
Layer 0 weight grad [0][0] = 15.103354


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 170
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.036477
Layer 0 weight grad [0][0] = 14.994249


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 171
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.461336
Layer 0 weight grad [0][0] = 16.363085


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 172
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.024753
Layer 0 weight grad [0][0] = 15.784940


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 173
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.453138
Layer 0 weight grad [0][0] = 15.861223


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 174
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.052053
Layer 0 weight grad [0][0] = 15.813503


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 175
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.090788
Layer 0 weight grad [0][0] = 15.816299


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 176
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.419337
Layer 0 weight grad [0][0] = 15.368596


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 177
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.048598
Layer 0 weight grad [0][0] = 14.757330


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 178
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.330476
Layer 0 weight grad [0][0] = 16.497177


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 179
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.052418
Layer 0 weight grad [0][0] = 15.282009


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 180
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.236919
Layer 0 weight grad [0][0] = 15.600417


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 181
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.043551
Layer 0 weight grad [0][0] = 15.833551


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 182
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.164348
Layer 0 weight grad [0][0] = 16.010532


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 183
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.038116
Layer 0 weight grad [0][0] = 16.067787


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 184
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.040746
Layer 0 weight grad [0][0] = 15.696217


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 185
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.039723
Layer 0 weight grad [0][0] = 15.160026


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 186
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.526412
Layer 0 weight grad [0][0] = 14.609801


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 187
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.012605
Layer 0 weight grad [0][0] = 16.679705


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 188
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.033748
Layer 0 weight grad [0][0] = 15.961526


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 189
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.540139
Layer 0 weight grad [0][0] = 14.804974


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 190
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.137481
Layer 0 weight grad [0][0] = 15.407056


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 191
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.029767
Layer 0 weight grad [0][0] = 15.722513


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 192
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.028517
Layer 0 weight grad [0][0] = 15.793261


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 193
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.175137
Layer 0 weight grad [0][0] = 16.398384


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 194
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.488177
Layer 0 weight grad [0][0] = 14.321250


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 195
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.682221
Layer 0 weight grad [0][0] = 15.873521


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 196
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.022463
Layer 0 weight grad [0][0] = 15.164261


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 197
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.029048
Layer 0 weight grad [0][0] = 16.085846


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 198
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.615702
Layer 0 weight grad [0][0] = 15.704571


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 199
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.473283
Layer 0 weight grad [0][0] = 14.936107


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 200
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.013606
Layer 0 weight grad [0][0] = 16.089077


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 201
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.383501
Layer 0 weight grad [0][0] = 15.976454


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 202
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.056410
Layer 0 weight grad [0][0] = 16.508348


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 203
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.246664
Layer 0 weight grad [0][0] = 15.406984


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 204
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.715978
Layer 0 weight grad [0][0] = 15.110211


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 205
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.170590
Layer 0 weight grad [0][0] = 16.347406


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 206
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.500422
Layer 0 weight grad [0][0] = 16.388762


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 207
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.002212
Layer 0 weight grad [0][0] = 14.460219


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 208
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.686303
Layer 0 weight grad [0][0] = 16.513403


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 209
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.205298
Layer 0 weight grad [0][0] = 15.527747


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 210
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.567332
Layer 0 weight grad [0][0] = 15.353259


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 211
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.479590
Layer 0 weight grad [0][0] = 16.558548


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 212
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.231189
Layer 0 weight grad [0][0] = 15.341179


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 213
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.480786
Layer 0 weight grad [0][0] = 15.243155


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 214
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.481376
Layer 0 weight grad [0][0] = 14.613029


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 215
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.622405
Layer 0 weight grad [0][0] = 15.517616


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 216
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.017715
Layer 0 weight grad [0][0] = 15.399469


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 217
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.016247
Layer 0 weight grad [0][0] = 16.570690


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 218
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.022371
Layer 0 weight grad [0][0] = 16.158981


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 219
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.470799
Layer 0 weight grad [0][0] = 15.142689


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 220
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.030341
Layer 0 weight grad [0][0] = 15.508109


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 221
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.174522
Layer 0 weight grad [0][0] = 15.766487


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 222
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.027585
Layer 0 weight grad [0][0] = 15.887516


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 223
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.023125
Layer 0 weight grad [0][0] = 16.845591


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 224
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.474023
Layer 0 weight grad [0][0] = 16.270250


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 225
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.035171
Layer 0 weight grad [0][0] = 16.035112


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 226
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.023934
Layer 0 weight grad [0][0] = 15.835441


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 227
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.593291
Layer 0 weight grad [0][0] = 16.511524


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 228
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.453438
Layer 0 weight grad [0][0] = 16.568090


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 229
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.047908
Layer 0 weight grad [0][0] = 15.904634


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 230
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.048966
Layer 0 weight grad [0][0] = 15.644031


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 231
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.449297
Layer 0 weight grad [0][0] = 17.196453


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 232
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.051957
Layer 0 weight grad [0][0] = 16.015039


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 233
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.047313
Layer 0 weight grad [0][0] = 15.859776


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 234
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.048156
Layer 0 weight grad [0][0] = 15.294871


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 235
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.026218
Layer 0 weight grad [0][0] = 15.193748


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 236
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.160879
Layer 0 weight grad [0][0] = 15.614861


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 237
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.023327
Layer 0 weight grad [0][0] = 14.824851


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 238
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.039695
Layer 0 weight grad [0][0] = 15.397654


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 239
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.038188
Layer 0 weight grad [0][0] = 15.427679


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 240
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.458892
Layer 0 weight grad [0][0] = 16.118574


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 241
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.044411
Layer 0 weight grad [0][0] = 14.993129


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 242
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.041004
Layer 0 weight grad [0][0] = 15.270255


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 243
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.074025
Layer 0 weight grad [0][0] = 15.797105


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 244
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.476173
Layer 0 weight grad [0][0] = 16.005133


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 245
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.040898
Layer 0 weight grad [0][0] = 14.862892


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 246
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.588013
Layer 0 weight grad [0][0] = 16.128174


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 247
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.371492
Layer 0 weight grad [0][0] = 15.443338


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 248
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.042837
Layer 0 weight grad [0][0] = 16.637794


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 249
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.047747
Layer 0 weight grad [0][0] = 14.562522


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 250
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.080448
Layer 0 weight grad [0][0] = 16.910690


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 251
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.042591
Layer 0 weight grad [0][0] = 16.218836


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 252
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.044602
Layer 0 weight grad [0][0] = 15.280483


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 253
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.045341
Layer 0 weight grad [0][0] = 15.375806


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 254
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.456342
Layer 0 weight grad [0][0] = 15.750990


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 255
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.025887
Layer 0 weight grad [0][0] = 15.409988


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 256
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.044584
Layer 0 weight grad [0][0] = 15.398976


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 257
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.473143
Layer 0 weight grad [0][0] = 16.997372


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 258
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.024945
Layer 0 weight grad [0][0] = 17.559399


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 259
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.578498
Layer 0 weight grad [0][0] = 15.147017


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 260
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.526326
Layer 0 weight grad [0][0] = 15.400590


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 261
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.256606
Layer 0 weight grad [0][0] = 15.135149


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 262
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.083615
Layer 0 weight grad [0][0] = 15.753649


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 263
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.080643
Layer 0 weight grad [0][0] = 15.602273


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 264
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.038112
Layer 0 weight grad [0][0] = 16.224209


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 265
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.018870
Layer 0 weight grad [0][0] = 16.368141


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 266
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.663881
Layer 0 weight grad [0][0] = 15.891249


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 267
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.856293
Layer 0 weight grad [0][0] = 15.838115


Training loss: 2.302585
Training accuracy: 0.375000

epoch: 268
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.042511
Layer 0 weight grad [0][0] = 15.328677


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 269
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.199881
Layer 0 weight grad [0][0] = 15.964590


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 270
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.589572
Layer 0 weight grad [0][0] = 15.442972


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 271
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.041958
Layer 0 weight grad [0][0] = 16.247120


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 272
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.025210
Layer 0 weight grad [0][0] = 15.899157


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 273
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.451879
Layer 0 weight grad [0][0] = 15.567369


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 274
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.261012
Layer 0 weight grad [0][0] = 17.246344


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 275
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.602375
Layer 0 weight grad [0][0] = 15.914789


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 276
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.253208
Layer 0 weight grad [0][0] = 16.056231


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 277
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.035753
Layer 0 weight grad [0][0] = 16.075666


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 278
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.057998
Layer 0 weight grad [0][0] = 15.854204


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 279
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.241711
Layer 0 weight grad [0][0] = 14.693710


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 280
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.255984
Layer 0 weight grad [0][0] = 14.726623


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 281
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.820670
Layer 0 weight grad [0][0] = 15.175570


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 282
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.091631
Layer 0 weight grad [0][0] = 15.575440


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 283
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.033413
Layer 0 weight grad [0][0] = 16.522566


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 284
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.030911
Layer 0 weight grad [0][0] = 15.801677


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 285
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.052886
Layer 0 weight grad [0][0] = 15.307407


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 286
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.032713
Layer 0 weight grad [0][0] = 15.504210


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 287
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.031237
Layer 0 weight grad [0][0] = 16.705730


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 288
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.053763
Layer 0 weight grad [0][0] = 15.504484


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 289
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.444425
Layer 0 weight grad [0][0] = 15.457583


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 290
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.458336
Layer 0 weight grad [0][0] = 15.861442


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 291
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.457460
Layer 0 weight grad [0][0] = 15.352945


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 292
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.059843
Layer 0 weight grad [0][0] = 16.874231


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 293
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.454309
Layer 0 weight grad [0][0] = 16.623829


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 294
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.440719
Layer 0 weight grad [0][0] = 16.534527


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 295
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.062976
Layer 0 weight grad [0][0] = 14.790330


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 296
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.172837
Layer 0 weight grad [0][0] = 15.728280


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 297
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.061015
Layer 0 weight grad [0][0] = 15.634570


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 298
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.045433
Layer 0 weight grad [0][0] = 14.279460


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 299
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.063265
Layer 0 weight grad [0][0] = 14.724019


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 300
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.529396
Layer 0 weight grad [0][0] = 14.959460


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 301
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.104458
Layer 0 weight grad [0][0] = 16.024946


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 302
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.647121
Layer 0 weight grad [0][0] = 15.110966


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 303
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.441556
Layer 0 weight grad [0][0] = 15.443074


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 304
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.031388
Layer 0 weight grad [0][0] = 15.449916


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 305
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.038972
Layer 0 weight grad [0][0] = 15.451205


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 306
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.057590
Layer 0 weight grad [0][0] = 15.638089


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 307
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.442840
Layer 0 weight grad [0][0] = 15.274864


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 308
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.042832
Layer 0 weight grad [0][0] = 14.984420


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 309
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.158347
Layer 0 weight grad [0][0] = 15.569186


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 310
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.063819
Layer 0 weight grad [0][0] = 15.565557


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 311
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.031816
Layer 0 weight grad [0][0] = 14.539053


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 312
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.062593
Layer 0 weight grad [0][0] = 16.053410


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 313
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.063569
Layer 0 weight grad [0][0] = 15.443723


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 314
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.064533
Layer 0 weight grad [0][0] = 15.494756


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 315
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.449746
Layer 0 weight grad [0][0] = 15.558758


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 316
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.067399
Layer 0 weight grad [0][0] = 16.818123


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 317
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.445591
Layer 0 weight grad [0][0] = 15.296916


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 318
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.044928
Layer 0 weight grad [0][0] = 15.694734


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 319
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.062942
Layer 0 weight grad [0][0] = 16.162636


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 320
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.100520
Layer 0 weight grad [0][0] = 16.465422


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 321
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.205674
Layer 0 weight grad [0][0] = 16.267483


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 322
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.061893
Layer 0 weight grad [0][0] = 16.008474


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 323
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.143028
Layer 0 weight grad [0][0] = 16.239519


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 324
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.146691
Layer 0 weight grad [0][0] = 15.617644


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 325
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.055440
Layer 0 weight grad [0][0] = 14.905864


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 326
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000004 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.286582
Layer 0 weight grad [0][0] = 15.636248


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 327
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.446016
Layer 0 weight grad [0][0] = 16.404470


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 328
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.095857
Layer 0 weight grad [0][0] = 15.273677


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 329
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.054660
Layer 0 weight grad [0][0] = 16.853310


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 330
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.453595
Layer 0 weight grad [0][0] = 15.814101


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 331
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.607266
Layer 0 weight grad [0][0] = 14.981979


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 332
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.146071
Layer 0 weight grad [0][0] = 14.761158


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 333
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.096967
Layer 0 weight grad [0][0] = 16.213547


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 334
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.082465
Layer 0 weight grad [0][0] = 15.573512


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 335
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.051805
Layer 0 weight grad [0][0] = 16.132080


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 336
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.054210
Layer 0 weight grad [0][0] = 15.412636


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 337
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.087924
Layer 0 weight grad [0][0] = 15.946589


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 338
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.465062
Layer 0 weight grad [0][0] = 15.205396


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 339
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.175929
Layer 0 weight grad [0][0] = 15.519225


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 340
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.046428
Layer 0 weight grad [0][0] = 17.091841


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 341
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.455021
Layer 0 weight grad [0][0] = 15.546210


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 342
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.857949
Layer 0 weight grad [0][0] = 15.125274


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 343
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.047366
Layer 0 weight grad [0][0] = 16.380457


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 344
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.044009
Layer 0 weight grad [0][0] = 15.494165


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 345
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.046064
Layer 0 weight grad [0][0] = 16.460814


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 346
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.047102
Layer 0 weight grad [0][0] = 15.236646


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 347
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.595318
Layer 0 weight grad [0][0] = 16.368832


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 348
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.673166
Layer 0 weight grad [0][0] = 15.930735


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 349
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.161540
Layer 0 weight grad [0][0] = 15.971247


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 350
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.040815
Layer 0 weight grad [0][0] = 15.442280


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 351
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.038742
Layer 0 weight grad [0][0] = 15.560209


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 352
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.077166
Layer 0 weight grad [0][0] = 15.766275


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 353
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.039549
Layer 0 weight grad [0][0] = 16.336594


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 354
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.041228
Layer 0 weight grad [0][0] = 15.732223


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 355
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.042356
Layer 0 weight grad [0][0] = 15.860725


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 356
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.594094
Layer 0 weight grad [0][0] = 16.042259


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 357
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.159087
Layer 0 weight grad [0][0] = 16.670845


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 358
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.162473
Layer 0 weight grad [0][0] = 15.381272


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 359
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.091250
Layer 0 weight grad [0][0] = 15.155936


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 360
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.028603
Layer 0 weight grad [0][0] = 14.793830


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 361
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.029821
Layer 0 weight grad [0][0] = 16.135788


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 362
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.088378
Layer 0 weight grad [0][0] = 14.956320


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 363
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.031813
Layer 0 weight grad [0][0] = 16.422354


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 364
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.667850
Layer 0 weight grad [0][0] = 15.245139


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 365
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.049660
Layer 0 weight grad [0][0] = 16.501862


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 366
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.088369
Layer 0 weight grad [0][0] = 14.360723


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 367
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.097797
Layer 0 weight grad [0][0] = 15.459751


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 368
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.052808
Layer 0 weight grad [0][0] = 15.214394


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 369
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.032714
Layer 0 weight grad [0][0] = 15.658905


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 370
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.604497
Layer 0 weight grad [0][0] = 15.341651


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 371
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.057043
Layer 0 weight grad [0][0] = 15.032521


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 372
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.055438
Layer 0 weight grad [0][0] = 15.545120


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 373
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.038797
Layer 0 weight grad [0][0] = 16.145521


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 374
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.056671
Layer 0 weight grad [0][0] = 14.609948


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 375
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.057558
Layer 0 weight grad [0][0] = 15.853435


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 376
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.094170
Layer 0 weight grad [0][0] = 15.087559


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 377
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.648567
Layer 0 weight grad [0][0] = 16.369486


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 378
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.144461
Layer 0 weight grad [0][0] = 15.657975


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 379
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.441157
Layer 0 weight grad [0][0] = 15.696949


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 380
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.062711
Layer 0 weight grad [0][0] = 15.340505


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 381
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.730296
Layer 0 weight grad [0][0] = 15.139782


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 382
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.064062
Layer 0 weight grad [0][0] = 15.291030


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 383
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.062143
Layer 0 weight grad [0][0] = 15.013848


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 384
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.454684
Layer 0 weight grad [0][0] = 16.307692


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 385
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.060261
Layer 0 weight grad [0][0] = 15.646365


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 386
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.147452
Layer 0 weight grad [0][0] = 15.834589


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 387
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.187681
Layer 0 weight grad [0][0] = 16.357529


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 388
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.463787
Layer 0 weight grad [0][0] = 15.354814


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 389
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.173093
Layer 0 weight grad [0][0] = 15.880725


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 390
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.162154
Layer 0 weight grad [0][0] = 15.391448


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 391
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.273665
Layer 0 weight grad [0][0] = 15.490421


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 392
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.153497
Layer 0 weight grad [0][0] = 16.125395


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 393
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.033279
Layer 0 weight grad [0][0] = 16.141636


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 394
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.036300
Layer 0 weight grad [0][0] = 15.843235


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 395
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.000495
Layer 0 weight grad [0][0] = 15.650614


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 396
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.033568
Layer 0 weight grad [0][0] = 15.821112


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 397
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.031991
Layer 0 weight grad [0][0] = 14.754164


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 398
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.027655
Layer 0 weight grad [0][0] = 16.632282


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 399
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.033085
Layer 0 weight grad [0][0] = 15.530614


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 400
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.014728
Layer 0 weight grad [0][0] = 15.726166


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 401
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.171498
Layer 0 weight grad [0][0] = 15.987168


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 402
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.031524
Layer 0 weight grad [0][0] = 15.522846


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 403
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.031064
Layer 0 weight grad [0][0] = 15.382459


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 404
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.081915
Layer 0 weight grad [0][0] = 15.439382


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 405
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.588159
Layer 0 weight grad [0][0] = 15.401802


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 406
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.282190
Layer 0 weight grad [0][0] = 16.079554


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 407
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.056397
Layer 0 weight grad [0][0] = 16.043600


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 408
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.037101
Layer 0 weight grad [0][0] = 15.950531


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 409
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.321729
Layer 0 weight grad [0][0] = 15.730397


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 410
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.040181
Layer 0 weight grad [0][0] = 16.336744


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 411
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.023920
Layer 0 weight grad [0][0] = 15.745030


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 412
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.046729
Layer 0 weight grad [0][0] = 15.201615


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 413
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.046487
Layer 0 weight grad [0][0] = 14.725423


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 414
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.028025
Layer 0 weight grad [0][0] = 15.703210


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 415
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.050880
Layer 0 weight grad [0][0] = 15.816608


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 416
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.445535
Layer 0 weight grad [0][0] = 15.830226


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 417
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.057953
Layer 0 weight grad [0][0] = 15.111658


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 418
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.228138
Layer 0 weight grad [0][0] = 17.016962


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 419
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.059551
Layer 0 weight grad [0][0] = 15.967256


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 420
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.098638
Layer 0 weight grad [0][0] = 16.115725


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 421
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.121187
Layer 0 weight grad [0][0] = 15.144701


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 422
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.097511
Layer 0 weight grad [0][0] = 16.453806


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 423
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.150390
Layer 0 weight grad [0][0] = 14.661896


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 424
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.345948
Layer 0 weight grad [0][0] = 15.482750


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 425
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.379322
Layer 0 weight grad [0][0] = 16.683786


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 426
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.042958
Layer 0 weight grad [0][0] = 15.461052


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 427
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.026543
Layer 0 weight grad [0][0] = 16.429045


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 428
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.454466
Layer 0 weight grad [0][0] = 15.789932


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 429
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.671406
Layer 0 weight grad [0][0] = 15.674880


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 430
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.090923
Layer 0 weight grad [0][0] = 15.630006


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 431
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.099114
Layer 0 weight grad [0][0] = 15.562708


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 432
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.076746
Layer 0 weight grad [0][0] = 15.460119


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 433
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.482542
Layer 0 weight grad [0][0] = 16.969025


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 434
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.465321
Layer 0 weight grad [0][0] = 17.109560


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 435
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.129990
Layer 0 weight grad [0][0] = 16.817768


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 436
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.067866
Layer 0 weight grad [0][0] = 14.943937


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 437
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.070937
Layer 0 weight grad [0][0] = 16.716036


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 438
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.020949
Layer 0 weight grad [0][0] = 15.520499


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 439
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.053953
Layer 0 weight grad [0][0] = 15.260327


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 440
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.039280
Layer 0 weight grad [0][0] = 15.165678


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 441
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.463348
Layer 0 weight grad [0][0] = 15.916599


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 442
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.593311
Layer 0 weight grad [0][0] = 15.730968


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 443
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.081337
Layer 0 weight grad [0][0] = 13.724024


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 444
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.085298
Layer 0 weight grad [0][0] = 16.185610


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 445
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.674242
Layer 0 weight grad [0][0] = 15.793654


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 446
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.043392
Layer 0 weight grad [0][0] = 16.969250


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 447
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.046091
Layer 0 weight grad [0][0] = 16.280722


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 448
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.030917
Layer 0 weight grad [0][0] = 15.962726


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 449
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.052098
Layer 0 weight grad [0][0] = 16.231606


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 450
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.449285
Layer 0 weight grad [0][0] = 15.907624


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 451
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.848919
Layer 0 weight grad [0][0] = 15.297411


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 452
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.305278
Layer 0 weight grad [0][0] = 16.537203


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 453
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.052471
Layer 0 weight grad [0][0] = 15.531259


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 454
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.051378
Layer 0 weight grad [0][0] = 15.621976


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 455
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.050230
Layer 0 weight grad [0][0] = 16.249985


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 456
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.052737
Layer 0 weight grad [0][0] = 15.420622


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 457
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.463731
Layer 0 weight grad [0][0] = 15.742835


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 458
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.272078
Layer 0 weight grad [0][0] = 16.413631


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 459
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.362751
Layer 0 weight grad [0][0] = 16.008890


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 460
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.039318
Layer 0 weight grad [0][0] = 15.948683


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 461
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.016211
Layer 0 weight grad [0][0] = 15.371594


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 462
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.067296
Layer 0 weight grad [0][0] = 15.529525


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 463
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.576176
Layer 0 weight grad [0][0] = 15.946073


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 464
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.028524
Layer 0 weight grad [0][0] = 15.477503


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 465
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.009406
Layer 0 weight grad [0][0] = 16.153147


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 466
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.030493
Layer 0 weight grad [0][0] = 16.060472


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 467
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.010279
Layer 0 weight grad [0][0] = 14.528118


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 468
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.176724
Layer 0 weight grad [0][0] = 16.213253


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 469
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.083071
Layer 0 weight grad [0][0] = 16.497528


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 470
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.061146
Layer 0 weight grad [0][0] = 16.213266


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 471
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.418125
Layer 0 weight grad [0][0] = 16.234266


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 472
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.203757
Layer 0 weight grad [0][0] = 15.836194


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 473
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.988439
Layer 0 weight grad [0][0] = 16.610313


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 474
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.020318
Layer 0 weight grad [0][0] = 16.189817


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 475
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.021326
Layer 0 weight grad [0][0] = 17.135496


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 476
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.046686
Layer 0 weight grad [0][0] = 15.538429


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 477
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.021689
Layer 0 weight grad [0][0] = 16.009109


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 478
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.019436
Layer 0 weight grad [0][0] = 15.243471


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 479
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.188540
Layer 0 weight grad [0][0] = 16.051115


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 480
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.013915
Layer 0 weight grad [0][0] = 15.090199


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 481
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.158132
Layer 0 weight grad [0][0] = 15.798580


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 482
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.096029
Layer 0 weight grad [0][0] = 16.304623


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 483
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.035497
Layer 0 weight grad [0][0] = 15.125623


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 484
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.569410
Layer 0 weight grad [0][0] = 14.387438


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 485
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.026695
Layer 0 weight grad [0][0] = 15.880985


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 486
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.005256
Layer 0 weight grad [0][0] = 17.764116


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 487
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.128013
Layer 0 weight grad [0][0] = 16.606400


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 488
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.725476
Layer 0 weight grad [0][0] = 15.581948


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 489
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.028258
Layer 0 weight grad [0][0] = 16.654016


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 490
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.013646
Layer 0 weight grad [0][0] = 16.204088


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 491
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.014532
Layer 0 weight grad [0][0] = 14.830869


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 492
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.512435
Layer 0 weight grad [0][0] = 15.973854


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 493
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.180558
Layer 0 weight grad [0][0] = 14.537825


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 494
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.661188
Layer 0 weight grad [0][0] = 16.326626


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 495
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.125408
Layer 0 weight grad [0][0] = 16.647806


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 496
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.017982
Layer 0 weight grad [0][0] = 16.123037


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 497
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.019443
Layer 0 weight grad [0][0] = 15.398079


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 498
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.017260
Layer 0 weight grad [0][0] = 16.347610


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 499
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.021176
Layer 0 weight grad [0][0] = 16.053986


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 500
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.018602
Layer 0 weight grad [0][0] = 16.368788


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 501
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.533795
Layer 0 weight grad [0][0] = 14.354618


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 502
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.512546
Layer 0 weight grad [0][0] = 15.636551


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 503
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.541884
Layer 0 weight grad [0][0] = 14.838084


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 504
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.005319
Layer 0 weight grad [0][0] = 16.120426


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 505
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.003850
Layer 0 weight grad [0][0] = 16.119564


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 506
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.545813
Layer 0 weight grad [0][0] = 14.751639


Training loss: 2.302585
Training accuracy: 0.375000

epoch: 507
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.001368
Layer 0 weight grad [0][0] = 15.236180


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 508
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.210682
Layer 0 weight grad [0][0] = 16.078527


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 509
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.008040
Layer 0 weight grad [0][0] = 16.693295


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 510
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.074332
Layer 0 weight grad [0][0] = 15.923688


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 511
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.029976
Layer 0 weight grad [0][0] = 16.394478


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 512
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.509713
Layer 0 weight grad [0][0] = 15.258013


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 513
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.022280
Layer 0 weight grad [0][0] = 16.008337


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 514
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.002941
Layer 0 weight grad [0][0] = 16.488485


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 515
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.004846
Layer 0 weight grad [0][0] = 15.695031


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 516
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.225548
Layer 0 weight grad [0][0] = 16.536503


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 517
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.020680
Layer 0 weight grad [0][0] = 15.047701


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 518
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.637755
Layer 0 weight grad [0][0] = 17.643171


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 519
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.553651
Layer 0 weight grad [0][0] = 15.793525


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 520
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.203764
Layer 0 weight grad [0][0] = 16.235870


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 521
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.531462
Layer 0 weight grad [0][0] = 15.270087


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 522
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.004284
Layer 0 weight grad [0][0] = 15.538682


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 523
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.041677
Layer 0 weight grad [0][0] = 15.749721


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 524
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.003005
Layer 0 weight grad [0][0] = 15.757876


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 525
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.514310
Layer 0 weight grad [0][0] = 15.392280


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 526
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.002045
Layer 0 weight grad [0][0] = 17.031645


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 527
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.537181
Layer 0 weight grad [0][0] = 14.366281


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 528
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.195848
Layer 0 weight grad [0][0] = 15.469583


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 529
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.006651
Layer 0 weight grad [0][0] = 15.524481


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 530
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.005619
Layer 0 weight grad [0][0] = 15.447140


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 531
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.496764
Layer 0 weight grad [0][0] = 16.221750


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 532
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.004770
Layer 0 weight grad [0][0] = 17.948513


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 533
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.011566
Layer 0 weight grad [0][0] = 15.626489


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 534
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.007675
Layer 0 weight grad [0][0] = 16.134468


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 535
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.080237
Layer 0 weight grad [0][0] = 15.371732


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 536
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.008802
Layer 0 weight grad [0][0] = 15.321541


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 537
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.487614
Layer 0 weight grad [0][0] = 16.380112


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 538
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.071736
Layer 0 weight grad [0][0] = 16.066605


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 539
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.489084
Layer 0 weight grad [0][0] = 15.729737


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 540
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.566675
Layer 0 weight grad [0][0] = 15.003653


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 541
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.019267
Layer 0 weight grad [0][0] = 15.701473


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 542
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.572355
Layer 0 weight grad [0][0] = 16.212858


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 543
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.024860
Layer 0 weight grad [0][0] = 16.974430


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 544
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.963993
Layer 0 weight grad [0][0] = 15.580865


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 545
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.470956
Layer 0 weight grad [0][0] = 16.257450


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 546
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.032722
Layer 0 weight grad [0][0] = 14.916135


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 547
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.012860
Layer 0 weight grad [0][0] = 15.662229


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 548
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.053300
Layer 0 weight grad [0][0] = 15.691748


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 549
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.471020
Layer 0 weight grad [0][0] = 15.790089


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 550
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.483897
Layer 0 weight grad [0][0] = 17.203272


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 551
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.481627
Layer 0 weight grad [0][0] = 16.278425


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 552
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.586613
Layer 0 weight grad [0][0] = 15.526525


Training loss: 2.302585
Training accuracy: 0.375000

epoch: 553
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.021318
Layer 0 weight grad [0][0] = 15.147004


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 554
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.040248
Layer 0 weight grad [0][0] = 15.779343


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 555
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.039867
Layer 0 weight grad [0][0] = 16.168756


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 556
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.683389
Layer 0 weight grad [0][0] = 16.695471


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 557
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.016299
Layer 0 weight grad [0][0] = 15.483267


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 558
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.170451
Layer 0 weight grad [0][0] = 15.411974


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 559
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.031925
Layer 0 weight grad [0][0] = 15.784513


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 560
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.065917
Layer 0 weight grad [0][0] = 15.745420


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 561
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.025080
Layer 0 weight grad [0][0] = 15.656145


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 562
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.026419
Layer 0 weight grad [0][0] = 15.255838


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 563
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.489198
Layer 0 weight grad [0][0] = 17.475952


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 564
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.470585
Layer 0 weight grad [0][0] = 15.399264


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 565
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.468288
Layer 0 weight grad [0][0] = 15.985121


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 566
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.674472
Layer 0 weight grad [0][0] = 14.935266


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 567
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.030486
Layer 0 weight grad [0][0] = 15.184541


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 568
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.015306
Layer 0 weight grad [0][0] = 17.233679


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 569
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.074005
Layer 0 weight grad [0][0] = 16.440351


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 570
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.072578
Layer 0 weight grad [0][0] = 15.397419


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 571
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.015762
Layer 0 weight grad [0][0] = 15.396875


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 572
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.585616
Layer 0 weight grad [0][0] = 14.874445


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 573
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.461261
Layer 0 weight grad [0][0] = 14.815711


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 574
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.458283
Layer 0 weight grad [0][0] = 15.801412


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 575
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.041834
Layer 0 weight grad [0][0] = 17.048235


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 576
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.021188
Layer 0 weight grad [0][0] = 15.514635


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 577
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.043464
Layer 0 weight grad [0][0] = 15.963226


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 578
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.596328
Layer 0 weight grad [0][0] = 15.251200


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 579
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.635238
Layer 0 weight grad [0][0] = 16.270407


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 580
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.158129
Layer 0 weight grad [0][0] = 17.275116


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 581
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.455182
Layer 0 weight grad [0][0] = 15.587106


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 582
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.453762
Layer 0 weight grad [0][0] = 14.978143


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 583
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.047603
Layer 0 weight grad [0][0] = 15.560332


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 584
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.027477
Layer 0 weight grad [0][0] = 16.119741


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 585
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.044232
Layer 0 weight grad [0][0] = 14.815656


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 586
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.124169
Layer 0 weight grad [0][0] = 15.374246


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 587
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.037139
Layer 0 weight grad [0][0] = 15.208714


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 588
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.254450
Layer 0 weight grad [0][0] = 14.999684


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 589
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.124662
Layer 0 weight grad [0][0] = 14.749161


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 590
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.480207
Layer 0 weight grad [0][0] = 16.593941


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 591
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.034033
Layer 0 weight grad [0][0] = 13.967570


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 592
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.672865
Layer 0 weight grad [0][0] = 16.319983


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 593
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.137263
Layer 0 weight grad [0][0] = 16.438150


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 594
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.025582
Layer 0 weight grad [0][0] = 15.005665


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 595
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.676454
Layer 0 weight grad [0][0] = 15.985751


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 596
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.028753
Layer 0 weight grad [0][0] = 16.196283


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 597
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.174405
Layer 0 weight grad [0][0] = 16.384550


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 598
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.470928
Layer 0 weight grad [0][0] = 15.530762


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 599
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.466176
Layer 0 weight grad [0][0] = 16.549774


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 600
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.174623
Layer 0 weight grad [0][0] = 15.662226


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 601
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.210304
Layer 0 weight grad [0][0] = 15.739212


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 602
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.027105
Layer 0 weight grad [0][0] = 15.828230


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 603
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.231593
Layer 0 weight grad [0][0] = 16.180557


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 604
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.011604
Layer 0 weight grad [0][0] = 15.803753


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 605
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.030736
Layer 0 weight grad [0][0] = 15.746698


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 606
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.723571
Layer 0 weight grad [0][0] = 15.189006


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 607
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.035028
Layer 0 weight grad [0][0] = 14.702796


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 608
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.586949
Layer 0 weight grad [0][0] = 15.753701


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 609
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.475503
Layer 0 weight grad [0][0] = 15.595829


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 610
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.130120
Layer 0 weight grad [0][0] = 15.709403


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 611
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.134575
Layer 0 weight grad [0][0] = 16.258270


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 612
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.162718
Layer 0 weight grad [0][0] = 16.256960


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 613
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.044200
Layer 0 weight grad [0][0] = 15.642356


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 614
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.041520
Layer 0 weight grad [0][0] = 15.538051


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 615
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.021538
Layer 0 weight grad [0][0] = 15.215339


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 616
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.038103
Layer 0 weight grad [0][0] = 17.357939


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 617
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.474628
Layer 0 weight grad [0][0] = 15.547935


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 618
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.163963
Layer 0 weight grad [0][0] = 16.606508


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 619
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.038558
Layer 0 weight grad [0][0] = 15.251218


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 620
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.037637
Layer 0 weight grad [0][0] = 15.447437


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 621
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.134041
Layer 0 weight grad [0][0] = 16.679464


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 622
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.028705
Layer 0 weight grad [0][0] = 16.203377


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 623
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.467635
Layer 0 weight grad [0][0] = 14.326961


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 624
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.584618
Layer 0 weight grad [0][0] = 15.714832


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 625
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.461834
Layer 0 weight grad [0][0] = 16.482822


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 626
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.078134
Layer 0 weight grad [0][0] = 16.423187


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 627
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.039498
Layer 0 weight grad [0][0] = 15.459845


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 628
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.041880
Layer 0 weight grad [0][0] = 16.436840


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 629
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.095555
Layer 0 weight grad [0][0] = 15.827162


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 630
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.050675
Layer 0 weight grad [0][0] = 17.036314


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 631
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.049572
Layer 0 weight grad [0][0] = 14.832236


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 632
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.117806
Layer 0 weight grad [0][0] = 15.287320


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 633
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.045857
Layer 0 weight grad [0][0] = 16.149918


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 634
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.040346
Layer 0 weight grad [0][0] = 14.431558


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 635
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.699842
Layer 0 weight grad [0][0] = 16.174778


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 636
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.197658
Layer 0 weight grad [0][0] = 15.901302


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 637
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.071546
Layer 0 weight grad [0][0] = 16.446659


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 638
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.034439
Layer 0 weight grad [0][0] = 16.953804


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 639
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.153729
Layer 0 weight grad [0][0] = 15.765730


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 640
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.259465
Layer 0 weight grad [0][0] = 16.703087


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 641
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.034182
Layer 0 weight grad [0][0] = 16.407103


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 642
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.035469
Layer 0 weight grad [0][0] = 15.967674


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 643
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.071308
Layer 0 weight grad [0][0] = 15.377596


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 644
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.173172
Layer 0 weight grad [0][0] = 16.099989


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 645
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.469946
Layer 0 weight grad [0][0] = 15.270982


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 646
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.484619
Layer 0 weight grad [0][0] = 15.323125


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 647
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.065602
Layer 0 weight grad [0][0] = 15.842604


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 648
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.028392
Layer 0 weight grad [0][0] = 15.922925


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 649
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.013173
Layer 0 weight grad [0][0] = 15.837872


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 650
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.480828
Layer 0 weight grad [0][0] = 15.406153


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 651
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.478705
Layer 0 weight grad [0][0] = 14.914433


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 652
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.587917
Layer 0 weight grad [0][0] = 15.263429


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 653
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.474892
Layer 0 weight grad [0][0] = 15.349312


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 654
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.461282
Layer 0 weight grad [0][0] = 15.565585


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 655
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.025931
Layer 0 weight grad [0][0] = 15.464602


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 656
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.470464
Layer 0 weight grad [0][0] = 15.408526


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 657
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.160207
Layer 0 weight grad [0][0] = 15.701367


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 658
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.041982
Layer 0 weight grad [0][0] = 15.237717


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 659
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.454836
Layer 0 weight grad [0][0] = 15.942562


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 660
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.048505
Layer 0 weight grad [0][0] = 15.993098


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 661
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.069189
Layer 0 weight grad [0][0] = 14.993168


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 662
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.048293
Layer 0 weight grad [0][0] = 15.186845


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 663
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.078212
Layer 0 weight grad [0][0] = 15.077089


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 664
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.058995
Layer 0 weight grad [0][0] = 15.293676


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 665
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.041725
Layer 0 weight grad [0][0] = 16.370878


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 666
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.274726
Layer 0 weight grad [0][0] = 15.495188


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 667
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.045663
Layer 0 weight grad [0][0] = 15.390920


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 668
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.047389
Layer 0 weight grad [0][0] = 15.561867


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 669
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.120609
Layer 0 weight grad [0][0] = 16.149475


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 670
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.164583
Layer 0 weight grad [0][0] = 15.841060


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 671
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.037126
Layer 0 weight grad [0][0] = 16.349216


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 672
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.134319
Layer 0 weight grad [0][0] = 15.460665


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 673
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.471659
Layer 0 weight grad [0][0] = 16.984640


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 674
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.031491
Layer 0 weight grad [0][0] = 15.745241


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 675
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.029766
Layer 0 weight grad [0][0] = 16.554371


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 676
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.389519
Layer 0 weight grad [0][0] = 16.434118


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 677
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.171948
Layer 0 weight grad [0][0] = 15.586696


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 678
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000057 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.029538
Layer 0 weight grad [0][0] = 16.014467


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 679
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.011922
Layer 0 weight grad [0][0] = 15.659417


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 680
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.034803
Layer 0 weight grad [0][0] = 15.808305


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 681
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.037940
Layer 0 weight grad [0][0] = 15.003381


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 682
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.035860
Layer 0 weight grad [0][0] = 15.709823


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 683
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.185999
Layer 0 weight grad [0][0] = 14.673069


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 684
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.584350
Layer 0 weight grad [0][0] = 14.995687


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 685
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.035897
Layer 0 weight grad [0][0] = 15.458397


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 686
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.465397
Layer 0 weight grad [0][0] = 15.552907


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 687
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.666277
Layer 0 weight grad [0][0] = 16.254169


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 688
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.013591
Layer 0 weight grad [0][0] = 15.487334


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 689
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.018403
Layer 0 weight grad [0][0] = 15.406238


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 690
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.463046
Layer 0 weight grad [0][0] = 16.570940


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 691
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.040774
Layer 0 weight grad [0][0] = 16.738111


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 692
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.038273
Layer 0 weight grad [0][0] = 15.407885


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 693
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.074036
Layer 0 weight grad [0][0] = 15.678642


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 694
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.037298
Layer 0 weight grad [0][0] = 15.272824


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 695
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.038479
Layer 0 weight grad [0][0] = 15.550600


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 696
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.077263
Layer 0 weight grad [0][0] = 15.358458


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 697
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.567452
Layer 0 weight grad [0][0] = 15.275468


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 698
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.365381
Layer 0 weight grad [0][0] = 15.742951


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 699
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.042538
Layer 0 weight grad [0][0] = 15.851980


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 700
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.633093
Layer 0 weight grad [0][0] = 15.963478


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 701
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.354896
Layer 0 weight grad [0][0] = 15.964857


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 702
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.467296
Layer 0 weight grad [0][0] = 15.488503


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 703
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.158297
Layer 0 weight grad [0][0] = 15.531347


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 704
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.456617
Layer 0 weight grad [0][0] = 15.531249


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 705
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.045482
Layer 0 weight grad [0][0] = 16.173698


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 706
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.041758
Layer 0 weight grad [0][0] = 14.914986


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 707
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.042582
Layer 0 weight grad [0][0] = 15.832175


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 708
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.076062
Layer 0 weight grad [0][0] = 15.192387


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 709
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.037186
Layer 0 weight grad [0][0] = 15.166964


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 710
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.017679
Layer 0 weight grad [0][0] = 15.988381


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 711
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.465628
Layer 0 weight grad [0][0] = 15.607620


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 712
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.037832
Layer 0 weight grad [0][0] = 18.177950


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 713
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.074500
Layer 0 weight grad [0][0] = 15.923209


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 714
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.022310
Layer 0 weight grad [0][0] = 15.504950


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 715
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.575724
Layer 0 weight grad [0][0] = 14.121154


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 716
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.046677
Layer 0 weight grad [0][0] = 16.438406


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 717
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.136070
Layer 0 weight grad [0][0] = 15.417667


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 718
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.026924
Layer 0 weight grad [0][0] = 16.159637


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 719
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.036021
Layer 0 weight grad [0][0] = 15.637435


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 720
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.167990
Layer 0 weight grad [0][0] = 17.251499


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 721
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.105659
Layer 0 weight grad [0][0] = 14.949485


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 722
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.104324
Layer 0 weight grad [0][0] = 15.374239


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 723
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.673383
Layer 0 weight grad [0][0] = 16.153700


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 724
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.662549
Layer 0 weight grad [0][0] = 15.291135


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 725
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.573390
Layer 0 weight grad [0][0] = 15.370200


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 726
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.454790
Layer 0 weight grad [0][0] = 17.041599


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 727
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.047349
Layer 0 weight grad [0][0] = 15.558357


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 728
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.048296
Layer 0 weight grad [0][0] = 15.655487


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 729
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.088454
Layer 0 weight grad [0][0] = 15.701784


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 730
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.047218
Layer 0 weight grad [0][0] = 16.839941


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 731
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.080298
Layer 0 weight grad [0][0] = 15.702205


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 732
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.041048
Layer 0 weight grad [0][0] = 16.390993


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 733
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.165917
Layer 0 weight grad [0][0] = 16.628153


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 734
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.057907
Layer 0 weight grad [0][0] = 16.099630


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 735
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.057176
Layer 0 weight grad [0][0] = 17.759436


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 736
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.442365
Layer 0 weight grad [0][0] = 16.197248


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 737
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.110398
Layer 0 weight grad [0][0] = 15.007939


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 738
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.449177
Layer 0 weight grad [0][0] = 15.422959


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 739
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.052545
Layer 0 weight grad [0][0] = 15.474606


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 740
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.465816
Layer 0 weight grad [0][0] = 14.867393


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 741
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.045099
Layer 0 weight grad [0][0] = 15.098624


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 742
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.453701
Layer 0 weight grad [0][0] = 15.200850


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 743
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.049772
Layer 0 weight grad [0][0] = 16.025625


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 744
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.050141
Layer 0 weight grad [0][0] = 15.012506


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 745
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.120444
Layer 0 weight grad [0][0] = 15.701531


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 746
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.076170
Layer 0 weight grad [0][0] = 15.851178


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 747
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.072750
Layer 0 weight grad [0][0] = 15.822289


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 748
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.469584
Layer 0 weight grad [0][0] = 15.685385


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 749
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.658763
Layer 0 weight grad [0][0] = 17.120316


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 750
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.044063
Layer 0 weight grad [0][0] = 16.124929


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 751
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.044546
Layer 0 weight grad [0][0] = 17.772068


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 752
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.644867
Layer 0 weight grad [0][0] = 15.249817


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 753
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.369246
Layer 0 weight grad [0][0] = 16.229904


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 754
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.462163
Layer 0 weight grad [0][0] = 16.509764


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 755
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.053025
Layer 0 weight grad [0][0] = 15.601112


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 756
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.144176
Layer 0 weight grad [0][0] = 15.061267


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 757
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.052010
Layer 0 weight grad [0][0] = 16.028774


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 758
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.118273
Layer 0 weight grad [0][0] = 15.311399


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 759
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.466245
Layer 0 weight grad [0][0] = 16.291395


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 760
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.158290
Layer 0 weight grad [0][0] = 15.159451


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 761
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.041674
Layer 0 weight grad [0][0] = 15.588700


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 762
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.587598
Layer 0 weight grad [0][0] = 15.891033


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 763
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.037833
Layer 0 weight grad [0][0] = 15.441556


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 764
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.189846
Layer 0 weight grad [0][0] = 15.380769


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 765
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.481986
Layer 0 weight grad [0][0] = 17.860615


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 766
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.483322
Layer 0 weight grad [0][0] = 15.299130


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 767
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.027192
Layer 0 weight grad [0][0] = 15.876438


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 768
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.229250
Layer 0 weight grad [0][0] = 15.477474


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 769
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.346078
Layer 0 weight grad [0][0] = 16.110355


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 770
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.015485
Layer 0 weight grad [0][0] = 14.818366


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 771
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.572672
Layer 0 weight grad [0][0] = 15.154520


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 772
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.576320
Layer 0 weight grad [0][0] = 15.579515


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 773
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.485432
Layer 0 weight grad [0][0] = 15.134759


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 774
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.080830
Layer 0 weight grad [0][0] = 16.102463


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 775
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.141536
Layer 0 weight grad [0][0] = 15.076683


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 776
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.032368
Layer 0 weight grad [0][0] = 16.398077


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 777
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.535434
Layer 0 weight grad [0][0] = 15.420762


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 778
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.031226
Layer 0 weight grad [0][0] = 16.580700


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 779
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.178887
Layer 0 weight grad [0][0] = 15.484113


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 780
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.021439
Layer 0 weight grad [0][0] = 15.774259


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 781
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.017091
Layer 0 weight grad [0][0] = 15.018990


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 782
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.510195
Layer 0 weight grad [0][0] = 14.820089


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 783
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.704656
Layer 0 weight grad [0][0] = 16.404980


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 784
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.013018
Layer 0 weight grad [0][0] = 15.961350


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 785
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.008585
Layer 0 weight grad [0][0] = 15.400230


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 786
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.005320
Layer 0 weight grad [0][0] = 16.000002


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 787
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.005560
Layer 0 weight grad [0][0] = 15.490804


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 788
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.716555
Layer 0 weight grad [0][0] = 15.951350


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 789
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.034582
Layer 0 weight grad [0][0] = 16.800905


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 790
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.026682
Layer 0 weight grad [0][0] = 15.261985


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 791
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.578640
Layer 0 weight grad [0][0] = 15.098686


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 792
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.011283
Layer 0 weight grad [0][0] = 16.774158


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 793
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.530185
Layer 0 weight grad [0][0] = 14.804444


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 794
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.033171
Layer 0 weight grad [0][0] = 15.711037


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 795
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.014450
Layer 0 weight grad [0][0] = 15.705170


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 796
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.015907
Layer 0 weight grad [0][0] = 16.124613


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 797
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.033697
Layer 0 weight grad [0][0] = 16.270082


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 798
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.529088
Layer 0 weight grad [0][0] = 14.946913


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 799
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.013870
Layer 0 weight grad [0][0] = 16.082478


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 800
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.529458
Layer 0 weight grad [0][0] = 16.609102


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 801
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.015834
Layer 0 weight grad [0][0] = 15.737671


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 802
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.020675
Layer 0 weight grad [0][0] = 14.489037


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 803
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.529549
Layer 0 weight grad [0][0] = 16.439333


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 804
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.020462
Layer 0 weight grad [0][0] = 15.594348


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 805
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.230982
Layer 0 weight grad [0][0] = 14.909737


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 806
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.048911
Layer 0 weight grad [0][0] = 14.000526


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 807
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.032393
Layer 0 weight grad [0][0] = 16.943748


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 808
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.260653
Layer 0 weight grad [0][0] = 16.768728


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 809
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.040763
Layer 0 weight grad [0][0] = 14.567062


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 810
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.044400
Layer 0 weight grad [0][0] = 16.087553


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 811
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.442154
Layer 0 weight grad [0][0] = 16.199419


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 812
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.533543
Layer 0 weight grad [0][0] = 15.547998


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 813
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.003963
Layer 0 weight grad [0][0] = 16.052492


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 814
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.501654
Layer 0 weight grad [0][0] = 15.712987


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 815
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.028481
Layer 0 weight grad [0][0] = 14.862131


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 816
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.028836
Layer 0 weight grad [0][0] = 15.859875


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 817
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.030302
Layer 0 weight grad [0][0] = 14.739896


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 818
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.524183
Layer 0 weight grad [0][0] = 15.863434


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 819
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.032928
Layer 0 weight grad [0][0] = 15.326495


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 820
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.034674
Layer 0 weight grad [0][0] = 15.842753


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 821
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.054218
Layer 0 weight grad [0][0] = 16.071507


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 822
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.019158
Layer 0 weight grad [0][0] = 15.566210


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 823
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.283928
Layer 0 weight grad [0][0] = 14.307870


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 824
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.016328
Layer 0 weight grad [0][0] = 15.560758


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 825
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.241760
Layer 0 weight grad [0][0] = 14.181486


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 826
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.013781
Layer 0 weight grad [0][0] = 16.814205


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 827
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.009315
Layer 0 weight grad [0][0] = 16.587811


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 828
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.002732
Layer 0 weight grad [0][0] = 16.508589


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 829
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.359239
Layer 0 weight grad [0][0] = 17.586397


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 830
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.038981
Layer 0 weight grad [0][0] = 15.011444


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 831
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.039357
Layer 0 weight grad [0][0] = 15.907540


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 832
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.556368
Layer 0 weight grad [0][0] = 16.045561


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 833
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.006671
Layer 0 weight grad [0][0] = 15.518131


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 834
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.005921
Layer 0 weight grad [0][0] = 16.158146


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 835
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.234435
Layer 0 weight grad [0][0] = 14.948840


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 836
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.505936
Layer 0 weight grad [0][0] = 15.504958


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 837
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.042145
Layer 0 weight grad [0][0] = 15.349476


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 838
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.044916
Layer 0 weight grad [0][0] = 15.463634


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 839
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.525007
Layer 0 weight grad [0][0] = 14.842118


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 840
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.540673
Layer 0 weight grad [0][0] = 14.999704


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 841
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.525163
Layer 0 weight grad [0][0] = 17.560246


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 842
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.287491
Layer 0 weight grad [0][0] = 15.643607


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 843
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.047527
Layer 0 weight grad [0][0] = 15.343312


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 844
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.530789
Layer 0 weight grad [0][0] = 14.769774


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 845
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.047950
Layer 0 weight grad [0][0] = 15.129204


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 846
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.006509
Layer 0 weight grad [0][0] = 14.184148


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 847
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.533305
Layer 0 weight grad [0][0] = 16.186348


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 848
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.049103
Layer 0 weight grad [0][0] = 16.264425


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 849
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.030967
Layer 0 weight grad [0][0] = 16.917866


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 850
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.517608
Layer 0 weight grad [0][0] = 15.508555


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 851
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.517546
Layer 0 weight grad [0][0] = 16.069336


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 852
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.002276
Layer 0 weight grad [0][0] = 16.145508


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 853
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.548351
Layer 0 weight grad [0][0] = 16.501358


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 854
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.002319
Layer 0 weight grad [0][0] = 17.299149


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 855
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.398340
Layer 0 weight grad [0][0] = 16.295240


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 856
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.005362
Layer 0 weight grad [0][0] = 15.868153


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 857
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.042358
Layer 0 weight grad [0][0] = 15.213989


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 858
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.006723
Layer 0 weight grad [0][0] = 16.579733


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 859
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.653118
Layer 0 weight grad [0][0] = 15.289071


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 860
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.015355
Layer 0 weight grad [0][0] = 16.151136


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 861
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.055740
Layer 0 weight grad [0][0] = 15.207272


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 862
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.078852
Layer 0 weight grad [0][0] = 15.996328


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 863
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.060727
Layer 0 weight grad [0][0] = 15.823929


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 864
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.913948
Layer 0 weight grad [0][0] = 15.573512


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 865
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.029629
Layer 0 weight grad [0][0] = 15.802484


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 866
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.013447
Layer 0 weight grad [0][0] = 15.290815


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 867
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.054895
Layer 0 weight grad [0][0] = 15.565157


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 868
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.570544
Layer 0 weight grad [0][0] = 17.231152


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 869
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.466125
Layer 0 weight grad [0][0] = 15.913163


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 870
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.062482
Layer 0 weight grad [0][0] = 15.227167


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 871
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.456686
Layer 0 weight grad [0][0] = 14.730371


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 872
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.750403
Layer 0 weight grad [0][0] = 15.109301


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 873
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.279409
Layer 0 weight grad [0][0] = 15.496870


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 874
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.097789
Layer 0 weight grad [0][0] = 18.164940


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 875
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.572998
Layer 0 weight grad [0][0] = 16.603022


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 876
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.617910
Layer 0 weight grad [0][0] = 17.240219


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 877
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.062191
Layer 0 weight grad [0][0] = 14.952819


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 878
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.269588
Layer 0 weight grad [0][0] = 16.105906


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 879
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.693564
Layer 0 weight grad [0][0] = 15.909100


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 880
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.073197
Layer 0 weight grad [0][0] = 15.555738


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 881
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.074803
Layer 0 weight grad [0][0] = 16.258045


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 882
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.097589
Layer 0 weight grad [0][0] = 15.343504


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 883
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.302610
Layer 0 weight grad [0][0] = 15.956654


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 884
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.306446
Layer 0 weight grad [0][0] = 16.598129


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 885
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.256324
Layer 0 weight grad [0][0] = 16.592796


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 886
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.571873
Layer 0 weight grad [0][0] = 15.604560


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 887
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.821211
Layer 0 weight grad [0][0] = 15.389197


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 888
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.070242
Layer 0 weight grad [0][0] = 16.669859


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 889
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.091022
Layer 0 weight grad [0][0] = 15.489635


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 890
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.662337
Layer 0 weight grad [0][0] = 15.191555


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 891
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.096198
Layer 0 weight grad [0][0] = 16.473242


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 892
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.450530
Layer 0 weight grad [0][0] = 15.757263


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 893
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.450900
Layer 0 weight grad [0][0] = 16.739885


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 894
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.826637
Layer 0 weight grad [0][0] = 15.634461


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 895
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.045785
Layer 0 weight grad [0][0] = 16.208651


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 896
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.051386
Layer 0 weight grad [0][0] = 14.404377


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 897
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.247271
Layer 0 weight grad [0][0] = 16.560286


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 898
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.463823
Layer 0 weight grad [0][0] = 16.864037


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 899
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.735896
Layer 0 weight grad [0][0] = 14.868460


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 900
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.086062
Layer 0 weight grad [0][0] = 15.535444


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 901
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.585353
Layer 0 weight grad [0][0] = 15.684313


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 902
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.102272
Layer 0 weight grad [0][0] = 15.481385


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 903
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.546867
Layer 0 weight grad [0][0] = 14.937277


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 904
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.101010
Layer 0 weight grad [0][0] = 14.864782


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 905
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.081459
Layer 0 weight grad [0][0] = 13.582164


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 906
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.581480
Layer 0 weight grad [0][0] = 15.826129


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 907
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.077582
Layer 0 weight grad [0][0] = 15.534145


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 908
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.267158
Layer 0 weight grad [0][0] = 14.955209


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 909
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.067567
Layer 0 weight grad [0][0] = 16.015066


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 910
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.067739
Layer 0 weight grad [0][0] = 14.739276


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 911
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.482512
Layer 0 weight grad [0][0] = 15.748935


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 912
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.067780
Layer 0 weight grad [0][0] = 17.185686


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 913
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.071691
Layer 0 weight grad [0][0] = 17.051304


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 914
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.257698
Layer 0 weight grad [0][0] = 16.243721


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 915
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.058091
Layer 0 weight grad [0][0] = 15.183651


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 916
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.580148
Layer 0 weight grad [0][0] = 15.363371


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 917
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.065712
Layer 0 weight grad [0][0] = 16.152103


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 918
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.462050
Layer 0 weight grad [0][0] = 16.674393


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 919
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.049598
Layer 0 weight grad [0][0] = 13.950156


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 920
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.054543
Layer 0 weight grad [0][0] = 16.906698


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 921
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.572167
Layer 0 weight grad [0][0] = 14.894234


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 922
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.553634
Layer 0 weight grad [0][0] = 15.384233


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 923
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.260701
Layer 0 weight grad [0][0] = 14.978275


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 924
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.567113
Layer 0 weight grad [0][0] = 14.424086


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 925
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.026114
Layer 0 weight grad [0][0] = 15.308203


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 926
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.082925
Layer 0 weight grad [0][0] = 16.053284


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 927
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.569162
Layer 0 weight grad [0][0] = 16.249821


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 928
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.060682
Layer 0 weight grad [0][0] = 15.895035


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 929
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.060914
Layer 0 weight grad [0][0] = 14.270297


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 930
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.102229
Layer 0 weight grad [0][0] = 14.529698


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 931
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.616689
Layer 0 weight grad [0][0] = 16.092419


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 932
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.082748
Layer 0 weight grad [0][0] = 16.745989


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 933
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.028163
Layer 0 weight grad [0][0] = 16.547798


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 934
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.071974
Layer 0 weight grad [0][0] = 15.414149


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 935
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.476892
Layer 0 weight grad [0][0] = 14.814075


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 936
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.073378
Layer 0 weight grad [0][0] = 15.091292


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 937
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.253746
Layer 0 weight grad [0][0] = 14.456227


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 938
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.094081
Layer 0 weight grad [0][0] = 15.653002


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 939
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.776174
Layer 0 weight grad [0][0] = 14.982724


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 940
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.728320
Layer 0 weight grad [0][0] = 16.408978


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 941
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.490939
Layer 0 weight grad [0][0] = 13.808474


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 942
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.059657
Layer 0 weight grad [0][0] = 15.579038


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 943
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.026357
Layer 0 weight grad [0][0] = 14.914229


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 944
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.079731
Layer 0 weight grad [0][0] = 14.803670


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 945
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.025519
Layer 0 weight grad [0][0] = 16.032522


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 946
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.669217
Layer 0 weight grad [0][0] = 15.554322


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 947
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.573767
Layer 0 weight grad [0][0] = 15.271463


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 948
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.072999
Layer 0 weight grad [0][0] = 15.362104


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 949
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.038677
Layer 0 weight grad [0][0] = 15.932556


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 950
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.080483
Layer 0 weight grad [0][0] = 15.745571


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 951
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.783975
Layer 0 weight grad [0][0] = 16.352922


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 952
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.331730
Layer 0 weight grad [0][0] = 15.231778


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 953
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.084440
Layer 0 weight grad [0][0] = 15.862520


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 954
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.599980
Layer 0 weight grad [0][0] = 16.339479


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 955
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.581589
Layer 0 weight grad [0][0] = 15.467496


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 956
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.650789
Layer 0 weight grad [0][0] = 14.506705


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 957
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.071869
Layer 0 weight grad [0][0] = 14.683390


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 958
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.037378
Layer 0 weight grad [0][0] = 15.920976


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 959
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.287207
Layer 0 weight grad [0][0] = 15.354266


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 960
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.613895
Layer 0 weight grad [0][0] = 14.281014


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 961
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.090334
Layer 0 weight grad [0][0] = 15.231431


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 962
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.094481
Layer 0 weight grad [0][0] = 18.019857


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 963
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.096365
Layer 0 weight grad [0][0] = 16.324495


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 964
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.097126
Layer 0 weight grad [0][0] = 15.343193


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 965
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.065234
Layer 0 weight grad [0][0] = 16.329870


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 966
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.289692
Layer 0 weight grad [0][0] = 14.866653


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 967
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.090399
Layer 0 weight grad [0][0] = 16.097542


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 968
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.723062
Layer 0 weight grad [0][0] = 15.423740


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 969
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.611892
Layer 0 weight grad [0][0] = 15.229818


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 970
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.451928
Layer 0 weight grad [0][0] = 15.222118


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 971
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.098513
Layer 0 weight grad [0][0] = 15.429406


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 972
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.103679
Layer 0 weight grad [0][0] = 16.284140


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 973
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.311287
Layer 0 weight grad [0][0] = 16.263453


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 974
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.111718
Layer 0 weight grad [0][0] = 15.926193


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 975
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.723264
Layer 0 weight grad [0][0] = 15.395162


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 976
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.090123
Layer 0 weight grad [0][0] = 15.742836


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 977
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.630961
Layer 0 weight grad [0][0] = 15.285563


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 978
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.703136
Layer 0 weight grad [0][0] = 16.128935


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 979
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.706869
Layer 0 weight grad [0][0] = 15.297105


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 980
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.135189
Layer 0 weight grad [0][0] = 15.531585


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 981
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.135787
Layer 0 weight grad [0][0] = 16.304350


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 982
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.655050
Layer 0 weight grad [0][0] = 14.604925


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 983
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.138179
Layer 0 weight grad [0][0] = 16.140684


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 984
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.102738
Layer 0 weight grad [0][0] = 15.886589


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 985
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.144536
Layer 0 weight grad [0][0] = 18.113668


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 986
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.120709
Layer 0 weight grad [0][0] = 15.242533


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 987
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.891430
Layer 0 weight grad [0][0] = 15.219876


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 988
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.765757
Layer 0 weight grad [0][0] = 15.391459


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 989
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.769286
Layer 0 weight grad [0][0] = 16.142101


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 990
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.915677
Layer 0 weight grad [0][0] = 15.549565


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 991
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.138590
Layer 0 weight grad [0][0] = 13.258086


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 992
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.343464
Layer 0 weight grad [0][0] = 15.729050


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 993
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.143979
Layer 0 weight grad [0][0] = 14.618594


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 994
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.444167
Layer 0 weight grad [0][0] = 15.056149


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 995
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.146057
Layer 0 weight grad [0][0] = 16.413473


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 996
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.147828
Layer 0 weight grad [0][0] = 14.429176


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 997
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.403998
Layer 0 weight grad [0][0] = 14.221829


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 998
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.404352
Layer 0 weight grad [0][0] = 13.876266


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 999
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.040161
Layer 0 weight grad [0][0] = 15.059426


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1000
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.020260
Layer 0 weight grad [0][0] = 16.017853


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1001
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.125190
Layer 0 weight grad [0][0] = 14.193910


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1002
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.914491
Layer 0 weight grad [0][0] = 16.115589


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1003
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.161321
Layer 0 weight grad [0][0] = 15.749924


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1004
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.157452
Layer 0 weight grad [0][0] = 15.280346


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1005
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.177006
Layer 0 weight grad [0][0] = 16.187746


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1006
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.157232
Layer 0 weight grad [0][0] = 16.397217


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1007
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.656732
Layer 0 weight grad [0][0] = 16.262165


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1008
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.653459
Layer 0 weight grad [0][0] = 15.363304


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1009
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.155755
Layer 0 weight grad [0][0] = 16.002604


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1010
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.123348
Layer 0 weight grad [0][0] = 14.553808


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1011
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.674926
Layer 0 weight grad [0][0] = 15.119845


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1012
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.124145
Layer 0 weight grad [0][0] = 15.020812


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1013
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.659415
Layer 0 weight grad [0][0] = 16.220732


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1014
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.157375
Layer 0 weight grad [0][0] = 15.472772


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1015
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.158082
Layer 0 weight grad [0][0] = 15.022891


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1016
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.169505
Layer 0 weight grad [0][0] = 17.102619


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1017
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.109319
Layer 0 weight grad [0][0] = 16.417261


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1018
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.149913
Layer 0 weight grad [0][0] = 16.819080


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1019
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.146008
Layer 0 weight grad [0][0] = 15.289725


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1020
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.095426
Layer 0 weight grad [0][0] = 15.368731


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1021
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.658686
Layer 0 weight grad [0][0] = 16.728745


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1022
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.369223
Layer 0 weight grad [0][0] = 14.766930


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1023
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.149672
Layer 0 weight grad [0][0] = 15.395481


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1024
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.766725
Layer 0 weight grad [0][0] = 16.131489


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1025
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.121844
Layer 0 weight grad [0][0] = 15.730898


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1026
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.678526
Layer 0 weight grad [0][0] = 17.736790


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1027
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.395854
Layer 0 weight grad [0][0] = 14.235687


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1028
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.134192
Layer 0 weight grad [0][0] = 16.846933


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1029
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.152115
Layer 0 weight grad [0][0] = 15.421666


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1030
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.857864
Layer 0 weight grad [0][0] = 15.581152


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1031
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.142948
Layer 0 weight grad [0][0] = 15.471981


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1032
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.370266
Layer 0 weight grad [0][0] = 15.548201


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 1033
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.697280
Layer 0 weight grad [0][0] = 14.778606


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1034
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.110645
Layer 0 weight grad [0][0] = 15.236021


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1035
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.152110
Layer 0 weight grad [0][0] = 15.560076


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1036
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.117751
Layer 0 weight grad [0][0] = 14.266972


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1037
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.229905
Layer 0 weight grad [0][0] = 14.756724


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1038
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.188328
Layer 0 weight grad [0][0] = 16.840380


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1039
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.342733
Layer 0 weight grad [0][0] = 15.176002


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1040
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.183094
Layer 0 weight grad [0][0] = 15.741185


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1041
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.183571
Layer 0 weight grad [0][0] = 15.974286


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1042
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.391174
Layer 0 weight grad [0][0] = 16.288439


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1043
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.209647
Layer 0 weight grad [0][0] = 16.171072


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1044
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.813322
Layer 0 weight grad [0][0] = 17.096056


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1045
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.191523
Layer 0 weight grad [0][0] = 15.423522


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1046
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.159516
Layer 0 weight grad [0][0] = 15.777679


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1047
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.715248
Layer 0 weight grad [0][0] = 15.553650


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1048
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.348319
Layer 0 weight grad [0][0] = 15.270668


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1049
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2.041738
Layer 0 weight grad [0][0] = 15.045956


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1050
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.727292
Layer 0 weight grad [0][0] = 15.237841


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1051
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.421965
Layer 0 weight grad [0][0] = 15.168425


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1052
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.222556
Layer 0 weight grad [0][0] = 15.647394


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1053
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.216851
Layer 0 weight grad [0][0] = 16.821728


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1054
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.193758
Layer 0 weight grad [0][0] = 15.817282


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1055
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.838875
Layer 0 weight grad [0][0] = 15.934092


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1056
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.712448
Layer 0 weight grad [0][0] = 16.598526


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1057
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.700565
Layer 0 weight grad [0][0] = 16.697493


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1058
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.796588
Layer 0 weight grad [0][0] = 15.017297


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1059
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.178476
Layer 0 weight grad [0][0] = 15.282112


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1060
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.180259
Layer 0 weight grad [0][0] = 15.558069


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1061
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.185490
Layer 0 weight grad [0][0] = 15.859402


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1062
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.705864
Layer 0 weight grad [0][0] = 16.053488


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1063
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.398348
Layer 0 weight grad [0][0] = 16.190344


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1064
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.486160
Layer 0 weight grad [0][0] = 16.696529


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 1065
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.187766
Layer 0 weight grad [0][0] = 14.818815


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1066
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.183848
Layer 0 weight grad [0][0] = 15.208048


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1067
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.183863
Layer 0 weight grad [0][0] = 16.413065


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1068
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.654927
Layer 0 weight grad [0][0] = 16.402828


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1069
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.130646
Layer 0 weight grad [0][0] = 16.810852


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1070
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.437583
Layer 0 weight grad [0][0] = 15.049452


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1071
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.466816
Layer 0 weight grad [0][0] = 15.783860


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1072
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.114203
Layer 0 weight grad [0][0] = 15.758938


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1073
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.154206
Layer 0 weight grad [0][0] = 15.529050


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1074
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.360109
Layer 0 weight grad [0][0] = 14.941778


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1075
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.033502
Layer 0 weight grad [0][0] = 14.417798


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1076
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.132641
Layer 0 weight grad [0][0] = 15.955104


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 1077
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.139971
Layer 0 weight grad [0][0] = 14.300373


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1078
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.359065
Layer 0 weight grad [0][0] = 15.275369


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1079
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.340488
Layer 0 weight grad [0][0] = 15.463704


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1080
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.180503
Layer 0 weight grad [0][0] = 15.652217


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1081
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.185148
Layer 0 weight grad [0][0] = 15.654684


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1082
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.143704
Layer 0 weight grad [0][0] = 15.202208


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1083
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.208177
Layer 0 weight grad [0][0] = 15.277477


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1084
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.378146
Layer 0 weight grad [0][0] = 16.345978


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1085
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.181272
Layer 0 weight grad [0][0] = 15.417213


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 1086
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.219048
Layer 0 weight grad [0][0] = 16.658995


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1087
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.366642
Layer 0 weight grad [0][0] = 15.455299


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1088
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.011749
Layer 0 weight grad [0][0] = 14.906605


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1089
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.229198
Layer 0 weight grad [0][0] = 17.049652


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1090
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.937114
Layer 0 weight grad [0][0] = 16.116976


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1091
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.207921
Layer 0 weight grad [0][0] = 15.487173


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1092
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.727634
Layer 0 weight grad [0][0] = 16.385452


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 1093
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.213691
Layer 0 weight grad [0][0] = 15.866738


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1094
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.213454
Layer 0 weight grad [0][0] = 16.434715


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 1095
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.191859
Layer 0 weight grad [0][0] = 16.539368


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1096
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.685588
Layer 0 weight grad [0][0] = 16.688446


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1097
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.187739
Layer 0 weight grad [0][0] = 15.744081


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1098
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.687106
Layer 0 weight grad [0][0] = 15.209533


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1099
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.165281
Layer 0 weight grad [0][0] = 14.846557


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 1100
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.166144
Layer 0 weight grad [0][0] = 14.863944


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1101
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.210405
Layer 0 weight grad [0][0] = 17.143864


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1102
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.159787
Layer 0 weight grad [0][0] = 16.426165


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1103
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.160568
Layer 0 weight grad [0][0] = 15.972491


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1104
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.663052
Layer 0 weight grad [0][0] = 15.463103


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1105
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.125436
Layer 0 weight grad [0][0] = 16.312605


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1106
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000004 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.162037
Layer 0 weight grad [0][0] = 14.608093


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1107
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.106835
Layer 0 weight grad [0][0] = 15.259946


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1108
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.111661
Layer 0 weight grad [0][0] = 15.526546


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1109
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.650664
Layer 0 weight grad [0][0] = 15.376691


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1110
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.149280
Layer 0 weight grad [0][0] = 16.178431


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1111
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.149085
Layer 0 weight grad [0][0] = 15.319348


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1112
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.437683
Layer 0 weight grad [0][0] = 15.177085


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1113
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.873082
Layer 0 weight grad [0][0] = 15.404290


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1114
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.175805
Layer 0 weight grad [0][0] = 15.963213


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1115
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.860494
Layer 0 weight grad [0][0] = 15.564586


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1116
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.392539
Layer 0 weight grad [0][0] = 15.182886


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1117
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.121146
Layer 0 weight grad [0][0] = 15.237428


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1118
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.866295
Layer 0 weight grad [0][0] = 15.884332


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1119
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.161917
Layer 0 weight grad [0][0] = 15.330707


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1120
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.162205
Layer 0 weight grad [0][0] = 16.086691


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1121
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.129742
Layer 0 weight grad [0][0] = 15.824171


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1122
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.660969
Layer 0 weight grad [0][0] = 16.126949


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1123
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.150595
Layer 0 weight grad [0][0] = 14.984408


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1124
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.389448
Layer 0 weight grad [0][0] = 14.891521


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1125
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.140393
Layer 0 weight grad [0][0] = 15.149073


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1126
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.367597
Layer 0 weight grad [0][0] = 15.482372


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1127
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.646899
Layer 0 weight grad [0][0] = 16.909845


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1128
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.145786
Layer 0 weight grad [0][0] = 15.182374


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1129
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.649519
Layer 0 weight grad [0][0] = 15.448635


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1130
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.168202
Layer 0 weight grad [0][0] = 15.327947


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1131
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.149331
Layer 0 weight grad [0][0] = 15.634824


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1132
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.149422
Layer 0 weight grad [0][0] = 15.838046


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1133
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.150650
Layer 0 weight grad [0][0] = 15.421906


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1134
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.642656
Layer 0 weight grad [0][0] = 16.467113


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1135
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.347338
Layer 0 weight grad [0][0] = 16.395716


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1136
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.607074
Layer 0 weight grad [0][0] = 16.654587


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1137
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.832642
Layer 0 weight grad [0][0] = 15.572900


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1138
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.120822
Layer 0 weight grad [0][0] = 15.734342


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1139
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.366902
Layer 0 weight grad [0][0] = 15.376621


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1140
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.167170
Layer 0 weight grad [0][0] = 14.972023


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1141
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.186511
Layer 0 weight grad [0][0] = 17.465313


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1142
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.443223
Layer 0 weight grad [0][0] = 14.770560


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1143
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.146678
Layer 0 weight grad [0][0] = 16.111254


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1144
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.597716
Layer 0 weight grad [0][0] = 15.741021


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1145
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.117172
Layer 0 weight grad [0][0] = 16.357979


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1146
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.121648
Layer 0 weight grad [0][0] = 15.917211


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1147
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.653148
Layer 0 weight grad [0][0] = 15.910779


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1148
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.455292
Layer 0 weight grad [0][0] = 14.874536


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1149
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.889311
Layer 0 weight grad [0][0] = 15.786243


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1150
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.841263
Layer 0 weight grad [0][0] = 15.181628


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1151
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.156904
Layer 0 weight grad [0][0] = 16.353201


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1152
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.138531
Layer 0 weight grad [0][0] = 15.206507


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1153
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.936982
Layer 0 weight grad [0][0] = 16.199247


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1154
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.142669
Layer 0 weight grad [0][0] = 14.654552


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1155
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.134375
Layer 0 weight grad [0][0] = 15.639043


Training loss: 2.302585
Training accuracy: 0.375000

epoch: 1156
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.115911
Layer 0 weight grad [0][0] = 16.232368


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1157
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.631658
Layer 0 weight grad [0][0] = 16.663052


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1158
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.091418
Layer 0 weight grad [0][0] = 15.956860


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1159
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.066354
Layer 0 weight grad [0][0] = 16.949492


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1160
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.566999
Layer 0 weight grad [0][0] = 15.301310


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1161
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.366503
Layer 0 weight grad [0][0] = 15.757174


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1162
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.045189
Layer 0 weight grad [0][0] = 15.357820


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1163
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.104393
Layer 0 weight grad [0][0] = 16.185560


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1164
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.085570
Layer 0 weight grad [0][0] = 15.132355


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1165
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.604328
Layer 0 weight grad [0][0] = 15.925293


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1166
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.090720
Layer 0 weight grad [0][0] = 16.523130


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1167
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.065151
Layer 0 weight grad [0][0] = 15.485105


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1168
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.084090
Layer 0 weight grad [0][0] = 16.317663


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1169
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.028159
Layer 0 weight grad [0][0] = 17.346567


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1170
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.246949
Layer 0 weight grad [0][0] = 15.442579


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1171
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.861843
Layer 0 weight grad [0][0] = 15.322488


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1172
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.052280
Layer 0 weight grad [0][0] = 16.649282


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1173
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.052043
Layer 0 weight grad [0][0] = 17.184504


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1174
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.222963
Layer 0 weight grad [0][0] = 15.768839


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1175
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.895494
Layer 0 weight grad [0][0] = 15.948698


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1176
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.568937
Layer 0 weight grad [0][0] = 15.276957


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1177
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.033638
Layer 0 weight grad [0][0] = 16.061985


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1178
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.074755
Layer 0 weight grad [0][0] = 15.657831


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1179
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.092268
Layer 0 weight grad [0][0] = 16.802334


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1180
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.045138
Layer 0 weight grad [0][0] = 15.053551


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1181
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.009979
Layer 0 weight grad [0][0] = 13.740138


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1182
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.054162
Layer 0 weight grad [0][0] = 16.169888


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1183
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.055104
Layer 0 weight grad [0][0] = 16.047699


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1184
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.050944
Layer 0 weight grad [0][0] = 15.074672


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1185
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.014737
Layer 0 weight grad [0][0] = 16.179510


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1186
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.499808
Layer 0 weight grad [0][0] = 15.950603


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1187
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.049767
Layer 0 weight grad [0][0] = 15.368161


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1188
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.277986
Layer 0 weight grad [0][0] = 17.755829


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1189
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.036533
Layer 0 weight grad [0][0] = 15.981387


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1190
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.875445
Layer 0 weight grad [0][0] = 15.591743


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1191
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.534277
Layer 0 weight grad [0][0] = 16.333786


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1192
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.050336
Layer 0 weight grad [0][0] = 16.058094


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1193
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.812791
Layer 0 weight grad [0][0] = 16.843573


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1194
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.506754
Layer 0 weight grad [0][0] = 15.605906


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1195
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.031296
Layer 0 weight grad [0][0] = 13.451981


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1196
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.539134
Layer 0 weight grad [0][0] = 15.066425


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1197
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.010020
Layer 0 weight grad [0][0] = 15.258010


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1198
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.027219
Layer 0 weight grad [0][0] = 16.984407


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1199
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.658147
Layer 0 weight grad [0][0] = 16.699347


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1200
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.016412
Layer 0 weight grad [0][0] = 15.851477


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1201
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.416673
Layer 0 weight grad [0][0] = 15.614400


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1202
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.023520
Layer 0 weight grad [0][0] = 18.755476


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1203
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.023539
Layer 0 weight grad [0][0] = 15.521811


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1204
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.180959
Layer 0 weight grad [0][0] = 14.780289


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1205
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.185686
Layer 0 weight grad [0][0] = 15.835974


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1206
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.051518
Layer 0 weight grad [0][0] = 17.321617


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1207
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.598053
Layer 0 weight grad [0][0] = 15.965499


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 1208
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.045571
Layer 0 weight grad [0][0] = 15.863602


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1209
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.011071
Layer 0 weight grad [0][0] = 15.092529


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1210
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.010502
Layer 0 weight grad [0][0] = 15.879110


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1211
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.008291
Layer 0 weight grad [0][0] = 15.786853


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1212
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.196111
Layer 0 weight grad [0][0] = 15.461834


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1213
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.285160
Layer 0 weight grad [0][0] = 15.560673


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1214
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.231040
Layer 0 weight grad [0][0] = 17.103565


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1215
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.029814
Layer 0 weight grad [0][0] = 14.724301


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1216
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.526348
Layer 0 weight grad [0][0] = 15.510176


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1217
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.245826
Layer 0 weight grad [0][0] = 15.065058


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1218
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.004131
Layer 0 weight grad [0][0] = 16.655268


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1219
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.023809
Layer 0 weight grad [0][0] = 14.904558


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1220
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.025972
Layer 0 weight grad [0][0] = 16.460371


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1221
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.000917
Layer 0 weight grad [0][0] = 16.001204


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1222
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.015953
Layer 0 weight grad [0][0] = 16.419603


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1223
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.555987
Layer 0 weight grad [0][0] = 14.507871


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1224
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.010550
Layer 0 weight grad [0][0] = 16.108374


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1225
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.297554
Layer 0 weight grad [0][0] = 16.201447


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1226
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.016423
Layer 0 weight grad [0][0] = 15.946970


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1227
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.034289
Layer 0 weight grad [0][0] = 18.225784


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1228
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.049912
Layer 0 weight grad [0][0] = 16.337656


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1229
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.683208
Layer 0 weight grad [0][0] = 15.669188


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1230
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.675485
Layer 0 weight grad [0][0] = 15.510435


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1231
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.007061
Layer 0 weight grad [0][0] = 15.594083


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1232
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.507823
Layer 0 weight grad [0][0] = 14.222863


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1233
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.624483
Layer 0 weight grad [0][0] = 15.513208


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1234
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.437597
Layer 0 weight grad [0][0] = 14.928889


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1235
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.025365
Layer 0 weight grad [0][0] = 16.276285


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1236
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.008986
Layer 0 weight grad [0][0] = 16.767002


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1237
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.001657
Layer 0 weight grad [0][0] = 15.407087


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 1238
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.003804
Layer 0 weight grad [0][0] = 17.645706


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1239
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.618849
Layer 0 weight grad [0][0] = 15.552359


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1240
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.385126
Layer 0 weight grad [0][0] = 15.427490


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1241
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.025657
Layer 0 weight grad [0][0] = 17.138075


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1242
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.026299
Layer 0 weight grad [0][0] = 15.433825


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1243
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.311309
Layer 0 weight grad [0][0] = 16.625948


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1244
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.574897
Layer 0 weight grad [0][0] = 14.743855


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 1245
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.788584
Layer 0 weight grad [0][0] = 14.858241


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1246
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.061370
Layer 0 weight grad [0][0] = 15.212169


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1247
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.018765
Layer 0 weight grad [0][0] = 15.324020


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1248
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.016132
Layer 0 weight grad [0][0] = 16.304276


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1249
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.630078
Layer 0 weight grad [0][0] = 15.238020


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1250
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.401057
Layer 0 weight grad [0][0] = 15.389824


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 1251
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.396579
Layer 0 weight grad [0][0] = 17.023235


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1252
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.568262
Layer 0 weight grad [0][0] = 16.362164


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1253
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.020490
Layer 0 weight grad [0][0] = 15.973843


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1254
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.021274
Layer 0 weight grad [0][0] = 16.314573


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1255
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.059605
Layer 0 weight grad [0][0] = 17.500359


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1256
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.081614
Layer 0 weight grad [0][0] = 14.146145


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1257
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.474918
Layer 0 weight grad [0][0] = 16.627895


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1258
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.023238
Layer 0 weight grad [0][0] = 15.911886


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1259
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.041656
Layer 0 weight grad [0][0] = 16.878317


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1260
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.193182
Layer 0 weight grad [0][0] = 15.431817


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 1261
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.165158
Layer 0 weight grad [0][0] = 15.871708


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1262
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.162744
Layer 0 weight grad [0][0] = 15.230916


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1263
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.477123
Layer 0 weight grad [0][0] = 16.471291


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1264
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.756437
Layer 0 weight grad [0][0] = 15.584291


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1265
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.507353
Layer 0 weight grad [0][0] = 15.225729


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1266
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.800689
Layer 0 weight grad [0][0] = 15.879769


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1267
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.016953
Layer 0 weight grad [0][0] = 15.792202


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1268
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.508525
Layer 0 weight grad [0][0] = 15.484596


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1269
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.502818
Layer 0 weight grad [0][0] = 17.886160


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1270
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.039782
Layer 0 weight grad [0][0] = 16.428783


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1271
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.475091
Layer 0 weight grad [0][0] = 15.452215


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1272
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.196845
Layer 0 weight grad [0][0] = 16.294306


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1273
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.197608
Layer 0 weight grad [0][0] = 15.331493


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1274
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.176388
Layer 0 weight grad [0][0] = 15.429380


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1275
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.710275
Layer 0 weight grad [0][0] = 16.142633


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1276
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.022486
Layer 0 weight grad [0][0] = 13.881495


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1277
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.928424
Layer 0 weight grad [0][0] = 15.689984


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1278
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.539421
Layer 0 weight grad [0][0] = 14.722009


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1279
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.011290
Layer 0 weight grad [0][0] = 15.189325


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1280
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.881685
Layer 0 weight grad [0][0] = 14.917053


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1281
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.547270
Layer 0 weight grad [0][0] = 16.012041


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1282
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.030466
Layer 0 weight grad [0][0] = 16.121893


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1283
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.531268
Layer 0 weight grad [0][0] = 15.879313


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1284
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.030268
Layer 0 weight grad [0][0] = 17.057199


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1285
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.691242
Layer 0 weight grad [0][0] = 14.203436


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1286
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.549697
Layer 0 weight grad [0][0] = 15.218091


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1287
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.002855
Layer 0 weight grad [0][0] = 16.012327


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1288
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.028956
Layer 0 weight grad [0][0] = 15.853608


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1289
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.048779
Layer 0 weight grad [0][0] = 14.962938


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1290
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.029541
Layer 0 weight grad [0][0] = 15.690501


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1291
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.545678
Layer 0 weight grad [0][0] = 14.852323


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1292
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.582413
Layer 0 weight grad [0][0] = 15.504310


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1293
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.066665
Layer 0 weight grad [0][0] = 15.891211


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1294
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.085795
Layer 0 weight grad [0][0] = 16.131578


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1295
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.564185
Layer 0 weight grad [0][0] = 16.110857


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1296
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.559814
Layer 0 weight grad [0][0] = 15.192842


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1297
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.107977
Layer 0 weight grad [0][0] = 16.120146


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1298
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.256937
Layer 0 weight grad [0][0] = 16.275850


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1299
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.884433
Layer 0 weight grad [0][0] = 15.836329


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1300
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.057608
Layer 0 weight grad [0][0] = 15.554133


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1301
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.060658
Layer 0 weight grad [0][0] = 16.319435


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1302
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.099803
Layer 0 weight grad [0][0] = 15.455894


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1303
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.449275
Layer 0 weight grad [0][0] = 16.677774


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 1304
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.062456
Layer 0 weight grad [0][0] = 16.273336


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1305
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2.286130
Layer 0 weight grad [0][0] = 13.764931


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1306
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.103367
Layer 0 weight grad [0][0] = 15.556695


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1307
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.102514
Layer 0 weight grad [0][0] = 15.913958


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 1308
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.608604
Layer 0 weight grad [0][0] = 14.806893


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1309
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.066382
Layer 0 weight grad [0][0] = 15.320341


Training loss: 2.302585
Training accuracy: 0.375000

epoch: 1310
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.062680
Layer 0 weight grad [0][0] = 15.545759


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1311
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.599265
Layer 0 weight grad [0][0] = 14.581724


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1312
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.095712
Layer 0 weight grad [0][0] = 15.539643


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1313
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.592758
Layer 0 weight grad [0][0] = 13.532222


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1314
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.105641
Layer 0 weight grad [0][0] = 15.603538


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1315
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.084003
Layer 0 weight grad [0][0] = 15.217045


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1316
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.992989
Layer 0 weight grad [0][0] = 15.501609


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1317
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.596633
Layer 0 weight grad [0][0] = 16.063257


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1318
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.591507
Layer 0 weight grad [0][0] = 15.414964


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1319
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.256846
Layer 0 weight grad [0][0] = 15.702314


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1320
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.093778
Layer 0 weight grad [0][0] = 15.488286


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1321
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.091923
Layer 0 weight grad [0][0] = 14.734702


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1322
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.608660
Layer 0 weight grad [0][0] = 16.496387


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1323
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.093917
Layer 0 weight grad [0][0] = 16.023794


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 1324
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.455049
Layer 0 weight grad [0][0] = 16.353380


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1325
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.091659
Layer 0 weight grad [0][0] = 15.561722


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1326
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.458493
Layer 0 weight grad [0][0] = 14.901694


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1327
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.587497
Layer 0 weight grad [0][0] = 15.789731


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1328
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.092010
Layer 0 weight grad [0][0] = 14.525495


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1329
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.560115
Layer 0 weight grad [0][0] = 15.483046


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1330
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.054574
Layer 0 weight grad [0][0] = 15.340154


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1331
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.473896
Layer 0 weight grad [0][0] = 15.290423


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1332
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.269807
Layer 0 weight grad [0][0] = 16.018553


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1333
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.066727
Layer 0 weight grad [0][0] = 16.965834


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1334
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.562852
Layer 0 weight grad [0][0] = 16.856209


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1335
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.499870
Layer 0 weight grad [0][0] = 15.638897


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1336
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.749145
Layer 0 weight grad [0][0] = 17.759682


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1337
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.219935
Layer 0 weight grad [0][0] = 15.036337


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1338
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.098197
Layer 0 weight grad [0][0] = 16.315489


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1339
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.227536
Layer 0 weight grad [0][0] = 15.577674


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1340
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.142934
Layer 0 weight grad [0][0] = 15.862388


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1341
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.493875
Layer 0 weight grad [0][0] = 14.243593


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1342
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.585755
Layer 0 weight grad [0][0] = 15.759401


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1343
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.172483
Layer 0 weight grad [0][0] = 14.690527


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1344
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.119009
Layer 0 weight grad [0][0] = 15.100119


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1345
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.162766
Layer 0 weight grad [0][0] = 15.635448


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1346
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.997202
Layer 0 weight grad [0][0] = 14.840194


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1347
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.160127
Layer 0 weight grad [0][0] = 16.009645


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1348
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.296910
Layer 0 weight grad [0][0] = 14.635383


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1349
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.340889
Layer 0 weight grad [0][0] = 14.893723


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1350
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.326712
Layer 0 weight grad [0][0] = 14.775573


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1351
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.200032
Layer 0 weight grad [0][0] = 15.483120


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1352
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.353442
Layer 0 weight grad [0][0] = 15.602996


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1353
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.692210
Layer 0 weight grad [0][0] = 15.724113


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 1354
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.395571
Layer 0 weight grad [0][0] = 14.228869


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1355
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.358103
Layer 0 weight grad [0][0] = 15.899947


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1356
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.703730
Layer 0 weight grad [0][0] = 15.415890


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1357
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.056948
Layer 0 weight grad [0][0] = 13.358899


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1358
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.200808
Layer 0 weight grad [0][0] = 16.751036


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1359
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.198622
Layer 0 weight grad [0][0] = 16.135393


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1360
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.147378
Layer 0 weight grad [0][0] = 17.910610


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1361
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.397226
Layer 0 weight grad [0][0] = 16.289450


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1362
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.399802
Layer 0 weight grad [0][0] = 14.859813


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1363
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.711802
Layer 0 weight grad [0][0] = 15.883617


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1364
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.157111
Layer 0 weight grad [0][0] = 15.760551


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1365
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.195424
Layer 0 weight grad [0][0] = 14.909187


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1366
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.935802
Layer 0 weight grad [0][0] = 15.361007


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1367
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.204519
Layer 0 weight grad [0][0] = 15.732885


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1368
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.884232
Layer 0 weight grad [0][0] = 16.621191


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1369
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.727698
Layer 0 weight grad [0][0] = 15.256363


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1370
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.729512
Layer 0 weight grad [0][0] = 14.863622


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1371
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.178818
Layer 0 weight grad [0][0] = 15.623409


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1372
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.217130
Layer 0 weight grad [0][0] = 15.930807


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1373
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.701008
Layer 0 weight grad [0][0] = 16.281778


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1374
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.694518
Layer 0 weight grad [0][0] = 15.267588


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1375
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.191446
Layer 0 weight grad [0][0] = 17.037521


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1376
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.135173
Layer 0 weight grad [0][0] = 15.834225


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1377
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.190503
Layer 0 weight grad [0][0] = 17.059076


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1378
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.169515
Layer 0 weight grad [0][0] = 14.770459


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1379
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.117234
Layer 0 weight grad [0][0] = 15.270988


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1380
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.162334
Layer 0 weight grad [0][0] = 16.092304


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1381
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.161384
Layer 0 weight grad [0][0] = 15.340310


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1382
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.176647
Layer 0 weight grad [0][0] = 18.692419


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1383
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.121416
Layer 0 weight grad [0][0] = 15.237416


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1384
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.120424
Layer 0 weight grad [0][0] = 16.658094


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1385
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.085949
Layer 0 weight grad [0][0] = 15.124847


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1386
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.587658
Layer 0 weight grad [0][0] = 17.091713


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1387
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.101958
Layer 0 weight grad [0][0] = 15.302714


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1388
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.031393
Layer 0 weight grad [0][0] = 16.304901


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1389
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.603390
Layer 0 weight grad [0][0] = 16.227255


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1390
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.105069
Layer 0 weight grad [0][0] = 15.565150


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1391
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.049919
Layer 0 weight grad [0][0] = 15.812852


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1392
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.055833
Layer 0 weight grad [0][0] = 15.526452


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1393
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.498021
Layer 0 weight grad [0][0] = 15.958737


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 1394
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.090007
Layer 0 weight grad [0][0] = 15.174067


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1395
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.089412
Layer 0 weight grad [0][0] = 15.786523


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1396
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.091045
Layer 0 weight grad [0][0] = 15.236661


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1397
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.054842
Layer 0 weight grad [0][0] = 15.607927


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1398
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.094359
Layer 0 weight grad [0][0] = 15.723148


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 1399
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.537471
Layer 0 weight grad [0][0] = 15.162297


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1400
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2.346782
Layer 0 weight grad [0][0] = 14.424658


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 1401
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.593793
Layer 0 weight grad [0][0] = 15.514983


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 1402
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.194820
Layer 0 weight grad [0][0] = 15.993288


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1403
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.194300
Layer 0 weight grad [0][0] = 16.905088


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1404
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.688047
Layer 0 weight grad [0][0] = 15.705622


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1405
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.172434
Layer 0 weight grad [0][0] = 15.688837


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1406
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.188119
Layer 0 weight grad [0][0] = 15.413100


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1407
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.052170
Layer 0 weight grad [0][0] = 15.025899


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1408
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2.104746
Layer 0 weight grad [0][0] = 15.890746


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1409
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.199689
Layer 0 weight grad [0][0] = 16.668451


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1410
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.174257
Layer 0 weight grad [0][0] = 18.103212


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1411
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.141712
Layer 0 weight grad [0][0] = 16.410076


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1412
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.640536
Layer 0 weight grad [0][0] = 15.831210


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1413
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.636734
Layer 0 weight grad [0][0] = 18.435860


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1414
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.138281
Layer 0 weight grad [0][0] = 15.419354


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1415
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.676274
Layer 0 weight grad [0][0] = 15.430970


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1416
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.658617
Layer 0 weight grad [0][0] = 15.062556


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1417
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.173743
Layer 0 weight grad [0][0] = 15.468856


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1418
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.487065
Layer 0 weight grad [0][0] = 16.291817


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1419
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.915784
Layer 0 weight grad [0][0] = 14.959164


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1420
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.788054
Layer 0 weight grad [0][0] = 15.085814


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1421
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.211474
Layer 0 weight grad [0][0] = 14.901400


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 1422
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.479968
Layer 0 weight grad [0][0] = 16.077513


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1423
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.306383
Layer 0 weight grad [0][0] = 14.692603


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1424
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.206594
Layer 0 weight grad [0][0] = 14.661323


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1425
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.022251
Layer 0 weight grad [0][0] = 15.339521


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1426
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.738795
Layer 0 weight grad [0][0] = 15.600919


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1427
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.346858
Layer 0 weight grad [0][0] = 15.537348


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1428
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.785634
Layer 0 weight grad [0][0] = 15.710211


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1429
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.319103
Layer 0 weight grad [0][0] = 13.891212


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1430
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.229776
Layer 0 weight grad [0][0] = 16.996429


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1431
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.703725
Layer 0 weight grad [0][0] = 15.132607


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1432
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.718810
Layer 0 weight grad [0][0] = 15.978693


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1433
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.202965
Layer 0 weight grad [0][0] = 17.371456


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1434
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.413674
Layer 0 weight grad [0][0] = 14.653530


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1435
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.139364
Layer 0 weight grad [0][0] = 16.079493


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 1436
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.295974
Layer 0 weight grad [0][0] = 16.448809


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1437
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.796263
Layer 0 weight grad [0][0] = 15.831468


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1438
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.247083
Layer 0 weight grad [0][0] = 15.735673


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1439
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.307015
Layer 0 weight grad [0][0] = 14.926344


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1440
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.220886
Layer 0 weight grad [0][0] = 15.451150


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1441
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.220143
Layer 0 weight grad [0][0] = 15.481433


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1442
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.219440
Layer 0 weight grad [0][0] = 14.078291


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1443
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.326580
Layer 0 weight grad [0][0] = 14.843972


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1444
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.765002
Layer 0 weight grad [0][0] = 14.087492


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1445
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.929926
Layer 0 weight grad [0][0] = 15.237152


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1446
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.213899
Layer 0 weight grad [0][0] = 16.207006


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1447
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.206232
Layer 0 weight grad [0][0] = 15.658980


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1448
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.171248
Layer 0 weight grad [0][0] = 14.944666


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1449
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.650068
Layer 0 weight grad [0][0] = 16.442722


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1450
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.121713
Layer 0 weight grad [0][0] = 14.772825


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1451
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.122408
Layer 0 weight grad [0][0] = 13.929542


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1452
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.425374
Layer 0 weight grad [0][0] = 14.761439


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1453
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.124018
Layer 0 weight grad [0][0] = 14.748224


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1454
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.422455
Layer 0 weight grad [0][0] = 14.919354


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1455
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.127028
Layer 0 weight grad [0][0] = 15.240885


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1456
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.131380
Layer 0 weight grad [0][0] = 16.920004


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1457
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.697799
Layer 0 weight grad [0][0] = 15.742136


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1458
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.117944
Layer 0 weight grad [0][0] = 15.526731


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1459
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.363140
Layer 0 weight grad [0][0] = 16.408981


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 1460
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.126140
Layer 0 weight grad [0][0] = 13.764634


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1461
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.166338
Layer 0 weight grad [0][0] = 17.152111


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1462
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.650155
Layer 0 weight grad [0][0] = 15.565672


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1463
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.134962
Layer 0 weight grad [0][0] = 15.843642


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1464
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.911759
Layer 0 weight grad [0][0] = 16.493378


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1465
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.153657
Layer 0 weight grad [0][0] = 15.241681


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1466
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.249013
Layer 0 weight grad [0][0] = 17.477890


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1467
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.806531
Layer 0 weight grad [0][0] = 15.250577


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1468
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.382988
Layer 0 weight grad [0][0] = 16.300570


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1469
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.222809
Layer 0 weight grad [0][0] = 14.808074


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 1470
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.690328
Layer 0 weight grad [0][0] = 14.562287


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1471
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.702572
Layer 0 weight grad [0][0] = 15.809748


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1472
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.688031
Layer 0 weight grad [0][0] = 15.168574


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1473
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.685874
Layer 0 weight grad [0][0] = 15.936334


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1474
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.153518
Layer 0 weight grad [0][0] = 15.790172


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1475
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.117213
Layer 0 weight grad [0][0] = 17.031948


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1476
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000004 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.391495
Layer 0 weight grad [0][0] = 15.221244


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1477
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.176585
Layer 0 weight grad [0][0] = 16.878321


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1478
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.673240
Layer 0 weight grad [0][0] = 14.473402


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 1479
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.673460
Layer 0 weight grad [0][0] = 14.703485


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1480
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000021 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.160204
Layer 0 weight grad [0][0] = 16.413298


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1481
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.627452
Layer 0 weight grad [0][0] = 14.732512


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1482
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.546843
Layer 0 weight grad [0][0] = 18.520775


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1483
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.169742
Layer 0 weight grad [0][0] = 17.106256


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1484
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.407399
Layer 0 weight grad [0][0] = 15.888852


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1485
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.309501
Layer 0 weight grad [0][0] = 16.803942


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1486
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.488599
Layer 0 weight grad [0][0] = 14.824408


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1487
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.065579
Layer 0 weight grad [0][0] = 15.164363


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1488
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.625732
Layer 0 weight grad [0][0] = 15.602859


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1489
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.110973
Layer 0 weight grad [0][0] = 15.867529


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1490
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.033977
Layer 0 weight grad [0][0] = 16.015581


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1491
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.101069
Layer 0 weight grad [0][0] = 15.650975


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1492
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.101998
Layer 0 weight grad [0][0] = 14.596564


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1493
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.392397
Layer 0 weight grad [0][0] = 17.167562


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1494
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.100177
Layer 0 weight grad [0][0] = 16.717989


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1495
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.103342
Layer 0 weight grad [0][0] = 16.921457


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1496
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.068300
Layer 0 weight grad [0][0] = 15.392679


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1497
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.370729
Layer 0 weight grad [0][0] = 15.259946


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1498
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.388840
Layer 0 weight grad [0][0] = 14.867244


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1499
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.660481
Layer 0 weight grad [0][0] = 16.431391


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1500
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.363796
Layer 0 weight grad [0][0] = 15.585254


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1501
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.663659
Layer 0 weight grad [0][0] = 15.572721


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1502
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.400364
Layer 0 weight grad [0][0] = 15.212608


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1503
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.353824
Layer 0 weight grad [0][0] = 16.434572


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1504
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.103318
Layer 0 weight grad [0][0] = 13.521259


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1505
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.151590
Layer 0 weight grad [0][0] = 16.019516


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1506
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.142918
Layer 0 weight grad [0][0] = 14.784925


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1507
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.124717
Layer 0 weight grad [0][0] = 15.529549


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1508
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.606685
Layer 0 weight grad [0][0] = 15.487730


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1509
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.137009
Layer 0 weight grad [0][0] = 16.786455


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1510
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.141961
Layer 0 weight grad [0][0] = 13.708859


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 1511
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.194492
Layer 0 weight grad [0][0] = 15.445306


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1512
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.344405
Layer 0 weight grad [0][0] = 15.395679


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1513
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.213225
Layer 0 weight grad [0][0] = 16.319357


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1514
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.266093
Layer 0 weight grad [0][0] = 14.295737


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1515
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.170243
Layer 0 weight grad [0][0] = 16.305847


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1516
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.415380
Layer 0 weight grad [0][0] = 15.911682


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1517
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.138781
Layer 0 weight grad [0][0] = 15.405015


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1518
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.672299
Layer 0 weight grad [0][0] = 15.860095


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1519
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.188673
Layer 0 weight grad [0][0] = 17.555481


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1520
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.472302
Layer 0 weight grad [0][0] = 16.117073


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1521
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.693068
Layer 0 weight grad [0][0] = 16.049427


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1522
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.194626
Layer 0 weight grad [0][0] = 15.536944


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1523
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.194092
Layer 0 weight grad [0][0] = 15.214761


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1524
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.692198
Layer 0 weight grad [0][0] = 15.536145


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1525
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.154301
Layer 0 weight grad [0][0] = 15.296247


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1526
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.692738
Layer 0 weight grad [0][0] = 15.062430


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1527
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.671265
Layer 0 weight grad [0][0] = 15.999194


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1528
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.381025
Layer 0 weight grad [0][0] = 15.361652


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1529
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.394919
Layer 0 weight grad [0][0] = 15.220258


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1530
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.670917
Layer 0 weight grad [0][0] = 15.424725


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1531
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.156580
Layer 0 weight grad [0][0] = 15.301060


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1532
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.158185
Layer 0 weight grad [0][0] = 15.113100


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1533
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.063507
Layer 0 weight grad [0][0] = 16.062944


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1534
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.338818
Layer 0 weight grad [0][0] = 15.920646


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1535
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.136733
Layer 0 weight grad [0][0] = 15.580512


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1536
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.084093
Layer 0 weight grad [0][0] = 15.560905


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1537
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.106464
Layer 0 weight grad [0][0] = 16.566504


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 1538
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.444020
Layer 0 weight grad [0][0] = 16.052061


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 1539
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.106385
Layer 0 weight grad [0][0] = 14.528652


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1540
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.124546
Layer 0 weight grad [0][0] = 16.732042


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1541
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.621786
Layer 0 weight grad [0][0] = 16.565439


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1542
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.057724
Layer 0 weight grad [0][0] = 13.747622


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1543
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.378480
Layer 0 weight grad [0][0] = 15.653237


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1544
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.091326
Layer 0 weight grad [0][0] = 15.352698


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1545
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.794517
Layer 0 weight grad [0][0] = 14.687783


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1546
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.483874
Layer 0 weight grad [0][0] = 15.352053


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1547
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.084816
Layer 0 weight grad [0][0] = 17.303459


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1548
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.853656
Layer 0 weight grad [0][0] = 15.510216


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1549
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.075234
Layer 0 weight grad [0][0] = 15.147538


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1550
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.041242
Layer 0 weight grad [0][0] = 16.423948


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1551
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.099644
Layer 0 weight grad [0][0] = 15.939344


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1552
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.596639
Layer 0 weight grad [0][0] = 15.376222


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1553
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.081963
Layer 0 weight grad [0][0] = 15.203883


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1554
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.048127
Layer 0 weight grad [0][0] = 14.891567


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1555
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.591479
Layer 0 weight grad [0][0] = 15.979755


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1556
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.108986
Layer 0 weight grad [0][0] = 17.201384


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1557
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.295276
Layer 0 weight grad [0][0] = 16.736666


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1558
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.453994
Layer 0 weight grad [0][0] = 14.837386


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1559
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.060849
Layer 0 weight grad [0][0] = 15.513053


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1560
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.065722
Layer 0 weight grad [0][0] = 16.807051


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1561
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.033932
Layer 0 weight grad [0][0] = 17.198700


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1562
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.075576
Layer 0 weight grad [0][0] = 15.820856


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1563
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.079547
Layer 0 weight grad [0][0] = 16.519077


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 1564
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.719377
Layer 0 weight grad [0][0] = 14.970899


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1565
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.072150
Layer 0 weight grad [0][0] = 14.077100


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1566
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.283280
Layer 0 weight grad [0][0] = 16.087278


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 1567
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.936365
Layer 0 weight grad [0][0] = 15.325140


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1568
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.018647
Layer 0 weight grad [0][0] = 16.364153


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 1569
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2.196788
Layer 0 weight grad [0][0] = 16.087894


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1570
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.781061
Layer 0 weight grad [0][0] = 15.294434


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1571
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2.456950
Layer 0 weight grad [0][0] = 14.939917


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1572
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.670147
Layer 0 weight grad [0][0] = 15.123972


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1573
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2.557766
Layer 0 weight grad [0][0] = 15.615077


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 1574
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.723769
Layer 0 weight grad [0][0] = 14.974907


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1575
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.729525
Layer 0 weight grad [0][0] = 16.429960


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1576
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.216638
Layer 0 weight grad [0][0] = 15.250469


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1577
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.717664
Layer 0 weight grad [0][0] = 16.255251


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1578
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.215534
Layer 0 weight grad [0][0] = 15.559071


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1579
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.217837
Layer 0 weight grad [0][0] = 15.978913


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1580
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.218437
Layer 0 weight grad [0][0] = 15.218639


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1581
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.941106
Layer 0 weight grad [0][0] = 13.667560


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1582
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.245166
Layer 0 weight grad [0][0] = 15.618443


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1583
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.226340
Layer 0 weight grad [0][0] = 15.949786


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1584
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.434086
Layer 0 weight grad [0][0] = 16.005508


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1585
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.235712
Layer 0 weight grad [0][0] = 15.862867


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1586
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.260033
Layer 0 weight grad [0][0] = 15.757976


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1587
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.057828
Layer 0 weight grad [0][0] = 14.558029


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1588
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.243058
Layer 0 weight grad [0][0] = 16.561556


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1589
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.184017
Layer 0 weight grad [0][0] = 15.802596


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1590
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.168661
Layer 0 weight grad [0][0] = 15.348750


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1591
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.188754
Layer 0 weight grad [0][0] = 15.997180


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1592
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.172027
Layer 0 weight grad [0][0] = 16.908875


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1593
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -3.002433
Layer 0 weight grad [0][0] = 14.298420


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1594
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -3.052564
Layer 0 weight grad [0][0] = 16.410212


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1595
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.236793
Layer 0 weight grad [0][0] = 15.005483


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1596
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.443188
Layer 0 weight grad [0][0] = 15.897556


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1597
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.226569
Layer 0 weight grad [0][0] = 15.133989


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1598
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.733836
Layer 0 weight grad [0][0] = 17.032579


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1599
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.462795
Layer 0 weight grad [0][0] = 15.537191


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1600
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.451886
Layer 0 weight grad [0][0] = 16.176178


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1601
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.219046
Layer 0 weight grad [0][0] = 16.388018


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1602
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.262120
Layer 0 weight grad [0][0] = 17.097284


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1603
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.223553
Layer 0 weight grad [0][0] = 17.212107


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1604
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.700889
Layer 0 weight grad [0][0] = 16.363808


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1605
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.356989
Layer 0 weight grad [0][0] = 15.922480


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1606
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.197176
Layer 0 weight grad [0][0] = 14.560130


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1607
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.326367
Layer 0 weight grad [0][0] = 16.603035


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1608
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.203034
Layer 0 weight grad [0][0] = 15.918252


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1609
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.702098
Layer 0 weight grad [0][0] = 16.080044


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1610
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2.785974
Layer 0 weight grad [0][0] = 14.456177


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1611
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.344608
Layer 0 weight grad [0][0] = 15.725026


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1612
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.177851
Layer 0 weight grad [0][0] = 16.302618


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1613
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.720701
Layer 0 weight grad [0][0] = 15.842628


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1614
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.191186
Layer 0 weight grad [0][0] = 14.322099


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1615
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.321034
Layer 0 weight grad [0][0] = 14.753666


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1616
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.731426
Layer 0 weight grad [0][0] = 16.435349


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1617
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.249886
Layer 0 weight grad [0][0] = 15.007759


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1618
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -3.280998
Layer 0 weight grad [0][0] = 15.216504


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1619
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.271057
Layer 0 weight grad [0][0] = 16.634884


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1620
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.319351
Layer 0 weight grad [0][0] = 14.519667


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1621
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.316557
Layer 0 weight grad [0][0] = 14.627400


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1622
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.236642
Layer 0 weight grad [0][0] = 15.541579


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1623
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.240190
Layer 0 weight grad [0][0] = 15.155063


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1624
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.744419
Layer 0 weight grad [0][0] = 15.431877


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1625
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.246638
Layer 0 weight grad [0][0] = 15.615843


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1626
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.249904
Layer 0 weight grad [0][0] = 18.869045


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1627
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2.906895
Layer 0 weight grad [0][0] = 17.177843


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1628
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.158477
Layer 0 weight grad [0][0] = 15.084369


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1629
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.154339
Layer 0 weight grad [0][0] = 14.811496


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1630
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.204188
Layer 0 weight grad [0][0] = 12.858608


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1631
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.723069
Layer 0 weight grad [0][0] = 15.765642


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1632
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.213870
Layer 0 weight grad [0][0] = 16.384544


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1633
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.735585
Layer 0 weight grad [0][0] = 15.270357


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1634
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.223905
Layer 0 weight grad [0][0] = 14.925381


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1635
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.322599
Layer 0 weight grad [0][0] = 15.885301


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 1636
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.499523
Layer 0 weight grad [0][0] = 14.823203


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1637
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.722819
Layer 0 weight grad [0][0] = 15.634442


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1638
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.227569
Layer 0 weight grad [0][0] = 16.433441


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1639
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.252827
Layer 0 weight grad [0][0] = 14.909225


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1640
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.753259
Layer 0 weight grad [0][0] = 15.139973


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1641
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.741189
Layer 0 weight grad [0][0] = 18.760685


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1642
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.195554
Layer 0 weight grad [0][0] = 17.427027


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1643
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.204285
Layer 0 weight grad [0][0] = 15.921701


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1644
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.208102
Layer 0 weight grad [0][0] = 15.664145


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1645
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.711462
Layer 0 weight grad [0][0] = 15.538144


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1646
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.844297
Layer 0 weight grad [0][0] = 15.040197


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1647
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.383237
Layer 0 weight grad [0][0] = 15.074821


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 1648
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.211628
Layer 0 weight grad [0][0] = 14.612745


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1649
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.018602
Layer 0 weight grad [0][0] = 15.116960


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1650
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.207523
Layer 0 weight grad [0][0] = 14.364889


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1651
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.215806
Layer 0 weight grad [0][0] = 17.212406


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1652
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -3.643966
Layer 0 weight grad [0][0] = 15.216706


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1653
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.198828
Layer 0 weight grad [0][0] = 14.936234


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1654
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.244661
Layer 0 weight grad [0][0] = 15.815498


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1655
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.297996
Layer 0 weight grad [0][0] = 14.976280


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1656
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -3.708042
Layer 0 weight grad [0][0] = 15.142908


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1657
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.255262
Layer 0 weight grad [0][0] = 14.996883


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1658
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.814820
Layer 0 weight grad [0][0] = 16.201502


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1659
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.283753
Layer 0 weight grad [0][0] = 14.855999


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1660
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.252563
Layer 0 weight grad [0][0] = 16.377392


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1661
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.002167
Layer 0 weight grad [0][0] = 15.073848


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1662
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.252989
Layer 0 weight grad [0][0] = 14.924510


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1663
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.510632
Layer 0 weight grad [0][0] = 15.382379


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1664
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.844566
Layer 0 weight grad [0][0] = 14.862535


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1665
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.531311
Layer 0 weight grad [0][0] = 16.378420


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1666
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.539526
Layer 0 weight grad [0][0] = 14.504470


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1667
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.324053
Layer 0 weight grad [0][0] = 14.930153


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1668
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.293598
Layer 0 weight grad [0][0] = 15.622297


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1669
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.316071
Layer 0 weight grad [0][0] = 16.408098


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1670
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -4.271098
Layer 0 weight grad [0][0] = 16.073778


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1671
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.881783
Layer 0 weight grad [0][0] = 15.749678


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1672
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.364916
Layer 0 weight grad [0][0] = 14.851010


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1673
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.349040
Layer 0 weight grad [0][0] = 17.949360


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1674
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.806878
Layer 0 weight grad [0][0] = 14.942356


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1675
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.799485
Layer 0 weight grad [0][0] = 16.399954


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1676
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.273388
Layer 0 weight grad [0][0] = 15.042204


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1677
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -3.573870
Layer 0 weight grad [0][0] = 15.081156


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1678
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -3.814739
Layer 0 weight grad [0][0] = 15.014555


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1679
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.207896
Layer 0 weight grad [0][0] = 15.720977


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1680
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -3.927205
Layer 0 weight grad [0][0] = 15.107026


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1681
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.434245
Layer 0 weight grad [0][0] = 15.144266


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1682
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.402722
Layer 0 weight grad [0][0] = 14.448242


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 1683
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.440863
Layer 0 weight grad [0][0] = 16.114796


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1684
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.465516
Layer 0 weight grad [0][0] = 18.101393


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1685
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.353858
Layer 0 weight grad [0][0] = 16.294178


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1686
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.396885
Layer 0 weight grad [0][0] = 19.239534


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1687
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.376295
Layer 0 weight grad [0][0] = 13.229641


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1688
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.230920
Layer 0 weight grad [0][0] = 16.014860


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1689
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.378911
Layer 0 weight grad [0][0] = 18.006645


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1690
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.837602
Layer 0 weight grad [0][0] = 15.240713


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1691
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.290474
Layer 0 weight grad [0][0] = 15.160786


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1692
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.334189
Layer 0 weight grad [0][0] = 14.972465


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1693
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.338961
Layer 0 weight grad [0][0] = 14.641685


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1694
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.347361
Layer 0 weight grad [0][0] = 16.614588


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1695
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.328952
Layer 0 weight grad [0][0] = 14.845145


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1696
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.281838
Layer 0 weight grad [0][0] = 15.440589


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1697
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.506363
Layer 0 weight grad [0][0] = 14.942490


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1698
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.199705
Layer 0 weight grad [0][0] = 15.004729


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1699
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.354544
Layer 0 weight grad [0][0] = 15.151764


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1700
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.190317
Layer 0 weight grad [0][0] = 13.893112


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1701
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.363525
Layer 0 weight grad [0][0] = 15.276956


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1702
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.368770
Layer 0 weight grad [0][0] = 14.065197


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1703
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.312413
Layer 0 weight grad [0][0] = 15.587339


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1704
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.334874
Layer 0 weight grad [0][0] = 18.911755


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1705
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.757811
Layer 0 weight grad [0][0] = 14.769156


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1706
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.261955
Layer 0 weight grad [0][0] = 15.704241


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1707
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.266605
Layer 0 weight grad [0][0] = 15.198582


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1708
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.289091
Layer 0 weight grad [0][0] = 14.324244


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1709
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.273256
Layer 0 weight grad [0][0] = 17.634014


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1710
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.218211
Layer 0 weight grad [0][0] = 15.160262


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1711
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.221062
Layer 0 weight grad [0][0] = 16.550236


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1712
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.227754
Layer 0 weight grad [0][0] = 16.835587


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1713
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.778062
Layer 0 weight grad [0][0] = 14.986754


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1714
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.744558
Layer 0 weight grad [0][0] = 15.358534


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1715
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -3.999159
Layer 0 weight grad [0][0] = 15.088811


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1716
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.278488
Layer 0 weight grad [0][0] = 15.179877


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1717
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -3.385911
Layer 0 weight grad [0][0] = 14.235637


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1718
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.340712
Layer 0 weight grad [0][0] = 16.350237


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1719
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.322697
Layer 0 weight grad [0][0] = 12.232933


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1720
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.290917
Layer 0 weight grad [0][0] = 14.857088


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1721
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -3.619396
Layer 0 weight grad [0][0] = 15.060341


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1722
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.100986
Layer 0 weight grad [0][0] = 15.450395


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1723
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.389943
Layer 0 weight grad [0][0] = 17.705299


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1724
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.848286
Layer 0 weight grad [0][0] = 15.338413


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1725
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.356124
Layer 0 weight grad [0][0] = 15.554188


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1726
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.843635
Layer 0 weight grad [0][0] = 16.061726


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1727
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.294628
Layer 0 weight grad [0][0] = 14.702767


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1728
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.551303
Layer 0 weight grad [0][0] = 14.084675


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1729
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.578431
Layer 0 weight grad [0][0] = 15.126547


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1730
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -3.708594
Layer 0 weight grad [0][0] = 15.140333


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1731
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.184170
Layer 0 weight grad [0][0] = 16.244469


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1732
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.397364
Layer 0 weight grad [0][0] = 14.842788


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1733
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.402030
Layer 0 weight grad [0][0] = 16.767107


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1734
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.404944
Layer 0 weight grad [0][0] = 15.372391


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1735
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.095085
Layer 0 weight grad [0][0] = 15.777809


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1736
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.895037
Layer 0 weight grad [0][0] = 15.032957


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1737
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.399193
Layer 0 weight grad [0][0] = 15.214826


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1738
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.402506
Layer 0 weight grad [0][0] = 14.915677


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1739
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.249952
Layer 0 weight grad [0][0] = 18.297216


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1740
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.042080
Layer 0 weight grad [0][0] = 16.093834


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1741
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.343639
Layer 0 weight grad [0][0] = 18.182295


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1742
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.304546
Layer 0 weight grad [0][0] = 14.525476


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1743
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.288574
Layer 0 weight grad [0][0] = 15.785285


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1744
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.295917
Layer 0 weight grad [0][0] = 14.196728


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1745
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -3.334206
Layer 0 weight grad [0][0] = 14.717205


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1746
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.870525
Layer 0 weight grad [0][0] = 15.038186


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1747
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.360610
Layer 0 weight grad [0][0] = 16.666603


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1748
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.344973
Layer 0 weight grad [0][0] = 16.527475


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1749
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -3.644233
Layer 0 weight grad [0][0] = 14.856828


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1750
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.420315
Layer 0 weight grad [0][0] = 15.251325


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1751
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.898088
Layer 0 weight grad [0][0] = 14.809452


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1752
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.906549
Layer 0 weight grad [0][0] = 20.103632


Training loss: 2.302585
Training accuracy: 0.437500

epoch: 1753
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.355542
Layer 0 weight grad [0][0] = 14.863104


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1754
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.340066
Layer 0 weight grad [0][0] = 15.037677


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1755
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.345147
Layer 0 weight grad [0][0] = 15.628473


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1756
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.867906
Layer 0 weight grad [0][0] = 16.248766


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1757
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.320667
Layer 0 weight grad [0][0] = 14.890501


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1758
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.364864
Layer 0 weight grad [0][0] = 15.129826


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1759
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.373181
Layer 0 weight grad [0][0] = 15.644907


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1760
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.893144
Layer 0 weight grad [0][0] = 15.707288


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1761
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.105525
Layer 0 weight grad [0][0] = 16.556198


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1762
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.396255
Layer 0 weight grad [0][0] = 15.232839


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1763
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.902412
Layer 0 weight grad [0][0] = 15.753878


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1764
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.405026
Layer 0 weight grad [0][0] = 14.796883


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1765
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -3.930395
Layer 0 weight grad [0][0] = 15.541580


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1766
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.981988
Layer 0 weight grad [0][0] = 15.196601


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1767
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.473703
Layer 0 weight grad [0][0] = 17.643961


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1768
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.380309
Layer 0 weight grad [0][0] = 15.223289


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1769
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.426677
Layer 0 weight grad [0][0] = 14.876364


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1770
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -3.897910
Layer 0 weight grad [0][0] = 15.397087


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1771
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.681837
Layer 0 weight grad [0][0] = 14.898266


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1772
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.002849
Layer 0 weight grad [0][0] = 15.361316


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1773
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -3.881043
Layer 0 weight grad [0][0] = 15.155032


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1774
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.541473
Layer 0 weight grad [0][0] = 14.916442


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1775
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.548818
Layer 0 weight grad [0][0] = 15.996415


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1776
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.519548
Layer 0 weight grad [0][0] = 14.878513


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1777
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.566314
Layer 0 weight grad [0][0] = 15.430864


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1778
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -4.434999
Layer 0 weight grad [0][0] = 14.887329


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1779
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.025211
Layer 0 weight grad [0][0] = 16.416136


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1780
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -4.537421
Layer 0 weight grad [0][0] = 14.243369


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1781
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.662350
Layer 0 weight grad [0][0] = 16.362904


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1782
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.667248
Layer 0 weight grad [0][0] = 14.631059


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1783
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.658170
Layer 0 weight grad [0][0] = 16.936602


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 1784
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.179254
Layer 0 weight grad [0][0] = 20.755249


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1785
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.116919
Layer 0 weight grad [0][0] = 15.867061


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1786
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.605687
Layer 0 weight grad [0][0] = 15.681666


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1787
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.611373
Layer 0 weight grad [0][0] = 14.972379


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1788
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -4.111916
Layer 0 weight grad [0][0] = 15.019712


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1789
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.374455
Layer 0 weight grad [0][0] = 15.094257


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1790
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.675561
Layer 0 weight grad [0][0] = 15.208068


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1791
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.620122
Layer 0 weight grad [0][0] = 14.701905


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1792
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.411843
Layer 0 weight grad [0][0] = 15.417329


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1793
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.597352
Layer 0 weight grad [0][0] = 15.538455


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1794
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.635164
Layer 0 weight grad [0][0] = 13.337568


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1795
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.657266
Layer 0 weight grad [0][0] = 16.213512


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1796
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.090540
Layer 0 weight grad [0][0] = 10.807931


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 1797
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.642979
Layer 0 weight grad [0][0] = 18.398834


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1798
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.096578
Layer 0 weight grad [0][0] = 14.292560


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1799
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.037918
Layer 0 weight grad [0][0] = 16.015738


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1800
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.574468
Layer 0 weight grad [0][0] = 17.961956


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1801
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.542992
Layer 0 weight grad [0][0] = 15.985674


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1802
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.029092
Layer 0 weight grad [0][0] = 15.561056


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1803
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.787660
Layer 0 weight grad [0][0] = 15.863782


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1804
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.608346
Layer 0 weight grad [0][0] = 15.148487


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1805
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.556891
Layer 0 weight grad [0][0] = 14.593513


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1806
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.594258
Layer 0 weight grad [0][0] = 15.263759


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1807
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.100644
Layer 0 weight grad [0][0] = 15.347229


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1808
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.602525
Layer 0 weight grad [0][0] = 14.404680


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1809
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.573784
Layer 0 weight grad [0][0] = 16.083721


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1810
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.070393
Layer 0 weight grad [0][0] = 15.394920


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1811
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.623322
Layer 0 weight grad [0][0] = 15.696102


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1812
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.626414
Layer 0 weight grad [0][0] = 15.322082


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1813
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.828929
Layer 0 weight grad [0][0] = 16.577627


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1814
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.146896
Layer 0 weight grad [0][0] = 16.421831


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1815
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -5.289097
Layer 0 weight grad [0][0] = 15.683362


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1816
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.176742
Layer 0 weight grad [0][0] = 17.260004


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1817
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.192791
Layer 0 weight grad [0][0] = 15.937809


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1818
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.133890
Layer 0 weight grad [0][0] = 14.968045


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1819
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -5.452332
Layer 0 weight grad [0][0] = 15.512750


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1820
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.735516
Layer 0 weight grad [0][0] = 18.822239


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1821
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.907650
Layer 0 weight grad [0][0] = 17.805321


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1822
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.188383
Layer 0 weight grad [0][0] = 15.099575


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1823
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.708712
Layer 0 weight grad [0][0] = 14.292601


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 1824
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.649461
Layer 0 weight grad [0][0] = 15.810451


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1825
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.891614
Layer 0 weight grad [0][0] = 15.749762


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1826
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.002796
Layer 0 weight grad [0][0] = 16.449936


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1827
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.636884
Layer 0 weight grad [0][0] = 16.064671


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1828
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.682885
Layer 0 weight grad [0][0] = 19.590282


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1829
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.636685
Layer 0 weight grad [0][0] = 12.994132


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1830
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.596781
Layer 0 weight grad [0][0] = 16.073677


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1831
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.656299
Layer 0 weight grad [0][0] = 12.448658


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1832
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.641053
Layer 0 weight grad [0][0] = 17.708019


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1833
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.848323
Layer 0 weight grad [0][0] = 16.798815


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1834
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.614182
Layer 0 weight grad [0][0] = 11.475374


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1835
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.650454
Layer 0 weight grad [0][0] = 15.437446


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1836
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.651763
Layer 0 weight grad [0][0] = 15.869631


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1837
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.161803
Layer 0 weight grad [0][0] = 16.182177


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1838
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -5.262443
Layer 0 weight grad [0][0] = 18.392424


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1839
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.608985
Layer 0 weight grad [0][0] = 13.192005


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1840
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -4.885539
Layer 0 weight grad [0][0] = 17.458412


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1841
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.706456
Layer 0 weight grad [0][0] = 16.355902


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1842
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.211576
Layer 0 weight grad [0][0] = 15.597939


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1843
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.152773
Layer 0 weight grad [0][0] = 10.778398


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1844
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.703744
Layer 0 weight grad [0][0] = 16.392237


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1845
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.672182
Layer 0 weight grad [0][0] = 16.801876


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1846
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -5.147290
Layer 0 weight grad [0][0] = 15.730451


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1847
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.765378
Layer 0 weight grad [0][0] = 15.873248


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1848
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.778267
Layer 0 weight grad [0][0] = 17.214554


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1849
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.718486
Layer 0 weight grad [0][0] = 15.471049


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1850
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.713189
Layer 0 weight grad [0][0] = 17.947065


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1851
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.675132
Layer 0 weight grad [0][0] = 16.881075


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 1852
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.675835
Layer 0 weight grad [0][0] = 14.469278


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1853
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.049365
Layer 0 weight grad [0][0] = 14.344502


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 1854
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.154471
Layer 0 weight grad [0][0] = 15.784742


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1855
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.633726
Layer 0 weight grad [0][0] = 14.728292


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1856
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.596210
Layer 0 weight grad [0][0] = 14.188905


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1857
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.597189
Layer 0 weight grad [0][0] = 12.379417


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1858
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.598586
Layer 0 weight grad [0][0] = 16.364933


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1859
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.471964
Layer 0 weight grad [0][0] = 12.965257


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1860
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.574266
Layer 0 weight grad [0][0] = 16.297512


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 1861
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.538449
Layer 0 weight grad [0][0] = 16.560476


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1862
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.583292
Layer 0 weight grad [0][0] = 15.947835


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1863
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.230456
Layer 0 weight grad [0][0] = 16.764051


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1864
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.585122
Layer 0 weight grad [0][0] = 15.677940


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1865
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.566051
Layer 0 weight grad [0][0] = 14.690291


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1866
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.524620
Layer 0 weight grad [0][0] = 14.982238


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1867
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.023769
Layer 0 weight grad [0][0] = 15.094405


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1868
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.697621
Layer 0 weight grad [0][0] = 11.053606


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1869
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.539340
Layer 0 weight grad [0][0] = 11.080961


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1870
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.941788
Layer 0 weight grad [0][0] = 15.673660


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1871
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.730179
Layer 0 weight grad [0][0] = 15.676742


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1872
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.531597
Layer 0 weight grad [0][0] = 18.283960


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1873
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.064041
Layer 0 weight grad [0][0] = 15.213027


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1874
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.486920
Layer 0 weight grad [0][0] = 16.689518


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1875
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.510798
Layer 0 weight grad [0][0] = 16.553951


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1876
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.511028
Layer 0 weight grad [0][0] = 17.439297


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1877
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.511249
Layer 0 weight grad [0][0] = 16.327417


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1878
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.513464
Layer 0 weight grad [0][0] = 16.509563


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1879
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.696129
Layer 0 weight grad [0][0] = 16.367287


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1880
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.996271
Layer 0 weight grad [0][0] = 15.916363


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1881
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.453881
Layer 0 weight grad [0][0] = 15.729313


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1882
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.052515
Layer 0 weight grad [0][0] = 15.176948


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1883
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.498047
Layer 0 weight grad [0][0] = 15.687649


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1884
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.467124
Layer 0 weight grad [0][0] = 15.303755


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1885
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.511353
Layer 0 weight grad [0][0] = 16.661167


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1886
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.517147
Layer 0 weight grad [0][0] = 16.731979


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1887
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.518251
Layer 0 weight grad [0][0] = 16.208508


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1888
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.512854
Layer 0 weight grad [0][0] = 15.715964


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1889
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.481042
Layer 0 weight grad [0][0] = 18.034184


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1890
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.488441
Layer 0 weight grad [0][0] = 16.072714


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1891
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.057879
Layer 0 weight grad [0][0] = 11.902770


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1892
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.492686
Layer 0 weight grad [0][0] = 16.275099


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1893
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.877953
Layer 0 weight grad [0][0] = 14.811059


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1894
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.974443
Layer 0 weight grad [0][0] = 13.467854


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1895
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.976908
Layer 0 weight grad [0][0] = 16.590719


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1896
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.005568
Layer 0 weight grad [0][0] = 16.681919


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1897
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.957243
Layer 0 weight grad [0][0] = 14.569327


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1898
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.444149
Layer 0 weight grad [0][0] = 17.282925


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1899
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.429773
Layer 0 weight grad [0][0] = 16.359072


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1900
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.433722
Layer 0 weight grad [0][0] = 16.954926


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1901
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.135943
Layer 0 weight grad [0][0] = 13.686461


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1902
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.271910
Layer 0 weight grad [0][0] = 15.426831


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1903
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.399506
Layer 0 weight grad [0][0] = 15.321481


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1904
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.521847
Layer 0 weight grad [0][0] = 17.326975


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1905
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.350151
Layer 0 weight grad [0][0] = 16.637594


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1906
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.786045
Layer 0 weight grad [0][0] = 16.883089


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 1907
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.502922
Layer 0 weight grad [0][0] = 13.444223


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1908
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.305619
Layer 0 weight grad [0][0] = 17.406517


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1909
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.287501
Layer 0 weight grad [0][0] = 15.472634


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1910
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.287407
Layer 0 weight grad [0][0] = 16.043322


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1911
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.771184
Layer 0 weight grad [0][0] = 15.222163


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1912
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.774498
Layer 0 weight grad [0][0] = 17.060888


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1913
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.278689
Layer 0 weight grad [0][0] = 15.230918


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1914
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.171231
Layer 0 weight grad [0][0] = 15.789433


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1915
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.256618
Layer 0 weight grad [0][0] = 15.538149


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1916
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.763272
Layer 0 weight grad [0][0] = 17.167336


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1917
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.246452
Layer 0 weight grad [0][0] = 15.250370


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1918
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.532721
Layer 0 weight grad [0][0] = 15.071839


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1919
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.202532
Layer 0 weight grad [0][0] = 15.606869


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1920
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.206568
Layer 0 weight grad [0][0] = 16.533686


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1921
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.416210
Layer 0 weight grad [0][0] = 16.903292


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1922
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.424374
Layer 0 weight grad [0][0] = 16.311636


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1923
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.432365
Layer 0 weight grad [0][0] = 13.815144


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1924
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.252363
Layer 0 weight grad [0][0] = 16.348028


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1925
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.734779
Layer 0 weight grad [0][0] = 16.488159


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1926
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.707748
Layer 0 weight grad [0][0] = 17.646448


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1927
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.172067
Layer 0 weight grad [0][0] = 15.442860


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1928
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.215007
Layer 0 weight grad [0][0] = 16.026463


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1929
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.817306
Layer 0 weight grad [0][0] = 16.958561


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1930
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.910001
Layer 0 weight grad [0][0] = 15.872976


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1931
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.214378
Layer 0 weight grad [0][0] = 17.068754


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1932
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.176968
Layer 0 weight grad [0][0] = 16.330120


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1933
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.698225
Layer 0 weight grad [0][0] = 16.445034


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1934
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.683356
Layer 0 weight grad [0][0] = 15.725255


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1935
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.170598
Layer 0 weight grad [0][0] = 16.217440


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1936
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.157354
Layer 0 weight grad [0][0] = 17.655703


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1937
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -3.980724
Layer 0 weight grad [0][0] = 15.729464


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1938
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000030 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.203449
Layer 0 weight grad [0][0] = 16.366310


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1939
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.177009
Layer 0 weight grad [0][0] = 12.242520


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1940
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.383857
Layer 0 weight grad [0][0] = 16.361210


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1941
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.203804
Layer 0 weight grad [0][0] = 15.394404


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1942
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.190229
Layer 0 weight grad [0][0] = 15.349169


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1943
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.683772
Layer 0 weight grad [0][0] = 15.482118


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1944
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.182889
Layer 0 weight grad [0][0] = 16.608997


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1945
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -3.885336
Layer 0 weight grad [0][0] = 15.398162


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1946
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.222589
Layer 0 weight grad [0][0] = 12.552597


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1947
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.192231
Layer 0 weight grad [0][0] = 15.957943


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1948
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.237959
Layer 0 weight grad [0][0] = 15.371455


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1949
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.241501
Layer 0 weight grad [0][0] = 15.846862


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1950
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.864772
Layer 0 weight grad [0][0] = 16.686766


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 1951
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.726977
Layer 0 weight grad [0][0] = 18.543879


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1952
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.689169
Layer 0 weight grad [0][0] = 16.860706


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1953
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.154277
Layer 0 weight grad [0][0] = 15.048832


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1954
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.199974
Layer 0 weight grad [0][0] = 17.705046


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1955
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.702951
Layer 0 weight grad [0][0] = 12.894017


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1956
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.912243
Layer 0 weight grad [0][0] = 15.368302


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1957
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.211810
Layer 0 weight grad [0][0] = 17.691006


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1958
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.730139
Layer 0 weight grad [0][0] = 14.800996


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1959
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.199800
Layer 0 weight grad [0][0] = 16.883949


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1960
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -3.912996
Layer 0 weight grad [0][0] = 16.207867


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1961
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -3.887013
Layer 0 weight grad [0][0] = 16.682808


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1962
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.226310
Layer 0 weight grad [0][0] = 16.050133


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1963
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.268421
Layer 0 weight grad [0][0] = 19.404461


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1964
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.242548
Layer 0 weight grad [0][0] = 15.490114


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1965
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.235758
Layer 0 weight grad [0][0] = 16.657274


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1966
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.711279
Layer 0 weight grad [0][0] = 17.256086


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1967
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.215086
Layer 0 weight grad [0][0] = 16.109104


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1968
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.717258
Layer 0 weight grad [0][0] = 15.645852


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1969
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.938443
Layer 0 weight grad [0][0] = 14.449405


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1970
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.227378
Layer 0 weight grad [0][0] = 16.831623


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 1971
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.199168
Layer 0 weight grad [0][0] = 15.350228


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 1972
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.204380
Layer 0 weight grad [0][0] = 15.042748


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1973
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.337682
Layer 0 weight grad [0][0] = 14.990759


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1974
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.334697
Layer 0 weight grad [0][0] = 14.735894


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 1975
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.218618
Layer 0 weight grad [0][0] = 13.230230


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1976
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.185646
Layer 0 weight grad [0][0] = 12.848013


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1977
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.938222
Layer 0 weight grad [0][0] = 14.454055


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1978
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.203881
Layer 0 weight grad [0][0] = 15.976633


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1979
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.218652
Layer 0 weight grad [0][0] = 14.744503


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1980
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.227060
Layer 0 weight grad [0][0] = 13.236024


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1981
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.219742
Layer 0 weight grad [0][0] = 17.715475


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1982
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.929456
Layer 0 weight grad [0][0] = 15.443324


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1983
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.194099
Layer 0 weight grad [0][0] = 16.122686


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1984
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -3.352793
Layer 0 weight grad [0][0] = 16.135557


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1985
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.481466
Layer 0 weight grad [0][0] = 16.523785


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1986
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.800987
Layer 0 weight grad [0][0] = 15.497036


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1987
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -3.400735
Layer 0 weight grad [0][0] = 15.107763


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1988
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.327900
Layer 0 weight grad [0][0] = 17.561886


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1989
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.823722
Layer 0 weight grad [0][0] = 14.713299


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1990
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.331401
Layer 0 weight grad [0][0] = 17.138462


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1991
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.793418
Layer 0 weight grad [0][0] = 15.157700


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1992
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.294130
Layer 0 weight grad [0][0] = 16.443226


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1993
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.263730
Layer 0 weight grad [0][0] = 13.506070


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1994
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.247810
Layer 0 weight grad [0][0] = 15.362875


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 1995
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.292796
Layer 0 weight grad [0][0] = 15.437459


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1996
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.314130
Layer 0 weight grad [0][0] = 17.434284


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 1997
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.317872
Layer 0 weight grad [0][0] = 15.875520


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 1998
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.267328
Layer 0 weight grad [0][0] = 15.626816


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 1999
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.311556
Layer 0 weight grad [0][0] = 16.061493


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2000
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -3.040634
Layer 0 weight grad [0][0] = 15.684035


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2001
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.438040
Layer 0 weight grad [0][0] = 16.295040


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2002
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.304351
Layer 0 weight grad [0][0] = 12.178039


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2003
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.222427
Layer 0 weight grad [0][0] = 14.755168


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2004
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.829716
Layer 0 weight grad [0][0] = 15.788112


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2005
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -3.210905
Layer 0 weight grad [0][0] = 15.182310


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2006
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -3.219384
Layer 0 weight grad [0][0] = 17.938976


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2007
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2.834473
Layer 0 weight grad [0][0] = 15.211042


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2008
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.395688
Layer 0 weight grad [0][0] = 14.077774


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2009
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.402339
Layer 0 weight grad [0][0] = 15.583640


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2010
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2.964021
Layer 0 weight grad [0][0] = 18.858561


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2011
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.926294
Layer 0 weight grad [0][0] = 17.510372


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2012
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.375996
Layer 0 weight grad [0][0] = 12.640967


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2013
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.588727
Layer 0 weight grad [0][0] = 16.933781


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2014
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.412031
Layer 0 weight grad [0][0] = 14.631669


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2015
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.566706
Layer 0 weight grad [0][0] = 16.052185


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2016
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.412964
Layer 0 weight grad [0][0] = 15.396441


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2017
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.412327
Layer 0 weight grad [0][0] = 19.680408


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2018
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.877502
Layer 0 weight grad [0][0] = 15.642643


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2019
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.873688
Layer 0 weight grad [0][0] = 11.987164


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2020
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.379887
Layer 0 weight grad [0][0] = 17.234362


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2021
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.573480
Layer 0 weight grad [0][0] = 16.296305


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2022
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.733831
Layer 0 weight grad [0][0] = 18.010509


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2023
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.270228
Layer 0 weight grad [0][0] = 14.523840


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2024
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.262258
Layer 0 weight grad [0][0] = 16.635622


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2025
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.248292
Layer 0 weight grad [0][0] = 17.609186


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2026
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.308134
Layer 0 weight grad [0][0] = 14.796022


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2027
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.220613
Layer 0 weight grad [0][0] = 15.242493


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2028
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.705737
Layer 0 weight grad [0][0] = 15.501085


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2029
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.568184
Layer 0 weight grad [0][0] = 16.588875


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2030
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.322633
Layer 0 weight grad [0][0] = 18.174904


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2031
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.231784
Layer 0 weight grad [0][0] = 16.686863


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2032
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.233742
Layer 0 weight grad [0][0] = 18.430470


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2033
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.716879
Layer 0 weight grad [0][0] = 15.339805


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2034
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.327369
Layer 0 weight grad [0][0] = 17.694445


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2035
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.245804
Layer 0 weight grad [0][0] = 17.664663


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2036
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.747362
Layer 0 weight grad [0][0] = 17.145472


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2037
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.215346
Layer 0 weight grad [0][0] = 15.226256


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2038
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.221256
Layer 0 weight grad [0][0] = 15.824903


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 2039
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.250272
Layer 0 weight grad [0][0] = 14.377109


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2040
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.271373
Layer 0 weight grad [0][0] = 16.328239


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2041
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.093207
Layer 0 weight grad [0][0] = 16.850510


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2042
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.778606
Layer 0 weight grad [0][0] = 16.110851


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2043
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.280828
Layer 0 weight grad [0][0] = 14.284070


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2044
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.801973
Layer 0 weight grad [0][0] = 14.154382


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2045
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.480402
Layer 0 weight grad [0][0] = 16.115057


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2046
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.284666
Layer 0 weight grad [0][0] = 15.568300


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2047
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.253885
Layer 0 weight grad [0][0] = 16.018528


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2048
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.814244
Layer 0 weight grad [0][0] = 16.837406


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2049
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.477269
Layer 0 weight grad [0][0] = 13.392491


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2050
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.819952
Layer 0 weight grad [0][0] = 15.813687


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2051
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.320583
Layer 0 weight grad [0][0] = 16.093512


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2052
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.289862
Layer 0 weight grad [0][0] = 16.072124


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2053
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.035887
Layer 0 weight grad [0][0] = 15.829788


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2054
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.367401
Layer 0 weight grad [0][0] = 15.589397


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2055
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.373359
Layer 0 weight grad [0][0] = 15.531665


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2056
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.379244
Layer 0 weight grad [0][0] = 16.060087


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2057
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.387232
Layer 0 weight grad [0][0] = 14.795147


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2058
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.877641
Layer 0 weight grad [0][0] = 15.639251


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2059
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.113019
Layer 0 weight grad [0][0] = 16.247339


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2060
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.399221
Layer 0 weight grad [0][0] = 15.790442


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2061
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.425377
Layer 0 weight grad [0][0] = 16.908499


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2062
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.579594
Layer 0 weight grad [0][0] = 15.303082


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2063
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.422736
Layer 0 weight grad [0][0] = 16.734640


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2064
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.390735
Layer 0 weight grad [0][0] = 15.110190


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2065
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.428668
Layer 0 weight grad [0][0] = 16.031315


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2066
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.136976
Layer 0 weight grad [0][0] = 14.994558


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 2067
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -3.085043
Layer 0 weight grad [0][0] = 15.826603


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2068
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.364210
Layer 0 weight grad [0][0] = 14.759701


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2069
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.928587
Layer 0 weight grad [0][0] = 16.935499


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2070
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.606775
Layer 0 weight grad [0][0] = 17.965557


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2071
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.925616
Layer 0 weight grad [0][0] = 15.963665


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2072
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.417331
Layer 0 weight grad [0][0] = 15.236526


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2073
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.150550
Layer 0 weight grad [0][0] = 16.804747


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 2074
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.402646
Layer 0 weight grad [0][0] = 15.475167


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2075
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.373161
Layer 0 weight grad [0][0] = 17.619112


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2076
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.916852
Layer 0 weight grad [0][0] = 16.003994


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2077
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -3.148560
Layer 0 weight grad [0][0] = 12.628688


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2078
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.344555
Layer 0 weight grad [0][0] = 16.063047


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2079
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.824355
Layer 0 weight grad [0][0] = 15.588516


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2080
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.325839
Layer 0 weight grad [0][0] = 15.276921


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2081
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.332972
Layer 0 weight grad [0][0] = 16.088011


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2082
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.313285
Layer 0 weight grad [0][0] = 17.351215


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2083
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.333369
Layer 0 weight grad [0][0] = 15.357903


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2084
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.835646
Layer 0 weight grad [0][0] = 16.953329


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2085
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.325632
Layer 0 weight grad [0][0] = 16.329876


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2086
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.447006
Layer 0 weight grad [0][0] = 15.893750


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2087
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -3.122419
Layer 0 weight grad [0][0] = 15.942602


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2088
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.277670
Layer 0 weight grad [0][0] = 12.143756


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2089
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.317989
Layer 0 weight grad [0][0] = 15.705609


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2090
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.517941
Layer 0 weight grad [0][0] = 16.118353


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2091
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.321505
Layer 0 weight grad [0][0] = 15.401632


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2092
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.884201
Layer 0 weight grad [0][0] = 15.028302


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2093
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.572115
Layer 0 weight grad [0][0] = 15.435359


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2094
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -3.364323
Layer 0 weight grad [0][0] = 12.795134


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2095
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2.947273
Layer 0 weight grad [0][0] = 13.086891


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2096
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.317944
Layer 0 weight grad [0][0] = 15.919658


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2097
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.322524
Layer 0 weight grad [0][0] = 17.068308


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2098
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2.523622
Layer 0 weight grad [0][0] = 19.570290


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2099
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.217903
Layer 0 weight grad [0][0] = 13.654992


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2100
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.777349
Layer 0 weight grad [0][0] = 15.552295


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2101
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.266477
Layer 0 weight grad [0][0] = 16.194939


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2102
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.768299
Layer 0 weight grad [0][0] = 17.512857


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2103
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.279646
Layer 0 weight grad [0][0] = 16.810692


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2104
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.789054
Layer 0 weight grad [0][0] = 16.204893


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 2105
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.797125
Layer 0 weight grad [0][0] = 15.862139


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2106
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.300156
Layer 0 weight grad [0][0] = 16.093821


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2107
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.232719
Layer 0 weight grad [0][0] = 15.735379


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2108
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.300379
Layer 0 weight grad [0][0] = 16.399565


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2109
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.278425
Layer 0 weight grad [0][0] = 16.511003


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2110
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.763124
Layer 0 weight grad [0][0] = 17.016880


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2111
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.319924
Layer 0 weight grad [0][0] = 15.442782


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2112
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.665576
Layer 0 weight grad [0][0] = 13.274821


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2113
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.277793
Layer 0 weight grad [0][0] = 15.859553


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2114
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.320510
Layer 0 weight grad [0][0] = 16.338686


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2115
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.326671
Layer 0 weight grad [0][0] = 16.068644


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2116
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.345642
Layer 0 weight grad [0][0] = 15.329861


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2117
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.053643
Layer 0 weight grad [0][0] = 14.380342


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2118
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.839905
Layer 0 weight grad [0][0] = 16.433676


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2119
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.357177
Layer 0 weight grad [0][0] = 15.855178


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2120
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.854197
Layer 0 weight grad [0][0] = 16.204969


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2121
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.344260
Layer 0 weight grad [0][0] = 16.314510


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2122
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.322509
Layer 0 weight grad [0][0] = 14.928363


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2123
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.346575
Layer 0 weight grad [0][0] = 17.855087


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2124
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.332636
Layer 0 weight grad [0][0] = 16.469946


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2125
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.333508
Layer 0 weight grad [0][0] = 12.583509


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2126
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.852234
Layer 0 weight grad [0][0] = 18.445467


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2127
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -3.186684
Layer 0 weight grad [0][0] = 14.991598


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2128
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.289224
Layer 0 weight grad [0][0] = 15.391956


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2129
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.810694
Layer 0 weight grad [0][0] = 16.490391


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2130
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.503952
Layer 0 weight grad [0][0] = 15.578320


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2131
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.305122
Layer 0 weight grad [0][0] = 16.585903


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2132
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.273413
Layer 0 weight grad [0][0] = 18.156057


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2133
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.319062
Layer 0 weight grad [0][0] = 12.191486


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2134
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.342304
Layer 0 weight grad [0][0] = 17.101788


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2135
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.286521
Layer 0 weight grad [0][0] = 16.014673


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2136
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.329352
Layer 0 weight grad [0][0] = 13.839215


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2137
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.331997
Layer 0 weight grad [0][0] = 14.759124


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2138
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.851951
Layer 0 weight grad [0][0] = 18.861349


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2139
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.341934
Layer 0 weight grad [0][0] = 14.531530


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2140
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.859138
Layer 0 weight grad [0][0] = 16.203066


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2141
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2.355375
Layer 0 weight grad [0][0] = 16.007490


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2142
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.302970
Layer 0 weight grad [0][0] = 16.597799


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2143
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2.494625
Layer 0 weight grad [0][0] = 15.854989


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2144
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.226629
Layer 0 weight grad [0][0] = 18.474707


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2145
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.746609
Layer 0 weight grad [0][0] = 15.137913


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2146
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.234202
Layer 0 weight grad [0][0] = 15.110105


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2147
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.454516
Layer 0 weight grad [0][0] = 14.008211


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2148
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.755006
Layer 0 weight grad [0][0] = 17.445559


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2149
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.253579
Layer 0 weight grad [0][0] = 14.258114


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2150
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.478192
Layer 0 weight grad [0][0] = 16.178904


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2151
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.276777
Layer 0 weight grad [0][0] = 15.674474


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2152
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.978323
Layer 0 weight grad [0][0] = 15.647940


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2153
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.762820
Layer 0 weight grad [0][0] = 14.893733


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2154
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.236442
Layer 0 weight grad [0][0] = 17.300682


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2155
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.333844
Layer 0 weight grad [0][0] = 16.108624


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2156
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.164827
Layer 0 weight grad [0][0] = 15.970477


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2157
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.206678
Layer 0 weight grad [0][0] = 16.672407


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2158
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.324157
Layer 0 weight grad [0][0] = 14.976538


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2159
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.224000
Layer 0 weight grad [0][0] = 15.172449


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2160
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.173439
Layer 0 weight grad [0][0] = 16.155867


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2161
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.254452
Layer 0 weight grad [0][0] = 16.457052


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2162
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.272378
Layer 0 weight grad [0][0] = 16.054853


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2163
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.252291
Layer 0 weight grad [0][0] = 15.633845


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2164
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.253334
Layer 0 weight grad [0][0] = 16.733210


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2165
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.270974
Layer 0 weight grad [0][0] = 16.516581


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2166
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.250362
Layer 0 weight grad [0][0] = 16.563406


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2167
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.206100
Layer 0 weight grad [0][0] = 15.265041


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2168
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.264022
Layer 0 weight grad [0][0] = 16.963724


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2169
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.451617
Layer 0 weight grad [0][0] = 15.599464


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2170
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.242864
Layer 0 weight grad [0][0] = 15.691260


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2171
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.256090
Layer 0 weight grad [0][0] = 15.714841


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2172
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.288110
Layer 0 weight grad [0][0] = 17.185553


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2173
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.263162
Layer 0 weight grad [0][0] = 15.398415


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2174
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.283358
Layer 0 weight grad [0][0] = 16.955858


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2175
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.268837
Layer 0 weight grad [0][0] = 16.745609


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2176
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.291068
Layer 0 weight grad [0][0] = 15.071211


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2177
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.259207
Layer 0 weight grad [0][0] = 16.655876


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2178
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.407796
Layer 0 weight grad [0][0] = 15.349709


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2179
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.929797
Layer 0 weight grad [0][0] = 13.412169


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2180
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.338114
Layer 0 weight grad [0][0] = 16.522310


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2181
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.229135
Layer 0 weight grad [0][0] = 14.892223


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2182
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.338523
Layer 0 weight grad [0][0] = 15.579180


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2183
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.834979
Layer 0 weight grad [0][0] = 18.517334


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2184
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.339190
Layer 0 weight grad [0][0] = 16.695318


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2185
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.319276
Layer 0 weight grad [0][0] = 11.659001


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2186
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.319002
Layer 0 weight grad [0][0] = 14.583409


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2187
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.042159
Layer 0 weight grad [0][0] = 15.332819


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2188
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.328047
Layer 0 weight grad [0][0] = 15.948227


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2189
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.257749
Layer 0 weight grad [0][0] = 15.058230


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2190
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.557537
Layer 0 weight grad [0][0] = 15.566626


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2191
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.911892
Layer 0 weight grad [0][0] = 15.906926


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2192
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.311179
Layer 0 weight grad [0][0] = 16.829678


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2193
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.498520
Layer 0 weight grad [0][0] = 14.561807


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2194
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.815819
Layer 0 weight grad [0][0] = 16.601940


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2195
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.266744
Layer 0 weight grad [0][0] = 15.723123


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2196
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.237164
Layer 0 weight grad [0][0] = 15.877861


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2197
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.314534
Layer 0 weight grad [0][0] = 15.868631


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2198
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.286319
Layer 0 weight grad [0][0] = 14.607780


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 2199
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.289301
Layer 0 weight grad [0][0] = 15.648712


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2200
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2.264706
Layer 0 weight grad [0][0] = 12.800437


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2201
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.380759
Layer 0 weight grad [0][0] = 13.261155


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2202
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.364283
Layer 0 weight grad [0][0] = 15.454066


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 2203
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.367810
Layer 0 weight grad [0][0] = 15.993364


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2204
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.870446
Layer 0 weight grad [0][0] = 17.057743


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2205
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.571395
Layer 0 weight grad [0][0] = 16.479355


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2206
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.353542
Layer 0 weight grad [0][0] = 17.526808


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2207
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.356705
Layer 0 weight grad [0][0] = 14.795042


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 2208
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.322682
Layer 0 weight grad [0][0] = 16.613548


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2209
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.383536
Layer 0 weight grad [0][0] = 16.646763


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 2210
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.384327
Layer 0 weight grad [0][0] = 16.094460


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2211
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.654888
Layer 0 weight grad [0][0] = 15.562000


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2212
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.901718
Layer 0 weight grad [0][0] = 16.025835


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2213
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.400972
Layer 0 weight grad [0][0] = 17.669977


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2214
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.389278
Layer 0 weight grad [0][0] = 15.804648


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2215
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.116501
Layer 0 weight grad [0][0] = 15.114637


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2216
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.404261
Layer 0 weight grad [0][0] = 12.316003


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2217
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.565528
Layer 0 weight grad [0][0] = 15.237768


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 2218
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2.294497
Layer 0 weight grad [0][0] = 15.482270


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2219
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2.015817
Layer 0 weight grad [0][0] = 16.247576


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2220
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.370914
Layer 0 weight grad [0][0] = 17.222191


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2221
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.328911
Layer 0 weight grad [0][0] = 16.135780


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2222
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.553845
Layer 0 weight grad [0][0] = 15.060541


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2223
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.336518
Layer 0 weight grad [0][0] = 12.521564


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2224
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.343737
Layer 0 weight grad [0][0] = 15.610839


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2225
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.347287
Layer 0 weight grad [0][0] = 15.697153


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 2226
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.600891
Layer 0 weight grad [0][0] = 15.613216


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2227
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.597179
Layer 0 weight grad [0][0] = 16.273937


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2228
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.404318
Layer 0 weight grad [0][0] = 16.273146


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2229
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.410020
Layer 0 weight grad [0][0] = 15.609561


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2230
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.916140
Layer 0 weight grad [0][0] = 16.535120


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2231
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.416960
Layer 0 weight grad [0][0] = 15.564987


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2232
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.921752
Layer 0 weight grad [0][0] = 16.692873


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2233
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.440493
Layer 0 weight grad [0][0] = 16.777048


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2234
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.921505
Layer 0 weight grad [0][0] = 14.440080


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2235
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.444482
Layer 0 weight grad [0][0] = 16.192606


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2236
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.427095
Layer 0 weight grad [0][0] = 15.747736


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2237
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.637974
Layer 0 weight grad [0][0] = 15.639281


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2238
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.459453
Layer 0 weight grad [0][0] = 16.438995


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2239
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.446396
Layer 0 weight grad [0][0] = 12.993740


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2240
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2.073038
Layer 0 weight grad [0][0] = 16.441450


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2241
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.467667
Layer 0 weight grad [0][0] = 16.237202


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2242
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.991097
Layer 0 weight grad [0][0] = 15.340457


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2243
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.980203
Layer 0 weight grad [0][0] = 16.928766


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2244
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.448055
Layer 0 weight grad [0][0] = 15.471587


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2245
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.496612
Layer 0 weight grad [0][0] = 15.130799


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2246
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2.553746
Layer 0 weight grad [0][0] = 16.353027


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2247
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.428963
Layer 0 weight grad [0][0] = 14.854700


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2248
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.639844
Layer 0 weight grad [0][0] = 15.472722


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2249
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2.251458
Layer 0 weight grad [0][0] = 16.104202


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2250
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.925095
Layer 0 weight grad [0][0] = 15.269732


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2251
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.931245
Layer 0 weight grad [0][0] = 16.688145


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2252
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.907232
Layer 0 weight grad [0][0] = 14.895842


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2253
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.354006
Layer 0 weight grad [0][0] = 14.234313


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2254
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.215639
Layer 0 weight grad [0][0] = 14.731328


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2255
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.225897
Layer 0 weight grad [0][0] = 15.262165


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2256
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.775341
Layer 0 weight grad [0][0] = 18.083454


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2257
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.302204
Layer 0 weight grad [0][0] = 15.827667


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2258
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.288608
Layer 0 weight grad [0][0] = 15.361443


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2259
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.315413
Layer 0 weight grad [0][0] = 16.160110


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2260
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.822077
Layer 0 weight grad [0][0] = 13.800656


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2261
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.318704
Layer 0 weight grad [0][0] = 16.647585


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2262
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.920622
Layer 0 weight grad [0][0] = 15.248005


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2263
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.509650
Layer 0 weight grad [0][0] = 18.562592


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2264
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.714348
Layer 0 weight grad [0][0] = 15.735822


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2265
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.224090
Layer 0 weight grad [0][0] = 15.885723


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2266
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.236629
Layer 0 weight grad [0][0] = 16.892607


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2267
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.236628
Layer 0 weight grad [0][0] = 14.878447


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2268
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.116408
Layer 0 weight grad [0][0] = 15.192688


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2269
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.190907
Layer 0 weight grad [0][0] = 17.980606


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2270
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.105006
Layer 0 weight grad [0][0] = 16.833170


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2271
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2.377539
Layer 0 weight grad [0][0] = 16.332352


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2272
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.374903
Layer 0 weight grad [0][0] = 15.186763


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2273
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.386522
Layer 0 weight grad [0][0] = 15.606375


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2274
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.545876
Layer 0 weight grad [0][0] = 14.657252


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2275
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.428635
Layer 0 weight grad [0][0] = 15.463059


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2276
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.117907
Layer 0 weight grad [0][0] = 15.740727


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2277
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.839336
Layer 0 weight grad [0][0] = 15.401914


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2278
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.071883
Layer 0 weight grad [0][0] = 14.941368


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2279
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.081773
Layer 0 weight grad [0][0] = 16.718904


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2280
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.025105
Layer 0 weight grad [0][0] = 15.702910


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2281
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.552058
Layer 0 weight grad [0][0] = 14.090073


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2282
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2.148977
Layer 0 weight grad [0][0] = 17.545208


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2283
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.007567
Layer 0 weight grad [0][0] = 15.778805


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2284
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.018830
Layer 0 weight grad [0][0] = 14.941788


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 2285
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.029489
Layer 0 weight grad [0][0] = 16.346167


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2286
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.040225
Layer 0 weight grad [0][0] = 14.850225


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2287
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.551259
Layer 0 weight grad [0][0] = 15.532036


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2288
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.559015
Layer 0 weight grad [0][0] = 15.921061


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2289
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.068899
Layer 0 weight grad [0][0] = 18.025255


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2290
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.511308
Layer 0 weight grad [0][0] = 15.351322


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2291
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.023004
Layer 0 weight grad [0][0] = 15.668646


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2292
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.034650
Layer 0 weight grad [0][0] = 15.079194


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 2293
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.046382
Layer 0 weight grad [0][0] = 15.791203


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 2294
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.667060
Layer 0 weight grad [0][0] = 17.092434


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2295
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.980736
Layer 0 weight grad [0][0] = 15.676973


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2296
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.321199
Layer 0 weight grad [0][0] = 17.171429


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2297
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.083651
Layer 0 weight grad [0][0] = 19.561333


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2298
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.139140
Layer 0 weight grad [0][0] = 17.168488


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2299
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.135816
Layer 0 weight grad [0][0] = 15.016992


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2300
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.501395
Layer 0 weight grad [0][0] = 15.110922


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2301
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.166361
Layer 0 weight grad [0][0] = 15.046128


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2302
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.361059
Layer 0 weight grad [0][0] = 15.735571


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2303
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.143269
Layer 0 weight grad [0][0] = 14.382723


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2304
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.142344
Layer 0 weight grad [0][0] = 15.486866


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2305
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.110137
Layer 0 weight grad [0][0] = 15.247642


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2306
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.125143
Layer 0 weight grad [0][0] = 14.919384


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2307
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.401152
Layer 0 weight grad [0][0] = 14.854182


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2308
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.403773
Layer 0 weight grad [0][0] = 17.086187


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2309
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.121148
Layer 0 weight grad [0][0] = 15.552306


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 2310
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.145057
Layer 0 weight grad [0][0] = 14.782494


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2311
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.470588
Layer 0 weight grad [0][0] = 17.138914


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2312
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.110503
Layer 0 weight grad [0][0] = 17.242737


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2313
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.013541
Layer 0 weight grad [0][0] = 15.701524


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2314
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.130448
Layer 0 weight grad [0][0] = 15.249341


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2315
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.174552
Layer 0 weight grad [0][0] = 15.450036


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2316
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.006762
Layer 0 weight grad [0][0] = 16.609831


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2317
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.140886
Layer 0 weight grad [0][0] = 16.614717


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2318
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.166278
Layer 0 weight grad [0][0] = 16.337471


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2319
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.097653
Layer 0 weight grad [0][0] = 16.602924


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 2320
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.100243
Layer 0 weight grad [0][0] = 15.133307


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2321
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.088997
Layer 0 weight grad [0][0] = 15.137810


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2322
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.056159
Layer 0 weight grad [0][0] = 16.322359


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2323
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.777849
Layer 0 weight grad [0][0] = 16.506994


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2324
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.460161
Layer 0 weight grad [0][0] = 14.731784


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2325
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.044037
Layer 0 weight grad [0][0] = 16.581345


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2326
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.031084
Layer 0 weight grad [0][0] = 14.964091


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2327
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.494880
Layer 0 weight grad [0][0] = 14.860292


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 2328
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.010675
Layer 0 weight grad [0][0] = 15.614960


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2329
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.574251
Layer 0 weight grad [0][0] = 14.185398


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2330
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.010979
Layer 0 weight grad [0][0] = 17.596197


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2331
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.435133
Layer 0 weight grad [0][0] = 16.773733


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2332
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.057667
Layer 0 weight grad [0][0] = 17.691320


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2333
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.044357
Layer 0 weight grad [0][0] = 15.261302


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2334
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.687426
Layer 0 weight grad [0][0] = 17.824673


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2335
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.309993
Layer 0 weight grad [0][0] = 15.164289


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2336
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.695665
Layer 0 weight grad [0][0] = 15.848428


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2337
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.118629
Layer 0 weight grad [0][0] = 15.972676


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2338
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.597214
Layer 0 weight grad [0][0] = 15.275596


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2339
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.095861
Layer 0 weight grad [0][0] = 14.875056


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2340
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.051889
Layer 0 weight grad [0][0] = 15.716291


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2341
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.096809
Layer 0 weight grad [0][0] = 15.739596


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2342
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.412515
Layer 0 weight grad [0][0] = 16.598574


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2343
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.098461
Layer 0 weight grad [0][0] = 15.679671


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2344
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.088188
Layer 0 weight grad [0][0] = 15.974831


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2345
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.127791
Layer 0 weight grad [0][0] = 14.808882


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2346
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.045605
Layer 0 weight grad [0][0] = 15.785665


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2347
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.034156
Layer 0 weight grad [0][0] = 15.398721


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2348
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.027531
Layer 0 weight grad [0][0] = 17.039640


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2349
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.199174
Layer 0 weight grad [0][0] = 17.987562


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2350
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.664537
Layer 0 weight grad [0][0] = 15.260348


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2351
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.692403
Layer 0 weight grad [0][0] = 14.697784


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2352
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.076194
Layer 0 weight grad [0][0] = 14.696633


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2353
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.065457
Layer 0 weight grad [0][0] = 15.965316


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2354
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.076703
Layer 0 weight grad [0][0] = 17.401186


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2355
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.238213
Layer 0 weight grad [0][0] = 14.939385


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2356
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.151952
Layer 0 weight grad [0][0] = 15.998922


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2357
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.143694
Layer 0 weight grad [0][0] = 15.439749


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2358
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.133237
Layer 0 weight grad [0][0] = 15.267282


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2359
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.360306
Layer 0 weight grad [0][0] = 15.192676


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2360
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.760724
Layer 0 weight grad [0][0] = 15.019732


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2361
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.103314
Layer 0 weight grad [0][0] = 15.013088


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2362
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.350164
Layer 0 weight grad [0][0] = 15.957240


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2363
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.386456
Layer 0 weight grad [0][0] = 15.135489


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2364
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.154972
Layer 0 weight grad [0][0] = 17.782284


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2365
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.165807
Layer 0 weight grad [0][0] = 15.017916


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2366
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.798262
Layer 0 weight grad [0][0] = 15.031703


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2367
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.145462
Layer 0 weight grad [0][0] = 15.650473


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2368
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.153144
Layer 0 weight grad [0][0] = 16.794970


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2369
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.294535
Layer 0 weight grad [0][0] = 14.571164


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2370
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.317105
Layer 0 weight grad [0][0] = 14.897983


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2371
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.326875
Layer 0 weight grad [0][0] = 16.307486


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2372
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.270424
Layer 0 weight grad [0][0] = 15.889069


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2373
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.626285
Layer 0 weight grad [0][0] = 14.358355


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2374
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.022486
Layer 0 weight grad [0][0] = 16.166224


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2375
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.169038
Layer 0 weight grad [0][0] = 17.059074


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2376
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.295894
Layer 0 weight grad [0][0] = 18.040695


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2377
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.304241
Layer 0 weight grad [0][0] = 14.716573


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2378
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.645967
Layer 0 weight grad [0][0] = 15.514100


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2379
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.237198
Layer 0 weight grad [0][0] = 15.799662


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2380
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.248260
Layer 0 weight grad [0][0] = 15.891964


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2381
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.240552
Layer 0 weight grad [0][0] = 14.918593


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2382
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.240210
Layer 0 weight grad [0][0] = 16.511909


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2383
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.229354
Layer 0 weight grad [0][0] = 17.076645


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2384
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.278676
Layer 0 weight grad [0][0] = 15.420012


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2385
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.311981
Layer 0 weight grad [0][0] = 16.351040


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2386
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.265118
Layer 0 weight grad [0][0] = 16.334782


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2387
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.293067
Layer 0 weight grad [0][0] = 15.838582


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2388
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.244833
Layer 0 weight grad [0][0] = 15.945010


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2389
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.276493
Layer 0 weight grad [0][0] = 17.447018


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2390
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.326325
Layer 0 weight grad [0][0] = 15.193780


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2391
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.258462
Layer 0 weight grad [0][0] = 15.845541


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2392
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.270630
Layer 0 weight grad [0][0] = 15.609890


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2393
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.255966
Layer 0 weight grad [0][0] = 14.111703


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2394
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.249113
Layer 0 weight grad [0][0] = 15.027282


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2395
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.289346
Layer 0 weight grad [0][0] = 15.910622


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2396
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.279393
Layer 0 weight grad [0][0] = 16.711184


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2397
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.001513
Layer 0 weight grad [0][0] = 16.982115


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2398
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.215843
Layer 0 weight grad [0][0] = 16.538151


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2399
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.288717
Layer 0 weight grad [0][0] = 16.474316


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 2400
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.514588
Layer 0 weight grad [0][0] = 15.425231


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2401
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.194468
Layer 0 weight grad [0][0] = 17.323023


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2402
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.249439
Layer 0 weight grad [0][0] = 15.794009


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2403
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.462968
Layer 0 weight grad [0][0] = 17.254473


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 2404
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.780320
Layer 0 weight grad [0][0] = 15.502544


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2405
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.037058
Layer 0 weight grad [0][0] = 15.011439


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2406
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.285705
Layer 0 weight grad [0][0] = 13.962029


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2407
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.685594
Layer 0 weight grad [0][0] = 15.505114


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2408
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.508147
Layer 0 weight grad [0][0] = 15.299471


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2409
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.385709
Layer 0 weight grad [0][0] = 14.396841


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 2410
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.898543
Layer 0 weight grad [0][0] = 15.751653


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 2411
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.217171
Layer 0 weight grad [0][0] = 15.018418


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2412
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.499714
Layer 0 weight grad [0][0] = 15.758488


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 2413
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.086565
Layer 0 weight grad [0][0] = 15.523477


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2414
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.198851
Layer 0 weight grad [0][0] = 19.259903


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2415
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.259562
Layer 0 weight grad [0][0] = 15.395578


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2416
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.599607
Layer 0 weight grad [0][0] = 14.921535


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2417
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.247344
Layer 0 weight grad [0][0] = 16.181107


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2418
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.458504
Layer 0 weight grad [0][0] = 16.256248


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2419
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.236472
Layer 0 weight grad [0][0] = 17.929070


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2420
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.913061
Layer 0 weight grad [0][0] = 15.051291


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2421
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.193339
Layer 0 weight grad [0][0] = 15.663650


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2422
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.407227
Layer 0 weight grad [0][0] = 15.870267


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2423
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.288643
Layer 0 weight grad [0][0] = 15.695506


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2424
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.263210
Layer 0 weight grad [0][0] = 15.272451


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2425
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.069935
Layer 0 weight grad [0][0] = 17.393717


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2426
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.235458
Layer 0 weight grad [0][0] = 15.874599


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2427
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.258714
Layer 0 weight grad [0][0] = 14.929386


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2428
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.246018
Layer 0 weight grad [0][0] = 15.328634


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2429
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.786722
Layer 0 weight grad [0][0] = 14.816175


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2430
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.230641
Layer 0 weight grad [0][0] = 18.512079


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2431
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.276355
Layer 0 weight grad [0][0] = 14.395543


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 2432
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.265233
Layer 0 weight grad [0][0] = 16.724813


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2433
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.291271
Layer 0 weight grad [0][0] = 15.270189


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2434
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.252959
Layer 0 weight grad [0][0] = 15.753167


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2435
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.242466
Layer 0 weight grad [0][0] = 15.600842


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2436
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.590293
Layer 0 weight grad [0][0] = 17.212435


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2437
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.230956
Layer 0 weight grad [0][0] = 15.792542


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2438
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.258018
Layer 0 weight grad [0][0] = 14.794707


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2439
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.245150
Layer 0 weight grad [0][0] = 17.604851


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2440
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.006764
Layer 0 weight grad [0][0] = 15.758948


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2441
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.168364
Layer 0 weight grad [0][0] = 14.952544


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2442
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.181505
Layer 0 weight grad [0][0] = 15.082156


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2443
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.896674
Layer 0 weight grad [0][0] = 15.755527


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2444
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.725914
Layer 0 weight grad [0][0] = 14.450252


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2445
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.204888
Layer 0 weight grad [0][0] = 14.799870


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2446
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.068335
Layer 0 weight grad [0][0] = 14.870746


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2447
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.356496
Layer 0 weight grad [0][0] = 14.935564


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2448
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.182576
Layer 0 weight grad [0][0] = 18.153513


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2449
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.582859
Layer 0 weight grad [0][0] = 15.554639


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2450
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.298207
Layer 0 weight grad [0][0] = 18.777128


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2451
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.576417
Layer 0 weight grad [0][0] = 15.581251


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2452
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.262646
Layer 0 weight grad [0][0] = 19.231386


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2453
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.613764
Layer 0 weight grad [0][0] = 14.193197


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 2454
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.356453
Layer 0 weight grad [0][0] = 16.858116


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2455
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.421617
Layer 0 weight grad [0][0] = 14.921697


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2456
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.413418
Layer 0 weight grad [0][0] = 15.126399


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2457
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.394847
Layer 0 weight grad [0][0] = 18.933207


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2458
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.054936
Layer 0 weight grad [0][0] = 15.244673


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2459
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.297739
Layer 0 weight grad [0][0] = 15.695589


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2460
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.616175
Layer 0 weight grad [0][0] = 14.841958


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2461
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.996988
Layer 0 weight grad [0][0] = 15.009326


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2462
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.790723
Layer 0 weight grad [0][0] = 17.325668


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2463
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.450180
Layer 0 weight grad [0][0] = 15.096251


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2464
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.442736
Layer 0 weight grad [0][0] = 15.240227


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2465
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.434421
Layer 0 weight grad [0][0] = 17.820896


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2466
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.831515
Layer 0 weight grad [0][0] = 15.608381


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2467
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.510941
Layer 0 weight grad [0][0] = 17.810875


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2468
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.574663
Layer 0 weight grad [0][0] = 15.063589


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2469
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.566403
Layer 0 weight grad [0][0] = 16.315781


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2470
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.924336
Layer 0 weight grad [0][0] = 14.540719


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 2471
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.546134
Layer 0 weight grad [0][0] = 15.061583


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 2472
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.539030
Layer 0 weight grad [0][0] = 15.313889


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2473
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.082480
Layer 0 weight grad [0][0] = 14.056002


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2474
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.526725
Layer 0 weight grad [0][0] = 15.841817


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2475
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.503361
Layer 0 weight grad [0][0] = 15.517118


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2476
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.512457
Layer 0 weight grad [0][0] = 15.620566


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2477
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.483113
Layer 0 weight grad [0][0] = 16.305988


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2478
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.893798
Layer 0 weight grad [0][0] = 17.503071


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2479
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.487567
Layer 0 weight grad [0][0] = 16.270876


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2480
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.293781
Layer 0 weight grad [0][0] = 16.303638


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2481
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.484771
Layer 0 weight grad [0][0] = 15.520824


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2482
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.170944
Layer 0 weight grad [0][0] = 18.184402


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2483
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.716509
Layer 0 weight grad [0][0] = 16.384457


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2484
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.027965
Layer 0 weight grad [0][0] = 15.446384


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2485
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.101286
Layer 0 weight grad [0][0] = 15.093433


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 2486
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.026183
Layer 0 weight grad [0][0] = 16.247620


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2487
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.545197
Layer 0 weight grad [0][0] = 15.373940


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2488
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.086306
Layer 0 weight grad [0][0] = 15.621361


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2489
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.320392
Layer 0 weight grad [0][0] = 14.819786


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2490
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.304462
Layer 0 weight grad [0][0] = 14.861198


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 2491
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.476686
Layer 0 weight grad [0][0] = 15.824378


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2492
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.284629
Layer 0 weight grad [0][0] = 15.757283


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2493
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.529610
Layer 0 weight grad [0][0] = 15.019047


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2494
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.036014
Layer 0 weight grad [0][0] = 15.200522


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2495
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.022186
Layer 0 weight grad [0][0] = 15.206117


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2496
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.284061
Layer 0 weight grad [0][0] = 15.283051


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2497
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.040829
Layer 0 weight grad [0][0] = 15.703852


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2498
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.185102
Layer 0 weight grad [0][0] = 14.711946


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2499
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.454541
Layer 0 weight grad [0][0] = 19.728138


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2500
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.531378
Layer 0 weight grad [0][0] = 15.090467


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2501
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.351376
Layer 0 weight grad [0][0] = 15.034389


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2502
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.002673
Layer 0 weight grad [0][0] = 15.621334


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2503
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.019535
Layer 0 weight grad [0][0] = 18.643990


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2504
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.483295
Layer 0 weight grad [0][0] = 15.768633


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2505
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.456493
Layer 0 weight grad [0][0] = 14.966771


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2506
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.467119
Layer 0 weight grad [0][0] = 15.474926


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2507
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.510482
Layer 0 weight grad [0][0] = 13.558588


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2508
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.437310
Layer 0 weight grad [0][0] = 17.994617


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2509
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.516208
Layer 0 weight grad [0][0] = 14.895368


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2510
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.506583
Layer 0 weight grad [0][0] = 15.951823


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2511
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.018268
Layer 0 weight grad [0][0] = 13.940168


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2512
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.279027
Layer 0 weight grad [0][0] = 15.233457


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2513
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.470358
Layer 0 weight grad [0][0] = 15.574446


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 2514
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.012501
Layer 0 weight grad [0][0] = 15.545016


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2515
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.453397
Layer 0 weight grad [0][0] = 15.926043


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2516
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.216084
Layer 0 weight grad [0][0] = 16.352613


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2517
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.426514
Layer 0 weight grad [0][0] = 14.745375


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 2518
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.395712
Layer 0 weight grad [0][0] = 14.214229


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2519
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.887072
Layer 0 weight grad [0][0] = 15.163044


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2520
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.610407
Layer 0 weight grad [0][0] = 15.938609


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2521
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.420825
Layer 0 weight grad [0][0] = 15.528438


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2522
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.446041
Layer 0 weight grad [0][0] = 14.299784


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2523
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.374046
Layer 0 weight grad [0][0] = 14.619925


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2524
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.380093
Layer 0 weight grad [0][0] = 19.668888


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2525
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.442017
Layer 0 weight grad [0][0] = 17.710741


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2526
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.431664
Layer 0 weight grad [0][0] = 14.777822


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2527
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.772562
Layer 0 weight grad [0][0] = 14.938605


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2528
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.243317
Layer 0 weight grad [0][0] = 14.887481


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2529
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.427998
Layer 0 weight grad [0][0] = 14.719964


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 2530
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.081613
Layer 0 weight grad [0][0] = 16.067738


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2531
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.201356
Layer 0 weight grad [0][0] = 16.199829


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2532
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.392284
Layer 0 weight grad [0][0] = 14.571911


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 2533
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.325468
Layer 0 weight grad [0][0] = 18.207478


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2534
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.056066
Layer 0 weight grad [0][0] = 14.477087


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2535
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.999477
Layer 0 weight grad [0][0] = 15.325455


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2536
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.260075
Layer 0 weight grad [0][0] = 13.963346


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 2537
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000004 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.459120
Layer 0 weight grad [0][0] = 14.753262


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2538
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.036749
Layer 0 weight grad [0][0] = 15.849372


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2539
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.475379
Layer 0 weight grad [0][0] = 16.174507


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2540
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.426526
Layer 0 weight grad [0][0] = 16.813541


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2541
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.083382
Layer 0 weight grad [0][0] = 14.688490


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2542
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.522166
Layer 0 weight grad [0][0] = 16.774427


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2543
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.252143
Layer 0 weight grad [0][0] = 14.375405


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2544
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.161170
Layer 0 weight grad [0][0] = 15.710508


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2545
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.131561
Layer 0 weight grad [0][0] = 13.878407


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2546
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.860792
Layer 0 weight grad [0][0] = 17.070154


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2547
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.210415
Layer 0 weight grad [0][0] = 14.672095


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2548
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.030851
Layer 0 weight grad [0][0] = 16.447075


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2549
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.441724
Layer 0 weight grad [0][0] = 17.331944


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2550
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.548709
Layer 0 weight grad [0][0] = 16.713652


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2551
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.062980
Layer 0 weight grad [0][0] = 14.624005


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2552
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.430858
Layer 0 weight grad [0][0] = 14.835882


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2553
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.454647
Layer 0 weight grad [0][0] = 16.498955


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2554
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.954255
Layer 0 weight grad [0][0] = 14.502778


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2555
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.394826
Layer 0 weight grad [0][0] = 17.153749


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2556
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.129943
Layer 0 weight grad [0][0] = 18.300697


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2557
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.457943
Layer 0 weight grad [0][0] = 15.280211


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2558
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.443967
Layer 0 weight grad [0][0] = 14.823365


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2559
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.431913
Layer 0 weight grad [0][0] = 14.701931


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2560
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.421311
Layer 0 weight grad [0][0] = 14.841438


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2561
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.407687
Layer 0 weight grad [0][0] = 15.414899


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2562
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.101520
Layer 0 weight grad [0][0] = 15.672623


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2563
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.390337
Layer 0 weight grad [0][0] = 20.253485


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2564
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.033596
Layer 0 weight grad [0][0] = 14.518382


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2565
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.465510
Layer 0 weight grad [0][0] = 16.017559


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2566
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.292837
Layer 0 weight grad [0][0] = 15.152301


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2567
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.490120
Layer 0 weight grad [0][0] = 15.601604


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2568
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.443985
Layer 0 weight grad [0][0] = 14.294198


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2569
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.223824
Layer 0 weight grad [0][0] = 18.551435


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2570
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.523875
Layer 0 weight grad [0][0] = 15.488084


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2571
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.012422
Layer 0 weight grad [0][0] = 15.414436


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2572
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.297052
Layer 0 weight grad [0][0] = 14.959021


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2573
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.468514
Layer 0 weight grad [0][0] = 19.988997


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2574
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.897702
Layer 0 weight grad [0][0] = 14.809515


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2575
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.535495
Layer 0 weight grad [0][0] = 13.803180


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2576
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.041412
Layer 0 weight grad [0][0] = 17.561655


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2577
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.197276
Layer 0 weight grad [0][0] = 15.452713


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2578
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.036918
Layer 0 weight grad [0][0] = 20.830385


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2579
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.115539
Layer 0 weight grad [0][0] = 15.119472


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2580
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.292913
Layer 0 weight grad [0][0] = 15.259687


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2581
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.117141
Layer 0 weight grad [0][0] = 14.924191


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2582
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.471932
Layer 0 weight grad [0][0] = 17.483114


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2583
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.751996
Layer 0 weight grad [0][0] = 14.300587


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2584
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.294220
Layer 0 weight grad [0][0] = 15.509048


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2585
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.040729
Layer 0 weight grad [0][0] = 18.405128


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2586
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.663325
Layer 0 weight grad [0][0] = 15.487510


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2587
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.656741
Layer 0 weight grad [0][0] = 14.365440


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2588
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.660690
Layer 0 weight grad [0][0] = 14.443637


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2589
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.627141
Layer 0 weight grad [0][0] = 15.004185


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2590
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.630237
Layer 0 weight grad [0][0] = 15.093630


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2591
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.668164
Layer 0 weight grad [0][0] = 14.995207


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2592
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.644681
Layer 0 weight grad [0][0] = 15.114274


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2593
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.494671
Layer 0 weight grad [0][0] = 14.515787


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2594
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.598306
Layer 0 weight grad [0][0] = 14.131836


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2595
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.583740
Layer 0 weight grad [0][0] = 18.816183


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2596
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.567922
Layer 0 weight grad [0][0] = 14.170136


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2597
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.057799
Layer 0 weight grad [0][0] = 15.574681


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2598
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000038 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.569902
Layer 0 weight grad [0][0] = 14.455970


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2599
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.556782
Layer 0 weight grad [0][0] = 15.534921


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2600
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.116259
Layer 0 weight grad [0][0] = 14.466929


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2601
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.537276
Layer 0 weight grad [0][0] = 16.347248


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2602
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.575687
Layer 0 weight grad [0][0] = 15.934480


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2603
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.204079
Layer 0 weight grad [0][0] = 14.683554


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2604
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.499645
Layer 0 weight grad [0][0] = 15.346169


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2605
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.488605
Layer 0 weight grad [0][0] = 14.175429


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2606
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.473265
Layer 0 weight grad [0][0] = 14.034949


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2607
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.461152
Layer 0 weight grad [0][0] = 14.865457


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2608
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.000549
Layer 0 weight grad [0][0] = 13.951837


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2609
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.440738
Layer 0 weight grad [0][0] = 14.199225


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2610
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.425434
Layer 0 weight grad [0][0] = 14.694522


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2611
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.946373
Layer 0 weight grad [0][0] = 14.204860


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2612
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.956664
Layer 0 weight grad [0][0] = 15.150371


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2613
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.396474
Layer 0 weight grad [0][0] = 16.006432


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2614
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.641619
Layer 0 weight grad [0][0] = 14.796979


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2615
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.428763
Layer 0 weight grad [0][0] = 14.469698


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2616
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.761827
Layer 0 weight grad [0][0] = 15.910993


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2617
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.421223
Layer 0 weight grad [0][0] = 15.131450


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2618
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.881610
Layer 0 weight grad [0][0] = 19.545586


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2619
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.454476
Layer 0 weight grad [0][0] = 14.482944


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2620
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.420097
Layer 0 weight grad [0][0] = 18.932232


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2621
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.306826
Layer 0 weight grad [0][0] = 14.885653


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2622
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.005914
Layer 0 weight grad [0][0] = 18.558226


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2623
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.551696
Layer 0 weight grad [0][0] = 16.192780


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2624
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.578442
Layer 0 weight grad [0][0] = 18.519699


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2625
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.671499
Layer 0 weight grad [0][0] = 14.312920


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2626
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.138308
Layer 0 weight grad [0][0] = 17.115303


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2627
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.353472
Layer 0 weight grad [0][0] = 15.761971


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2628
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.659538
Layer 0 weight grad [0][0] = 15.246419


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2629
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.583055
Layer 0 weight grad [0][0] = 14.432284


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2630
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.682575
Layer 0 weight grad [0][0] = 14.257109


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2631
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.422325
Layer 0 weight grad [0][0] = 14.837084


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2632
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.609300
Layer 0 weight grad [0][0] = 15.496840


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2633
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.389498
Layer 0 weight grad [0][0] = 15.216368


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2634
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.144282
Layer 0 weight grad [0][0] = 12.855712


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2635
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.622878
Layer 0 weight grad [0][0] = 16.852884


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2636
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.049305
Layer 0 weight grad [0][0] = 19.817055


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2637
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.641817
Layer 0 weight grad [0][0] = 15.104746


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2638
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.181309
Layer 0 weight grad [0][0] = 17.467209


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 2639
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.601816
Layer 0 weight grad [0][0] = 14.401084


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2640
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.605568
Layer 0 weight grad [0][0] = 15.132938


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2641
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.592657
Layer 0 weight grad [0][0] = 18.720461


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2642
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.168874
Layer 0 weight grad [0][0] = 14.373496


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2643
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.654670
Layer 0 weight grad [0][0] = 16.410986


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 2644
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.663903
Layer 0 weight grad [0][0] = 16.883942


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 2645
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.722533
Layer 0 weight grad [0][0] = 14.148217


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 2646
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.663903
Layer 0 weight grad [0][0] = 18.381180


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2647
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.005683
Layer 0 weight grad [0][0] = 13.143623


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2648
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.849526
Layer 0 weight grad [0][0] = 14.042583


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2649
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.220871
Layer 0 weight grad [0][0] = 14.621370


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2650
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.708009
Layer 0 weight grad [0][0] = 13.971061


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2651
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.196617
Layer 0 weight grad [0][0] = 15.525243


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2652
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.239154
Layer 0 weight grad [0][0] = 14.948492


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2653
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.713808
Layer 0 weight grad [0][0] = 14.409557


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2654
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.661189
Layer 0 weight grad [0][0] = 15.465684


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 2655
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.474565
Layer 0 weight grad [0][0] = 14.582174


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2656
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.107168
Layer 0 weight grad [0][0] = 14.843610


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2657
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.466548
Layer 0 weight grad [0][0] = 15.517730


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 2658
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.621352
Layer 0 weight grad [0][0] = 16.715828


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2659
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.675901
Layer 0 weight grad [0][0] = 14.418404


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2660
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.743690
Layer 0 weight grad [0][0] = 15.409655


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2661
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.109937
Layer 0 weight grad [0][0] = 14.526162


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2662
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.599047
Layer 0 weight grad [0][0] = 18.606691


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2663
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.464418
Layer 0 weight grad [0][0] = 14.432524


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2664
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.453244
Layer 0 weight grad [0][0] = 14.538590


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2665
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.206612
Layer 0 weight grad [0][0] = 14.827540


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2666
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.641801
Layer 0 weight grad [0][0] = 15.067224


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2667
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000018 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.109652
Layer 0 weight grad [0][0] = 17.095024


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2668
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.587117
Layer 0 weight grad [0][0] = 15.074026


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2669
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.501089
Layer 0 weight grad [0][0] = 14.877687


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2670
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.646140
Layer 0 weight grad [0][0] = 14.734663


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2671
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.667499
Layer 0 weight grad [0][0] = 15.041443


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2672
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.096605
Layer 0 weight grad [0][0] = 14.857420


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2673
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.597539
Layer 0 weight grad [0][0] = 15.149786


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2674
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.582533
Layer 0 weight grad [0][0] = 15.275660


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2675
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.051215
Layer 0 weight grad [0][0] = 14.996578


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2676
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.232509
Layer 0 weight grad [0][0] = 18.899427


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2677
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.898776
Layer 0 weight grad [0][0] = 18.086451


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 2678
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.188591
Layer 0 weight grad [0][0] = 16.678419


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2679
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.622777
Layer 0 weight grad [0][0] = 14.751739


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2680
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.605729
Layer 0 weight grad [0][0] = 17.707876


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2681
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.136428
Layer 0 weight grad [0][0] = 15.079255


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2682
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.606243
Layer 0 weight grad [0][0] = 18.453859


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2683
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.084513
Layer 0 weight grad [0][0] = 14.373778


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2684
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.614340
Layer 0 weight grad [0][0] = 14.326713


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2685
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.598159
Layer 0 weight grad [0][0] = 15.232545


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2686
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.133786
Layer 0 weight grad [0][0] = 15.743125


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2687
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.569867
Layer 0 weight grad [0][0] = 14.484977


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2688
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.040583
Layer 0 weight grad [0][0] = 19.136045


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2689
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.014167
Layer 0 weight grad [0][0] = 17.390638


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2690
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.679117
Layer 0 weight grad [0][0] = 14.711421


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2691
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.657381
Layer 0 weight grad [0][0] = 15.875528


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2692
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.645506
Layer 0 weight grad [0][0] = 15.684441


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2693
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.587904
Layer 0 weight grad [0][0] = 15.671247


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2694
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.074475
Layer 0 weight grad [0][0] = 12.982418


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2695
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.564281
Layer 0 weight grad [0][0] = 17.780279


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 2696
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.049138
Layer 0 weight grad [0][0] = 14.937422


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2697
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000004 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.087414
Layer 0 weight grad [0][0] = 16.373003


Training loss: 2.302585
Training accuracy: 0.437500

epoch: 2698
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.526059
Layer 0 weight grad [0][0] = 16.710783


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2699
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.530569
Layer 0 weight grad [0][0] = 17.787516


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2700
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.388614
Layer 0 weight grad [0][0] = 14.848213


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2701
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.028378
Layer 0 weight grad [0][0] = 16.109421


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2702
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.532629
Layer 0 weight grad [0][0] = 18.685036


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2703
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.553331
Layer 0 weight grad [0][0] = 15.563051


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2704
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.497869
Layer 0 weight grad [0][0] = 14.843416


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2705
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.485564
Layer 0 weight grad [0][0] = 18.626793


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2706
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.663024
Layer 0 weight grad [0][0] = 15.937036


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2707
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.549198
Layer 0 weight grad [0][0] = 18.287348


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2708
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.646122
Layer 0 weight grad [0][0] = 15.953657


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2709
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.649799
Layer 0 weight grad [0][0] = 15.553678


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2710
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.220772
Layer 0 weight grad [0][0] = 14.071146


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2711
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.169199
Layer 0 weight grad [0][0] = 16.681778


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 2712
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.606214
Layer 0 weight grad [0][0] = 14.879815


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 2713
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.161138
Layer 0 weight grad [0][0] = 15.614644


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2714
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.598477
Layer 0 weight grad [0][0] = 14.793788


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2715
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.584612
Layer 0 weight grad [0][0] = 13.526458


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2716
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.069348
Layer 0 weight grad [0][0] = 13.956838


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2717
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.090535
Layer 0 weight grad [0][0] = 13.371407


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2718
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000004 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.032817
Layer 0 weight grad [0][0] = 14.704459


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2719
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.529793
Layer 0 weight grad [0][0] = 16.410511


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2720
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.063437
Layer 0 weight grad [0][0] = 14.282255


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 2721
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.050410
Layer 0 weight grad [0][0] = 13.448655


Training loss: 2.302585
Training accuracy: 0.375000

epoch: 2722
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.950583
Layer 0 weight grad [0][0] = 13.310582


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2723
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.494366
Layer 0 weight grad [0][0] = 15.284203


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2724
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.480247
Layer 0 weight grad [0][0] = 18.238605


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2725
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.540550
Layer 0 weight grad [0][0] = 17.483839


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2726
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.547790
Layer 0 weight grad [0][0] = 17.139826


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2727
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.127427
Layer 0 weight grad [0][0] = 14.139234


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2728
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.618831
Layer 0 weight grad [0][0] = 15.794514


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2729
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.606628
Layer 0 weight grad [0][0] = 16.452198


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2730
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.595887
Layer 0 weight grad [0][0] = 15.256743


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2731
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.135876
Layer 0 weight grad [0][0] = 14.642409


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 2732
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.576926
Layer 0 weight grad [0][0] = 17.095425


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2733
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.563298
Layer 0 weight grad [0][0] = 14.133956


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2734
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.550814
Layer 0 weight grad [0][0] = 14.815286


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 2735
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.539361
Layer 0 weight grad [0][0] = 13.748231


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2736
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.015071
Layer 0 weight grad [0][0] = 16.686890


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2737
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.012039
Layer 0 weight grad [0][0] = 16.094917


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2738
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.597870
Layer 0 weight grad [0][0] = 14.261436


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2739
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.494814
Layer 0 weight grad [0][0] = 15.351626


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2740
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.484656
Layer 0 weight grad [0][0] = 14.940035


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2741
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.708770
Layer 0 weight grad [0][0] = 16.254827


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2742
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.488013
Layer 0 weight grad [0][0] = 19.434723


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2743
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.116507
Layer 0 weight grad [0][0] = 14.730287


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2744
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.060359
Layer 0 weight grad [0][0] = 17.098276


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2745
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.556308
Layer 0 weight grad [0][0] = 15.170564


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 2746
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.543984
Layer 0 weight grad [0][0] = 14.372911


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2747
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.536221
Layer 0 weight grad [0][0] = 17.396418


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2748
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.663375
Layer 0 weight grad [0][0] = 15.862713


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2749
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.545205
Layer 0 weight grad [0][0] = 15.287481


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2750
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.181326
Layer 0 weight grad [0][0] = 16.557022


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2751
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.529657
Layer 0 weight grad [0][0] = 14.090633


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2752
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.524347
Layer 0 weight grad [0][0] = 16.540737


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 2753
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.498803
Layer 0 weight grad [0][0] = 15.779464


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2754
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.509884
Layer 0 weight grad [0][0] = 15.630536


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2755
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.009882
Layer 0 weight grad [0][0] = 14.432169


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2756
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.014947
Layer 0 weight grad [0][0] = 14.289174


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2757
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.789950
Layer 0 weight grad [0][0] = 14.811937


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2758
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.215213
Layer 0 weight grad [0][0] = 16.511084


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2759
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.496229
Layer 0 weight grad [0][0] = 12.228835


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2760
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.418842
Layer 0 weight grad [0][0] = 19.175781


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2761
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.561530
Layer 0 weight grad [0][0] = 10.662818


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 2762
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.806281
Layer 0 weight grad [0][0] = 16.498224


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2763
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.463266
Layer 0 weight grad [0][0] = 17.442646


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2764
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.042136
Layer 0 weight grad [0][0] = 15.716851


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2765
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.043955
Layer 0 weight grad [0][0] = 14.469473


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2766
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.394627
Layer 0 weight grad [0][0] = 15.311641


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2767
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.512895
Layer 0 weight grad [0][0] = 16.502258


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2768
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.471168
Layer 0 weight grad [0][0] = 21.044628


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2769
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.532973
Layer 0 weight grad [0][0] = 15.367085


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2770
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.083145
Layer 0 weight grad [0][0] = 15.500348


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2771
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.534380
Layer 0 weight grad [0][0] = 13.843554


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2772
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.041164
Layer 0 weight grad [0][0] = 15.721258


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2773
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.999650
Layer 0 weight grad [0][0] = 15.306437


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2774
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.474556
Layer 0 weight grad [0][0] = 17.700418


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2775
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.509221
Layer 0 weight grad [0][0] = 15.514200


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2776
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.239697
Layer 0 weight grad [0][0] = 17.839432


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2777
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.484540
Layer 0 weight grad [0][0] = 15.437499


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2778
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.521648
Layer 0 weight grad [0][0] = 11.063712


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2779
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.384495
Layer 0 weight grad [0][0] = 18.807211


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2780
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.463926
Layer 0 weight grad [0][0] = 16.191851


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2781
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.038222
Layer 0 weight grad [0][0] = 15.122690


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2782
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.463416
Layer 0 weight grad [0][0] = 18.361496


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 2783
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.459464
Layer 0 weight grad [0][0] = 12.308983


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2784
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.348977
Layer 0 weight grad [0][0] = 15.350872


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2785
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.364706
Layer 0 weight grad [0][0] = 15.252545


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2786
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.363717
Layer 0 weight grad [0][0] = 16.111841


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2787
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.361702
Layer 0 weight grad [0][0] = 15.093940


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2788
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.393524
Layer 0 weight grad [0][0] = 12.108292


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2789
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.530018
Layer 0 weight grad [0][0] = 15.033309


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2790
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.224847
Layer 0 weight grad [0][0] = 16.449324


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2791
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.242277
Layer 0 weight grad [0][0] = 15.102480


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2792
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.270053
Layer 0 weight grad [0][0] = 15.898778


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2793
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.092600
Layer 0 weight grad [0][0] = 15.860521


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2794
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.238829
Layer 0 weight grad [0][0] = 16.743538


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2795
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.253155
Layer 0 weight grad [0][0] = 15.887328


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2796
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.305974
Layer 0 weight grad [0][0] = 14.267834


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2797
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.315349
Layer 0 weight grad [0][0] = 14.781493


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2798
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.247119
Layer 0 weight grad [0][0] = 18.463190


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2799
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.315531
Layer 0 weight grad [0][0] = 14.184809


Training loss: 2.302585
Training accuracy: 0.375000

epoch: 2800
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.300225
Layer 0 weight grad [0][0] = 15.671812


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2801
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.840759
Layer 0 weight grad [0][0] = 14.644403


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2802
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.246573
Layer 0 weight grad [0][0] = 16.943501


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2803
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.945699
Layer 0 weight grad [0][0] = 16.032726


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2804
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.251353
Layer 0 weight grad [0][0] = 18.756826


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 2805
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.327329
Layer 0 weight grad [0][0] = 14.867580


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 2806
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.366415
Layer 0 weight grad [0][0] = 14.382629


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2807
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.366909
Layer 0 weight grad [0][0] = 15.049452


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2808
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.227433
Layer 0 weight grad [0][0] = 11.927293


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2809
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.220777
Layer 0 weight grad [0][0] = 15.148925


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2810
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.287359
Layer 0 weight grad [0][0] = 14.904783


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2811
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.244169
Layer 0 weight grad [0][0] = 16.159372


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2812
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.234690
Layer 0 weight grad [0][0] = 15.199907


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2813
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.125187
Layer 0 weight grad [0][0] = 17.903202


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2814
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.738972
Layer 0 weight grad [0][0] = 14.432431


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2815
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.332822
Layer 0 weight grad [0][0] = 14.442726


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2816
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.172068
Layer 0 weight grad [0][0] = 17.907581


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2817
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.839096
Layer 0 weight grad [0][0] = 14.655990


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2818
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.262863
Layer 0 weight grad [0][0] = 18.191902


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2819
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.255817
Layer 0 weight grad [0][0] = 17.773010


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 2820
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.239473
Layer 0 weight grad [0][0] = 14.889322


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2821
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.269711
Layer 0 weight grad [0][0] = 19.970064


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2822
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.307543
Layer 0 weight grad [0][0] = 15.775746


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2823
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.610769
Layer 0 weight grad [0][0] = 12.842633


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2824
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.238166
Layer 0 weight grad [0][0] = 18.306379


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2825
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.180364
Layer 0 weight grad [0][0] = 15.496583


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2826
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.299670
Layer 0 weight grad [0][0] = 12.594559


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2827
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.247039
Layer 0 weight grad [0][0] = 16.344286


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2828
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.397321
Layer 0 weight grad [0][0] = 13.865925


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2829
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.262104
Layer 0 weight grad [0][0] = 18.909918


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2830
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.289132
Layer 0 weight grad [0][0] = 15.038325


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 2831
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.005920
Layer 0 weight grad [0][0] = 14.236406


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2832
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.795456
Layer 0 weight grad [0][0] = 17.871120


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2833
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.864969
Layer 0 weight grad [0][0] = 19.575336


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2834
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.040434
Layer 0 weight grad [0][0] = 17.283657


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2835
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.028629
Layer 0 weight grad [0][0] = 14.722612


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2836
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.204828
Layer 0 weight grad [0][0] = 16.075390


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2837
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.011916
Layer 0 weight grad [0][0] = 14.696006


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2838
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.036336
Layer 0 weight grad [0][0] = 15.891262


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2839
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.172755
Layer 0 weight grad [0][0] = 15.380781


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2840
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.792803
Layer 0 weight grad [0][0] = 14.547878


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2841
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.233542
Layer 0 weight grad [0][0] = 14.175927


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2842
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.911227
Layer 0 weight grad [0][0] = 15.327534


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2843
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.180215
Layer 0 weight grad [0][0] = 20.061230


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2844
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.174373
Layer 0 weight grad [0][0] = 18.148636


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2845
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.736986
Layer 0 weight grad [0][0] = 14.469187


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2846
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.299622
Layer 0 weight grad [0][0] = 14.382376


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2847
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.272787
Layer 0 weight grad [0][0] = 13.326771


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2848
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000004 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.273098
Layer 0 weight grad [0][0] = 20.689053


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2849
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.263632
Layer 0 weight grad [0][0] = 11.680501


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2850
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000051 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.747169
Layer 0 weight grad [0][0] = 13.931301


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2851
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.208584
Layer 0 weight grad [0][0] = 14.469516


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2852
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.177353
Layer 0 weight grad [0][0] = 14.529035


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2853
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.233017
Layer 0 weight grad [0][0] = 13.983138


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2854
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.188981
Layer 0 weight grad [0][0] = 14.996781


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2855
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.365947
Layer 0 weight grad [0][0] = 14.529009


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 2856
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.067846
Layer 0 weight grad [0][0] = 13.668663


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2857
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.158190
Layer 0 weight grad [0][0] = 14.855539


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2858
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.805946
Layer 0 weight grad [0][0] = 12.600997


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2859
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.080367
Layer 0 weight grad [0][0] = 15.897099


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2860
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.671860
Layer 0 weight grad [0][0] = 14.705765


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2861
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.053844
Layer 0 weight grad [0][0] = 12.205908


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2862
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.390396
Layer 0 weight grad [0][0] = 14.533037


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2863
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.210859
Layer 0 weight grad [0][0] = 14.898633


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2864
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.000904
Layer 0 weight grad [0][0] = 17.940662


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2865
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.076119
Layer 0 weight grad [0][0] = 14.955146


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2866
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.616621
Layer 0 weight grad [0][0] = 14.700569


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2867
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.057949
Layer 0 weight grad [0][0] = 15.612167


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2868
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000004 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.048531
Layer 0 weight grad [0][0] = 14.978517


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2869
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.039024
Layer 0 weight grad [0][0] = 14.434369


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2870
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.027238
Layer 0 weight grad [0][0] = 14.724063


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2871
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.497956
Layer 0 weight grad [0][0] = 18.584536


Training loss: 2.302585
Training accuracy: 0.437500

epoch: 2872
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.134730
Layer 0 weight grad [0][0] = 14.314653


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2873
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.577003
Layer 0 weight grad [0][0] = 19.636999


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2874
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.653442
Layer 0 weight grad [0][0] = 13.810763


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2875
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.185725
Layer 0 weight grad [0][0] = 17.083534


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2876
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.156289
Layer 0 weight grad [0][0] = 15.047511


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2877
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.167599
Layer 0 weight grad [0][0] = 17.504652


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2878
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.159889
Layer 0 weight grad [0][0] = 15.022072


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2879
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.383437
Layer 0 weight grad [0][0] = 14.717971


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2880
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.712640
Layer 0 weight grad [0][0] = 14.380576


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2881
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.359612
Layer 0 weight grad [0][0] = 14.771416


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 2882
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.353516
Layer 0 weight grad [0][0] = 17.566216


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2883
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.594029
Layer 0 weight grad [0][0] = 15.370639


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2884
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.128439
Layer 0 weight grad [0][0] = 15.882132


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2885
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.141840
Layer 0 weight grad [0][0] = 11.396015


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2886
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.435026
Layer 0 weight grad [0][0] = 14.083432


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2887
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.524408
Layer 0 weight grad [0][0] = 11.515906


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2888
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.085011
Layer 0 weight grad [0][0] = 18.482737


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2889
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.013886
Layer 0 weight grad [0][0] = 14.771165


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2890
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.034018
Layer 0 weight grad [0][0] = 14.756251


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2891
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000004 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.222224
Layer 0 weight grad [0][0] = 13.887383


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2892
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.520546
Layer 0 weight grad [0][0] = 12.312301


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 2893
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.036884
Layer 0 weight grad [0][0] = 14.616332


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2894
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -3.144644
Layer 0 weight grad [0][0] = 15.748741


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2895
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.039539
Layer 0 weight grad [0][0] = 17.090857


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2896
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.046690
Layer 0 weight grad [0][0] = 22.329571


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2897
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.036146
Layer 0 weight grad [0][0] = 19.083576


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2898
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.648490
Layer 0 weight grad [0][0] = 14.616206


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2899
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.031593
Layer 0 weight grad [0][0] = 18.981771


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2900
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.039796
Layer 0 weight grad [0][0] = 14.580985


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2901
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.144976
Layer 0 weight grad [0][0] = 15.386344


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2902
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.050725
Layer 0 weight grad [0][0] = 14.294158


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2903
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.708794
Layer 0 weight grad [0][0] = 22.749128


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2904
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.193782
Layer 0 weight grad [0][0] = 13.883184


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2905
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.854140
Layer 0 weight grad [0][0] = 14.115520


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2906
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.148150
Layer 0 weight grad [0][0] = 14.402738


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2907
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.139221
Layer 0 weight grad [0][0] = 17.266418


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2908
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.423419
Layer 0 weight grad [0][0] = 15.681432


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2909
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.102430
Layer 0 weight grad [0][0] = 14.121890


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2910
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.147155
Layer 0 weight grad [0][0] = 20.488672


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2911
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.287956
Layer 0 weight grad [0][0] = 14.729937


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 2912
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.205440
Layer 0 weight grad [0][0] = 12.872974


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2913
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.212498
Layer 0 weight grad [0][0] = 14.998681


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2914
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.023976
Layer 0 weight grad [0][0] = 14.130008


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2915
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.167617
Layer 0 weight grad [0][0] = 25.422707


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2916
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.147899
Layer 0 weight grad [0][0] = 15.654035


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 2917
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.165325
Layer 0 weight grad [0][0] = 26.224430


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2918
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.064988
Layer 0 weight grad [0][0] = 15.815100


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2919
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.422545
Layer 0 weight grad [0][0] = 21.055656


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2920
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.219562
Layer 0 weight grad [0][0] = 13.561976


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2921
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.254484
Layer 0 weight grad [0][0] = 10.564466


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 2922
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.189216
Layer 0 weight grad [0][0] = 12.986035


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2923
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.191294
Layer 0 weight grad [0][0] = 13.472039


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2924
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.131647
Layer 0 weight grad [0][0] = 13.925230


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2925
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.107663
Layer 0 weight grad [0][0] = 13.647513


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2926
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.084679
Layer 0 weight grad [0][0] = 20.163073


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2927
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.808569
Layer 0 weight grad [0][0] = 13.437909


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 2928
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.750231
Layer 0 weight grad [0][0] = 12.992461


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2929
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.216790
Layer 0 weight grad [0][0] = 15.052186


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2930
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.194943
Layer 0 weight grad [0][0] = 13.263580


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2931
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.210859
Layer 0 weight grad [0][0] = 28.648952


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 2932
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.743869
Layer 0 weight grad [0][0] = 13.847008


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2933
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.122797
Layer 0 weight grad [0][0] = 13.582521


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2934
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.644168
Layer 0 weight grad [0][0] = 15.156557


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2935
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.155925
Layer 0 weight grad [0][0] = 14.840205


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2936
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.428410
Layer 0 weight grad [0][0] = 14.732141


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2937
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.718933
Layer 0 weight grad [0][0] = 28.527517


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2938
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.779915
Layer 0 weight grad [0][0] = 27.707012


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2939
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.616563
Layer 0 weight grad [0][0] = 12.714861


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2940
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.658239
Layer 0 weight grad [0][0] = 14.207077


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2941
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000004 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2.339368
Layer 0 weight grad [0][0] = 15.109030


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2942
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.464211
Layer 0 weight grad [0][0] = 13.673014


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2943
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.000396
Layer 0 weight grad [0][0] = 13.194039


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2944
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.001709
Layer 0 weight grad [0][0] = 12.340181


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2945
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.019003
Layer 0 weight grad [0][0] = 20.410910


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2946
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.372496
Layer 0 weight grad [0][0] = 26.276093


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2947
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.109853
Layer 0 weight grad [0][0] = 13.328897


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2948
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.859182
Layer 0 weight grad [0][0] = 13.138004


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2949
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.057763
Layer 0 weight grad [0][0] = 13.571472


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2950
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.017676
Layer 0 weight grad [0][0] = 14.394903


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2951
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.050074
Layer 0 weight grad [0][0] = 12.891321


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2952
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.045341
Layer 0 weight grad [0][0] = 15.416276


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2953
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.076415
Layer 0 weight grad [0][0] = 13.038342


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2954
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.055802
Layer 0 weight grad [0][0] = 22.172621


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2955
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.185160
Layer 0 weight grad [0][0] = 16.397518


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2956
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.797611
Layer 0 weight grad [0][0] = 12.647341


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2957
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.183218
Layer 0 weight grad [0][0] = 20.779585


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2958
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.277940
Layer 0 weight grad [0][0] = 20.167835


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2959
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.402257
Layer 0 weight grad [0][0] = 12.935535


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 2960
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.932326
Layer 0 weight grad [0][0] = 13.509156


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2961
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.345664
Layer 0 weight grad [0][0] = 20.610264


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2962
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.168500
Layer 0 weight grad [0][0] = 12.821380


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 2963
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.452054
Layer 0 weight grad [0][0] = 14.104833


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 2964
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.980046
Layer 0 weight grad [0][0] = 12.595295


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2965
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000004 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.409252
Layer 0 weight grad [0][0] = 13.015738


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2966
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.311032
Layer 0 weight grad [0][0] = 12.061254


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2967
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.127405
Layer 0 weight grad [0][0] = 12.819016


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2968
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.331616
Layer 0 weight grad [0][0] = 19.712791


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2969
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.044703
Layer 0 weight grad [0][0] = 27.136629


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2970
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.442538
Layer 0 weight grad [0][0] = 13.411128


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2971
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.212691
Layer 0 weight grad [0][0] = 12.712556


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2972
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.388566
Layer 0 weight grad [0][0] = 16.702274


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 2973
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.396388
Layer 0 weight grad [0][0] = 12.340808


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2974
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.331872
Layer 0 weight grad [0][0] = 14.694903


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2975
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.211069
Layer 0 weight grad [0][0] = 12.307139


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2976
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.280020
Layer 0 weight grad [0][0] = 30.085220


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2977
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.339070
Layer 0 weight grad [0][0] = 20.194948


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2978
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.478136
Layer 0 weight grad [0][0] = 13.137626


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2979
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.430655
Layer 0 weight grad [0][0] = 16.344780


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2980
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.408098
Layer 0 weight grad [0][0] = 13.348112


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2981
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.386973
Layer 0 weight grad [0][0] = 16.445795


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2982
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.076978
Layer 0 weight grad [0][0] = 13.394836


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2983
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.965333
Layer 0 weight grad [0][0] = 13.465059


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2984
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.102023
Layer 0 weight grad [0][0] = 13.310576


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2985
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.551790
Layer 0 weight grad [0][0] = 12.953124


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2986
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.341594
Layer 0 weight grad [0][0] = 14.298940


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2987
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.322928
Layer 0 weight grad [0][0] = 13.998049


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2988
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.302978
Layer 0 weight grad [0][0] = 25.975739


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2989
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.283832
Layer 0 weight grad [0][0] = 20.115656


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2990
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.444951
Layer 0 weight grad [0][0] = 14.042080


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 2991
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.387153
Layer 0 weight grad [0][0] = 20.243317


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2992
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.005860
Layer 0 weight grad [0][0] = 13.084554


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2993
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.473981
Layer 0 weight grad [0][0] = 13.302941


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2994
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.472018
Layer 0 weight grad [0][0] = 13.427784


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2995
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.251560
Layer 0 weight grad [0][0] = 24.403309


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2996
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.470423
Layer 0 weight grad [0][0] = 13.220546


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 2997
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.645104
Layer 0 weight grad [0][0] = 14.329223


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 2998
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.405664
Layer 0 weight grad [0][0] = 24.911489


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 2999
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.428497
Layer 0 weight grad [0][0] = 24.977825


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3000
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.359643
Layer 0 weight grad [0][0] = 13.446416


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3001
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.566704
Layer 0 weight grad [0][0] = 15.090401


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3002
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.166302
Layer 0 weight grad [0][0] = 24.021599


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3003
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.332539
Layer 0 weight grad [0][0] = 14.371549


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3004
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.313353
Layer 0 weight grad [0][0] = 13.782461


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3005
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.300470
Layer 0 weight grad [0][0] = 15.662396


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3006
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.287653
Layer 0 weight grad [0][0] = 14.027897


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3007
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.271733
Layer 0 weight grad [0][0] = 23.480772


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3008
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.257179
Layer 0 weight grad [0][0] = 14.818201


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3009
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.256872
Layer 0 weight grad [0][0] = 19.216927


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3010
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.375141
Layer 0 weight grad [0][0] = 24.825485


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3011
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.641406
Layer 0 weight grad [0][0] = 14.313543


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3012
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.147328
Layer 0 weight grad [0][0] = 13.533075


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3013
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.111369
Layer 0 weight grad [0][0] = 14.564490


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3014
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.869769
Layer 0 weight grad [0][0] = 15.148994


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 3015
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.768582
Layer 0 weight grad [0][0] = 14.216589


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3016
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.301632
Layer 0 weight grad [0][0] = 13.593820


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3017
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.786820
Layer 0 weight grad [0][0] = 13.809308


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3018
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.251115
Layer 0 weight grad [0][0] = 16.015692


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3019
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.220160
Layer 0 weight grad [0][0] = 19.672142


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3020
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.396646
Layer 0 weight grad [0][0] = 13.988908


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3021
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.171010
Layer 0 weight grad [0][0] = 24.068884


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3022
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.195302
Layer 0 weight grad [0][0] = 23.262018


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3023
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.855911
Layer 0 weight grad [0][0] = 24.505386


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3024
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.205067
Layer 0 weight grad [0][0] = 14.621599


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3025
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.778527
Layer 0 weight grad [0][0] = 12.826490


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 3026
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.215059
Layer 0 weight grad [0][0] = 15.302186


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3027
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.941118
Layer 0 weight grad [0][0] = 15.934300


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3028
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.077710
Layer 0 weight grad [0][0] = 13.876472


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3029
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.291740
Layer 0 weight grad [0][0] = 14.064744


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3030
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.303338
Layer 0 weight grad [0][0] = 18.258101


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3031
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.454777
Layer 0 weight grad [0][0] = 20.855091


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3032
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.842599
Layer 0 weight grad [0][0] = 13.388292


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3033
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.488937
Layer 0 weight grad [0][0] = 13.643171


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3034
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.474008
Layer 0 weight grad [0][0] = 14.952733


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3035
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.490008
Layer 0 weight grad [0][0] = 11.958668


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3036
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.475569
Layer 0 weight grad [0][0] = 13.527011


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3037
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.462333
Layer 0 weight grad [0][0] = 20.836653


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3038
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.616608
Layer 0 weight grad [0][0] = 13.409410


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3039
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000004 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.515488
Layer 0 weight grad [0][0] = 13.110174


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3040
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.551948
Layer 0 weight grad [0][0] = 13.999129


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3041
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.148201
Layer 0 weight grad [0][0] = 13.191344


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3042
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.008442
Layer 0 weight grad [0][0] = 14.240442


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3043
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.505656
Layer 0 weight grad [0][0] = 12.828566


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3044
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.513319
Layer 0 weight grad [0][0] = 12.586690


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3045
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.001028
Layer 0 weight grad [0][0] = 12.794559


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3046
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.609053
Layer 0 weight grad [0][0] = 14.339188


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3047
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.492393
Layer 0 weight grad [0][0] = 13.733923


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3048
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.538218
Layer 0 weight grad [0][0] = 16.316990


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3049
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.392266
Layer 0 weight grad [0][0] = 13.470942


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3050
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.327613
Layer 0 weight grad [0][0] = 13.175689


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3051
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.361966
Layer 0 weight grad [0][0] = 14.187217


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3052
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.337582
Layer 0 weight grad [0][0] = 14.034945


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3053
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.194037
Layer 0 weight grad [0][0] = 19.378872


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3054
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.690051
Layer 0 weight grad [0][0] = 14.255987


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3055
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.018578
Layer 0 weight grad [0][0] = 15.947699


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3056
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.372716
Layer 0 weight grad [0][0] = 14.065091


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3057
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.909282
Layer 0 weight grad [0][0] = 12.447997


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3058
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.345701
Layer 0 weight grad [0][0] = 16.510036


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3059
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.367189
Layer 0 weight grad [0][0] = 13.928063


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3060
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.406772
Layer 0 weight grad [0][0] = 23.131260


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3061
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.294298
Layer 0 weight grad [0][0] = 19.928162


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3062
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.374078
Layer 0 weight grad [0][0] = 14.598747


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3063
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.379559
Layer 0 weight grad [0][0] = 23.651392


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3064
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.160821
Layer 0 weight grad [0][0] = 13.838156


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3065
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.168342
Layer 0 weight grad [0][0] = 13.166308


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3066
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.331992
Layer 0 weight grad [0][0] = 22.283430


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3067
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.111027
Layer 0 weight grad [0][0] = 16.287666


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3068
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.091514
Layer 0 weight grad [0][0] = 13.481124


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3069
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.237141
Layer 0 weight grad [0][0] = 13.347298


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3070
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.393273
Layer 0 weight grad [0][0] = 13.881907


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3071
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.258648
Layer 0 weight grad [0][0] = 13.105147


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3072
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.589517
Layer 0 weight grad [0][0] = 16.610592


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3073
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.307858
Layer 0 weight grad [0][0] = 16.199286


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3074
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.137262
Layer 0 weight grad [0][0] = 16.685635


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3075
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.346085
Layer 0 weight grad [0][0] = 13.034532


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3076
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.324827
Layer 0 weight grad [0][0] = 17.255474


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3077
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.092809
Layer 0 weight grad [0][0] = 18.677416


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3078
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.554357
Layer 0 weight grad [0][0] = 13.908665


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3079
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.480222
Layer 0 weight grad [0][0] = 14.053398


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3080
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.466260
Layer 0 weight grad [0][0] = 15.392289


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3081
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.471432
Layer 0 weight grad [0][0] = 23.373758


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3082
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.456752
Layer 0 weight grad [0][0] = 12.763928


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3083
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.236352
Layer 0 weight grad [0][0] = 15.424635


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3084
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.104851
Layer 0 weight grad [0][0] = 13.802510


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3085
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.382539
Layer 0 weight grad [0][0] = 12.771626


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3086
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.405986
Layer 0 weight grad [0][0] = 14.026871


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3087
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.646899
Layer 0 weight grad [0][0] = 12.759264


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3088
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.595769
Layer 0 weight grad [0][0] = 13.762155


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3089
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.301949
Layer 0 weight grad [0][0] = 13.773590


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3090
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.078976
Layer 0 weight grad [0][0] = 14.209145


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3091
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.799348
Layer 0 weight grad [0][0] = 13.062361


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3092
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.239784
Layer 0 weight grad [0][0] = 14.035220


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3093
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.875775
Layer 0 weight grad [0][0] = 13.572604


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3094
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.172233
Layer 0 weight grad [0][0] = 17.267643


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 3095
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.213682
Layer 0 weight grad [0][0] = 13.151443


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3096
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.274549
Layer 0 weight grad [0][0] = 18.729963


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 3097
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.323336
Layer 0 weight grad [0][0] = 23.443247


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3098
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.084822
Layer 0 weight grad [0][0] = 15.789783


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3099
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.273545
Layer 0 weight grad [0][0] = 14.568481


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3100
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.831078
Layer 0 weight grad [0][0] = 13.158931


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3101
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.249404
Layer 0 weight grad [0][0] = 13.441102


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3102
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.237860
Layer 0 weight grad [0][0] = 22.707930


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3103
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.269444
Layer 0 weight grad [0][0] = 13.252816


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3104
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.235168
Layer 0 weight grad [0][0] = 16.713089


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3105
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.115178
Layer 0 weight grad [0][0] = 13.614057


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3106
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.224717
Layer 0 weight grad [0][0] = 21.718313


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3107
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.214154
Layer 0 weight grad [0][0] = 15.640708


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3108
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.005355
Layer 0 weight grad [0][0] = 17.267448


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3109
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.594891
Layer 0 weight grad [0][0] = 14.060283


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3110
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.139329
Layer 0 weight grad [0][0] = 15.595627


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3111
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.410272
Layer 0 weight grad [0][0] = 17.718964


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3112
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.332980
Layer 0 weight grad [0][0] = 14.025235


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3113
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.191284
Layer 0 weight grad [0][0] = 14.158190


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3114
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.825596
Layer 0 weight grad [0][0] = 16.586050


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3115
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.090945
Layer 0 weight grad [0][0] = 13.488714


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3116
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.074055
Layer 0 weight grad [0][0] = 13.692571


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3117
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.146153
Layer 0 weight grad [0][0] = 13.808240


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3118
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.459173
Layer 0 weight grad [0][0] = 13.358027


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3119
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.580283
Layer 0 weight grad [0][0] = 12.630500


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 3120
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.480701
Layer 0 weight grad [0][0] = 26.990913


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3121
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.108887
Layer 0 weight grad [0][0] = 13.860211


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3122
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.530148
Layer 0 weight grad [0][0] = 14.435899


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3123
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.445038
Layer 0 weight grad [0][0] = 16.261055


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3124
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.101596
Layer 0 weight grad [0][0] = 12.208893


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3125
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.085553
Layer 0 weight grad [0][0] = 21.615772


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3126
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.110422
Layer 0 weight grad [0][0] = 14.405345


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3127
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.454573
Layer 0 weight grad [0][0] = 15.985302


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3128
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.047378
Layer 0 weight grad [0][0] = 17.726591


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3129
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.127163
Layer 0 weight grad [0][0] = 13.803191


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3130
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.033212
Layer 0 weight grad [0][0] = 13.947783


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3131
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.079914
Layer 0 weight grad [0][0] = 13.559582


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3132
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.445172
Layer 0 weight grad [0][0] = 13.975991


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3133
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.060541
Layer 0 weight grad [0][0] = 13.180050


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3134
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.033497
Layer 0 weight grad [0][0] = 14.580740


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3135
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.041188
Layer 0 weight grad [0][0] = 14.774049


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3136
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.671439
Layer 0 weight grad [0][0] = 17.105404


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3137
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.060941
Layer 0 weight grad [0][0] = 21.225090


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3138
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.013817
Layer 0 weight grad [0][0] = 19.365582


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3139
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.412971
Layer 0 weight grad [0][0] = 20.585377


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3140
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.535526
Layer 0 weight grad [0][0] = 13.671096


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3141
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.179490
Layer 0 weight grad [0][0] = 21.220177


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3142
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.339512
Layer 0 weight grad [0][0] = 12.924870


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3143
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.001191
Layer 0 weight grad [0][0] = 16.463230


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3144
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.508209
Layer 0 weight grad [0][0] = 14.454745


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3145
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.034437
Layer 0 weight grad [0][0] = 12.995336


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3146
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.042640
Layer 0 weight grad [0][0] = 14.025520


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3147
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.028819
Layer 0 weight grad [0][0] = 13.821487


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3148
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.025217
Layer 0 weight grad [0][0] = 22.433861


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 3149
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.035624
Layer 0 weight grad [0][0] = 14.643044


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3150
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.250230
Layer 0 weight grad [0][0] = 13.466409


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3151
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.060240
Layer 0 weight grad [0][0] = 15.783878


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 3152
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.585245
Layer 0 weight grad [0][0] = 14.634185


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3153
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.100442
Layer 0 weight grad [0][0] = 23.637005


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3154
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.456871
Layer 0 weight grad [0][0] = 13.686294


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3155
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.309393
Layer 0 weight grad [0][0] = 15.479347


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3156
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.587848
Layer 0 weight grad [0][0] = 14.182532


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3157
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.115520
Layer 0 weight grad [0][0] = 13.842478


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3158
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.166309
Layer 0 weight grad [0][0] = 14.853429


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3159
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.176890
Layer 0 weight grad [0][0] = 20.015551


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3160
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.125374
Layer 0 weight grad [0][0] = 14.636868


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3161
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.168148
Layer 0 weight grad [0][0] = 23.079090


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3162
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.301728
Layer 0 weight grad [0][0] = 23.752087


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3163
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.199624
Layer 0 weight grad [0][0] = 23.226477


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3164
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.727157
Layer 0 weight grad [0][0] = 18.410738


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3165
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.110560
Layer 0 weight grad [0][0] = 13.500371


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3166
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.622531
Layer 0 weight grad [0][0] = 18.107679


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3167
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.026890
Layer 0 weight grad [0][0] = 13.389095


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3168
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.536561
Layer 0 weight grad [0][0] = 25.933846


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3169
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.533889
Layer 0 weight grad [0][0] = 30.968937


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3170
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.087641
Layer 0 weight grad [0][0] = 16.321680


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3171
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.078908
Layer 0 weight grad [0][0] = 13.365867


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3172
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.814325
Layer 0 weight grad [0][0] = 13.271070


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3173
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.123335
Layer 0 weight grad [0][0] = 14.762122


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3174
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.066325
Layer 0 weight grad [0][0] = 14.244675


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3175
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.056359
Layer 0 weight grad [0][0] = 12.940272


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3176
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.043069
Layer 0 weight grad [0][0] = 26.757816


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3177
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.182813
Layer 0 weight grad [0][0] = 14.985333


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3178
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.020870
Layer 0 weight grad [0][0] = 13.594690


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3179
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.049672
Layer 0 weight grad [0][0] = 14.909111


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3180
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.001530
Layer 0 weight grad [0][0] = 13.578526


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3181
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.532329
Layer 0 weight grad [0][0] = 13.584368


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3182
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.001243
Layer 0 weight grad [0][0] = 13.780756


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3183
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.015016
Layer 0 weight grad [0][0] = 12.156199


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3184
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.088068
Layer 0 weight grad [0][0] = 13.209051


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3185
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.577516
Layer 0 weight grad [0][0] = 13.013998


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3186
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.084780
Layer 0 weight grad [0][0] = 20.419390


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3187
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.038352
Layer 0 weight grad [0][0] = 18.769947


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3188
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.632495
Layer 0 weight grad [0][0] = 33.058174


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3189
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.234804
Layer 0 weight grad [0][0] = 25.659416


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3190
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.245565
Layer 0 weight grad [0][0] = 13.233405


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3191
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.239962
Layer 0 weight grad [0][0] = 13.644650


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3192
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.252611
Layer 0 weight grad [0][0] = 14.653596


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3193
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.280537
Layer 0 weight grad [0][0] = 19.702816


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3194
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.340790
Layer 0 weight grad [0][0] = 12.891717


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3195
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.399824
Layer 0 weight grad [0][0] = 15.294586


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 3196
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.342840
Layer 0 weight grad [0][0] = 14.494928


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3197
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.368542
Layer 0 weight grad [0][0] = 14.955815


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3198
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.360011
Layer 0 weight grad [0][0] = 12.643957


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3199
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.151947
Layer 0 weight grad [0][0] = 19.647816


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3200
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.482879
Layer 0 weight grad [0][0] = 14.852997


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3201
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.508978
Layer 0 weight grad [0][0] = 17.485363


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3202
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.569791
Layer 0 weight grad [0][0] = 13.541459


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3203
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.518656
Layer 0 weight grad [0][0] = 26.466213


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3204
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.509006
Layer 0 weight grad [0][0] = 13.639997


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3205
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.106906
Layer 0 weight grad [0][0] = 13.962672


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3206
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.496340
Layer 0 weight grad [0][0] = 13.190384


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3207
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.484592
Layer 0 weight grad [0][0] = 13.848372


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3208
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.615811
Layer 0 weight grad [0][0] = 13.188914


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3209
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.458333
Layer 0 weight grad [0][0] = 15.594342


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3210
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.506744
Layer 0 weight grad [0][0] = 27.922626


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3211
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.038524
Layer 0 weight grad [0][0] = 18.422117


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3212
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.473026
Layer 0 weight grad [0][0] = 18.019787


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3213
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.796958
Layer 0 weight grad [0][0] = 26.097475


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 3214
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.100835
Layer 0 weight grad [0][0] = 13.116462


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3215
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.687968
Layer 0 weight grad [0][0] = 26.357388


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3216
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.694837
Layer 0 weight grad [0][0] = 12.760349


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3217
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.679544
Layer 0 weight grad [0][0] = 13.012619


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3218
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.148271
Layer 0 weight grad [0][0] = 18.780405


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3219
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.605378
Layer 0 weight grad [0][0] = 13.912008


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3220
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.586774
Layer 0 weight grad [0][0] = 12.934234


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3221
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.259330
Layer 0 weight grad [0][0] = 13.557686


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3222
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.258603
Layer 0 weight grad [0][0] = 19.824644


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3223
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.903870
Layer 0 weight grad [0][0] = 19.471727


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3224
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.045611
Layer 0 weight grad [0][0] = 27.744888


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3225
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.514972
Layer 0 weight grad [0][0] = 21.077822


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3226
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.192191
Layer 0 weight grad [0][0] = 13.282468


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3227
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000012 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.359752
Layer 0 weight grad [0][0] = 13.558880


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3228
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.176471
Layer 0 weight grad [0][0] = 15.343749


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3229
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.162746
Layer 0 weight grad [0][0] = 13.521057


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3230
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.184806
Layer 0 weight grad [0][0] = 15.267536


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3231
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.744774
Layer 0 weight grad [0][0] = 12.415168


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3232
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.768007
Layer 0 weight grad [0][0] = 13.464436


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3233
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.165302
Layer 0 weight grad [0][0] = 10.989511


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3234
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.699898
Layer 0 weight grad [0][0] = 14.198519


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3235
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.136985
Layer 0 weight grad [0][0] = 14.462212


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3236
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.175600
Layer 0 weight grad [0][0] = 12.687488


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3237
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.936684
Layer 0 weight grad [0][0] = 30.392105


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 3238
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.936789
Layer 0 weight grad [0][0] = 12.184128


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3239
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.105374
Layer 0 weight grad [0][0] = 15.249969


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3240
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.112418
Layer 0 weight grad [0][0] = 29.906406


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3241
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.874210
Layer 0 weight grad [0][0] = 11.160266


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3242
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.581820
Layer 0 weight grad [0][0] = 15.352878


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3243
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.716384
Layer 0 weight grad [0][0] = 12.844492


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3244
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.051079
Layer 0 weight grad [0][0] = 14.093802


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 3245
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.000248
Layer 0 weight grad [0][0] = 13.240211


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3246
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.447061
Layer 0 weight grad [0][0] = 14.404994


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3247
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.948607
Layer 0 weight grad [0][0] = 12.975763


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3248
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.764612
Layer 0 weight grad [0][0] = 14.577701


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3249
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.910026
Layer 0 weight grad [0][0] = 30.099035


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3250
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.427340
Layer 0 weight grad [0][0] = 13.601293


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 3251
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.865827
Layer 0 weight grad [0][0] = 13.232749


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3252
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.660724
Layer 0 weight grad [0][0] = 16.510571


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3253
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.696045
Layer 0 weight grad [0][0] = 13.716321


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3254
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.884045
Layer 0 weight grad [0][0] = 13.916023


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3255
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.352878
Layer 0 weight grad [0][0] = 29.377537


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3256
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.341928
Layer 0 weight grad [0][0] = 12.829517


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3257
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.343362
Layer 0 weight grad [0][0] = 8.450675


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 3258
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.334496
Layer 0 weight grad [0][0] = 17.700792


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3259
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.209557
Layer 0 weight grad [0][0] = 32.038765


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3260
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.213197
Layer 0 weight grad [0][0] = 13.382737


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3261
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.218065
Layer 0 weight grad [0][0] = 14.519865


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3262
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.813524
Layer 0 weight grad [0][0] = 13.581661


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3263
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.835355
Layer 0 weight grad [0][0] = 20.729078


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3264
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.984466
Layer 0 weight grad [0][0] = 13.809141


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3265
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.963485
Layer 0 weight grad [0][0] = 13.355732


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3266
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.457256
Layer 0 weight grad [0][0] = 12.124878


Training loss: 2.302585
Training accuracy: 0.375000

epoch: 3267
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.928496
Layer 0 weight grad [0][0] = 13.299455


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3268
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.871283
Layer 0 weight grad [0][0] = 17.934685


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3269
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.855104
Layer 0 weight grad [0][0] = 19.064720


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3270
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.720763
Layer 0 weight grad [0][0] = 17.068298


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3271
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.887152
Layer 0 weight grad [0][0] = 12.550610


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3272
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.868793
Layer 0 weight grad [0][0] = 12.922565


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3273
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.402696
Layer 0 weight grad [0][0] = 12.375918


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3274
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.204075
Layer 0 weight grad [0][0] = 13.302550


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3275
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.269740
Layer 0 weight grad [0][0] = 11.701528


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3276
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.680986
Layer 0 weight grad [0][0] = 13.264411


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3277
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.471313
Layer 0 weight grad [0][0] = 12.598516


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3278
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.650297
Layer 0 weight grad [0][0] = 13.471514


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3279
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.870263
Layer 0 weight grad [0][0] = 11.366564


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3280
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.548729
Layer 0 weight grad [0][0] = 13.237842


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3281
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.562273
Layer 0 weight grad [0][0] = 10.983335


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3282
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.534129
Layer 0 weight grad [0][0] = 11.702876


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3283
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.452758
Layer 0 weight grad [0][0] = 12.954328


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3284
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.226249
Layer 0 weight grad [0][0] = 12.127733


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3285
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.086694
Layer 0 weight grad [0][0] = 12.957291


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3286
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.960453
Layer 0 weight grad [0][0] = 11.881131


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 3287
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.262211
Layer 0 weight grad [0][0] = 12.773959


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3288
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.303335
Layer 0 weight grad [0][0] = 11.341908


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3289
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.309376
Layer 0 weight grad [0][0] = 12.020650


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3290
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.232129
Layer 0 weight grad [0][0] = 11.893513


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3291
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.002314
Layer 0 weight grad [0][0] = 11.551018


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3292
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.766554
Layer 0 weight grad [0][0] = 12.466020


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3293
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.157630
Layer 0 weight grad [0][0] = 14.110433


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3294
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.360016
Layer 0 weight grad [0][0] = 12.765888


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3295
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.104232
Layer 0 weight grad [0][0] = 12.769521


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3296
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.102031
Layer 0 weight grad [0][0] = 13.642638


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3297
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.117341
Layer 0 weight grad [0][0] = 11.671576


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3298
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.058530
Layer 0 weight grad [0][0] = 12.466187


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3299
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -3.394855
Layer 0 weight grad [0][0] = 18.105988


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3300
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.032992
Layer 0 weight grad [0][0] = 13.374279


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3301
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.137106
Layer 0 weight grad [0][0] = 10.710266


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3302
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.040269
Layer 0 weight grad [0][0] = 12.160686


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3303
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.017269
Layer 0 weight grad [0][0] = 12.544416


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3304
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.045794
Layer 0 weight grad [0][0] = 11.403720


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3305
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.068500
Layer 0 weight grad [0][0] = 11.413028


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3306
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.589902
Layer 0 weight grad [0][0] = 21.246305


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3307
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.088132
Layer 0 weight grad [0][0] = 12.160701


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3308
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.991982
Layer 0 weight grad [0][0] = 34.087479


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3309
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.077086
Layer 0 weight grad [0][0] = 16.363106


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3310
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.506230
Layer 0 weight grad [0][0] = 32.972191


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3311
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.173744
Layer 0 weight grad [0][0] = 11.479906


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 3312
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -4.775392
Layer 0 weight grad [0][0] = 11.018891


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 3313
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.142940
Layer 0 weight grad [0][0] = 21.466679


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3314
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2.913810
Layer 0 weight grad [0][0] = 11.648099


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3315
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.559197
Layer 0 weight grad [0][0] = 21.406612


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3316
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.170240
Layer 0 weight grad [0][0] = 12.256428


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3317
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.655601
Layer 0 weight grad [0][0] = 15.125706


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3318
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.083008
Layer 0 weight grad [0][0] = 15.534727


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3319
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.057457
Layer 0 weight grad [0][0] = 9.270267


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 3320
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.378047
Layer 0 weight grad [0][0] = 15.018024


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3321
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.065798
Layer 0 weight grad [0][0] = 11.645241


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3322
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.442384
Layer 0 weight grad [0][0] = 11.014709


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3323
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.046243
Layer 0 weight grad [0][0] = 10.850760


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 3324
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.022078
Layer 0 weight grad [0][0] = 11.753881


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3325
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.021541
Layer 0 weight grad [0][0] = 37.584656


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3326
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.008395
Layer 0 weight grad [0][0] = 11.375167


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3327
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.736855
Layer 0 weight grad [0][0] = 12.279453


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3328
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.102515
Layer 0 weight grad [0][0] = 12.500983


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3329
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.751880
Layer 0 weight grad [0][0] = 11.242204


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3330
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.173548
Layer 0 weight grad [0][0] = 12.684667


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3331
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -4.804090
Layer 0 weight grad [0][0] = 10.762260


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3332
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.261701
Layer 0 weight grad [0][0] = 11.238958


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3333
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.496988
Layer 0 weight grad [0][0] = 11.832709


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3334
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.654246
Layer 0 weight grad [0][0] = 37.837608


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3335
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.334013
Layer 0 weight grad [0][0] = 11.436759


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3336
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -7.067090
Layer 0 weight grad [0][0] = 11.541347


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3337
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -6.565283
Layer 0 weight grad [0][0] = 11.600968


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3338
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.059479
Layer 0 weight grad [0][0] = 11.571424


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3339
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.020994
Layer 0 weight grad [0][0] = 12.782019


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3340
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.301176
Layer 0 weight grad [0][0] = 13.267079


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3341
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.623404
Layer 0 weight grad [0][0] = 11.961991


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3342
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.612701
Layer 0 weight grad [0][0] = 15.180762


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3343
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.614846
Layer 0 weight grad [0][0] = 11.929935


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3344
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000028 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.827867
Layer 0 weight grad [0][0] = 11.863227


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3345
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.168603
Layer 0 weight grad [0][0] = 37.824390


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3346
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.400797
Layer 0 weight grad [0][0] = 13.718473


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3347
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.374800
Layer 0 weight grad [0][0] = 36.880238


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 3348
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -9.047837
Layer 0 weight grad [0][0] = 12.139103


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3349
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -9.281252
Layer 0 weight grad [0][0] = 11.262920


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3350
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.850037
Layer 0 weight grad [0][0] = 13.086366


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 3351
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.880605
Layer 0 weight grad [0][0] = 36.966534


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3352
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.422419
Layer 0 weight grad [0][0] = 21.487886


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3353
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.723834
Layer 0 weight grad [0][0] = 5.616666


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3354
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.713900
Layer 0 weight grad [0][0] = 13.128785


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3355
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.477114
Layer 0 weight grad [0][0] = 5.986719


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3356
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.312620
Layer 0 weight grad [0][0] = 12.704658


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3357
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.268940
Layer 0 weight grad [0][0] = 5.442878


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3358
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.047417
Layer 0 weight grad [0][0] = 12.319818


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3359
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -9.894085
Layer 0 weight grad [0][0] = 35.798012


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3360
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.427891
Layer 0 weight grad [0][0] = 7.700590


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3361
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.440850
Layer 0 weight grad [0][0] = 14.142788


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3362
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.166162
Layer 0 weight grad [0][0] = 12.364979


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3363
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -10.616036
Layer 0 weight grad [0][0] = 34.121834


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3364
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.056896
Layer 0 weight grad [0][0] = 15.286427


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3365
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.952818
Layer 0 weight grad [0][0] = 12.336471


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3366
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.507100
Layer 0 weight grad [0][0] = 13.548251


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3367
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -11.099435
Layer 0 weight grad [0][0] = 21.057178


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3368
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.888826
Layer 0 weight grad [0][0] = 34.315403


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3369
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.909738
Layer 0 weight grad [0][0] = 12.584436


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3370
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.443929
Layer 0 weight grad [0][0] = 13.478597


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3371
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.027047
Layer 0 weight grad [0][0] = 13.088095


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3372
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.001187
Layer 0 weight grad [0][0] = 15.831280


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3373
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.964707
Layer 0 weight grad [0][0] = 17.176712


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3374
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.435243
Layer 0 weight grad [0][0] = 15.278360


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3375
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.779545
Layer 0 weight grad [0][0] = 12.934930


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3376
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -9.063358
Layer 0 weight grad [0][0] = 32.182888


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3377
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.882884
Layer 0 weight grad [0][0] = 38.643307


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3378
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.239478
Layer 0 weight grad [0][0] = 12.855732


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3379
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.808888
Layer 0 weight grad [0][0] = 17.070538


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3380
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.464431
Layer 0 weight grad [0][0] = 13.463362


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3381
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.733135
Layer 0 weight grad [0][0] = 16.428432


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3382
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.714066
Layer 0 weight grad [0][0] = 20.940907


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3383
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.075279
Layer 0 weight grad [0][0] = 21.123117


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3384
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.905582
Layer 0 weight grad [0][0] = 7.362575


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3385
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.384946
Layer 0 weight grad [0][0] = 12.900576


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3386
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.958613
Layer 0 weight grad [0][0] = 5.617279


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3387
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.430268
Layer 0 weight grad [0][0] = 20.720648


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3388
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.310419
Layer 0 weight grad [0][0] = 14.113910


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3389
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.334129
Layer 0 weight grad [0][0] = 12.220586


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3390
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.767850
Layer 0 weight grad [0][0] = 17.994331


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3391
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.499110
Layer 0 weight grad [0][0] = 35.679131


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3392
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.114588
Layer 0 weight grad [0][0] = 11.394928


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3393
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.353123
Layer 0 weight grad [0][0] = 12.733396


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3394
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.338365
Layer 0 weight grad [0][0] = 2.743335


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3395
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.350468
Layer 0 weight grad [0][0] = 15.124901


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3396
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.419232
Layer 0 weight grad [0][0] = 12.747176


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3397
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.417309
Layer 0 weight grad [0][0] = 12.271790


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3398
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.471664
Layer 0 weight grad [0][0] = 34.214058


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3399
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.494553
Layer 0 weight grad [0][0] = 7.440020


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3400
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.045769
Layer 0 weight grad [0][0] = 4.020585


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3401
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.459640
Layer 0 weight grad [0][0] = 12.701516


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3402
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.478004
Layer 0 weight grad [0][0] = 12.921793


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3403
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.219427
Layer 0 weight grad [0][0] = 8.493140


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3404
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.434051
Layer 0 weight grad [0][0] = 7.010654


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3405
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.161588
Layer 0 weight grad [0][0] = 13.488478


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3406
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.114524
Layer 0 weight grad [0][0] = 12.915329


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3407
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -7.844164
Layer 0 weight grad [0][0] = 13.020170


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3408
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.917156
Layer 0 weight grad [0][0] = 12.191940


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3409
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.733529
Layer 0 weight grad [0][0] = 13.670760


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3410
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.714239
Layer 0 weight grad [0][0] = 19.640585


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3411
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.011536
Layer 0 weight grad [0][0] = 14.151880


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3412
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.132546
Layer 0 weight grad [0][0] = 12.058813


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3413
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.838654
Layer 0 weight grad [0][0] = 12.146770


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3414
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.654870
Layer 0 weight grad [0][0] = 10.799312


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 3415
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.088364
Layer 0 weight grad [0][0] = 11.961448


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3416
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.711666
Layer 0 weight grad [0][0] = 14.121400


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3417
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.157496
Layer 0 weight grad [0][0] = 13.081470


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3418
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.237945
Layer 0 weight grad [0][0] = 12.524013


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3419
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.742135
Layer 0 weight grad [0][0] = 12.942598


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3420
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.206958
Layer 0 weight grad [0][0] = 13.527699


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3421
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.770245
Layer 0 weight grad [0][0] = 14.161507


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3422
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.802183
Layer 0 weight grad [0][0] = 19.211966


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3423
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.635030
Layer 0 weight grad [0][0] = 12.811015


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3424
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.615182
Layer 0 weight grad [0][0] = 14.774021


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3425
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.685243
Layer 0 weight grad [0][0] = 20.509907


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3426
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.035110
Layer 0 weight grad [0][0] = 15.348701


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3427
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.177471
Layer 0 weight grad [0][0] = 31.627758


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 3428
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.555470
Layer 0 weight grad [0][0] = 13.712734


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3429
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.567459
Layer 0 weight grad [0][0] = 13.308779


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3430
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.030533
Layer 0 weight grad [0][0] = 13.159813


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3431
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.107355
Layer 0 weight grad [0][0] = 13.475903


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3432
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.606201
Layer 0 weight grad [0][0] = 10.450203


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3433
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.472873
Layer 0 weight grad [0][0] = 13.502831


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3434
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.603011
Layer 0 weight grad [0][0] = 13.060437


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3435
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.658788
Layer 0 weight grad [0][0] = 12.773598


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3436
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.669505
Layer 0 weight grad [0][0] = 12.063033


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3437
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -9.834674
Layer 0 weight grad [0][0] = 12.318206


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3438
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.763776
Layer 0 weight grad [0][0] = 19.437023


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3439
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.623183
Layer 0 weight grad [0][0] = 14.278531


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3440
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.635471
Layer 0 weight grad [0][0] = 12.716852


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3441
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.614924
Layer 0 weight grad [0][0] = 19.700190


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3442
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.027131
Layer 0 weight grad [0][0] = 13.415305


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3443
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.064739
Layer 0 weight grad [0][0] = 12.458924


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3444
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.534715
Layer 0 weight grad [0][0] = 14.114294


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3445
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.543682
Layer 0 weight grad [0][0] = 14.305525


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3446
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.070094
Layer 0 weight grad [0][0] = 11.875756


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 3447
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.566264
Layer 0 weight grad [0][0] = 12.790792


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3448
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.597071
Layer 0 weight grad [0][0] = 18.961807


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3449
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.427852
Layer 0 weight grad [0][0] = 19.616100


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3450
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.779013
Layer 0 weight grad [0][0] = 15.828863


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3451
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.231483
Layer 0 weight grad [0][0] = 13.283483


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3452
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.464594
Layer 0 weight grad [0][0] = 12.769695


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3453
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.271320
Layer 0 weight grad [0][0] = 13.453703


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3454
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.260841
Layer 0 weight grad [0][0] = 12.136455


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 3455
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.281930
Layer 0 weight grad [0][0] = 12.909269


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3456
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.241281
Layer 0 weight grad [0][0] = 15.158980


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3457
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.489903
Layer 0 weight grad [0][0] = 12.966875


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3458
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.002494
Layer 0 weight grad [0][0] = 12.890381


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3459
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -7.954424
Layer 0 weight grad [0][0] = 13.851274


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3460
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.438704
Layer 0 weight grad [0][0] = 14.224236


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3461
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.390410
Layer 0 weight grad [0][0] = 14.481054


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3462
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.461701
Layer 0 weight grad [0][0] = 14.286035


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3463
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.451352
Layer 0 weight grad [0][0] = 8.283625


Training loss: 2.302585
Training accuracy: 0.375000

epoch: 3464
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.502372
Layer 0 weight grad [0][0] = 13.398615


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3465
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.447182
Layer 0 weight grad [0][0] = 12.904014


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3466
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.011028
Layer 0 weight grad [0][0] = 13.916979


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3467
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.507872
Layer 0 weight grad [0][0] = 14.148807


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3468
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.020690
Layer 0 weight grad [0][0] = 11.653599


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3469
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.528803
Layer 0 weight grad [0][0] = 29.597277


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3470
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.260553
Layer 0 weight grad [0][0] = 13.301572


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3471
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.218078
Layer 0 weight grad [0][0] = 16.365707


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3472
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.216173
Layer 0 weight grad [0][0] = 28.910120


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3473
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.471826
Layer 0 weight grad [0][0] = 13.290334


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3474
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.528148
Layer 0 weight grad [0][0] = 14.361590


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3475
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.367089
Layer 0 weight grad [0][0] = 15.900873


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3476
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.343885
Layer 0 weight grad [0][0] = 12.966694


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3477
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.354897
Layer 0 weight grad [0][0] = 14.025548


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3478
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.569939
Layer 0 weight grad [0][0] = 29.425276


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3479
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.378236
Layer 0 weight grad [0][0] = 18.165461


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3480
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.589170
Layer 0 weight grad [0][0] = 16.017166


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3481
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.414569
Layer 0 weight grad [0][0] = 14.082141


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3482
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.736470
Layer 0 weight grad [0][0] = 13.212279


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3483
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.437889
Layer 0 weight grad [0][0] = 13.501817


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3484
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.758753
Layer 0 weight grad [0][0] = 14.052023


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3485
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.270094
Layer 0 weight grad [0][0] = 14.198669


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3486
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.278074
Layer 0 weight grad [0][0] = 13.521595


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3487
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.219829
Layer 0 weight grad [0][0] = 14.191879


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3488
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.431807
Layer 0 weight grad [0][0] = 3.237821


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 3489
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.365391
Layer 0 weight grad [0][0] = 12.687355


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3490
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -9.055594
Layer 0 weight grad [0][0] = 13.358415


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3491
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.361547
Layer 0 weight grad [0][0] = 15.786427


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3492
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -8.848424
Layer 0 weight grad [0][0] = 12.615867


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3493
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -8.905139
Layer 0 weight grad [0][0] = 13.903228


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3494
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.554483
Layer 0 weight grad [0][0] = 13.873605


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3495
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.766733
Layer 0 weight grad [0][0] = 14.641442


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3496
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.086843
Layer 0 weight grad [0][0] = 15.703828


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3497
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.439895
Layer 0 weight grad [0][0] = 10.028694


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3498
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.140007
Layer 0 weight grad [0][0] = 29.068043


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3499
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.095167
Layer 0 weight grad [0][0] = 13.202996


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3500
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.459823
Layer 0 weight grad [0][0] = 13.812573


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3501
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -9.445447
Layer 0 weight grad [0][0] = 12.171202


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3502
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -8.953311
Layer 0 weight grad [0][0] = 13.323077


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3503
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.700121
Layer 0 weight grad [0][0] = 15.048665


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3504
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.896720
Layer 0 weight grad [0][0] = 14.552220


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3505
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.972204
Layer 0 weight grad [0][0] = 13.358142


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3506
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.082434
Layer 0 weight grad [0][0] = 15.666690


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3507
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.666828
Layer 0 weight grad [0][0] = 13.016231


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 3508
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.686099
Layer 0 weight grad [0][0] = 13.782680


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3509
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.668824
Layer 0 weight grad [0][0] = 3.290318


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3510
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.676445
Layer 0 weight grad [0][0] = 13.574696


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3511
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.700516
Layer 0 weight grad [0][0] = 14.455014


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3512
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.892067
Layer 0 weight grad [0][0] = 12.788259


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3513
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.696307
Layer 0 weight grad [0][0] = 16.344242


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3514
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.201892
Layer 0 weight grad [0][0] = 14.981913


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3515
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.670401
Layer 0 weight grad [0][0] = 15.535501


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3516
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.728341
Layer 0 weight grad [0][0] = 14.381247


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3517
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.228281
Layer 0 weight grad [0][0] = 28.098906


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3518
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.720635
Layer 0 weight grad [0][0] = 14.287611


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3519
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.610803
Layer 0 weight grad [0][0] = 9.114353


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3520
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.218789
Layer 0 weight grad [0][0] = 13.229929


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3521
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.725281
Layer 0 weight grad [0][0] = 14.288114


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3522
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.123837
Layer 0 weight grad [0][0] = 28.870083


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3523
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.750579
Layer 0 weight grad [0][0] = 9.441772


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3524
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.443513
Layer 0 weight grad [0][0] = 13.593436


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3525
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.753273
Layer 0 weight grad [0][0] = 29.572254


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3526
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.255944
Layer 0 weight grad [0][0] = 16.892536


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3527
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -11.814421
Layer 0 weight grad [0][0] = 13.289186


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3528
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.820273
Layer 0 weight grad [0][0] = 13.183612


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3529
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.847960
Layer 0 weight grad [0][0] = 19.932428


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3530
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.985265
Layer 0 weight grad [0][0] = 16.575064


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3531
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.192627
Layer 0 weight grad [0][0] = 15.462466


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 3532
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.653426
Layer 0 weight grad [0][0] = 21.785501


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3533
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -10.394752
Layer 0 weight grad [0][0] = 12.427184


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3534
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.116214
Layer 0 weight grad [0][0] = 21.945742


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3535
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.465957
Layer 0 weight grad [0][0] = 13.223044


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3536
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.492038
Layer 0 weight grad [0][0] = 14.054083


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3537
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.443413
Layer 0 weight grad [0][0] = 12.994735


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3538
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.699006
Layer 0 weight grad [0][0] = 13.013638


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3539
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.506257
Layer 0 weight grad [0][0] = 14.309651


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3540
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.234156
Layer 0 weight grad [0][0] = 14.238946


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3541
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.524647
Layer 0 weight grad [0][0] = 12.983370


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3542
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.014525
Layer 0 weight grad [0][0] = 12.735904


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3543
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.559843
Layer 0 weight grad [0][0] = 12.468372


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3544
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.061551
Layer 0 weight grad [0][0] = 13.452798


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3545
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.761493
Layer 0 weight grad [0][0] = 13.326611


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3546
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.533429
Layer 0 weight grad [0][0] = 19.262436


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3547
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -9.554200
Layer 0 weight grad [0][0] = 13.874707


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3548
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.538208
Layer 0 weight grad [0][0] = 18.419342


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3549
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.509786
Layer 0 weight grad [0][0] = 12.972982


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3550
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.755589
Layer 0 weight grad [0][0] = 14.421301


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3551
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.560539
Layer 0 weight grad [0][0] = 31.797731


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3552
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.569677
Layer 0 weight grad [0][0] = 6.059658


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3553
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.054290
Layer 0 weight grad [0][0] = 13.766349


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3554
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.413305
Layer 0 weight grad [0][0] = 15.647336


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3555
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.516226
Layer 0 weight grad [0][0] = 13.883118


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3556
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.037093
Layer 0 weight grad [0][0] = 10.989493


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3557
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.492720
Layer 0 weight grad [0][0] = 18.106602


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 3558
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.403977
Layer 0 weight grad [0][0] = 14.052990


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3559
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.331828
Layer 0 weight grad [0][0] = 18.957771


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3560
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.708937
Layer 0 weight grad [0][0] = 31.190989


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3561
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -9.540686
Layer 0 weight grad [0][0] = 13.774652


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3562
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.503060
Layer 0 weight grad [0][0] = 14.106541


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3563
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.505618
Layer 0 weight grad [0][0] = 13.626481


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3564
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.011766
Layer 0 weight grad [0][0] = 14.572847


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3565
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.482185
Layer 0 weight grad [0][0] = 13.872046


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3566
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.234714
Layer 0 weight grad [0][0] = 13.983486


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3567
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.536982
Layer 0 weight grad [0][0] = 14.504421


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3568
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.678228
Layer 0 weight grad [0][0] = 9.620312


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3569
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -10.848952
Layer 0 weight grad [0][0] = 12.747426


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3570
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.950528
Layer 0 weight grad [0][0] = 10.145988


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3571
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.704682
Layer 0 weight grad [0][0] = 16.029991


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3572
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.628817
Layer 0 weight grad [0][0] = 11.192416


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3573
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -10.652315
Layer 0 weight grad [0][0] = 20.248234


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3574
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.605907
Layer 0 weight grad [0][0] = 34.608471


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3575
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.592087
Layer 0 weight grad [0][0] = 5.729272


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3576
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.307307
Layer 0 weight grad [0][0] = 21.518156


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3577
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.646605
Layer 0 weight grad [0][0] = 37.082695


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3578
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.177007
Layer 0 weight grad [0][0] = 13.540778


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3579
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.200015
Layer 0 weight grad [0][0] = 14.140592


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3580
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.213191
Layer 0 weight grad [0][0] = 14.485097


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3581
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.462054
Layer 0 weight grad [0][0] = 12.682530


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3582
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.514763
Layer 0 weight grad [0][0] = 13.635847


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3583
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.519941
Layer 0 weight grad [0][0] = 13.278532


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3584
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.491268
Layer 0 weight grad [0][0] = 13.911960


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3585
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.535850
Layer 0 weight grad [0][0] = 39.439903


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3586
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.543759
Layer 0 weight grad [0][0] = 13.203229


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3587
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.511373
Layer 0 weight grad [0][0] = 7.301713


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3588
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.000723
Layer 0 weight grad [0][0] = 13.697993


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3589
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.776062
Layer 0 weight grad [0][0] = 13.857222


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3590
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.264043
Layer 0 weight grad [0][0] = 34.429214


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3591
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.777297
Layer 0 weight grad [0][0] = 13.667469


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3592
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -10.886008
Layer 0 weight grad [0][0] = 19.955587


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3593
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.404541
Layer 0 weight grad [0][0] = 35.283733


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 3594
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.595156
Layer 0 weight grad [0][0] = 14.476256


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3595
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.096199
Layer 0 weight grad [0][0] = 13.837382


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3596
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.594970
Layer 0 weight grad [0][0] = 12.942253


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3597
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -10.255404
Layer 0 weight grad [0][0] = 13.456656


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3598
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.126207
Layer 0 weight grad [0][0] = 13.822531


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3599
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -11.097996
Layer 0 weight grad [0][0] = 14.401185


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3600
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.795617
Layer 0 weight grad [0][0] = 14.746284


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3601
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.786868
Layer 0 weight grad [0][0] = 10.179070


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3602
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.853163
Layer 0 weight grad [0][0] = 14.560827


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3603
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.838508
Layer 0 weight grad [0][0] = 7.743030


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3604
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -11.905655
Layer 0 weight grad [0][0] = 33.424175


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3605
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.476802
Layer 0 weight grad [0][0] = 9.090758


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3606
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.979303
Layer 0 weight grad [0][0] = 14.545599


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3607
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.397229
Layer 0 weight grad [0][0] = 14.150957


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3608
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.010943
Layer 0 weight grad [0][0] = 15.103032


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3609
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.957357
Layer 0 weight grad [0][0] = 13.301270


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3610
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.515672
Layer 0 weight grad [0][0] = 8.949521


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 3611
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.967142
Layer 0 weight grad [0][0] = 13.414166


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3612
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.022145
Layer 0 weight grad [0][0] = 14.295122


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3613
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.292185
Layer 0 weight grad [0][0] = 14.315594


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3614
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.047405
Layer 0 weight grad [0][0] = 15.378663


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3615
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.599203
Layer 0 weight grad [0][0] = 17.914927


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3616
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.085005
Layer 0 weight grad [0][0] = 13.767387


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3617
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.107940
Layer 0 weight grad [0][0] = 32.009651


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3618
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.300777
Layer 0 weight grad [0][0] = 13.624119


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3619
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.604075
Layer 0 weight grad [0][0] = 13.683769


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3620
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.810313
Layer 0 weight grad [0][0] = 14.357151


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3621
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.626157
Layer 0 weight grad [0][0] = 14.240396


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3622
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.078451
Layer 0 weight grad [0][0] = 12.414385


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3623
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.117742
Layer 0 weight grad [0][0] = 16.600876


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3624
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.019424
Layer 0 weight grad [0][0] = 13.853477


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3625
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.063926
Layer 0 weight grad [0][0] = 6.876814


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 3626
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.070148
Layer 0 weight grad [0][0] = 7.880293


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3627
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.094056
Layer 0 weight grad [0][0] = 12.355255


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3628
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.528226
Layer 0 weight grad [0][0] = 12.858797


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3629
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.083215
Layer 0 weight grad [0][0] = 13.678124


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3630
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.106043
Layer 0 weight grad [0][0] = 18.877775


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3631
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.934832
Layer 0 weight grad [0][0] = 15.625827


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3632
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.928895
Layer 0 weight grad [0][0] = 33.736298


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3633
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.913685
Layer 0 weight grad [0][0] = 13.210236


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3634
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.917286
Layer 0 weight grad [0][0] = 13.611449


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3635
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.938213
Layer 0 weight grad [0][0] = 16.580137


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3636
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.361326
Layer 0 weight grad [0][0] = 32.830730


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3637
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -13.463817
Layer 0 weight grad [0][0] = 8.025667


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3638
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.943565
Layer 0 weight grad [0][0] = 13.497826


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3639
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.964534
Layer 0 weight grad [0][0] = 12.894625


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3640
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.461555
Layer 0 weight grad [0][0] = 14.701083


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3641
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.174976
Layer 0 weight grad [0][0] = 12.324304


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3642
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.015520
Layer 0 weight grad [0][0] = 33.004280


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3643
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.035729
Layer 0 weight grad [0][0] = 9.374823


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3644
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.040909
Layer 0 weight grad [0][0] = 13.336082


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3645
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.043545
Layer 0 weight grad [0][0] = 16.769312


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3646
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.943866
Layer 0 weight grad [0][0] = 13.107532


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3647
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.038822
Layer 0 weight grad [0][0] = 17.168396


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3648
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.962080
Layer 0 weight grad [0][0] = 9.421419


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3649
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -14.140366
Layer 0 weight grad [0][0] = 13.349929


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3650
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.577281
Layer 0 weight grad [0][0] = 12.764563


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3651
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.068738
Layer 0 weight grad [0][0] = 12.131405


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3652
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.571779
Layer 0 weight grad [0][0] = 32.593327


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3653
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -14.824987
Layer 0 weight grad [0][0] = 13.072032


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3654
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.155841
Layer 0 weight grad [0][0] = 12.184165


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3655
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.365025
Layer 0 weight grad [0][0] = 12.442531


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3656
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.667504
Layer 0 weight grad [0][0] = 16.788673


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3657
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.354946
Layer 0 weight grad [0][0] = 13.355165


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3658
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -14.903447
Layer 0 weight grad [0][0] = 14.380245


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 3659
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.166826
Layer 0 weight grad [0][0] = 35.440411


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3660
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.686830
Layer 0 weight grad [0][0] = 14.234801


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3661
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.691761
Layer 0 weight grad [0][0] = 14.359758


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3662
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.777589
Layer 0 weight grad [0][0] = 13.308249


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3663
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -14.964562
Layer 0 weight grad [0][0] = 17.063828


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3664
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.960548
Layer 0 weight grad [0][0] = 14.564582


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3665
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.248899
Layer 0 weight grad [0][0] = 12.203379


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 3666
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.256812
Layer 0 weight grad [0][0] = 12.942595


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3667
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.484947
Layer 0 weight grad [0][0] = 15.200944


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3668
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.274243
Layer 0 weight grad [0][0] = 17.188768


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3669
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.226838
Layer 0 weight grad [0][0] = 14.768998


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3670
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.274362
Layer 0 weight grad [0][0] = 8.464642


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 3671
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.281471
Layer 0 weight grad [0][0] = 12.531458


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3672
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.800360
Layer 0 weight grad [0][0] = 18.228947


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3673
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.208484
Layer 0 weight grad [0][0] = 13.701117


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3674
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.155519
Layer 0 weight grad [0][0] = 16.339064


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3675
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.129804
Layer 0 weight grad [0][0] = 9.412787


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 3676
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.427350
Layer 0 weight grad [0][0] = 16.303207


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3677
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.935878
Layer 0 weight grad [0][0] = 16.080492


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3678
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.658758
Layer 0 weight grad [0][0] = 32.582470


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3679
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.196946
Layer 0 weight grad [0][0] = 4.455625


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 3680
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.095380
Layer 0 weight grad [0][0] = 13.632752


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3681
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.820351
Layer 0 weight grad [0][0] = 14.285439


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3682
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.073340
Layer 0 weight grad [0][0] = 13.876502


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3683
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.118159
Layer 0 weight grad [0][0] = 18.549770


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3684
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.029446
Layer 0 weight grad [0][0] = 14.721086


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3685
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.463566
Layer 0 weight grad [0][0] = 14.377079


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3686
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -12.434794
Layer 0 weight grad [0][0] = 13.944094


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3687
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.537053
Layer 0 weight grad [0][0] = 13.127033


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3688
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.605326
Layer 0 weight grad [0][0] = 14.338741


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3689
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.093297
Layer 0 weight grad [0][0] = 13.249600


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3690
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.612954
Layer 0 weight grad [0][0] = 12.600900


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3691
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.542400
Layer 0 weight grad [0][0] = 14.325279


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3692
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.267877
Layer 0 weight grad [0][0] = 30.395714


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3693
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.121195
Layer 0 weight grad [0][0] = 17.588739


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3694
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.395565
Layer 0 weight grad [0][0] = 13.811937


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3695
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.072085
Layer 0 weight grad [0][0] = 18.138819


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3696
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.453236
Layer 0 weight grad [0][0] = 10.230688


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3697
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.969577
Layer 0 weight grad [0][0] = 13.369057


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3698
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.012023
Layer 0 weight grad [0][0] = 13.552583


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3699
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.033628
Layer 0 weight grad [0][0] = 12.396681


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3700
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.942445
Layer 0 weight grad [0][0] = 17.950428


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3701
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.831442
Layer 0 weight grad [0][0] = 13.820471


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3702
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.856668
Layer 0 weight grad [0][0] = 13.909491


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3703
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.859387
Layer 0 weight grad [0][0] = 19.485209


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3704
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.242124
Layer 0 weight grad [0][0] = 30.757692


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3705
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.233646
Layer 0 weight grad [0][0] = 13.631009


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3706
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.652288
Layer 0 weight grad [0][0] = 13.024264


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3707
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.246572
Layer 0 weight grad [0][0] = 12.663416


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3708
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.314418
Layer 0 weight grad [0][0] = 17.774277


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3709
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.140756
Layer 0 weight grad [0][0] = 12.900914


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3710
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.694561
Layer 0 weight grad [0][0] = 7.858991


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3711
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.699720
Layer 0 weight grad [0][0] = 7.309184


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3712
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.910811
Layer 0 weight grad [0][0] = 13.612700


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3713
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.213113
Layer 0 weight grad [0][0] = 13.303121


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3714
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -11.649498
Layer 0 weight grad [0][0] = 14.291080


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3715
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.790454
Layer 0 weight grad [0][0] = 18.209740


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3716
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -10.380437
Layer 0 weight grad [0][0] = 16.382160


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3717
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.716878
Layer 0 weight grad [0][0] = 13.893976


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 3718
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.702855
Layer 0 weight grad [0][0] = 16.750057


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3719
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -9.626497
Layer 0 weight grad [0][0] = 15.706018


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3720
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.937633
Layer 0 weight grad [0][0] = 14.722919


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3721
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.236183
Layer 0 weight grad [0][0] = 18.328928


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3722
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.463447
Layer 0 weight grad [0][0] = 13.789099


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3723
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.674363
Layer 0 weight grad [0][0] = 14.889667


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3724
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.323829
Layer 0 weight grad [0][0] = 16.821289


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3725
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.182483
Layer 0 weight grad [0][0] = 16.392082


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3726
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.124981
Layer 0 weight grad [0][0] = 13.535217


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3727
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.678389
Layer 0 weight grad [0][0] = 13.920141


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3728
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.683206
Layer 0 weight grad [0][0] = 11.288868


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3729
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.100291
Layer 0 weight grad [0][0] = 14.443254


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3730
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.449139
Layer 0 weight grad [0][0] = 35.361320


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3731
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.014207
Layer 0 weight grad [0][0] = 12.318928


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3732
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.503232
Layer 0 weight grad [0][0] = 15.928336


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3733
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.753896
Layer 0 weight grad [0][0] = 14.183731


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3734
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.557748
Layer 0 weight grad [0][0] = 10.887191


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3735
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.951236
Layer 0 weight grad [0][0] = 21.398634


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3736
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.359554
Layer 0 weight grad [0][0] = 13.514132


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3737
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.308711
Layer 0 weight grad [0][0] = 29.017973


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3738
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.871988
Layer 0 weight grad [0][0] = 32.007881


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3739
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.707269
Layer 0 weight grad [0][0] = 16.486340


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3740
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.344432
Layer 0 weight grad [0][0] = 13.835243


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3741
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.716385
Layer 0 weight grad [0][0] = 15.217997


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3742
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.421664
Layer 0 weight grad [0][0] = 7.399199


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3743
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.428506
Layer 0 weight grad [0][0] = 19.531586


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3744
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -6.422625
Layer 0 weight grad [0][0] = 14.339648


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3745
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -6.528985
Layer 0 weight grad [0][0] = 14.023155


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3746
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.441946
Layer 0 weight grad [0][0] = 29.586403


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3747
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.413777
Layer 0 weight grad [0][0] = 18.787771


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3748
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.461562
Layer 0 weight grad [0][0] = 13.061227


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3749
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.472700
Layer 0 weight grad [0][0] = 13.605824


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3750
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.483280
Layer 0 weight grad [0][0] = 12.661963


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3751
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.494897
Layer 0 weight grad [0][0] = 20.650913


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3752
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.502807
Layer 0 weight grad [0][0] = 6.794442


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3753
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.512337
Layer 0 weight grad [0][0] = 12.836287


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3754
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.521900
Layer 0 weight grad [0][0] = 13.388038


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3755
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.529398
Layer 0 weight grad [0][0] = 13.855663


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3756
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.501165
Layer 0 weight grad [0][0] = 18.347521


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3757
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.598428
Layer 0 weight grad [0][0] = 12.933207


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3758
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.490232
Layer 0 weight grad [0][0] = 9.291615


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3759
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.500768
Layer 0 weight grad [0][0] = 6.016338


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3760
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.013527
Layer 0 weight grad [0][0] = 13.032168


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3761
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.023854
Layer 0 weight grad [0][0] = 14.395482


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3762
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.533932
Layer 0 weight grad [0][0] = 12.641639


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3763
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -8.477900
Layer 0 weight grad [0][0] = 13.394892


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3764
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.607857
Layer 0 weight grad [0][0] = 22.427401


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3765
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.072954
Layer 0 weight grad [0][0] = 11.865685


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 3766
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.633617
Layer 0 weight grad [0][0] = 31.338243


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3767
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.647850
Layer 0 weight grad [0][0] = 16.573006


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3768
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.577283
Layer 0 weight grad [0][0] = 22.168608


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3769
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -9.063417
Layer 0 weight grad [0][0] = 13.643131


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3770
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.106294
Layer 0 weight grad [0][0] = 13.176751


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3771
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.631814
Layer 0 weight grad [0][0] = 12.707308


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3772
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.498533
Layer 0 weight grad [0][0] = 13.850117


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3773
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.244143
Layer 0 weight grad [0][0] = 12.925537


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3774
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.760158
Layer 0 weight grad [0][0] = 17.406393


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3775
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.848434
Layer 0 weight grad [0][0] = 11.773647


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3776
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.671998
Layer 0 weight grad [0][0] = 12.436037


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3777
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -9.469822
Layer 0 weight grad [0][0] = 11.566120


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3778
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.898976
Layer 0 weight grad [0][0] = 13.156530


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3779
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.683510
Layer 0 weight grad [0][0] = 13.426792


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3780
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.482300
Layer 0 weight grad [0][0] = 23.332674


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3781
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.905327
Layer 0 weight grad [0][0] = 12.272616


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3782
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -10.393067
Layer 0 weight grad [0][0] = 12.881429


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3783
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.481957
Layer 0 weight grad [0][0] = 13.834636


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3784
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.169814
Layer 0 weight grad [0][0] = 23.316114


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3785
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.043557
Layer 0 weight grad [0][0] = 12.473609


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3786
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.054456
Layer 0 weight grad [0][0] = 23.535982


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3787
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.271659
Layer 0 weight grad [0][0] = 12.985796


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3788
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.289507
Layer 0 weight grad [0][0] = 13.093392


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3789
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.119288
Layer 0 weight grad [0][0] = 12.399536


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3790
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.115617
Layer 0 weight grad [0][0] = 12.894235


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3791
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.127164
Layer 0 weight grad [0][0] = 12.662678


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3792
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.714021
Layer 0 weight grad [0][0] = 20.869938


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3793
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -12.490726
Layer 0 weight grad [0][0] = 13.551959


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3794
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.405429
Layer 0 weight grad [0][0] = 12.242843


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3795
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.338939
Layer 0 weight grad [0][0] = 20.934832


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3796
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.350292
Layer 0 weight grad [0][0] = 12.173375


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3797
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.360008
Layer 0 weight grad [0][0] = 13.047406


Training loss: 2.302585
Training accuracy: 0.375000

epoch: 3798
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.245191
Layer 0 weight grad [0][0] = 12.182343


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3799
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.257159
Layer 0 weight grad [0][0] = 19.041628


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3800
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.637514
Layer 0 weight grad [0][0] = 12.253753


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 3801
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.644331
Layer 0 weight grad [0][0] = 39.320217


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3802
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.561108
Layer 0 weight grad [0][0] = 13.445667


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3803
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.555180
Layer 0 weight grad [0][0] = 18.194147


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3804
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.384350
Layer 0 weight grad [0][0] = 12.082672


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 3805
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.942345
Layer 0 weight grad [0][0] = 18.606173


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3806
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.858489
Layer 0 weight grad [0][0] = 33.865414


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3807
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -10.423769
Layer 0 weight grad [0][0] = 18.574829


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3808
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.827841
Layer 0 weight grad [0][0] = 41.508190


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3809
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.709380
Layer 0 weight grad [0][0] = 4.167370


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3810
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.723367
Layer 0 weight grad [0][0] = 12.971210


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3811
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.700957
Layer 0 weight grad [0][0] = 16.359488


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3812
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.619615
Layer 0 weight grad [0][0] = 26.662600


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3813
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.575084
Layer 0 weight grad [0][0] = 15.921647


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3814
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.005202
Layer 0 weight grad [0][0] = 17.620239


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 3815
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.542431
Layer 0 weight grad [0][0] = 11.417989


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3816
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.354105
Layer 0 weight grad [0][0] = 13.493831


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3817
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.130973
Layer 0 weight grad [0][0] = 12.868862


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3818
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.015282
Layer 0 weight grad [0][0] = 12.166982


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3819
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.475597
Layer 0 weight grad [0][0] = 11.230392


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3820
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.543751
Layer 0 weight grad [0][0] = 11.331516


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3821
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.555527
Layer 0 weight grad [0][0] = 12.832685


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3822
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.753004
Layer 0 weight grad [0][0] = 2.428279


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3823
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -7.443441
Layer 0 weight grad [0][0] = 12.104585


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3824
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.606306
Layer 0 weight grad [0][0] = 6.767699


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 3825
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.113928
Layer 0 weight grad [0][0] = 13.853052


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3826
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.339419
Layer 0 weight grad [0][0] = 13.766109


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3827
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.647981
Layer 0 weight grad [0][0] = 4.235026


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3828
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.613865
Layer 0 weight grad [0][0] = 12.573521


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3829
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.619743
Layer 0 weight grad [0][0] = 21.147417


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3830
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.126472
Layer 0 weight grad [0][0] = 12.802289


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3831
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.629841
Layer 0 weight grad [0][0] = 13.509324


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3832
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.133444
Layer 0 weight grad [0][0] = 22.722115


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3833
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.635427
Layer 0 weight grad [0][0] = 12.772141


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3834
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.638940
Layer 0 weight grad [0][0] = 12.448624


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3835
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.067215
Layer 0 weight grad [0][0] = 14.860888


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3836
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.663063
Layer 0 weight grad [0][0] = 8.553421


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 3837
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.574774
Layer 0 weight grad [0][0] = 18.280109


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3838
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.447061
Layer 0 weight grad [0][0] = 12.370964


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3839
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.451366
Layer 0 weight grad [0][0] = 12.941534


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 3840
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -6.977695
Layer 0 weight grad [0][0] = 12.977351


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 3841
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.977012
Layer 0 weight grad [0][0] = 20.613911


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 3842
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.496122
Layer 0 weight grad [0][0] = 14.019745


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3843
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.500648
Layer 0 weight grad [0][0] = 3.720637


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 3844
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.505181
Layer 0 weight grad [0][0] = 35.488438


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3845
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.941993
Layer 0 weight grad [0][0] = 12.252084


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3846
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.582158
Layer 0 weight grad [0][0] = 18.539686


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 3847
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.433077
Layer 0 weight grad [0][0] = 27.113649


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3848
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.932750
Layer 0 weight grad [0][0] = 14.290435


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3849
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.118468
Layer 0 weight grad [0][0] = 11.036503


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3850
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.931343
Layer 0 weight grad [0][0] = 36.169029


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3851
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.930287
Layer 0 weight grad [0][0] = 12.349184


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3852
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.428350
Layer 0 weight grad [0][0] = 13.379777


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 3853
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.633589
Layer 0 weight grad [0][0] = 14.110526


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3854
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.430364
Layer 0 weight grad [0][0] = 12.680771


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3855
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.928829
Layer 0 weight grad [0][0] = 33.100193


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3856
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.487857
Layer 0 weight grad [0][0] = 1.982772


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3857
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.489615
Layer 0 weight grad [0][0] = 12.220774


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3858
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.511644
Layer 0 weight grad [0][0] = 12.195688


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3859
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.492418
Layer 0 weight grad [0][0] = 13.237568


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3860
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.440975
Layer 0 weight grad [0][0] = 12.227117


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3861
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.503515
Layer 0 weight grad [0][0] = 9.782205


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3862
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.054279
Layer 0 weight grad [0][0] = 12.074427


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3863
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -8.818810
Layer 0 weight grad [0][0] = 11.390241


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3864
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.005107
Layer 0 weight grad [0][0] = 11.887547


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3865
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.517972
Layer 0 weight grad [0][0] = 29.808491


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3866
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.727504
Layer 0 weight grad [0][0] = 12.573133


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3867
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.565814
Layer 0 weight grad [0][0] = 17.894991


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3868
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -8.236650
Layer 0 weight grad [0][0] = 34.698036


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3869
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.962785
Layer 0 weight grad [0][0] = 13.911578


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3870
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.946868
Layer 0 weight grad [0][0] = 12.649838


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3871
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.103958
Layer 0 weight grad [0][0] = 14.326222


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3872
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.648654
Layer 0 weight grad [0][0] = 15.250255


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 3873
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.445800
Layer 0 weight grad [0][0] = 13.274474


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3874
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.667282
Layer 0 weight grad [0][0] = 13.672953


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3875
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.943002
Layer 0 weight grad [0][0] = 12.625516


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3876
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.438500
Layer 0 weight grad [0][0] = 13.719860


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3877
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.436479
Layer 0 weight grad [0][0] = 13.380839


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3878
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.449681
Layer 0 weight grad [0][0] = 14.433588


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3879
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.425804
Layer 0 weight grad [0][0] = 14.799378


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3880
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -8.695032
Layer 0 weight grad [0][0] = 14.339878


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3881
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.446435
Layer 0 weight grad [0][0] = 39.550339


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3882
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.804988
Layer 0 weight grad [0][0] = 13.036845


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3883
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -7.659768
Layer 0 weight grad [0][0] = 8.046714


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3884
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.448218
Layer 0 weight grad [0][0] = 12.959330


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3885
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.716190
Layer 0 weight grad [0][0] = 6.605438


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3886
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.595987
Layer 0 weight grad [0][0] = 13.055510


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3887
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.532122
Layer 0 weight grad [0][0] = 13.585949


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3888
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.582009
Layer 0 weight grad [0][0] = 37.846981


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3889
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.951749
Layer 0 weight grad [0][0] = 13.276505


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 3890
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.607802
Layer 0 weight grad [0][0] = 0.883960


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3891
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.484395
Layer 0 weight grad [0][0] = 13.299168


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3892
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.441735
Layer 0 weight grad [0][0] = 12.816242


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3893
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.282146
Layer 0 weight grad [0][0] = 13.702207


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3894
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -8.712404
Layer 0 weight grad [0][0] = 13.792691


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3895
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -8.722569
Layer 0 weight grad [0][0] = 13.121323


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3896
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.042970
Layer 0 weight grad [0][0] = 13.195169


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3897
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.248140
Layer 0 weight grad [0][0] = 13.159041


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3898
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.001040
Layer 0 weight grad [0][0] = 28.030775


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3899
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.697063
Layer 0 weight grad [0][0] = 13.614229


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3900
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.499632
Layer 0 weight grad [0][0] = 9.760817


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3901
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -9.684639
Layer 0 weight grad [0][0] = 1.816254


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3902
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.614745
Layer 0 weight grad [0][0] = 23.580391


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3903
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.688531
Layer 0 weight grad [0][0] = 18.288109


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3904
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.413510
Layer 0 weight grad [0][0] = 32.234047


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3905
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -9.193274
Layer 0 weight grad [0][0] = 14.038344


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3906
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.816569
Layer 0 weight grad [0][0] = 11.094032


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3907
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.232792
Layer 0 weight grad [0][0] = 3.086376


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3908
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.452072
Layer 0 weight grad [0][0] = 14.828233


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3909
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.736072
Layer 0 weight grad [0][0] = 22.827436


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3910
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.757264
Layer 0 weight grad [0][0] = 14.375791


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3911
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.796609
Layer 0 weight grad [0][0] = 36.468418


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3912
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.133717
Layer 0 weight grad [0][0] = 14.203884


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3913
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.886319
Layer 0 weight grad [0][0] = 13.816196


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3914
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.648529
Layer 0 weight grad [0][0] = 13.828472


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3915
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.914007
Layer 0 weight grad [0][0] = 26.961481


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3916
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.753823
Layer 0 weight grad [0][0] = 30.582352


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3917
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.938227
Layer 0 weight grad [0][0] = 13.471433


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3918
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.942952
Layer 0 weight grad [0][0] = 13.498853


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3919
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.759866
Layer 0 weight grad [0][0] = 33.226460


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3920
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.739709
Layer 0 weight grad [0][0] = 18.933517


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3921
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.637454
Layer 0 weight grad [0][0] = 13.975213


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3922
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.152200
Layer 0 weight grad [0][0] = 30.347040


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3923
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -9.257229
Layer 0 weight grad [0][0] = 13.933935


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3924
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.811608
Layer 0 weight grad [0][0] = 28.903362


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3925
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -9.339893
Layer 0 weight grad [0][0] = 15.832592


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3926
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.350425
Layer 0 weight grad [0][0] = 13.758109


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3927
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.648298
Layer 0 weight grad [0][0] = 16.800917


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 3928
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.555178
Layer 0 weight grad [0][0] = 12.889281


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3929
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.762422
Layer 0 weight grad [0][0] = 13.523011


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3930
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.569312
Layer 0 weight grad [0][0] = 12.367836


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3931
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.572226
Layer 0 weight grad [0][0] = 27.949961


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3932
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.629552
Layer 0 weight grad [0][0] = 16.664637


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3933
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.627212
Layer 0 weight grad [0][0] = 30.301546


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3934
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.120377
Layer 0 weight grad [0][0] = 14.295120


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3935
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.772250
Layer 0 weight grad [0][0] = 14.972357


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3936
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.608102
Layer 0 weight grad [0][0] = 14.787092


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3937
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.393744
Layer 0 weight grad [0][0] = 29.526634


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3938
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.157112
Layer 0 weight grad [0][0] = 13.849194


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3939
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.807448
Layer 0 weight grad [0][0] = 13.828341


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3940
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.659603
Layer 0 weight grad [0][0] = 14.277053


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3941
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.306203
Layer 0 weight grad [0][0] = 14.048889


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3942
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.679248
Layer 0 weight grad [0][0] = 26.035456


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3943
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.724014
Layer 0 weight grad [0][0] = 28.594540


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3944
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.891570
Layer 0 weight grad [0][0] = 25.040558


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3945
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.727902
Layer 0 weight grad [0][0] = 15.595317


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3946
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.741955
Layer 0 weight grad [0][0] = 20.066080


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3947
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.252334
Layer 0 weight grad [0][0] = 3.351164


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 3948
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.777513
Layer 0 weight grad [0][0] = 29.069597


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 3949
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.772848
Layer 0 weight grad [0][0] = 13.572376


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 3950
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.736663
Layer 0 weight grad [0][0] = 14.219240


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3951
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.771113
Layer 0 weight grad [0][0] = 30.280798


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3952
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.971285
Layer 0 weight grad [0][0] = 16.056614


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3953
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.765653
Layer 0 weight grad [0][0] = 14.454171


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3954
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.764012
Layer 0 weight grad [0][0] = 14.544160


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3955
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.757565
Layer 0 weight grad [0][0] = 16.669544


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3956
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.674531
Layer 0 weight grad [0][0] = 3.838900


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3957
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.632783
Layer 0 weight grad [0][0] = 14.433186


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3958
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.976874
Layer 0 weight grad [0][0] = 18.436573


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3959
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.172584
Layer 0 weight grad [0][0] = 5.268125


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3960
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.859479
Layer 0 weight grad [0][0] = 15.162178


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3961
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -8.348142
Layer 0 weight grad [0][0] = 18.024891


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3962
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -7.606520
Layer 0 weight grad [0][0] = 20.685465


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3963
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.103011
Layer 0 weight grad [0][0] = 14.870489


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3964
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -7.643242
Layer 0 weight grad [0][0] = 18.533846


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3965
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.652445
Layer 0 weight grad [0][0] = 14.388752


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 3966
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.349296
Layer 0 weight grad [0][0] = 31.337570


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3967
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.638528
Layer 0 weight grad [0][0] = 14.524310


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3968
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.839581
Layer 0 weight grad [0][0] = 14.885715


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3969
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.148072
Layer 0 weight grad [0][0] = 18.819002


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3970
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.627337
Layer 0 weight grad [0][0] = 13.954090


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3971
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.124205
Layer 0 weight grad [0][0] = 17.583048


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3972
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -7.697041
Layer 0 weight grad [0][0] = 15.354363


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3973
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.750743
Layer 0 weight grad [0][0] = 30.636837


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3974
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.543508
Layer 0 weight grad [0][0] = 5.403517


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3975
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.419634
Layer 0 weight grad [0][0] = 11.092022


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3976
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.469997
Layer 0 weight grad [0][0] = 14.579486


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3977
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.502530
Layer 0 weight grad [0][0] = 2.854220


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3978
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.411852
Layer 0 weight grad [0][0] = 15.270265


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3979
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.061910
Layer 0 weight grad [0][0] = 14.405076


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3980
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.556422
Layer 0 weight grad [0][0] = 14.962523


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3981
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.530554
Layer 0 weight grad [0][0] = 14.837569


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3982
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.522835
Layer 0 weight grad [0][0] = 3.698605


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3983
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.518286
Layer 0 weight grad [0][0] = 14.253589


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3984
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.513681
Layer 0 weight grad [0][0] = 31.889811


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3985
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.505610
Layer 0 weight grad [0][0] = 13.820800


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3986
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.500926
Layer 0 weight grad [0][0] = 22.719494


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 3987
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.056825
Layer 0 weight grad [0][0] = 14.313326


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3988
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.690558
Layer 0 weight grad [0][0] = 14.393575


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 3989
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.445471
Layer 0 weight grad [0][0] = 14.163007


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3990
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -7.747441
Layer 0 weight grad [0][0] = 19.440819


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3991
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.579010
Layer 0 weight grad [0][0] = 17.120331


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3992
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.048761
Layer 0 weight grad [0][0] = 23.862967


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3993
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.709907
Layer 0 weight grad [0][0] = 15.091429


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 3994
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.505606
Layer 0 weight grad [0][0] = 17.763186


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 3995
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.421743
Layer 0 weight grad [0][0] = 30.588417


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3996
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.419421
Layer 0 weight grad [0][0] = 16.586920


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3997
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.520943
Layer 0 weight grad [0][0] = 15.192549


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 3998
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.492198
Layer 0 weight grad [0][0] = 15.325282


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 3999
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.483474
Layer 0 weight grad [0][0] = 14.490129


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4000
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.475569
Layer 0 weight grad [0][0] = 14.038175


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4001
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.466605
Layer 0 weight grad [0][0] = 14.580137


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4002
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -7.675138
Layer 0 weight grad [0][0] = 14.978658


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4003
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.464683
Layer 0 weight grad [0][0] = 14.141753


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4004
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.409662
Layer 0 weight grad [0][0] = 4.685960


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4005
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.485977
Layer 0 weight grad [0][0] = 17.935663


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4006
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.408536
Layer 0 weight grad [0][0] = 14.388900


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4007
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.150728
Layer 0 weight grad [0][0] = 22.107418


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4008
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.440847
Layer 0 weight grad [0][0] = 5.286655


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 4009
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.491240
Layer 0 weight grad [0][0] = 12.045491


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4010
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.055951
Layer 0 weight grad [0][0] = 17.032804


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4011
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.119406
Layer 0 weight grad [0][0] = 28.319801


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4012
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.528703
Layer 0 weight grad [0][0] = 16.105043


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4013
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.022346
Layer 0 weight grad [0][0] = 14.562099


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4014
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.233706
Layer 0 weight grad [0][0] = 15.312844


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4015
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.510302
Layer 0 weight grad [0][0] = 23.574347


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4016
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.285391
Layer 0 weight grad [0][0] = 13.939561


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4017
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.261485
Layer 0 weight grad [0][0] = 14.736324


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4018
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.399959
Layer 0 weight grad [0][0] = 15.999271


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4019
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.604867
Layer 0 weight grad [0][0] = 14.765710


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4020
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.952326
Layer 0 weight grad [0][0] = 11.463787


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4021
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -7.914947
Layer 0 weight grad [0][0] = 13.754812


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4022
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.901200
Layer 0 weight grad [0][0] = 5.082765


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4023
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.197576
Layer 0 weight grad [0][0] = 14.719793


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4024
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.716524
Layer 0 weight grad [0][0] = 15.926340


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4025
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.221542
Layer 0 weight grad [0][0] = 27.436487


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4026
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.694967
Layer 0 weight grad [0][0] = 16.840052


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4027
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.626045
Layer 0 weight grad [0][0] = 28.006472


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4028
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.026966
Layer 0 weight grad [0][0] = 28.137344


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4029
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.681169
Layer 0 weight grad [0][0] = 13.973545


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4030
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.173425
Layer 0 weight grad [0][0] = 14.133170


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4031
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.659347
Layer 0 weight grad [0][0] = 29.426689


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4032
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.669109
Layer 0 weight grad [0][0] = 16.981127


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4033
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.636396
Layer 0 weight grad [0][0] = 13.594248


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4034
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.626475
Layer 0 weight grad [0][0] = 14.478120


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4035
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.579161
Layer 0 weight grad [0][0] = 23.642811


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4036
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -7.231995
Layer 0 weight grad [0][0] = 16.336317


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4037
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -7.212445
Layer 0 weight grad [0][0] = 14.324260


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4038
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.189634
Layer 0 weight grad [0][0] = 15.135325


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4039
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.888565
Layer 0 weight grad [0][0] = 5.881167


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 4040
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.991246
Layer 0 weight grad [0][0] = 13.567110


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4041
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.770284
Layer 0 weight grad [0][0] = 29.206375


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4042
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.933462
Layer 0 weight grad [0][0] = 12.575527


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4043
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.780032
Layer 0 weight grad [0][0] = 13.449052


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4044
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.265219
Layer 0 weight grad [0][0] = 14.023429


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 4045
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.738604
Layer 0 weight grad [0][0] = 24.358755


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4046
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.288145
Layer 0 weight grad [0][0] = 12.423144


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4047
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.799592
Layer 0 weight grad [0][0] = 27.938236


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4048
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.532671
Layer 0 weight grad [0][0] = 14.869864


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4049
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.316743
Layer 0 weight grad [0][0] = 13.929170


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4050
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.011888
Layer 0 weight grad [0][0] = 13.983003


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4051
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.817517
Layer 0 weight grad [0][0] = 11.275289


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4052
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -9.107738
Layer 0 weight grad [0][0] = 11.255974


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4053
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.935960
Layer 0 weight grad [0][0] = 22.234600


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4054
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.924053
Layer 0 weight grad [0][0] = 13.511134


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4055
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.121893
Layer 0 weight grad [0][0] = 14.123112


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4056
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.408490
Layer 0 weight grad [0][0] = 15.518409


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4057
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -9.450594
Layer 0 weight grad [0][0] = 14.369525


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4058
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.596489
Layer 0 weight grad [0][0] = 29.509262


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4059
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.420973
Layer 0 weight grad [0][0] = 13.757852


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4060
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.960890
Layer 0 weight grad [0][0] = 14.197835


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4061
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.950747
Layer 0 weight grad [0][0] = 16.859259


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4062
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.872707
Layer 0 weight grad [0][0] = 18.298054


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4063
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.361693
Layer 0 weight grad [0][0] = 21.189331


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4064
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.843795
Layer 0 weight grad [0][0] = 13.486526


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4065
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.833452
Layer 0 weight grad [0][0] = 5.911992


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4066
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.031852
Layer 0 weight grad [0][0] = 13.778243


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4067
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.577744
Layer 0 weight grad [0][0] = 14.314506


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4068
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.385273
Layer 0 weight grad [0][0] = 30.433023


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 4069
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -8.319392
Layer 0 weight grad [0][0] = 22.056118


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4070
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -8.298385
Layer 0 weight grad [0][0] = 14.476259


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4071
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.392474
Layer 0 weight grad [0][0] = 14.161206


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4072
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.886463
Layer 0 weight grad [0][0] = 15.120202


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4073
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.878049
Layer 0 weight grad [0][0] = 13.818531


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4074
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.322712
Layer 0 weight grad [0][0] = 14.454002


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4075
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.862952
Layer 0 weight grad [0][0] = 14.871932


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4076
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.303420
Layer 0 weight grad [0][0] = 13.419509


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4077
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.806963
Layer 0 weight grad [0][0] = 13.951935


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4078
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.841177
Layer 0 weight grad [0][0] = 17.841656


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4079
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.207084
Layer 0 weight grad [0][0] = 14.857991


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4080
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.746440
Layer 0 weight grad [0][0] = 14.472362


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4081
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.737917
Layer 0 weight grad [0][0] = 20.029039


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4082
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.227508
Layer 0 weight grad [0][0] = 15.431867


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4083
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.734280
Layer 0 weight grad [0][0] = 29.541048


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4084
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.704617
Layer 0 weight grad [0][0] = 13.919754


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4085
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.695999
Layer 0 weight grad [0][0] = 15.381997


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4086
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.686163
Layer 0 weight grad [0][0] = 5.864276


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4087
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.192182
Layer 0 weight grad [0][0] = 30.412317


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4088
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.801862
Layer 0 weight grad [0][0] = 14.540094


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4089
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.090875
Layer 0 weight grad [0][0] = 14.577554


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4090
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.784313
Layer 0 weight grad [0][0] = 28.228567


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4091
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.023683
Layer 0 weight grad [0][0] = 15.500601


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4092
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.563198
Layer 0 weight grad [0][0] = 15.323063


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4093
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.556188
Layer 0 weight grad [0][0] = 15.485051


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4094
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.550569
Layer 0 weight grad [0][0] = 19.468966


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4095
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -6.725351
Layer 0 weight grad [0][0] = 15.465856


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4096
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.472963
Layer 0 weight grad [0][0] = 6.303619


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4097
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.963875
Layer 0 weight grad [0][0] = 15.046526


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4098
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.470414
Layer 0 weight grad [0][0] = 14.509619


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4099
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.944742
Layer 0 weight grad [0][0] = 15.387633


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4100
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.432686
Layer 0 weight grad [0][0] = 14.570566


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4101
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.632818
Layer 0 weight grad [0][0] = 15.204484


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4102
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.937603
Layer 0 weight grad [0][0] = 16.955296


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4103
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.346769
Layer 0 weight grad [0][0] = 15.716049


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4104
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.335824
Layer 0 weight grad [0][0] = 15.120625


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4105
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.292334
Layer 0 weight grad [0][0] = 14.973442


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4106
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.326618
Layer 0 weight grad [0][0] = 16.459406


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4107
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.320560
Layer 0 weight grad [0][0] = 14.835815


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4108
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.232867
Layer 0 weight grad [0][0] = 27.930544


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4109
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.312272
Layer 0 weight grad [0][0] = 17.472414


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 4110
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.157647
Layer 0 weight grad [0][0] = 14.570257


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4111
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.692720
Layer 0 weight grad [0][0] = 15.599317


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4112
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.702242
Layer 0 weight grad [0][0] = 19.162468


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4113
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.187096
Layer 0 weight grad [0][0] = 18.589577


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4114
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.304708
Layer 0 weight grad [0][0] = 14.044421


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4115
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.471593
Layer 0 weight grad [0][0] = 12.899065


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4116
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.073233
Layer 0 weight grad [0][0] = 18.976006


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4117
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.767694
Layer 0 weight grad [0][0] = 28.472715


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4118
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.145250
Layer 0 weight grad [0][0] = 17.805656


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4119
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.034555
Layer 0 weight grad [0][0] = 14.523783


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4120
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.027108
Layer 0 weight grad [0][0] = 12.242025


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4121
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.579929
Layer 0 weight grad [0][0] = 13.694856


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4122
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.090269
Layer 0 weight grad [0][0] = 11.651587


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4123
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.408599
Layer 0 weight grad [0][0] = 33.260693


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4124
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.097331
Layer 0 weight grad [0][0] = 30.207863


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4125
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.379081
Layer 0 weight grad [0][0] = 13.970553


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4126
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.170933
Layer 0 weight grad [0][0] = 14.504083


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4127
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.125623
Layer 0 weight grad [0][0] = 33.179211


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4128
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.081959
Layer 0 weight grad [0][0] = 28.120100


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4129
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.647306
Layer 0 weight grad [0][0] = 32.724915


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4130
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.122444
Layer 0 weight grad [0][0] = 31.823999


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4131
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.611554
Layer 0 weight grad [0][0] = 15.233253


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4132
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.101994
Layer 0 weight grad [0][0] = 19.532822


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4133
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.093946
Layer 0 weight grad [0][0] = 16.158674


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4134
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.026992
Layer 0 weight grad [0][0] = 11.203439


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4135
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -5.340296
Layer 0 weight grad [0][0] = 13.275425


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4136
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.118146
Layer 0 weight grad [0][0] = 14.058956


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4137
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.067976
Layer 0 weight grad [0][0] = 13.424898


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4138
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.059675
Layer 0 weight grad [0][0] = 14.949751


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4139
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.088253
Layer 0 weight grad [0][0] = 7.741148


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4140
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.079999
Layer 0 weight grad [0][0] = 15.253029


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4141
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.565855
Layer 0 weight grad [0][0] = 14.103232


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4142
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.254677
Layer 0 weight grad [0][0] = 32.542316


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4143
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.040549
Layer 0 weight grad [0][0] = 14.186121


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4144
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.233202
Layer 0 weight grad [0][0] = 14.806235


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4145
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.225533
Layer 0 weight grad [0][0] = 18.918644


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4146
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -5.432279
Layer 0 weight grad [0][0] = 2.004968


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4147
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.108968
Layer 0 weight grad [0][0] = 32.330059


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4148
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.268156
Layer 0 weight grad [0][0] = 14.537277


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4149
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -5.893157
Layer 0 weight grad [0][0] = 14.410718


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4150
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.635485
Layer 0 weight grad [0][0] = 5.463966


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4151
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.120896
Layer 0 weight grad [0][0] = 30.528269


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4152
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.607112
Layer 0 weight grad [0][0] = 28.347027


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4153
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.606188
Layer 0 weight grad [0][0] = 29.674421


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4154
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.781741
Layer 0 weight grad [0][0] = 14.885126


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4155
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.064295
Layer 0 weight grad [0][0] = 11.715734


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4156
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -6.452546
Layer 0 weight grad [0][0] = 14.756033


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4157
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.123621
Layer 0 weight grad [0][0] = 16.781679


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4158
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.617420
Layer 0 weight grad [0][0] = 11.276392


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4159
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.369850
Layer 0 weight grad [0][0] = 15.188607


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4160
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.414755
Layer 0 weight grad [0][0] = 4.796079


Training loss: 2.302585
Training accuracy: 0.375000

epoch: 4161
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -6.431019
Layer 0 weight grad [0][0] = 32.012814


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4162
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.119057
Layer 0 weight grad [0][0] = 14.810338


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4163
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.145379
Layer 0 weight grad [0][0] = 27.107225


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4164
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.698034
Layer 0 weight grad [0][0] = 15.065176


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4165
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.185388
Layer 0 weight grad [0][0] = 31.380089


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4166
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.686068
Layer 0 weight grad [0][0] = 14.472543


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4167
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.658663
Layer 0 weight grad [0][0] = 15.555304


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4168
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.316735
Layer 0 weight grad [0][0] = 15.289733


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4169
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.405079
Layer 0 weight grad [0][0] = 13.885240


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4170
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.288539
Layer 0 weight grad [0][0] = 14.073186


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4171
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.184928
Layer 0 weight grad [0][0] = 15.953585


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4172
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.677357
Layer 0 weight grad [0][0] = 15.344636


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4173
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.665671
Layer 0 weight grad [0][0] = 5.063288


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4174
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -7.095571
Layer 0 weight grad [0][0] = 14.571245


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4175
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.192949
Layer 0 weight grad [0][0] = 14.881367


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4176
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.201211
Layer 0 weight grad [0][0] = 15.460695


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4177
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.171190
Layer 0 weight grad [0][0] = 17.146250


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4178
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.677092
Layer 0 weight grad [0][0] = 16.319969


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4179
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.321350
Layer 0 weight grad [0][0] = 16.013380


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4180
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -7.127495
Layer 0 weight grad [0][0] = 16.182127


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4181
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.179784
Layer 0 weight grad [0][0] = 15.452123


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4182
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.136753
Layer 0 weight grad [0][0] = 12.456583


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4183
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -7.815509
Layer 0 weight grad [0][0] = 14.793689


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4184
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.258669
Layer 0 weight grad [0][0] = 26.092587


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4185
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.271276
Layer 0 weight grad [0][0] = 24.320459


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4186
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.248262
Layer 0 weight grad [0][0] = 16.834738


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4187
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.453366
Layer 0 weight grad [0][0] = 14.921740


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4188
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.746680
Layer 0 weight grad [0][0] = 19.278358


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4189
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -7.179176
Layer 0 weight grad [0][0] = 15.654579


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4190
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.173862
Layer 0 weight grad [0][0] = 24.837269


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4191
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.115296
Layer 0 weight grad [0][0] = 15.329438


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4192
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -7.318761
Layer 0 weight grad [0][0] = 15.464563


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4193
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.391274
Layer 0 weight grad [0][0] = 15.863662


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4194
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.190275
Layer 0 weight grad [0][0] = 16.339113


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4195
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.189848
Layer 0 weight grad [0][0] = 15.924654


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4196
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.362456
Layer 0 weight grad [0][0] = 16.218935


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4197
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.423592
Layer 0 weight grad [0][0] = 16.238930


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4198
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -7.737021
Layer 0 weight grad [0][0] = 12.806474


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4199
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.253773
Layer 0 weight grad [0][0] = 14.875914


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4200
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.416360
Layer 0 weight grad [0][0] = 16.090269


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4201
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.331021
Layer 0 weight grad [0][0] = 13.444362


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4202
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.842072
Layer 0 weight grad [0][0] = 12.435511


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4203
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.366544
Layer 0 weight grad [0][0] = 13.000791


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4204
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.485811
Layer 0 weight grad [0][0] = 20.213057


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4205
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.389250
Layer 0 weight grad [0][0] = 6.330866


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4206
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.330294
Layer 0 weight grad [0][0] = 16.344707


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4207
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.365790
Layer 0 weight grad [0][0] = 23.948227


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 4208
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.364600
Layer 0 weight grad [0][0] = 15.299677


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 4209
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.379569
Layer 0 weight grad [0][0] = 15.824725


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4210
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -9.157141
Layer 0 weight grad [0][0] = 16.551693


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4211
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.362330
Layer 0 weight grad [0][0] = 15.288940


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4212
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.358596
Layer 0 weight grad [0][0] = 15.337770


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4213
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -9.043863
Layer 0 weight grad [0][0] = 24.290499


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4214
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.381121
Layer 0 weight grad [0][0] = 16.540676


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4215
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.088959
Layer 0 weight grad [0][0] = 15.371370


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4216
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.392374
Layer 0 weight grad [0][0] = 16.465815


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4217
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.896302
Layer 0 weight grad [0][0] = 15.082455


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4218
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.408216
Layer 0 weight grad [0][0] = 14.269352


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4219
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.979614
Layer 0 weight grad [0][0] = 16.241291


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4220
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.958801
Layer 0 weight grad [0][0] = 6.533560


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4221
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.464446
Layer 0 weight grad [0][0] = 15.359257


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4222
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.416613
Layer 0 weight grad [0][0] = 14.539318


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4223
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.457006
Layer 0 weight grad [0][0] = 14.553213


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4224
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.461845
Layer 0 weight grad [0][0] = 14.737854


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4225
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -10.465906
Layer 0 weight grad [0][0] = 14.857968


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4226
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.968307
Layer 0 weight grad [0][0] = 15.953771


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4227
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.512762
Layer 0 weight grad [0][0] = 14.671209


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4228
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.064832
Layer 0 weight grad [0][0] = 32.608536


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4229
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.558718
Layer 0 weight grad [0][0] = 20.032475


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4230
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -10.544791
Layer 0 weight grad [0][0] = 15.329104


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4231
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.473256
Layer 0 weight grad [0][0] = 14.719563


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4232
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.490770
Layer 0 weight grad [0][0] = 16.221169


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4233
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -10.239151
Layer 0 weight grad [0][0] = 15.479948


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4234
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.199681
Layer 0 weight grad [0][0] = 26.922697


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4235
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.472010
Layer 0 weight grad [0][0] = 13.169159


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4236
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -10.738521
Layer 0 weight grad [0][0] = 14.688890


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4237
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.757090
Layer 0 weight grad [0][0] = 15.113836


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4238
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.082561
Layer 0 weight grad [0][0] = 8.818830


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4239
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.686916
Layer 0 weight grad [0][0] = 15.285552


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 4240
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.495703
Layer 0 weight grad [0][0] = 5.486009


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4241
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.503625
Layer 0 weight grad [0][0] = 15.063096


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 4242
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.009477
Layer 0 weight grad [0][0] = 13.929939


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4243
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.726270
Layer 0 weight grad [0][0] = 14.889594


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4244
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.538116
Layer 0 weight grad [0][0] = 14.143152


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4245
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.570501
Layer 0 weight grad [0][0] = 15.317413


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4246
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.562523
Layer 0 weight grad [0][0] = 14.612409


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4247
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.424972
Layer 0 weight grad [0][0] = 15.172609


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4248
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.664084
Layer 0 weight grad [0][0] = 15.186376


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4249
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -11.971567
Layer 0 weight grad [0][0] = 13.438925


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4250
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.681041
Layer 0 weight grad [0][0] = 14.313466


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4251
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.696430
Layer 0 weight grad [0][0] = 13.689567


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4252
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.710897
Layer 0 weight grad [0][0] = 13.632071


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4253
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.727952
Layer 0 weight grad [0][0] = 15.451310


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4254
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.412397
Layer 0 weight grad [0][0] = 9.922072


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4255
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.776191
Layer 0 weight grad [0][0] = 16.287508


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4256
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.846692
Layer 0 weight grad [0][0] = 14.451765


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4257
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.843684
Layer 0 weight grad [0][0] = 15.276353


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4258
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.822470
Layer 0 weight grad [0][0] = 5.855888


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4259
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.325130
Layer 0 weight grad [0][0] = 14.509826


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4260
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.485597
Layer 0 weight grad [0][0] = 15.470934


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4261
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.466553
Layer 0 weight grad [0][0] = 25.878355


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4262
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.601870
Layer 0 weight grad [0][0] = 15.910113


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4263
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.501756
Layer 0 weight grad [0][0] = 25.955776


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 4264
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -15.012636
Layer 0 weight grad [0][0] = 14.974345


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4265
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.127606
Layer 0 weight grad [0][0] = 12.363604


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4266
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.121532
Layer 0 weight grad [0][0] = 14.548739


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4267
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.129886
Layer 0 weight grad [0][0] = 26.768633


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4268
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.845920
Layer 0 weight grad [0][0] = 14.632040


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4269
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.667740
Layer 0 weight grad [0][0] = 14.374396


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4270
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -16.199535
Layer 0 weight grad [0][0] = 14.323092


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4271
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.217393
Layer 0 weight grad [0][0] = 25.930857


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4272
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.065358
Layer 0 weight grad [0][0] = 25.667599


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4273
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -15.195523
Layer 0 weight grad [0][0] = 14.999468


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4274
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.794876
Layer 0 weight grad [0][0] = 15.830350


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4275
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.206222
Layer 0 weight grad [0][0] = 15.169805


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4276
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.163981
Layer 0 weight grad [0][0] = 14.932373


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4277
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.219165
Layer 0 weight grad [0][0] = 7.268888


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4278
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.235990
Layer 0 weight grad [0][0] = 11.889674


Training loss: 2.302585
Training accuracy: 0.375000

epoch: 4279
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.755799
Layer 0 weight grad [0][0] = 14.958334


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4280
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.296270
Layer 0 weight grad [0][0] = 18.645206


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4281
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -16.128885
Layer 0 weight grad [0][0] = 14.122978


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4282
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.831678
Layer 0 weight grad [0][0] = 19.122437


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4283
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.425348
Layer 0 weight grad [0][0] = 8.098289


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4284
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.367056
Layer 0 weight grad [0][0] = 14.516712


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4285
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.361908
Layer 0 weight grad [0][0] = 2.758381


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4286
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -17.169821
Layer 0 weight grad [0][0] = 6.506831


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4287
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.445428
Layer 0 weight grad [0][0] = 15.809633


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4288
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.854995
Layer 0 weight grad [0][0] = 14.588427


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4289
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.457410
Layer 0 weight grad [0][0] = 24.694214


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4290
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -17.533543
Layer 0 weight grad [0][0] = 23.694258


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4291
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.035327
Layer 0 weight grad [0][0] = 12.440992


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4292
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.533947
Layer 0 weight grad [0][0] = 24.037868


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4293
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -16.390533
Layer 0 weight grad [0][0] = 14.060008


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4294
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.896058
Layer 0 weight grad [0][0] = 14.273817


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4295
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.086083
Layer 0 weight grad [0][0] = 14.310053


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4296
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.196224
Layer 0 weight grad [0][0] = 9.550797


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4297
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.713786
Layer 0 weight grad [0][0] = 24.237288


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 4298
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.732910
Layer 0 weight grad [0][0] = 14.828755


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4299
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.994760
Layer 0 weight grad [0][0] = 14.054259


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 4300
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.573699
Layer 0 weight grad [0][0] = 15.217487


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4301
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.593690
Layer 0 weight grad [0][0] = 24.726681


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4302
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.586337
Layer 0 weight grad [0][0] = 14.319221


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4303
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.097512
Layer 0 weight grad [0][0] = 14.225941


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4304
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.609037
Layer 0 weight grad [0][0] = 15.789061


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4305
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.584764
Layer 0 weight grad [0][0] = 14.704994


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4306
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.634975
Layer 0 weight grad [0][0] = 4.472491


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4307
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.646697
Layer 0 weight grad [0][0] = 22.507118


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4308
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.625853
Layer 0 weight grad [0][0] = 24.087383


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4309
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.454117
Layer 0 weight grad [0][0] = 14.517162


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4310
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.471200
Layer 0 weight grad [0][0] = 13.758868


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4311
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.449050
Layer 0 weight grad [0][0] = 14.562162


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4312
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.503004
Layer 0 weight grad [0][0] = 14.766730


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4313
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.533458
Layer 0 weight grad [0][0] = 11.958709


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4314
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.502020
Layer 0 weight grad [0][0] = 14.430245


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 4315
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.517324
Layer 0 weight grad [0][0] = 26.926390


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4316
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -18.019154
Layer 0 weight grad [0][0] = 14.055018


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4317
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.472518
Layer 0 weight grad [0][0] = 10.337832


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4318
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.493771
Layer 0 weight grad [0][0] = 15.498551


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4319
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.513398
Layer 0 weight grad [0][0] = 23.148005


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4320
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.332814
Layer 0 weight grad [0][0] = 15.276948


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4321
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -17.365435
Layer 0 weight grad [0][0] = 14.410559


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 4322
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.325461
Layer 0 weight grad [0][0] = 14.694360


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4323
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.560197
Layer 0 weight grad [0][0] = 8.173323


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 4324
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.838593
Layer 0 weight grad [0][0] = 14.656608


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4325
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.416276
Layer 0 weight grad [0][0] = 15.571712


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4326
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.446306
Layer 0 weight grad [0][0] = 13.596968


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4327
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.439657
Layer 0 weight grad [0][0] = 8.477601


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4328
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.507272
Layer 0 weight grad [0][0] = 14.056590


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4329
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.638319
Layer 0 weight grad [0][0] = 23.333317


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4330
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.961469
Layer 0 weight grad [0][0] = 26.073681


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4331
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.454181
Layer 0 weight grad [0][0] = 20.881441


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4332
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.740067
Layer 0 weight grad [0][0] = 13.694402


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4333
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.100915
Layer 0 weight grad [0][0] = 15.068061


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4334
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.475807
Layer 0 weight grad [0][0] = 15.085969


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4335
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.507221
Layer 0 weight grad [0][0] = 10.085851


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4336
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -17.366413
Layer 0 weight grad [0][0] = 15.191301


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4337
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.380411
Layer 0 weight grad [0][0] = 13.873270


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4338
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.411450
Layer 0 weight grad [0][0] = 9.145574


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4339
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.943571
Layer 0 weight grad [0][0] = 28.577293


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4340
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.062915
Layer 0 weight grad [0][0] = 14.567408


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4341
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.983840
Layer 0 weight grad [0][0] = 14.608523


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4342
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.025979
Layer 0 weight grad [0][0] = 10.075518


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4343
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.555859
Layer 0 weight grad [0][0] = 13.111131


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4344
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.477931
Layer 0 weight grad [0][0] = 14.095918


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4345
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.466340
Layer 0 weight grad [0][0] = 14.983928


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4346
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.710688
Layer 0 weight grad [0][0] = 14.801109


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4347
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.583608
Layer 0 weight grad [0][0] = 14.714541


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4348
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.619116
Layer 0 weight grad [0][0] = 23.480009


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4349
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.169333
Layer 0 weight grad [0][0] = 14.255830


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4350
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.787559
Layer 0 weight grad [0][0] = 11.568433


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4351
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -19.198509
Layer 0 weight grad [0][0] = 22.906530


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4352
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.804908
Layer 0 weight grad [0][0] = 13.752086


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4353
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.575363
Layer 0 weight grad [0][0] = 15.271728


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4354
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.171138
Layer 0 weight grad [0][0] = 14.591797


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4355
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.003815
Layer 0 weight grad [0][0] = 8.750825


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4356
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.538409
Layer 0 weight grad [0][0] = 27.649220


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4357
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.843484
Layer 0 weight grad [0][0] = 17.418110


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4358
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.854508
Layer 0 weight grad [0][0] = 17.258251


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4359
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.887351
Layer 0 weight grad [0][0] = 25.328455


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4360
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.645807
Layer 0 weight grad [0][0] = 14.097348


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4361
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.719701
Layer 0 weight grad [0][0] = 14.071505


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4362
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.716204
Layer 0 weight grad [0][0] = 14.746368


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4363
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -18.716177
Layer 0 weight grad [0][0] = 20.392813


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4364
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.673034
Layer 0 weight grad [0][0] = 7.205135


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4365
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -16.993490
Layer 0 weight grad [0][0] = 14.464611


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4366
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.548501
Layer 0 weight grad [0][0] = 14.779528


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4367
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.051096
Layer 0 weight grad [0][0] = 15.093740


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4368
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.768162
Layer 0 weight grad [0][0] = 15.066203


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4369
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.773553
Layer 0 weight grad [0][0] = 14.587285


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4370
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.947174
Layer 0 weight grad [0][0] = 15.047496


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4371
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.358079
Layer 0 weight grad [0][0] = 11.461459


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4372
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.863720
Layer 0 weight grad [0][0] = 17.444662


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4373
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.050605
Layer 0 weight grad [0][0] = 23.419634


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4374
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.385109
Layer 0 weight grad [0][0] = 14.942941


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4375
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.112015
Layer 0 weight grad [0][0] = 14.173444


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4376
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.917561
Layer 0 weight grad [0][0] = 17.786509


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4377
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.320419
Layer 0 weight grad [0][0] = 14.555748


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4378
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.393695
Layer 0 weight grad [0][0] = 15.698231


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4379
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.122109
Layer 0 weight grad [0][0] = 23.148762


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4380
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.945186
Layer 0 weight grad [0][0] = 25.852325


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4381
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.968487
Layer 0 weight grad [0][0] = 13.425297


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4382
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.085202
Layer 0 weight grad [0][0] = 24.399796


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4383
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.972051
Layer 0 weight grad [0][0] = 13.423478


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4384
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.015309
Layer 0 weight grad [0][0] = 14.006030


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4385
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.052724
Layer 0 weight grad [0][0] = 14.541332


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4386
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.049619
Layer 0 weight grad [0][0] = 20.344151


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4387
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.994058
Layer 0 weight grad [0][0] = 14.092817


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4388
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.476282
Layer 0 weight grad [0][0] = 4.378939


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 4389
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.263409
Layer 0 weight grad [0][0] = 15.731238


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4390
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.093993
Layer 0 weight grad [0][0] = -7.565361


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4391
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.124820
Layer 0 weight grad [0][0] = 14.443242


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4392
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -19.264969
Layer 0 weight grad [0][0] = 11.734807


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4393
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.452877
Layer 0 weight grad [0][0] = 14.563870


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4394
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.975829
Layer 0 weight grad [0][0] = 9.711042


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4395
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.029929
Layer 0 weight grad [0][0] = 22.833359


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4396
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.055608
Layer 0 weight grad [0][0] = 6.460262


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4397
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.596064
Layer 0 weight grad [0][0] = 24.392946


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4398
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.921643
Layer 0 weight grad [0][0] = 24.980652


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4399
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.941369
Layer 0 weight grad [0][0] = 9.551270


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4400
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.990105
Layer 0 weight grad [0][0] = 23.502459


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4401
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.828775
Layer 0 weight grad [0][0] = 14.920852


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4402
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.098954
Layer 0 weight grad [0][0] = 12.705304


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4403
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -18.155794
Layer 0 weight grad [0][0] = 13.920662


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4404
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.078137
Layer 0 weight grad [0][0] = 12.716158


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4405
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.149389
Layer 0 weight grad [0][0] = 13.353985


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4406
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.975790
Layer 0 weight grad [0][0] = -5.061800


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4407
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -19.909649
Layer 0 weight grad [0][0] = 13.611856


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4408
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.978953
Layer 0 weight grad [0][0] = 6.472117


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4409
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.029992
Layer 0 weight grad [0][0] = 18.505545


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4410
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.078788
Layer 0 weight grad [0][0] = 12.772226


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4411
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.129984
Layer 0 weight grad [0][0] = 7.718380


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4412
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.175266
Layer 0 weight grad [0][0] = 15.252084


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4413
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.053928
Layer 0 weight grad [0][0] = 13.926914


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4414
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.869554
Layer 0 weight grad [0][0] = 13.866623


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4415
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.400759
Layer 0 weight grad [0][0] = 14.420093


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4416
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.409811
Layer 0 weight grad [0][0] = 13.404489


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4417
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.492673
Layer 0 weight grad [0][0] = 22.529184


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4418
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.501823
Layer 0 weight grad [0][0] = 7.957929


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4419
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.582489
Layer 0 weight grad [0][0] = 17.257034


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4420
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.397970
Layer 0 weight grad [0][0] = 12.841149


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4421
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.954157
Layer 0 weight grad [0][0] = 14.845626


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4422
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.479086
Layer 0 weight grad [0][0] = 13.155276


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4423
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.516891
Layer 0 weight grad [0][0] = 14.830505


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4424
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.062723
Layer 0 weight grad [0][0] = 13.963870


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4425
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.572300
Layer 0 weight grad [0][0] = 13.911059


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4426
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.174615
Layer 0 weight grad [0][0] = 13.992171


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4427
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -26.131096
Layer 0 weight grad [0][0] = 13.819230


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4428
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.079854
Layer 0 weight grad [0][0] = 21.996756


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4429
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.680382
Layer 0 weight grad [0][0] = 14.173318


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4430
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.244997
Layer 0 weight grad [0][0] = 9.337626


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4431
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.780689
Layer 0 weight grad [0][0] = 13.925948


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4432
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.832994
Layer 0 weight grad [0][0] = 13.554098


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4433
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.884508
Layer 0 weight grad [0][0] = 20.669098


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4434
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.955986
Layer 0 weight grad [0][0] = 20.311396


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4435
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.441786
Layer 0 weight grad [0][0] = 15.234025


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4436
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -27.808971
Layer 0 weight grad [0][0] = 14.156859


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4437
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.388657
Layer 0 weight grad [0][0] = 15.003381


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4438
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.933692
Layer 0 weight grad [0][0] = 24.389658


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4439
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.230440
Layer 0 weight grad [0][0] = 13.538255


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4440
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.327284
Layer 0 weight grad [0][0] = 14.016947


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4441
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -27.888964
Layer 0 weight grad [0][0] = 9.839054


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4442
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.840310
Layer 0 weight grad [0][0] = 13.360841


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4443
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.653522
Layer 0 weight grad [0][0] = 23.637945


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4444
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.233297
Layer 0 weight grad [0][0] = 15.593404


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4445
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.775516
Layer 0 weight grad [0][0] = 14.411861


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4446
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.342341
Layer 0 weight grad [0][0] = 25.222109


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4447
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.842787
Layer 0 weight grad [0][0] = 14.629542


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4448
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.708530
Layer 0 weight grad [0][0] = 21.656284


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4449
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.739726
Layer 0 weight grad [0][0] = 12.597056


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4450
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -28.343752
Layer 0 weight grad [0][0] = 13.323688


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4451
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.765094
Layer 0 weight grad [0][0] = 25.245056


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4452
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.349142
Layer 0 weight grad [0][0] = 13.902859


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4453
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.895342
Layer 0 weight grad [0][0] = 13.886432


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 4454
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.444907
Layer 0 weight grad [0][0] = 13.780132


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4455
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.204967
Layer 0 weight grad [0][0] = 14.651382


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4456
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.131138
Layer 0 weight grad [0][0] = 17.052233


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4457
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.163359
Layer 0 weight grad [0][0] = 26.077433


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4458
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.571278
Layer 0 weight grad [0][0] = 14.176048


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4459
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.065736
Layer 0 weight grad [0][0] = -0.963328


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4460
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.623409
Layer 0 weight grad [0][0] = 14.832613


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4461
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.173573
Layer 0 weight grad [0][0] = 25.090612


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4462
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.964549
Layer 0 weight grad [0][0] = 17.582249


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4463
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.022296
Layer 0 weight grad [0][0] = 13.761900


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4464
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.097575
Layer 0 weight grad [0][0] = 15.330576


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4465
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.140790
Layer 0 weight grad [0][0] = 12.587653


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4466
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.375112
Layer 0 weight grad [0][0] = 13.688536


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4467
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -32.610794
Layer 0 weight grad [0][0] = -0.535013


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4468
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.333721
Layer 0 weight grad [0][0] = 26.199488


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4469
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.819385
Layer 0 weight grad [0][0] = 8.739246


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4470
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.233447
Layer 0 weight grad [0][0] = 12.894377


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4471
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.799571
Layer 0 weight grad [0][0] = 15.919969


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4472
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.868065
Layer 0 weight grad [0][0] = 13.017725


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4473
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.433730
Layer 0 weight grad [0][0] = 22.594820


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4474
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -34.489960
Layer 0 weight grad [0][0] = 44.209221


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4475
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.043270
Layer 0 weight grad [0][0] = 12.636313


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4476
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.323251
Layer 0 weight grad [0][0] = 12.324771


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4477
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.708670
Layer 0 weight grad [0][0] = 34.200130


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4478
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.794182
Layer 0 weight grad [0][0] = 13.463414


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4479
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.868744
Layer 0 weight grad [0][0] = 13.366620


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4480
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.940849
Layer 0 weight grad [0][0] = 12.365127


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4481
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.010450
Layer 0 weight grad [0][0] = 8.445125


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 4482
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.109132
Layer 0 weight grad [0][0] = 8.623562


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4483
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.169156
Layer 0 weight grad [0][0] = 22.221008


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4484
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.248011
Layer 0 weight grad [0][0] = 11.426544


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 4485
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.337707
Layer 0 weight grad [0][0] = 15.160072


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4486
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.937583
Layer 0 weight grad [0][0] = 12.169822


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4487
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.525680
Layer 0 weight grad [0][0] = 12.700198


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4488
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.590968
Layer 0 weight grad [0][0] = 12.120132


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4489
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -36.856426
Layer 0 weight grad [0][0] = 12.313669


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4490
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.709044
Layer 0 weight grad [0][0] = 13.206045


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4491
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.794315
Layer 0 weight grad [0][0] = -0.789843


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4492
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.084641
Layer 0 weight grad [0][0] = 13.062090


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4493
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.173959
Layer 0 weight grad [0][0] = 13.550431


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4494
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -40.306828
Layer 0 weight grad [0][0] = 12.588460


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4495
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7.849364
Layer 0 weight grad [0][0] = 24.024672


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4496
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.343613
Layer 0 weight grad [0][0] = 19.500208


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 4497
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.817598
Layer 0 weight grad [0][0] = 16.873749


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4498
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.558268
Layer 0 weight grad [0][0] = 15.866529


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4499
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.607346
Layer 0 weight grad [0][0] = 16.351278


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4500
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.228715
Layer 0 weight grad [0][0] = 14.364736


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4501
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.329428
Layer 0 weight grad [0][0] = 13.099105


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4502
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.122791
Layer 0 weight grad [0][0] = 13.742166


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4503
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.983802
Layer 0 weight grad [0][0] = -2.439985


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4504
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -39.922874
Layer 0 weight grad [0][0] = 36.372334


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4505
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.343258
Layer 0 weight grad [0][0] = 12.840468


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4506
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.745387
Layer 0 weight grad [0][0] = 40.014286


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4507
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.318607
Layer 0 weight grad [0][0] = 42.364250


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4508
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.063873
Layer 0 weight grad [0][0] = 26.343990


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4509
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.051100
Layer 0 weight grad [0][0] = 43.064014


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4510
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -26.639593
Layer 0 weight grad [0][0] = 33.067780


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4511
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -22.939854
Layer 0 weight grad [0][0] = 14.393643


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4512
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -24.407984
Layer 0 weight grad [0][0] = 13.910682


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4513
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.791404
Layer 0 weight grad [0][0] = -1.939182


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4514
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.426587
Layer 0 weight grad [0][0] = 13.682309


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4515
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.461825
Layer 0 weight grad [0][0] = 35.641315


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4516
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -23.758781
Layer 0 weight grad [0][0] = 14.034468


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4517
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.854689
Layer 0 weight grad [0][0] = 14.700855


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4518
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.419455
Layer 0 weight grad [0][0] = 33.141956


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4519
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.557333
Layer 0 weight grad [0][0] = 34.121964


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4520
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.697637
Layer 0 weight grad [0][0] = 13.093214


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4521
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.757560
Layer 0 weight grad [0][0] = 10.812304


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4522
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.370253
Layer 0 weight grad [0][0] = -3.514075


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4523
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.433242
Layer 0 weight grad [0][0] = 13.138299


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4524
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.035742
Layer 0 weight grad [0][0] = 14.254733


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4525
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.066048
Layer 0 weight grad [0][0] = 23.300888


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4526
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.703645
Layer 0 weight grad [0][0] = 31.115286


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4527
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.372998
Layer 0 weight grad [0][0] = 24.297232


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4528
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.464354
Layer 0 weight grad [0][0] = 13.229747


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4529
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.513323
Layer 0 weight grad [0][0] = -4.086856


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4530
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.766529
Layer 0 weight grad [0][0] = 14.056145


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4531
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.611622
Layer 0 weight grad [0][0] = -2.530478


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4532
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.674615
Layer 0 weight grad [0][0] = 15.103047


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4533
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.698093
Layer 0 weight grad [0][0] = 33.965485


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4534
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.972085
Layer 0 weight grad [0][0] = 24.852045


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4535
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.566180
Layer 0 weight grad [0][0] = 15.750900


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4536
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.626878
Layer 0 weight grad [0][0] = 23.925987


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4537
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.427486
Layer 0 weight grad [0][0] = 14.356784


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4538
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.986312
Layer 0 weight grad [0][0] = 13.027685


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4539
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.961834
Layer 0 weight grad [0][0] = -3.492791


Training loss: 2.302585
Training accuracy: 0.437500

epoch: 4540
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.485939
Layer 0 weight grad [0][0] = 14.093390


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4541
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.663290
Layer 0 weight grad [0][0] = 14.652128


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4542
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -19.154526
Layer 0 weight grad [0][0] = 14.690694


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4543
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.761125
Layer 0 weight grad [0][0] = 13.761841


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4544
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.319339
Layer 0 weight grad [0][0] = -2.357873


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4545
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.058330
Layer 0 weight grad [0][0] = 27.848267


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4546
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.660099
Layer 0 weight grad [0][0] = 27.336836


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4547
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.107098
Layer 0 weight grad [0][0] = -1.347132


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4548
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.152140
Layer 0 weight grad [0][0] = 22.758200


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4549
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.475039
Layer 0 weight grad [0][0] = 26.464834


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4550
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.241458
Layer 0 weight grad [0][0] = -1.016841


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4551
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.244481
Layer 0 weight grad [0][0] = 23.459833


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4552
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.321919
Layer 0 weight grad [0][0] = 14.954502


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4553
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.799798
Layer 0 weight grad [0][0] = 14.182232


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 4554
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.446263
Layer 0 weight grad [0][0] = 25.725420


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4555
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.985736
Layer 0 weight grad [0][0] = 14.302642


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4556
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.525446
Layer 0 weight grad [0][0] = 26.903727


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4557
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.245493
Layer 0 weight grad [0][0] = 14.607113


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4558
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -16.152525
Layer 0 weight grad [0][0] = 27.624176


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4559
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.158720
Layer 0 weight grad [0][0] = 26.965372


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4560
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.957692
Layer 0 weight grad [0][0] = 14.885336


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4561
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.981673
Layer 0 weight grad [0][0] = 28.927588


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4562
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -10.426863
Layer 0 weight grad [0][0] = 15.555218


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4563
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.313958
Layer 0 weight grad [0][0] = 25.231031


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4564
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.606876
Layer 0 weight grad [0][0] = 33.227135


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4565
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.420708
Layer 0 weight grad [0][0] = 14.880868


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4566
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.822540
Layer 0 weight grad [0][0] = 21.622276


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4567
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.508816
Layer 0 weight grad [0][0] = 14.496182


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4568
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.873963
Layer 0 weight grad [0][0] = 14.575758


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4569
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.191097
Layer 0 weight grad [0][0] = 14.769732


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 4570
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.725288
Layer 0 weight grad [0][0] = 16.118729


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4571
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.984546
Layer 0 weight grad [0][0] = 15.427078


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4572
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.313117
Layer 0 weight grad [0][0] = 4.061222


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4573
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.680138
Layer 0 weight grad [0][0] = 14.705219


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4574
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.215126
Layer 0 weight grad [0][0] = 14.659562


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4575
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.706490
Layer 0 weight grad [0][0] = 8.145357


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4576
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.778885
Layer 0 weight grad [0][0] = 7.561034


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4577
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.304790
Layer 0 weight grad [0][0] = 29.782675


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4578
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.028824
Layer 0 weight grad [0][0] = 29.079950


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4579
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.241349
Layer 0 weight grad [0][0] = 15.336355


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4580
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.247456
Layer 0 weight grad [0][0] = 15.663108


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4581
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.792268
Layer 0 weight grad [0][0] = 24.496122


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4582
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.775742
Layer 0 weight grad [0][0] = 7.908259


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4583
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -8.166237
Layer 0 weight grad [0][0] = 15.030645


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4584
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.545891
Layer 0 weight grad [0][0] = 15.405081


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4585
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.723512
Layer 0 weight grad [0][0] = 16.099277


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4586
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -9.475558
Layer 0 weight grad [0][0] = 25.563532


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4587
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.736221
Layer 0 weight grad [0][0] = 25.285841


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4588
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.744306
Layer 0 weight grad [0][0] = 27.406555


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4589
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -8.556031
Layer 0 weight grad [0][0] = 6.477626


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4590
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.706272
Layer 0 weight grad [0][0] = 9.120466


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4591
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.740267
Layer 0 weight grad [0][0] = 14.448958


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4592
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.272101
Layer 0 weight grad [0][0] = 16.470440


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4593
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.797481
Layer 0 weight grad [0][0] = 25.656614


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4594
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.093341
Layer 0 weight grad [0][0] = 15.959573


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4595
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.050939
Layer 0 weight grad [0][0] = 3.229920


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4596
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.088816
Layer 0 weight grad [0][0] = 15.822651


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4597
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.602942
Layer 0 weight grad [0][0] = 15.413342


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4598
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.674039
Layer 0 weight grad [0][0] = 16.239460


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4599
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.170681
Layer 0 weight grad [0][0] = 15.698530


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4600
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.693695
Layer 0 weight grad [0][0] = 14.876850


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4601
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.232239
Layer 0 weight grad [0][0] = 25.279030


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4602
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.179685
Layer 0 weight grad [0][0] = 15.495605


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4603
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.691750
Layer 0 weight grad [0][0] = 24.667774


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4604
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -10.529002
Layer 0 weight grad [0][0] = 15.354798


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4605
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.364558
Layer 0 weight grad [0][0] = 24.946823


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4606
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.886985
Layer 0 weight grad [0][0] = 16.845444


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4607
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.890147
Layer 0 weight grad [0][0] = 33.773540


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4608
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.180615
Layer 0 weight grad [0][0] = 15.087729


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4609
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.746807
Layer 0 weight grad [0][0] = 16.367020


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4610
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.467195
Layer 0 weight grad [0][0] = 15.445268


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4611
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.287642
Layer 0 weight grad [0][0] = 15.561704


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4612
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.810082
Layer 0 weight grad [0][0] = 24.079117


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4613
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -10.396089
Layer 0 weight grad [0][0] = 16.243362


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4614
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.757827
Layer 0 weight grad [0][0] = 16.020584


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4615
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.784860
Layer 0 weight grad [0][0] = 24.784517


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4616
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.771252
Layer 0 weight grad [0][0] = 24.076338


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4617
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.159650
Layer 0 weight grad [0][0] = 15.772941


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4618
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.869305
Layer 0 weight grad [0][0] = 16.314447


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4619
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.685989
Layer 0 weight grad [0][0] = 15.568654


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4620
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.408833
Layer 0 weight grad [0][0] = 16.583370


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4621
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.117814
Layer 0 weight grad [0][0] = 27.093092


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4622
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.611041
Layer 0 weight grad [0][0] = 22.754490


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4623
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.930094
Layer 0 weight grad [0][0] = 15.265065


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4624
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.442023
Layer 0 weight grad [0][0] = 15.313286


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4625
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.677315
Layer 0 weight grad [0][0] = 15.460287


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4626
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.675593
Layer 0 weight grad [0][0] = 16.171850


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4627
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.560908
Layer 0 weight grad [0][0] = 24.977312


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4628
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.568708
Layer 0 weight grad [0][0] = 4.652576


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4629
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.764685
Layer 0 weight grad [0][0] = 14.728224


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4630
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.625321
Layer 0 weight grad [0][0] = 5.066545


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4631
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.644897
Layer 0 weight grad [0][0] = 11.459617


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4632
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.162614
Layer 0 weight grad [0][0] = 15.610130


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4633
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.694092
Layer 0 weight grad [0][0] = 21.447750


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4634
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.585552
Layer 0 weight grad [0][0] = 15.291832


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4635
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.596117
Layer 0 weight grad [0][0] = 16.696938


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4636
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.555236
Layer 0 weight grad [0][0] = 26.375463


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4637
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.360476
Layer 0 weight grad [0][0] = 15.272714


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4638
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.387107
Layer 0 weight grad [0][0] = 16.993206


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4639
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.337848
Layer 0 weight grad [0][0] = 1.685804


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4640
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -11.167898
Layer 0 weight grad [0][0] = 16.935413


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4641
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.569122
Layer 0 weight grad [0][0] = 16.089020


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4642
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.106572
Layer 0 weight grad [0][0] = 16.135155


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4643
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.614063
Layer 0 weight grad [0][0] = 14.790315


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4644
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.088556
Layer 0 weight grad [0][0] = 24.855547


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 4645
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -13.530147
Layer 0 weight grad [0][0] = 16.053501


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4646
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.852242
Layer 0 weight grad [0][0] = 16.378370


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4647
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -14.321330
Layer 0 weight grad [0][0] = -1.776073


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 4648
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.998134
Layer 0 weight grad [0][0] = 0.276770


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4649
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.049766
Layer 0 weight grad [0][0] = -2.133329


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4650
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.224992
Layer 0 weight grad [0][0] = 1.739631


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4651
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.644736
Layer 0 weight grad [0][0] = 16.344982


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4652
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.285667
Layer 0 weight grad [0][0] = 30.237181


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4653
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -13.560357
Layer 0 weight grad [0][0] = 15.925790


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4654
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.628963
Layer 0 weight grad [0][0] = -0.223303


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4655
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.202115
Layer 0 weight grad [0][0] = -2.899876


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4656
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.932855
Layer 0 weight grad [0][0] = 15.567955


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4657
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.255269
Layer 0 weight grad [0][0] = -2.461865


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4658
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -15.738799
Layer 0 weight grad [0][0] = 15.497952


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4659
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.957176
Layer 0 weight grad [0][0] = 14.870611


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4660
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.926093
Layer 0 weight grad [0][0] = 11.730566


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4661
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.467547
Layer 0 weight grad [0][0] = 17.100973


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4662
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.166753
Layer 0 weight grad [0][0] = 16.058187


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4663
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.461386
Layer 0 weight grad [0][0] = -3.640088


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4664
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -15.535217
Layer 0 weight grad [0][0] = 15.237341


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4665
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.664110
Layer 0 weight grad [0][0] = 29.623196


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4666
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.186113
Layer 0 weight grad [0][0] = 15.479794


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4667
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.262113
Layer 0 weight grad [0][0] = 16.353779


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4668
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.786581
Layer 0 weight grad [0][0] = 17.956413


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4669
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.021618
Layer 0 weight grad [0][0] = 15.130765


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4670
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.147801
Layer 0 weight grad [0][0] = -2.657961


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4671
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.932743
Layer 0 weight grad [0][0] = 16.950336


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4672
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -20.169518
Layer 0 weight grad [0][0] = 15.348514


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4673
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.231385
Layer 0 weight grad [0][0] = 15.917722


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 4674
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.728018
Layer 0 weight grad [0][0] = 0.314528


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4675
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.281159
Layer 0 weight grad [0][0] = 15.416338


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4676
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.819703
Layer 0 weight grad [0][0] = 15.353601


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4677
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.325575
Layer 0 weight grad [0][0] = 26.523354


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4678
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.103258
Layer 0 weight grad [0][0] = 15.158928


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4679
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.583416
Layer 0 weight grad [0][0] = 15.272756


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4680
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.160487
Layer 0 weight grad [0][0] = -0.038474


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4681
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.393606
Layer 0 weight grad [0][0] = 18.496225


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4682
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.730264
Layer 0 weight grad [0][0] = 17.141487


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4683
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.203884
Layer 0 weight grad [0][0] = 17.427116


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4684
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.712430
Layer 0 weight grad [0][0] = 14.419020


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4685
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.251219
Layer 0 weight grad [0][0] = 16.255302


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4686
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.335903
Layer 0 weight grad [0][0] = 26.372890


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4687
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.357804
Layer 0 weight grad [0][0] = 15.067504


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4688
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.331436
Layer 0 weight grad [0][0] = 15.531828


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4689
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.361572
Layer 0 weight grad [0][0] = 1.658597


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4690
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.942963
Layer 0 weight grad [0][0] = 28.930088


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4691
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -25.341461
Layer 0 weight grad [0][0] = 15.489048


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4692
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.304724
Layer 0 weight grad [0][0] = 39.965237


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4693
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.271015
Layer 0 weight grad [0][0] = 4.605976


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4694
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.103513
Layer 0 weight grad [0][0] = 16.156506


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4695
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -24.367809
Layer 0 weight grad [0][0] = 14.718151


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4696
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.355007
Layer 0 weight grad [0][0] = 14.322324


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4697
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.380981
Layer 0 weight grad [0][0] = 15.576938


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4698
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.039867
Layer 0 weight grad [0][0] = 17.107199


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4699
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.975646
Layer 0 weight grad [0][0] = 2.128903


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4700
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.959041
Layer 0 weight grad [0][0] = 15.987484


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4701
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.782702
Layer 0 weight grad [0][0] = 40.006397


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4702
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.562855
Layer 0 weight grad [0][0] = 17.205824


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4703
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.552354
Layer 0 weight grad [0][0] = 15.987136


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4704
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.771325
Layer 0 weight grad [0][0] = -12.045324


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4705
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -26.741535
Layer 0 weight grad [0][0] = 16.420025


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4706
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.516570
Layer 0 weight grad [0][0] = -8.037415


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4707
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.030121
Layer 0 weight grad [0][0] = 15.958981


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4708
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.008150
Layer 0 weight grad [0][0] = 27.293921


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4709
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.270714
Layer 0 weight grad [0][0] = 4.279595


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4710
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.086962
Layer 0 weight grad [0][0] = 25.844030


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4711
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.608955
Layer 0 weight grad [0][0] = 15.226317


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4712
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.920333
Layer 0 weight grad [0][0] = 18.906654


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4713
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -28.972084
Layer 0 weight grad [0][0] = 18.788406


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4714
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.188995
Layer 0 weight grad [0][0] = 31.000401


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4715
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.823175
Layer 0 weight grad [0][0] = 5.953336


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4716
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000016 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.888202
Layer 0 weight grad [0][0] = 15.185668


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4717
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.415445
Layer 0 weight grad [0][0] = 14.173838


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 4718
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -28.490522
Layer 0 weight grad [0][0] = 13.303011


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4719
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.653570
Layer 0 weight grad [0][0] = 13.903185


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4720
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.237208
Layer 0 weight grad [0][0] = 14.861355


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4721
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.367195
Layer 0 weight grad [0][0] = 27.745749


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4722
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.878204
Layer 0 weight grad [0][0] = 14.840108


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4723
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.178723
Layer 0 weight grad [0][0] = 14.545516


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4724
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.274450
Layer 0 weight grad [0][0] = 27.161875


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4725
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.316411
Layer 0 weight grad [0][0] = 1.821341


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4726
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.854137
Layer 0 weight grad [0][0] = 26.864922


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4727
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.375873
Layer 0 weight grad [0][0] = 14.328381


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4728
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.418658
Layer 0 weight grad [0][0] = 12.593715


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 4729
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.963412
Layer 0 weight grad [0][0] = 14.861473


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4730
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.505183
Layer 0 weight grad [0][0] = 15.318428


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4731
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -34.850510
Layer 0 weight grad [0][0] = 26.665548


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4732
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.974859
Layer 0 weight grad [0][0] = 2.309889


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4733
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.846710
Layer 0 weight grad [0][0] = 14.633278


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4734
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.348352
Layer 0 weight grad [0][0] = 15.167252


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4735
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.879671
Layer 0 weight grad [0][0] = 16.019789


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4736
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.456587
Layer 0 weight grad [0][0] = 31.333307


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4737
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.640852
Layer 0 weight grad [0][0] = 25.021162


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4738
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.672391
Layer 0 weight grad [0][0] = 15.619547


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4739
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.872610
Layer 0 weight grad [0][0] = 15.129148


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4740
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.236484
Layer 0 weight grad [0][0] = 17.248026


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 4741
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.256654
Layer 0 weight grad [0][0] = 15.520634


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4742
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -39.231800
Layer 0 weight grad [0][0] = 17.094671


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4743
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.566087
Layer 0 weight grad [0][0] = 16.164848


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4744
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.566705
Layer 0 weight grad [0][0] = 17.032238


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4745
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.100030
Layer 0 weight grad [0][0] = -5.164500


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4746
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.306238
Layer 0 weight grad [0][0] = 20.540524


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4747
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.121187
Layer 0 weight grad [0][0] = 17.037256


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4748
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.136320
Layer 0 weight grad [0][0] = -4.961125


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4749
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.915065
Layer 0 weight grad [0][0] = 16.988808


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4750
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -40.650154
Layer 0 weight grad [0][0] = 26.891195


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4751
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.990163
Layer 0 weight grad [0][0] = 16.426199


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4752
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.997382
Layer 0 weight grad [0][0] = 33.825836


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4753
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -37.932003
Layer 0 weight grad [0][0] = 28.076944


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4754
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.808575
Layer 0 weight grad [0][0] = 17.331211


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4755
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.814925
Layer 0 weight grad [0][0] = 17.177790


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4756
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.828642
Layer 0 weight grad [0][0] = 16.455387


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4757
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.814077
Layer 0 weight grad [0][0] = 28.716909


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4758
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.231947
Layer 0 weight grad [0][0] = 26.792454


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 4759
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.965520
Layer 0 weight grad [0][0] = -3.087234


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4760
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -33.596786
Layer 0 weight grad [0][0] = 19.665571


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4761
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -34.090504
Layer 0 weight grad [0][0] = 16.516272


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4762
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.022987
Layer 0 weight grad [0][0] = -1.470403


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4763
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.033827
Layer 0 weight grad [0][0] = 31.149803


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4764
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.470367
Layer 0 weight grad [0][0] = 0.919379


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 4765
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -32.675449
Layer 0 weight grad [0][0] = 15.657681


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4766
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.093158
Layer 0 weight grad [0][0] = 25.368645


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4767
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.940537
Layer 0 weight grad [0][0] = 18.205601


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4768
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.656593
Layer 0 weight grad [0][0] = 15.950933


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4769
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.160594
Layer 0 weight grad [0][0] = 16.232704


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4770
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.972893
Layer 0 weight grad [0][0] = -0.708224


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4771
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.985377
Layer 0 weight grad [0][0] = 15.889658


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4772
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.705257
Layer 0 weight grad [0][0] = 16.176634


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4773
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.514157
Layer 0 weight grad [0][0] = 12.597318


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4774
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.245544
Layer 0 weight grad [0][0] = 16.005301


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4775
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.207283
Layer 0 weight grad [0][0] = 16.320568


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4776
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.766365
Layer 0 weight grad [0][0] = 17.655148


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4777
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -33.740246
Layer 0 weight grad [0][0] = 4.513780


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4778
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.249003
Layer 0 weight grad [0][0] = -2.838016


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4779
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.808457
Layer 0 weight grad [0][0] = 16.331327


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4780
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.817161
Layer 0 weight grad [0][0] = -2.620148


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4781
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.834872
Layer 0 weight grad [0][0] = 15.465960


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4782
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.352439
Layer 0 weight grad [0][0] = 15.446399


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4783
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.378262
Layer 0 weight grad [0][0] = 15.614910


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4784
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.884667
Layer 0 weight grad [0][0] = -0.294518


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4785
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.906169
Layer 0 weight grad [0][0] = 15.319205


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4786
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.925754
Layer 0 weight grad [0][0] = 16.042156


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4787
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.412333
Layer 0 weight grad [0][0] = 15.962193


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4788
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.930736
Layer 0 weight grad [0][0] = 15.458219


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4789
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000017 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.715120
Layer 0 weight grad [0][0] = 15.842834


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4790
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -38.109589
Layer 0 weight grad [0][0] = 16.168474


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4791
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.779404
Layer 0 weight grad [0][0] = 17.082195


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4792
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.732959
Layer 0 weight grad [0][0] = -2.465216


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4793
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.261076
Layer 0 weight grad [0][0] = 16.259609


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4794
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.721820
Layer 0 weight grad [0][0] = 20.515490


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4795
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.840090
Layer 0 weight grad [0][0] = -3.193348


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 4796
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -41.045959
Layer 0 weight grad [0][0] = 16.622738


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4797
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.597653
Layer 0 weight grad [0][0] = 1.402885


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4798
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.282171
Layer 0 weight grad [0][0] = 16.634136


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4799
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.318353
Layer 0 weight grad [0][0] = 24.153297


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4800
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.151843
Layer 0 weight grad [0][0] = 18.810909


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4801
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.682976
Layer 0 weight grad [0][0] = 20.769148


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4802
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.178058
Layer 0 weight grad [0][0] = 30.646021


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4803
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.857712
Layer 0 weight grad [0][0] = 14.321788


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4804
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.118734
Layer 0 weight grad [0][0] = -2.056812


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4805
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.641171
Layer 0 weight grad [0][0] = 18.432598


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4806
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.072821
Layer 0 weight grad [0][0] = 1.647886


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4807
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.625654
Layer 0 weight grad [0][0] = 17.387472


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4808
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.080850
Layer 0 weight grad [0][0] = -2.345344


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4809
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.151290
Layer 0 weight grad [0][0] = 18.226976


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4810
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.159449
Layer 0 weight grad [0][0] = 16.661457


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4811
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.157276
Layer 0 weight grad [0][0] = 16.288141


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4812
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.689682
Layer 0 weight grad [0][0] = 18.105738


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4813
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.392889
Layer 0 weight grad [0][0] = 16.179930


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4814
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.205709
Layer 0 weight grad [0][0] = 16.646130


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4815
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.719479
Layer 0 weight grad [0][0] = 19.393705


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4816
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.754962
Layer 0 weight grad [0][0] = 21.164047


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4817
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.721097
Layer 0 weight grad [0][0] = 15.812966


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4818
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.294084
Layer 0 weight grad [0][0] = 30.091858


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4819
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.501375
Layer 0 weight grad [0][0] = 1.279034


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4820
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.540125
Layer 0 weight grad [0][0] = 25.427710


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4821
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.400406
Layer 0 weight grad [0][0] = 11.955809


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4822
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.213882
Layer 0 weight grad [0][0] = 15.636250


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4823
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.288110
Layer 0 weight grad [0][0] = 21.781792


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4824
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 10.983624
Layer 0 weight grad [0][0] = 15.061302


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4825
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000015 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -37.252113
Layer 0 weight grad [0][0] = 22.069111


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4826
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -36.420624
Layer 0 weight grad [0][0] = 15.223886


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4827
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7.072277
Layer 0 weight grad [0][0] = 4.072665


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4828
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -37.022972
Layer 0 weight grad [0][0] = 14.732333


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4829
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.950947
Layer 0 weight grad [0][0] = 11.805120


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4830
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.777526
Layer 0 weight grad [0][0] = 22.002350


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4831
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.418272
Layer 0 weight grad [0][0] = 18.547014


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4832
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.983303
Layer 0 weight grad [0][0] = 14.815825


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4833
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.801379
Layer 0 weight grad [0][0] = 32.271873


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4834
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.431911
Layer 0 weight grad [0][0] = 15.967087


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4835
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.951128
Layer 0 weight grad [0][0] = 51.367943


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4836
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.588286
Layer 0 weight grad [0][0] = 15.672378


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4837
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.092564
Layer 0 weight grad [0][0] = 32.711414


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4838
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -28.651484
Layer 0 weight grad [0][0] = 17.528906


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4839
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.015492
Layer 0 weight grad [0][0] = 17.646299


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4840
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.540617
Layer 0 weight grad [0][0] = 18.542906


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4841
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.711020
Layer 0 weight grad [0][0] = 16.324591


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4842
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.497669
Layer 0 weight grad [0][0] = 16.328745


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4843
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.254586
Layer 0 weight grad [0][0] = -7.871929


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4844
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.290663
Layer 0 weight grad [0][0] = 17.587999


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4845
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.283161
Layer 0 weight grad [0][0] = 28.758659


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4846
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.302723
Layer 0 weight grad [0][0] = 16.838001


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4847
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -32.906094
Layer 0 weight grad [0][0] = -6.119144


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 4848
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.258417
Layer 0 weight grad [0][0] = 17.918900


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4849
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.078333
Layer 0 weight grad [0][0] = 17.974876


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4850
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.575155
Layer 0 weight grad [0][0] = -4.682628


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4851
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.581498
Layer 0 weight grad [0][0] = -15.246942


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 4852
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -34.073750
Layer 0 weight grad [0][0] = 18.173958


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4853
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.841040
Layer 0 weight grad [0][0] = 17.970804


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4854
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.856758
Layer 0 weight grad [0][0] = 33.490868


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4855
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -35.172112
Layer 0 weight grad [0][0] = 28.724165


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4856
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.141060
Layer 0 weight grad [0][0] = 17.414333


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4857
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.354886
Layer 0 weight grad [0][0] = 16.666124


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4858
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.629953
Layer 0 weight grad [0][0] = -9.500049


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 4859
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.167014
Layer 0 weight grad [0][0] = 27.300768


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4860
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.672564
Layer 0 weight grad [0][0] = 28.396559


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4861
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -37.890888
Layer 0 weight grad [0][0] = -9.787206


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4862
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.959336
Layer 0 weight grad [0][0] = 16.461897


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4863
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -38.035454
Layer 0 weight grad [0][0] = 17.876448


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4864
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.767634
Layer 0 weight grad [0][0] = 17.160587


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4865
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.279403
Layer 0 weight grad [0][0] = 16.544973


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4866
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.812708
Layer 0 weight grad [0][0] = 15.800328


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4867
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.334587
Layer 0 weight grad [0][0] = 16.181488


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4868
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.846059
Layer 0 weight grad [0][0] = 16.926954


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4869
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -41.234459
Layer 0 weight grad [0][0] = 32.711102


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4870
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.690971
Layer 0 weight grad [0][0] = 13.409222


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4871
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -38.019894
Layer 0 weight grad [0][0] = 38.419624


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4872
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -34.030155
Layer 0 weight grad [0][0] = 16.446585


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4873
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.371134
Layer 0 weight grad [0][0] = 16.401447


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4874
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.906611
Layer 0 weight grad [0][0] = -7.150273


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4875
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.902622
Layer 0 weight grad [0][0] = 39.529186


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4876
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.440187
Layer 0 weight grad [0][0] = 28.188963


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4877
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.282525
Layer 0 weight grad [0][0] = 44.635208


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4878
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.607378
Layer 0 weight grad [0][0] = -2.328542


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4879
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.873762
Layer 0 weight grad [0][0] = 16.481060


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4880
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -3.162393
Layer 0 weight grad [0][0] = 26.267498


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4881
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.398087
Layer 0 weight grad [0][0] = -18.191387


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4882
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.124505
Layer 0 weight grad [0][0] = 17.916363


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4883
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -3.137952
Layer 0 weight grad [0][0] = 38.990929


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4884
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.628202
Layer 0 weight grad [0][0] = -16.138832


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4885
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.653249
Layer 0 weight grad [0][0] = 16.454569


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4886
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -27.142448
Layer 0 weight grad [0][0] = 17.672731


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4887
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.489243
Layer 0 weight grad [0][0] = 16.522610


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4888
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.554351
Layer 0 weight grad [0][0] = 39.479374


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4889
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.605935
Layer 0 weight grad [0][0] = 37.318565


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4890
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.639066
Layer 0 weight grad [0][0] = 20.563911


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 4891
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.356597
Layer 0 weight grad [0][0] = 16.695768


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4892
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.657671
Layer 0 weight grad [0][0] = 25.861715


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 4893
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.503521
Layer 0 weight grad [0][0] = -6.054773


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4894
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.375141
Layer 0 weight grad [0][0] = 16.482710


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4895
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.336266
Layer 0 weight grad [0][0] = 16.962803


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4896
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.389035
Layer 0 weight grad [0][0] = 18.365280


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4897
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.368003
Layer 0 weight grad [0][0] = 17.486012


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4898
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.921693
Layer 0 weight grad [0][0] = 18.800898


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4899
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.886244
Layer 0 weight grad [0][0] = 21.223921


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4900
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.915334
Layer 0 weight grad [0][0] = 17.433468


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4901
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.971251
Layer 0 weight grad [0][0] = -13.918425


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4902
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.467413
Layer 0 weight grad [0][0] = 18.417665


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4903
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.782482
Layer 0 weight grad [0][0] = -18.470486


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4904
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.806314
Layer 0 weight grad [0][0] = 13.021745


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4905
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.133281
Layer 0 weight grad [0][0] = -17.933670


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4906
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.593985
Layer 0 weight grad [0][0] = 18.468147


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4907
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.643729
Layer 0 weight grad [0][0] = 38.495541


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4908
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.711928
Layer 0 weight grad [0][0] = 17.932661


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4909
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.420846
Layer 0 weight grad [0][0] = 20.127939


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4910
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.688342
Layer 0 weight grad [0][0] = 16.297634


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4911
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.704550
Layer 0 weight grad [0][0] = 16.730173


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4912
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.439908
Layer 0 weight grad [0][0] = 17.465706


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4913
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -31.833418
Layer 0 weight grad [0][0] = 16.916727


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4914
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.719508
Layer 0 weight grad [0][0] = 23.906765


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4915
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.047547
Layer 0 weight grad [0][0] = 17.475426


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 4916
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.552948
Layer 0 weight grad [0][0] = 16.339674


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4917
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.047162
Layer 0 weight grad [0][0] = 17.213318


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4918
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.569962
Layer 0 weight grad [0][0] = 40.131870


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4919
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -33.854214
Layer 0 weight grad [0][0] = 16.817492


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4920
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.076468
Layer 0 weight grad [0][0] = 44.871223


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4921
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.480179
Layer 0 weight grad [0][0] = -13.567178


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4922
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.483055
Layer 0 weight grad [0][0] = 17.214031


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4923
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.492705
Layer 0 weight grad [0][0] = 39.759274


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4924
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.444767
Layer 0 weight grad [0][0] = 22.713688


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4925
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -29.937939
Layer 0 weight grad [0][0] = 15.232539


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4926
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.733499
Layer 0 weight grad [0][0] = 22.540833


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4927
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.579898
Layer 0 weight grad [0][0] = 14.660056


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4928
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.160627
Layer 0 weight grad [0][0] = 22.267792


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4929
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -29.866201
Layer 0 weight grad [0][0] = -17.244352


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4930
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.889663
Layer 0 weight grad [0][0] = 17.089436


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4931
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.967710
Layer 0 weight grad [0][0] = 16.599390


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4932
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.959496
Layer 0 weight grad [0][0] = -18.986431


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 4933
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.989317
Layer 0 weight grad [0][0] = 39.405018


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4934
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.008227
Layer 0 weight grad [0][0] = 3.523963


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4935
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.042820
Layer 0 weight grad [0][0] = 20.628256


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4936
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.270290
Layer 0 weight grad [0][0] = 19.357185


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4937
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.051895
Layer 0 weight grad [0][0] = 20.141680


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4938
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.011219
Layer 0 weight grad [0][0] = 38.190159


Training loss: 2.302585
Training accuracy: 0.375000

epoch: 4939
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.016742
Layer 0 weight grad [0][0] = 18.811399


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4940
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.989154
Layer 0 weight grad [0][0] = 18.239502


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4941
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -26.683468
Layer 0 weight grad [0][0] = 18.465168


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4942
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.612480
Layer 0 weight grad [0][0] = -13.521899


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4943
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.341536
Layer 0 weight grad [0][0] = -10.061517


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4944
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.388291
Layer 0 weight grad [0][0] = 37.347046


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4945
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.475919
Layer 0 weight grad [0][0] = 18.359987


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4946
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.391918
Layer 0 weight grad [0][0] = -12.171700


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4947
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.952087
Layer 0 weight grad [0][0] = 18.285395


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4948
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.007622
Layer 0 weight grad [0][0] = -12.487494


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4949
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.987985
Layer 0 weight grad [0][0] = 35.147182


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4950
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.000730
Layer 0 weight grad [0][0] = 21.499327


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4951
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.496849
Layer 0 weight grad [0][0] = 18.614868


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4952
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.981822
Layer 0 weight grad [0][0] = 18.780798


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4953
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.976366
Layer 0 weight grad [0][0] = 18.646881


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4954
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.193636
Layer 0 weight grad [0][0] = 18.368225


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4955
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.965066
Layer 0 weight grad [0][0] = 17.713337


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4956
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.977282
Layer 0 weight grad [0][0] = -12.831865


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4957
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -28.831144
Layer 0 weight grad [0][0] = 35.904476


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4958
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.016891
Layer 0 weight grad [0][0] = 19.296650


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4959
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.984747
Layer 0 weight grad [0][0] = 28.004730


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4960
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.989630
Layer 0 weight grad [0][0] = -4.885337


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4961
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.474380
Layer 0 weight grad [0][0] = 16.415739


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4962
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.987998
Layer 0 weight grad [0][0] = 29.008255


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4963
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.468052
Layer 0 weight grad [0][0] = -12.092159


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4964
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.028775
Layer 0 weight grad [0][0] = 19.362638


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4965
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.991147
Layer 0 weight grad [0][0] = 30.623892


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4966
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -26.297184
Layer 0 weight grad [0][0] = 32.006748


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4967
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.973607
Layer 0 weight grad [0][0] = 19.635715


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4968
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.497261
Layer 0 weight grad [0][0] = 23.606482


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4969
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.719849
Layer 0 weight grad [0][0] = 22.857246


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4970
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.712665
Layer 0 weight grad [0][0] = 21.726707


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4971
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.625942
Layer 0 weight grad [0][0] = -1.649012


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4972
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.441539
Layer 0 weight grad [0][0] = -10.455131


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4973
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.369836
Layer 0 weight grad [0][0] = 23.600153


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 4974
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.336396
Layer 0 weight grad [0][0] = 19.942358


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4975
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.347934
Layer 0 weight grad [0][0] = 21.831980


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4976
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.816772
Layer 0 weight grad [0][0] = 20.304346


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4977
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.455840
Layer 0 weight grad [0][0] = 23.139637


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4978
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.267924
Layer 0 weight grad [0][0] = 12.702035


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4979
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.408437
Layer 0 weight grad [0][0] = -13.807653


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4980
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.876420
Layer 0 weight grad [0][0] = 16.788809


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4981
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.449996
Layer 0 weight grad [0][0] = 24.851719


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4982
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.385734
Layer 0 weight grad [0][0] = 19.466200


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 4983
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.910789
Layer 0 weight grad [0][0] = 19.556763


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4984
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.374104
Layer 0 weight grad [0][0] = 19.556635


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4985
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.552270
Layer 0 weight grad [0][0] = 29.904737


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4986
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.324355
Layer 0 weight grad [0][0] = 17.354525


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4987
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.874001
Layer 0 weight grad [0][0] = 21.751133


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 4988
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.293732
Layer 0 weight grad [0][0] = 20.244003


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4989
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.320501
Layer 0 weight grad [0][0] = -6.082182


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4990
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.474257
Layer 0 weight grad [0][0] = 19.095640


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4991
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.838778
Layer 0 weight grad [0][0] = 19.279408


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4992
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.547242
Layer 0 weight grad [0][0] = 21.506397


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4993
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.727971
Layer 0 weight grad [0][0] = 19.106634


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4994
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.486104
Layer 0 weight grad [0][0] = 18.946205


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4995
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.476584
Layer 0 weight grad [0][0] = 31.491205


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 4996
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.436065
Layer 0 weight grad [0][0] = 19.452143


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4997
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -28.088362
Layer 0 weight grad [0][0] = 19.258659


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 4998
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -27.965796
Layer 0 weight grad [0][0] = 23.559437


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 4999
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.615349
Layer 0 weight grad [0][0] = 18.496307


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5000
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.599432
Layer 0 weight grad [0][0] = 18.168379


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5001
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.032221
Layer 0 weight grad [0][0] = 18.337967


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5002
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.563423
Layer 0 weight grad [0][0] = 19.446775


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5003
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7.600197
Layer 0 weight grad [0][0] = 29.935972


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5004
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.838134
Layer 0 weight grad [0][0] = -20.791374


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5005
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.332862
Layer 0 weight grad [0][0] = 34.633240


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5006
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 8.054463
Layer 0 weight grad [0][0] = 18.378155


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5007
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -27.920727
Layer 0 weight grad [0][0] = 17.769705


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5008
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -27.292137
Layer 0 weight grad [0][0] = 22.454741


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5009
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.139847
Layer 0 weight grad [0][0] = 17.609552


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5010
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.115104
Layer 0 weight grad [0][0] = 19.406088


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5011
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.107088
Layer 0 weight grad [0][0] = -20.065731


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5012
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.082394
Layer 0 weight grad [0][0] = 17.971951


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5013
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.538633
Layer 0 weight grad [0][0] = 19.436460


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5014
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.007436
Layer 0 weight grad [0][0] = 19.642525


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5015
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.500451
Layer 0 weight grad [0][0] = -17.734430


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5016
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.964468
Layer 0 weight grad [0][0] = -10.097146


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5017
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.219996
Layer 0 weight grad [0][0] = 18.182837


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5018
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.258642
Layer 0 weight grad [0][0] = 2.706208


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5019
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.716534
Layer 0 weight grad [0][0] = 6.078293


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5020
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.503295
Layer 0 weight grad [0][0] = -0.527399


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5021
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.481236
Layer 0 weight grad [0][0] = 19.143122


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5022
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.518321
Layer 0 weight grad [0][0] = -11.562599


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5023
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.346816
Layer 0 weight grad [0][0] = 17.012085


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5024
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.324930
Layer 0 weight grad [0][0] = 39.003635


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5025
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.704906
Layer 0 weight grad [0][0] = 18.527895


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5026
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.163403
Layer 0 weight grad [0][0] = 17.457935


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5027
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.592593
Layer 0 weight grad [0][0] = 16.785572


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5028
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.638077
Layer 0 weight grad [0][0] = -0.927378


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5029
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.619770
Layer 0 weight grad [0][0] = 16.867949


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5030
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -29.720152
Layer 0 weight grad [0][0] = 10.630298


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5031
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.322541
Layer 0 weight grad [0][0] = 3.084086


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5032
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.268713
Layer 0 weight grad [0][0] = -5.702961


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 5033
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.973760
Layer 0 weight grad [0][0] = 15.459354


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5034
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.203054
Layer 0 weight grad [0][0] = -3.253223


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5035
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -27.030985
Layer 0 weight grad [0][0] = 18.565926


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5036
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.436429
Layer 0 weight grad [0][0] = 17.854776


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5037
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.420517
Layer 0 weight grad [0][0] = 16.619802


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5038
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.919664
Layer 0 weight grad [0][0] = 30.568020


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5039
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.515788
Layer 0 weight grad [0][0] = 18.304346


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5040
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.255193
Layer 0 weight grad [0][0] = 17.110353


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5041
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.537368
Layer 0 weight grad [0][0] = 34.595234


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5042
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.696173
Layer 0 weight grad [0][0] = 16.985455


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5043
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.196188
Layer 0 weight grad [0][0] = 15.786263


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 5044
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.669818
Layer 0 weight grad [0][0] = 25.601885


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5045
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.437754
Layer 0 weight grad [0][0] = -3.248297


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5046
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.428726
Layer 0 weight grad [0][0] = -2.153276


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5047
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -25.036478
Layer 0 weight grad [0][0] = 16.694820


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5048
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.406050
Layer 0 weight grad [0][0] = 18.423765


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5049
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.380805
Layer 0 weight grad [0][0] = 17.922483


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5050
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.855448
Layer 0 weight grad [0][0] = 18.199499


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5051
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.278118
Layer 0 weight grad [0][0] = 18.876991


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5052
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.795467
Layer 0 weight grad [0][0] = -30.666704


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5053
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.729183
Layer 0 weight grad [0][0] = 19.533052


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5054
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.754855
Layer 0 weight grad [0][0] = 18.828716


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5055
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.719175
Layer 0 weight grad [0][0] = 19.476776


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5056
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.686895
Layer 0 weight grad [0][0] = 18.737537


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5057
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.654742
Layer 0 weight grad [0][0] = 18.134893


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5058
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.610377
Layer 0 weight grad [0][0] = 28.007277


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5059
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.383110
Layer 0 weight grad [0][0] = 1.524920


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5060
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 16.102104
Layer 0 weight grad [0][0] = 18.080303


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5061
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -27.748947
Layer 0 weight grad [0][0] = 31.673523


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5062
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.948889
Layer 0 weight grad [0][0] = 27.943899


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5063
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.733387
Layer 0 weight grad [0][0] = -7.179373


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 5064
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.492320
Layer 0 weight grad [0][0] = 19.136377


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 5065
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.986110
Layer 0 weight grad [0][0] = 19.096661


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5066
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.897325
Layer 0 weight grad [0][0] = -14.786770


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5067
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.924114
Layer 0 weight grad [0][0] = 26.626511


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5068
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.246179
Layer 0 weight grad [0][0] = 20.542671


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 5069
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.741488
Layer 0 weight grad [0][0] = 23.748737


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5070
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.295131
Layer 0 weight grad [0][0] = 17.574280


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5071
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.059483
Layer 0 weight grad [0][0] = 36.655502


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5072
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.919847
Layer 0 weight grad [0][0] = 32.511528


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5073
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.595881
Layer 0 weight grad [0][0] = 0.583751


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5074
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -22.802345
Layer 0 weight grad [0][0] = 0.585928


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5075
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.044033
Layer 0 weight grad [0][0] = 15.484183


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5076
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.512744
Layer 0 weight grad [0][0] = 15.935669


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5077
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.451492
Layer 0 weight grad [0][0] = 28.622252


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5078
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 15.807402
Layer 0 weight grad [0][0] = 16.768705


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5079
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.541074
Layer 0 weight grad [0][0] = 16.392839


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 5080
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -24.976345
Layer 0 weight grad [0][0] = 17.890041


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5081
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -25.194778
Layer 0 weight grad [0][0] = 5.292487


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5082
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.933135
Layer 0 weight grad [0][0] = 16.283403


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5083
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.650113
Layer 0 weight grad [0][0] = 4.894990


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5084
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.061904
Layer 0 weight grad [0][0] = 32.742649


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5085
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.144951
Layer 0 weight grad [0][0] = 4.109395


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5086
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.812099
Layer 0 weight grad [0][0] = 23.977734


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5087
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.638671
Layer 0 weight grad [0][0] = -16.360413


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 5088
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.838899
Layer 0 weight grad [0][0] = 5.422019


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5089
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.135662
Layer 0 weight grad [0][0] = 31.676664


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5090
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.239925
Layer 0 weight grad [0][0] = 33.769238


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5091
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -21.766615
Layer 0 weight grad [0][0] = 5.282046


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5092
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.915959
Layer 0 weight grad [0][0] = -15.615308


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5093
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.228269
Layer 0 weight grad [0][0] = 38.135242


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5094
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.728130
Layer 0 weight grad [0][0] = 15.186793


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5095
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -23.705053
Layer 0 weight grad [0][0] = 14.151111


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5096
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.092746
Layer 0 weight grad [0][0] = 14.198241


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5097
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.143515
Layer 0 weight grad [0][0] = -16.921011


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5098
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -25.260366
Layer 0 weight grad [0][0] = 14.460938


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5099
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.576076
Layer 0 weight grad [0][0] = 33.329384


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5100
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.419368
Layer 0 weight grad [0][0] = 35.505394


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5101
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.260296
Layer 0 weight grad [0][0] = 2.986522


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5102
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.439996
Layer 0 weight grad [0][0] = 14.202382


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5103
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.999726
Layer 0 weight grad [0][0] = 14.667946


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5104
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.457844
Layer 0 weight grad [0][0] = -15.250491


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5105
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.469662
Layer 0 weight grad [0][0] = 13.612338


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5106
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.994569
Layer 0 weight grad [0][0] = 14.526034


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5107
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.009436
Layer 0 weight grad [0][0] = -14.170666


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5108
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.491723
Layer 0 weight grad [0][0] = 13.010422


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5109
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -23.666853
Layer 0 weight grad [0][0] = 12.316957


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5110
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.669431
Layer 0 weight grad [0][0] = -9.630385


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5111
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -24.450642
Layer 0 weight grad [0][0] = 14.805603


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5112
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.513350
Layer 0 weight grad [0][0] = 13.563965


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5113
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -25.270334
Layer 0 weight grad [0][0] = 24.581789


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5114
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.315426
Layer 0 weight grad [0][0] = 23.860983


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5115
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.138770
Layer 0 weight grad [0][0] = 6.746942


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5116
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.732607
Layer 0 weight grad [0][0] = -11.548246


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 5117
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.719347
Layer 0 weight grad [0][0] = 15.392970


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5118
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.689416
Layer 0 weight grad [0][0] = 22.961761


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5119
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.577830
Layer 0 weight grad [0][0] = 14.735449


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5120
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.004636
Layer 0 weight grad [0][0] = 16.814077


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5121
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.702031
Layer 0 weight grad [0][0] = -12.206049


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 5122
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.678297
Layer 0 weight grad [0][0] = 1.026108


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5123
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.347985
Layer 0 weight grad [0][0] = 15.439088


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5124
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.771886
Layer 0 weight grad [0][0] = -0.588506


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5125
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.777858
Layer 0 weight grad [0][0] = 16.445002


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5126
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.782926
Layer 0 weight grad [0][0] = 15.371500


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5127
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.785378
Layer 0 weight grad [0][0] = 15.488239


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5128
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.287983
Layer 0 weight grad [0][0] = 16.409977


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5129
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.791533
Layer 0 weight grad [0][0] = 15.554053


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5130
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.816307
Layer 0 weight grad [0][0] = 35.889507


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5131
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.806835
Layer 0 weight grad [0][0] = 16.572699


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5132
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.811981
Layer 0 weight grad [0][0] = 15.058355


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5133
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.824786
Layer 0 weight grad [0][0] = 15.498880


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5134
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.799431
Layer 0 weight grad [0][0] = 14.850700


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5135
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.059324
Layer 0 weight grad [0][0] = 14.883677


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5136
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.091198
Layer 0 weight grad [0][0] = 19.416607


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5137
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.883690
Layer 0 weight grad [0][0] = -12.731897


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 5138
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.415113
Layer 0 weight grad [0][0] = 38.748348


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5139
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.391727
Layer 0 weight grad [0][0] = 39.422554


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5140
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.883322
Layer 0 weight grad [0][0] = 17.027456


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5141
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.896381
Layer 0 weight grad [0][0] = 15.503678


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5142
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.413155
Layer 0 weight grad [0][0] = -5.432333


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5143
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.930459
Layer 0 weight grad [0][0] = 15.063791


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5144
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.949124
Layer 0 weight grad [0][0] = 38.098122


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5145
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.899304
Layer 0 weight grad [0][0] = 14.834890


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5146
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.470767
Layer 0 weight grad [0][0] = 14.587337


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5147
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.175806
Layer 0 weight grad [0][0] = 13.303990


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5148
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.992187
Layer 0 weight grad [0][0] = 38.072540


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5149
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.510980
Layer 0 weight grad [0][0] = -12.799709


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5150
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 11.410542
Layer 0 weight grad [0][0] = 14.874407


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5151
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.104523
Layer 0 weight grad [0][0] = 17.279299


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5152
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.029742
Layer 0 weight grad [0][0] = 15.315570


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5153
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.084276
Layer 0 weight grad [0][0] = 15.781059


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5154
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.114842
Layer 0 weight grad [0][0] = 41.808540


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5155
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.027062
Layer 0 weight grad [0][0] = -12.467673


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5156
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.530610
Layer 0 weight grad [0][0] = 15.436896


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5157
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.762678
Layer 0 weight grad [0][0] = 14.501786


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5158
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.552230
Layer 0 weight grad [0][0] = 18.000153


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5159
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 15.039571
Layer 0 weight grad [0][0] = 17.268894


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5160
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.594180
Layer 0 weight grad [0][0] = 15.143027


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5161
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.032128
Layer 0 weight grad [0][0] = 14.796429


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5162
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.801057
Layer 0 weight grad [0][0] = -11.477449


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5163
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -30.150303
Layer 0 weight grad [0][0] = 42.574944


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5164
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -24.752455
Layer 0 weight grad [0][0] = 14.388415


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5165
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.965944
Layer 0 weight grad [0][0] = 15.151424


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 5166
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.481981
Layer 0 weight grad [0][0] = 13.965457


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5167
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.994131
Layer 0 weight grad [0][0] = 1.041466


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5168
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.029067
Layer 0 weight grad [0][0] = 13.784513


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5169
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.023975
Layer 0 weight grad [0][0] = 13.332715


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5170
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.041340
Layer 0 weight grad [0][0] = 14.343943


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5171
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.056408
Layer 0 weight grad [0][0] = 40.766289


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5172
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.431133
Layer 0 weight grad [0][0] = 15.243301


Training loss: 2.302585
Training accuracy: 0.437500

epoch: 5173
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.495738
Layer 0 weight grad [0][0] = 7.719353


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5174
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.898735
Layer 0 weight grad [0][0] = 41.300358


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5175
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.892656
Layer 0 weight grad [0][0] = 4.819185


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5176
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 13.446504
Layer 0 weight grad [0][0] = 13.528491


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5177
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 13.977116
Layer 0 weight grad [0][0] = 13.571465


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5178
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.527194
Layer 0 weight grad [0][0] = 15.488488


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5179
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.534593
Layer 0 weight grad [0][0] = 1.226046


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5180
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.519833
Layer 0 weight grad [0][0] = 5.333092


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5181
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.189935
Layer 0 weight grad [0][0] = 12.941525


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5182
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.477234
Layer 0 weight grad [0][0] = 12.864566


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5183
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.480086
Layer 0 weight grad [0][0] = 14.077071


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5184
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.477465
Layer 0 weight grad [0][0] = 5.197623


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5185
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.469335
Layer 0 weight grad [0][0] = 16.267567


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 5186
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.957013
Layer 0 weight grad [0][0] = 29.334604


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5187
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.153629
Layer 0 weight grad [0][0] = 15.875772


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5188
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.403923
Layer 0 weight grad [0][0] = 37.802704


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5189
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.956783
Layer 0 weight grad [0][0] = 15.704066


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5190
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.925660
Layer 0 weight grad [0][0] = -7.505840


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5191
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.873571
Layer 0 weight grad [0][0] = 16.121609


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5192
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.122724
Layer 0 weight grad [0][0] = 17.149752


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5193
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -29.630154
Layer 0 weight grad [0][0] = 17.287682


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5194
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.470537
Layer 0 weight grad [0][0] = 18.285124


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5195
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.447297
Layer 0 weight grad [0][0] = 16.765663


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5196
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.939635
Layer 0 weight grad [0][0] = 15.097140


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5197
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.124532
Layer 0 weight grad [0][0] = 16.976662


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5198
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.595595
Layer 0 weight grad [0][0] = 15.744516


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5199
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.096495
Layer 0 weight grad [0][0] = 15.866337


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5200
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.360803
Layer 0 weight grad [0][0] = 15.920441


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5201
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.546697
Layer 0 weight grad [0][0] = 15.452975


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5202
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.840440
Layer 0 weight grad [0][0] = 28.997541


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5203
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.307992
Layer 0 weight grad [0][0] = 39.552544


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5204
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.459890
Layer 0 weight grad [0][0] = 16.095982


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5205
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.482820
Layer 0 weight grad [0][0] = 16.808466


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5206
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.259680
Layer 0 weight grad [0][0] = 14.791741


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5207
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.752566
Layer 0 weight grad [0][0] = 15.963617


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5208
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.682109
Layer 0 weight grad [0][0] = 14.507870


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 5209
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.205500
Layer 0 weight grad [0][0] = 35.439014


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5210
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 27.086939
Layer 0 weight grad [0][0] = 15.540081


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 5211
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.682188
Layer 0 weight grad [0][0] = -18.649679


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5212
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.826668
Layer 0 weight grad [0][0] = 35.838421


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5213
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -34.702534
Layer 0 weight grad [0][0] = 14.683099


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5214
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.513081
Layer 0 weight grad [0][0] = 15.597755


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5215
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 23.956882
Layer 0 weight grad [0][0] = 10.759631


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5216
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.243129
Layer 0 weight grad [0][0] = 17.414791


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5217
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.221924
Layer 0 weight grad [0][0] = 38.699261


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5218
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.162940
Layer 0 weight grad [0][0] = 14.065703


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5219
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.349377
Layer 0 weight grad [0][0] = 15.481058


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5220
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.669794
Layer 0 weight grad [0][0] = 13.568091


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5221
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.355167
Layer 0 weight grad [0][0] = -13.421461


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5222
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.861582
Layer 0 weight grad [0][0] = 13.274908


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5223
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -38.980152
Layer 0 weight grad [0][0] = 34.985077


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5224
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.748860
Layer 0 weight grad [0][0] = 13.035745


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5225
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.717463
Layer 0 weight grad [0][0] = 26.327694


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5226
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 25.437407
Layer 0 weight grad [0][0] = 12.837289


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5227
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.231139
Layer 0 weight grad [0][0] = 13.875652


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5228
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.256015
Layer 0 weight grad [0][0] = 39.579041


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5229
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -37.213226
Layer 0 weight grad [0][0] = 38.716568


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5230
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.333607
Layer 0 weight grad [0][0] = 14.756147


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5231
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.773014
Layer 0 weight grad [0][0] = 12.619080


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5232
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.782923
Layer 0 weight grad [0][0] = 33.105900


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5233
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 23.642315
Layer 0 weight grad [0][0] = 13.950746


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5234
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.430782
Layer 0 weight grad [0][0] = 27.218523


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 5235
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.985644
Layer 0 weight grad [0][0] = 13.977557


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5236
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.973182
Layer 0 weight grad [0][0] = 6.828412


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5237
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.961177
Layer 0 weight grad [0][0] = 14.755479


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5238
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.907830
Layer 0 weight grad [0][0] = 13.879197


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5239
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.649690
Layer 0 weight grad [0][0] = 14.645100


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5240
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.428356
Layer 0 weight grad [0][0] = 14.646089


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5241
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.895223
Layer 0 weight grad [0][0] = -17.284079


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5242
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.897341
Layer 0 weight grad [0][0] = 15.748481


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5243
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.854793
Layer 0 weight grad [0][0] = -18.879278


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5244
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.301715
Layer 0 weight grad [0][0] = -14.689314


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5245
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 29.836514
Layer 0 weight grad [0][0] = 14.301600


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5246
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.959352
Layer 0 weight grad [0][0] = 24.952265


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5247
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 29.736370
Layer 0 weight grad [0][0] = 14.352835


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5248
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.910108
Layer 0 weight grad [0][0] = 14.609515


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5249
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.931334
Layer 0 weight grad [0][0] = 13.591197


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5250
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 30.031225
Layer 0 weight grad [0][0] = 40.203541


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5251
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.597007
Layer 0 weight grad [0][0] = 15.324685


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5252
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.069741
Layer 0 weight grad [0][0] = 31.066631


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5253
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -36.117428
Layer 0 weight grad [0][0] = 16.643633


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5254
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.601324
Layer 0 weight grad [0][0] = -17.521618


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5255
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 26.886152
Layer 0 weight grad [0][0] = 13.718132


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5256
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.816633
Layer 0 weight grad [0][0] = 13.146417


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5257
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 26.759781
Layer 0 weight grad [0][0] = 11.751634


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5258
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.492920
Layer 0 weight grad [0][0] = 12.994065


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5259
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.983980
Layer 0 weight grad [0][0] = 27.350113


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5260
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -36.779518
Layer 0 weight grad [0][0] = 44.418419


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5261
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.131883
Layer 0 weight grad [0][0] = 13.218154


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5262
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.323583
Layer 0 weight grad [0][0] = -18.671587


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5263
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.628482
Layer 0 weight grad [0][0] = 31.310986


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5264
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 25.429630
Layer 0 weight grad [0][0] = 10.860947


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5265
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.039542
Layer 0 weight grad [0][0] = 13.116169


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5266
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.535617
Layer 0 weight grad [0][0] = -18.303907


Training loss: 2.302585
Training accuracy: 0.437500

epoch: 5267
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -38.078457
Layer 0 weight grad [0][0] = 32.218227


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5268
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.577741
Layer 0 weight grad [0][0] = 8.579171


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5269
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.047814
Layer 0 weight grad [0][0] = -18.365866


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5270
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.575160
Layer 0 weight grad [0][0] = 45.907715


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5271
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.628094
Layer 0 weight grad [0][0] = 73.211716


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5272
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.015244
Layer 0 weight grad [0][0] = 5.798803


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5273
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 24.852577
Layer 0 weight grad [0][0] = 30.743319


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5274
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 22.258303
Layer 0 weight grad [0][0] = 48.719902


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5275
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.384843
Layer 0 weight grad [0][0] = 28.593496


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5276
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.999597
Layer 0 weight grad [0][0] = 29.355270


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5277
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -26.096828
Layer 0 weight grad [0][0] = 10.301256


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5278
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.160705
Layer 0 weight grad [0][0] = 10.044185


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5279
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.149048
Layer 0 weight grad [0][0] = 9.682977


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5280
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.126492
Layer 0 weight grad [0][0] = 50.273399


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5281
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.637784
Layer 0 weight grad [0][0] = 12.259855


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5282
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.225631
Layer 0 weight grad [0][0] = 10.911507


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5283
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.229751
Layer 0 weight grad [0][0] = 50.476925


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5284
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.765319
Layer 0 weight grad [0][0] = 33.432629


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5285
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.755800
Layer 0 weight grad [0][0] = 10.000082


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5286
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.215944
Layer 0 weight grad [0][0] = 32.822392


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5287
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.273879
Layer 0 weight grad [0][0] = 48.555210


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5288
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.780915
Layer 0 weight grad [0][0] = 8.613328


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 5289
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 26.358057
Layer 0 weight grad [0][0] = 8.391406


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5290
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.132951
Layer 0 weight grad [0][0] = 8.859800


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5291
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -34.927437
Layer 0 weight grad [0][0] = 29.703037


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5292
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.218230
Layer 0 weight grad [0][0] = 7.193362


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5293
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 21.240105
Layer 0 weight grad [0][0] = 9.392146


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5294
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.545049
Layer 0 weight grad [0][0] = 26.897875


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5295
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.157881
Layer 0 weight grad [0][0] = 9.967365


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5296
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.142455
Layer 0 weight grad [0][0] = 10.233409


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5297
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.122260
Layer 0 weight grad [0][0] = -34.941475


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5298
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.747662
Layer 0 weight grad [0][0] = 22.712938


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5299
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.760699
Layer 0 weight grad [0][0] = 37.237194


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5300
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.449266
Layer 0 weight grad [0][0] = 33.937279


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5301
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 24.978115
Layer 0 weight grad [0][0] = 12.161735


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5302
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.946035
Layer 0 weight grad [0][0] = 12.834517


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5303
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.408679
Layer 0 weight grad [0][0] = 13.303240


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5304
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.883724
Layer 0 weight grad [0][0] = 31.318432


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5305
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.843583
Layer 0 weight grad [0][0] = 22.439423


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5306
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.539833
Layer 0 weight grad [0][0] = -13.481103


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 5307
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -32.585552
Layer 0 weight grad [0][0] = 32.751823


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5308
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.161455
Layer 0 weight grad [0][0] = 30.185442


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5309
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.696819
Layer 0 weight grad [0][0] = 13.042069


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5310
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.697076
Layer 0 weight grad [0][0] = 29.432888


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5311
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.272338
Layer 0 weight grad [0][0] = 10.848529


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 5312
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.751381
Layer 0 weight grad [0][0] = -12.931417


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5313
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.217165
Layer 0 weight grad [0][0] = 21.258211


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5314
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.041759
Layer 0 weight grad [0][0] = 11.327042


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5315
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.415697
Layer 0 weight grad [0][0] = 20.090231


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5316
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.306440
Layer 0 weight grad [0][0] = 11.670999


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5317
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.141126
Layer 0 weight grad [0][0] = 25.304508


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5318
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.432098
Layer 0 weight grad [0][0] = 10.580714


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5319
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.433401
Layer 0 weight grad [0][0] = 11.812546


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5320
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.469730
Layer 0 weight grad [0][0] = 23.537439


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5321
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.502331
Layer 0 weight grad [0][0] = 31.882242


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5322
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.985205
Layer 0 weight grad [0][0] = 12.141441


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5323
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.610348
Layer 0 weight grad [0][0] = 10.285676


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5324
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.056220
Layer 0 weight grad [0][0] = 11.509233


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5325
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.088404
Layer 0 weight grad [0][0] = 54.199959


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5326
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -25.931366
Layer 0 weight grad [0][0] = -11.439077


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5327
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -26.147184
Layer 0 weight grad [0][0] = 11.598450


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5328
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.326966
Layer 0 weight grad [0][0] = 11.349483


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5329
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 29.159267
Layer 0 weight grad [0][0] = -9.701329


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5330
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.393053
Layer 0 weight grad [0][0] = 21.000298


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5331
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.395715
Layer 0 weight grad [0][0] = 10.471159


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5332
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -26.065762
Layer 0 weight grad [0][0] = 26.777056


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5333
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.178056
Layer 0 weight grad [0][0] = 11.057270


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5334
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.667113
Layer 0 weight grad [0][0] = -7.965442


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 5335
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.124373
Layer 0 weight grad [0][0] = 10.308563


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 5336
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.322545
Layer 0 weight grad [0][0] = 10.824184


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5337
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.071734
Layer 0 weight grad [0][0] = 11.392965


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5338
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.041960
Layer 0 weight grad [0][0] = 11.048100


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5339
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.027104
Layer 0 weight grad [0][0] = 10.677426


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 5340
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.688566
Layer 0 weight grad [0][0] = -5.357206


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5341
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.050015
Layer 0 weight grad [0][0] = 39.374584


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5342
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.292727
Layer 0 weight grad [0][0] = 30.140001


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5343
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.861983
Layer 0 weight grad [0][0] = 11.262630


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 5344
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -30.955038
Layer 0 weight grad [0][0] = 23.719385


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5345
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.277285
Layer 0 weight grad [0][0] = 12.651281


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5346
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -31.248947
Layer 0 weight grad [0][0] = 12.888225


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5347
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.402537
Layer 0 weight grad [0][0] = 12.828035


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5348
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.838316
Layer 0 weight grad [0][0] = 29.467319


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5349
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.468716
Layer 0 weight grad [0][0] = 13.809105


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5350
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.365320
Layer 0 weight grad [0][0] = 26.226425


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5351
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.860991
Layer 0 weight grad [0][0] = 25.114340


Training loss: 2.302585
Training accuracy: 0.375000

epoch: 5352
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.311843
Layer 0 weight grad [0][0] = 12.717803


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5353
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.271372
Layer 0 weight grad [0][0] = 34.669544


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5354
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.001720
Layer 0 weight grad [0][0] = 13.232194


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5355
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.072772
Layer 0 weight grad [0][0] = 15.223208


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5356
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.619834
Layer 0 weight grad [0][0] = 13.253155


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5357
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.108483
Layer 0 weight grad [0][0] = 13.682323


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5358
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.147545
Layer 0 weight grad [0][0] = 22.450468


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5359
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.169375
Layer 0 weight grad [0][0] = 13.240612


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5360
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.225172
Layer 0 weight grad [0][0] = 13.071382


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5361
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.301361
Layer 0 weight grad [0][0] = 15.106594


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5362
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.314074
Layer 0 weight grad [0][0] = -0.466526


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5363
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.507631
Layer 0 weight grad [0][0] = 21.010962


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5364
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -31.885014
Layer 0 weight grad [0][0] = 13.884987


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5365
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 30.994350
Layer 0 weight grad [0][0] = 24.857161


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5366
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.189423
Layer 0 weight grad [0][0] = 15.306507


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 5367
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -30.264511
Layer 0 weight grad [0][0] = 14.296379


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5368
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -29.883425
Layer 0 weight grad [0][0] = 15.718839


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5369
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 19.392572
Layer 0 weight grad [0][0] = 15.107400


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5370
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 20.130684
Layer 0 weight grad [0][0] = 16.768751


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5371
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.124123
Layer 0 weight grad [0][0] = 16.077135


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5372
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 21.097490
Layer 0 weight grad [0][0] = 15.105097


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5373
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.066076
Layer 0 weight grad [0][0] = 14.865026


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5374
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -31.624958
Layer 0 weight grad [0][0] = 14.422484


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5375
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.939915
Layer 0 weight grad [0][0] = 13.280832


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5376
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.677681
Layer 0 weight grad [0][0] = 14.738460


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5377
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.151660
Layer 0 weight grad [0][0] = 16.657284


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5378
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 18.969809
Layer 0 weight grad [0][0] = 16.907324


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5379
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.686566
Layer 0 weight grad [0][0] = -17.810921


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5380
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -32.963181
Layer 0 weight grad [0][0] = 26.203873


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5381
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.358081
Layer 0 weight grad [0][0] = 15.243715


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5382
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.314056
Layer 0 weight grad [0][0] = 17.279974


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5383
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.269756
Layer 0 weight grad [0][0] = 16.960100


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5384
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.719664
Layer 0 weight grad [0][0] = 14.877287


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5385
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.679954
Layer 0 weight grad [0][0] = -6.999810


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5386
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.130367
Layer 0 weight grad [0][0] = 20.134304


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5387
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.382045
Layer 0 weight grad [0][0] = 15.158919


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5388
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.876036
Layer 0 weight grad [0][0] = 13.966073


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5389
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.302539
Layer 0 weight grad [0][0] = 13.991310


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5390
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.196868
Layer 0 weight grad [0][0] = 14.635430


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5391
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 21.756224
Layer 0 weight grad [0][0] = 14.729461


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5392
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.743282
Layer 0 weight grad [0][0] = 28.292555


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5393
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.447682
Layer 0 weight grad [0][0] = 15.915289


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5394
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.385295
Layer 0 weight grad [0][0] = 15.975597


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5395
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.269958
Layer 0 weight grad [0][0] = 14.972468


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5396
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.459738
Layer 0 weight grad [0][0] = 14.757153


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5397
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.702154
Layer 0 weight grad [0][0] = 19.879492


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5398
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.559303
Layer 0 weight grad [0][0] = 13.838187


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5399
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.005251
Layer 0 weight grad [0][0] = 25.497028


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5400
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.928306
Layer 0 weight grad [0][0] = -20.796707


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5401
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -36.337605
Layer 0 weight grad [0][0] = 14.975124


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5402
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.622627
Layer 0 weight grad [0][0] = 17.336943


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5403
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.535701
Layer 0 weight grad [0][0] = 13.590499


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5404
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.549135
Layer 0 weight grad [0][0] = 13.675513


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5405
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.491594
Layer 0 weight grad [0][0] = -9.035514


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5406
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 25.931082
Layer 0 weight grad [0][0] = -7.433272


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5407
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.483119
Layer 0 weight grad [0][0] = 22.036091


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5408
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.139766
Layer 0 weight grad [0][0] = 15.308571


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5409
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.382320
Layer 0 weight grad [0][0] = 16.129780


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5410
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -39.797031
Layer 0 weight grad [0][0] = 14.153382


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5411
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.087373
Layer 0 weight grad [0][0] = 15.668133


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5412
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.751528
Layer 0 weight grad [0][0] = 15.402592


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5413
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -40.206520
Layer 0 weight grad [0][0] = 14.810116


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5414
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.722543
Layer 0 weight grad [0][0] = 15.330896


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5415
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.665838
Layer 0 weight grad [0][0] = 28.175539


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5416
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.324926
Layer 0 weight grad [0][0] = 17.867620


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5417
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.297392
Layer 0 weight grad [0][0] = 27.235785


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5418
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -37.178364
Layer 0 weight grad [0][0] = 15.994913


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5419
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.245436
Layer 0 weight grad [0][0] = -1.670431


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5420
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -35.668228
Layer 0 weight grad [0][0] = 16.163719


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5421
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.721294
Layer 0 weight grad [0][0] = 23.216246


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5422
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.990080
Layer 0 weight grad [0][0] = 22.785107


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5423
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 10.640141
Layer 0 weight grad [0][0] = 17.615816


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5424
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -33.493046
Layer 0 weight grad [0][0] = 27.954868


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5425
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.191502
Layer 0 weight grad [0][0] = 15.214932


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5426
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.609968
Layer 0 weight grad [0][0] = 14.616415


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5427
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -31.362530
Layer 0 weight grad [0][0] = 16.021534


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5428
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.381529
Layer 0 weight grad [0][0] = -5.397570


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5429
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -3.652337
Layer 0 weight grad [0][0] = 15.439353


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5430
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.503062
Layer 0 weight grad [0][0] = 20.475842


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5431
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.685284
Layer 0 weight grad [0][0] = 30.916821


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5432
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -3.463034
Layer 0 weight grad [0][0] = 15.662133


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5433
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.031624
Layer 0 weight grad [0][0] = 15.573790


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5434
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.988263
Layer 0 weight grad [0][0] = 27.248602


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5435
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2.661849
Layer 0 weight grad [0][0] = 17.071760


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5436
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.427312
Layer 0 weight grad [0][0] = 17.763676


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5437
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.357468
Layer 0 weight grad [0][0] = 23.732817


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5438
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.555057
Layer 0 weight grad [0][0] = 16.834660


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5439
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.486954
Layer 0 weight grad [0][0] = 27.714678


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5440
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.159782
Layer 0 weight grad [0][0] = 16.811014


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5441
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.765655
Layer 0 weight grad [0][0] = -9.236809


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5442
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.230613
Layer 0 weight grad [0][0] = 6.953966


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5443
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.167198
Layer 0 weight grad [0][0] = 24.669054


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5444
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.072210
Layer 0 weight grad [0][0] = 18.509796


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5445
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.056738
Layer 0 weight grad [0][0] = 15.962190


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5446
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -28.367992
Layer 0 weight grad [0][0] = 16.119202


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5447
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.765476
Layer 0 weight grad [0][0] = 30.386450


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5448
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.935159
Layer 0 weight grad [0][0] = 20.088884


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5449
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.989906
Layer 0 weight grad [0][0] = -8.734159


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5450
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.435067
Layer 0 weight grad [0][0] = 16.210533


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5451
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.386057
Layer 0 weight grad [0][0] = 15.959073


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5452
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.851041
Layer 0 weight grad [0][0] = 18.218018


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5453
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.289158
Layer 0 weight grad [0][0] = 21.600857


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5454
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.111355
Layer 0 weight grad [0][0] = 19.758482


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5455
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.578870
Layer 0 weight grad [0][0] = 15.408796


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5456
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.735075
Layer 0 weight grad [0][0] = 15.915255


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5457
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.968575
Layer 0 weight grad [0][0] = -9.064503


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5458
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.924518
Layer 0 weight grad [0][0] = -8.804594


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 5459
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.394727
Layer 0 weight grad [0][0] = 15.681941


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5460
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.337003
Layer 0 weight grad [0][0] = 15.848636


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5461
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.240968
Layer 0 weight grad [0][0] = 18.470793


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 5462
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.744104
Layer 0 weight grad [0][0] = 16.018730


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5463
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.903514
Layer 0 weight grad [0][0] = 26.728672


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5464
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.653281
Layer 0 weight grad [0][0] = 16.307848


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5465
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.324499
Layer 0 weight grad [0][0] = 15.191597


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5466
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.577362
Layer 0 weight grad [0][0] = 15.608040


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5467
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.511247
Layer 0 weight grad [0][0] = 32.838680


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5468
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.028098
Layer 0 weight grad [0][0] = 16.929825


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5469
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.529932
Layer 0 weight grad [0][0] = 24.153904


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 5470
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.985486
Layer 0 weight grad [0][0] = 35.116817


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5471
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.740964
Layer 0 weight grad [0][0] = 15.413129


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5472
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.517713
Layer 0 weight grad [0][0] = 35.252140


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5473
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.053589
Layer 0 weight grad [0][0] = 29.799109


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5474
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.873050
Layer 0 weight grad [0][0] = 14.712419


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5475
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.831592
Layer 0 weight grad [0][0] = 15.432316


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5476
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.791248
Layer 0 weight grad [0][0] = 14.748136


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5477
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.747415
Layer 0 weight grad [0][0] = 15.397417


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 5478
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 22.037525
Layer 0 weight grad [0][0] = 18.189198


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5479
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.846767
Layer 0 weight grad [0][0] = 16.838377


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5480
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.793944
Layer 0 weight grad [0][0] = 25.582960


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5481
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.545307
Layer 0 weight grad [0][0] = 16.935406


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5482
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.489665
Layer 0 weight grad [0][0] = 17.611523


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5483
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -28.991432
Layer 0 weight grad [0][0] = -17.493700


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5484
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.752924
Layer 0 weight grad [0][0] = 15.853906


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5485
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.688645
Layer 0 weight grad [0][0] = 22.602068


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5486
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.158430
Layer 0 weight grad [0][0] = 17.063868


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5487
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.313794
Layer 0 weight grad [0][0] = -17.337780


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5488
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.046190
Layer 0 weight grad [0][0] = 10.970379


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5489
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -31.866142
Layer 0 weight grad [0][0] = 16.666702


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5490
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.280664
Layer 0 weight grad [0][0] = 16.123495


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5491
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.695059
Layer 0 weight grad [0][0] = 25.832102


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5492
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.491610
Layer 0 weight grad [0][0] = 16.144466


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5493
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.442066
Layer 0 weight grad [0][0] = 16.364162


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5494
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -32.404655
Layer 0 weight grad [0][0] = 16.572578


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5495
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -32.181484
Layer 0 weight grad [0][0] = 16.154446


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5496
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.994051
Layer 0 weight grad [0][0] = 16.491175


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5497
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.157085
Layer 0 weight grad [0][0] = 16.663910


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5498
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.910184
Layer 0 weight grad [0][0] = 33.182217


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5499
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -30.303835
Layer 0 weight grad [0][0] = 18.514303


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5500
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.246663
Layer 0 weight grad [0][0] = 37.529865


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5501
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.005010
Layer 0 weight grad [0][0] = 20.647768


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5502
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.758492
Layer 0 weight grad [0][0] = -9.999526


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5503
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.716608
Layer 0 weight grad [0][0] = 16.717106


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5504
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.688120
Layer 0 weight grad [0][0] = 17.625832


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5505
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.620564
Layer 0 weight grad [0][0] = 28.143856


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5506
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.351045
Layer 0 weight grad [0][0] = 30.990299


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5507
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.045639
Layer 0 weight grad [0][0] = 15.694242


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5508
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.005626
Layer 0 weight grad [0][0] = 15.040768


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5509
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.139194
Layer 0 weight grad [0][0] = 14.805514


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5510
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.453601
Layer 0 weight grad [0][0] = 14.886003


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5511
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 14.368134
Layer 0 weight grad [0][0] = 15.719943


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5512
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.171070
Layer 0 weight grad [0][0] = 18.536589


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5513
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.645856
Layer 0 weight grad [0][0] = 14.861619


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5514
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 14.821585
Layer 0 weight grad [0][0] = 15.544643


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5515
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.317419
Layer 0 weight grad [0][0] = 26.669966


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5516
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -31.264357
Layer 0 weight grad [0][0] = 14.847475


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5517
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.912953
Layer 0 weight grad [0][0] = 14.404881


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5518
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.837188
Layer 0 weight grad [0][0] = 21.787510


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5519
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.857954
Layer 0 weight grad [0][0] = 13.089156


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5520
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.806613
Layer 0 weight grad [0][0] = -20.470455


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5521
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.234589
Layer 0 weight grad [0][0] = 12.918330


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 5522
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.273750
Layer 0 weight grad [0][0] = 13.885937


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5523
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.735280
Layer 0 weight grad [0][0] = 23.947874


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5524
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.495669
Layer 0 weight grad [0][0] = 12.882785


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 5525
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.919680
Layer 0 weight grad [0][0] = -17.656954


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5526
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.439303
Layer 0 weight grad [0][0] = 14.331021


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 5527
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.928365
Layer 0 weight grad [0][0] = 40.899555


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5528
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.019675
Layer 0 weight grad [0][0] = 13.248367


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5529
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.983930
Layer 0 weight grad [0][0] = -16.796375


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5530
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.264031
Layer 0 weight grad [0][0] = 13.041352


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5531
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -35.608727
Layer 0 weight grad [0][0] = 13.669054


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5532
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.588944
Layer 0 weight grad [0][0] = 28.365854


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 5533
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.534856
Layer 0 weight grad [0][0] = 14.721257


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5534
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 16.211044
Layer 0 weight grad [0][0] = -13.786703


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5535
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.164396
Layer 0 weight grad [0][0] = 12.938521


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 5536
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.699842
Layer 0 weight grad [0][0] = 42.746674


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5537
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.035158
Layer 0 weight grad [0][0] = 12.755931


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5538
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.973268
Layer 0 weight grad [0][0] = 14.386739


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5539
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.019487
Layer 0 weight grad [0][0] = -13.169242


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5540
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -36.008564
Layer 0 weight grad [0][0] = -12.267580


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5541
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.786213
Layer 0 weight grad [0][0] = 15.690907


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5542
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.290476
Layer 0 weight grad [0][0] = 31.904022


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5543
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -38.116867
Layer 0 weight grad [0][0] = 11.795350


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 5544
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -38.165016
Layer 0 weight grad [0][0] = 11.093452


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5545
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.116225
Layer 0 weight grad [0][0] = 17.564981


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5546
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.882567
Layer 0 weight grad [0][0] = 11.910490


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5547
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.536826
Layer 0 weight grad [0][0] = 11.442593


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5548
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.860590
Layer 0 weight grad [0][0] = 23.706779


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5549
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.167414
Layer 0 weight grad [0][0] = -8.790869


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5550
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7.143363
Layer 0 weight grad [0][0] = 11.961789


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5551
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.284987
Layer 0 weight grad [0][0] = 12.977394


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 5552
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -42.661007
Layer 0 weight grad [0][0] = 11.811616


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5553
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.082548
Layer 0 weight grad [0][0] = 11.434431


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5554
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.111181
Layer 0 weight grad [0][0] = -31.605715


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5555
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.535614
Layer 0 weight grad [0][0] = 12.793097


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5556
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.769169
Layer 0 weight grad [0][0] = 12.878228


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5557
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.972609
Layer 0 weight grad [0][0] = 11.486340


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5558
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.256374
Layer 0 weight grad [0][0] = 11.266480


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5559
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.217837
Layer 0 weight grad [0][0] = 23.302137


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5560
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.061139
Layer 0 weight grad [0][0] = -7.089093


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5561
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.231045
Layer 0 weight grad [0][0] = 12.993877


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5562
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.011547
Layer 0 weight grad [0][0] = 11.946733


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5563
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.015342
Layer 0 weight grad [0][0] = 18.964346


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5564
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.530927
Layer 0 weight grad [0][0] = 12.863060


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5565
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.829416
Layer 0 weight grad [0][0] = 20.196327


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5566
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.142397
Layer 0 weight grad [0][0] = 12.170556


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5567
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.626396
Layer 0 weight grad [0][0] = 12.047008


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5568
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.135985
Layer 0 weight grad [0][0] = 11.637816


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5569
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.117831
Layer 0 weight grad [0][0] = 11.675316


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5570
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -54.236912
Layer 0 weight grad [0][0] = 21.538641


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5571
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -53.082878
Layer 0 weight grad [0][0] = 52.342430


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5572
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.425168
Layer 0 weight grad [0][0] = 30.800940


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5573
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.929835
Layer 0 weight grad [0][0] = 10.700941


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5574
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.952012
Layer 0 weight grad [0][0] = 10.963137


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5575
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.075338
Layer 0 weight grad [0][0] = 16.818071


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5576
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.653966
Layer 0 weight grad [0][0] = 11.316313


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5577
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -50.371918
Layer 0 weight grad [0][0] = 10.102942


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5578
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.325570
Layer 0 weight grad [0][0] = 10.633257


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5579
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.584651
Layer 0 weight grad [0][0] = 9.768002


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5580
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.363496
Layer 0 weight grad [0][0] = 11.169166


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5581
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.438997
Layer 0 weight grad [0][0] = 56.448704


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5582
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.944981
Layer 0 weight grad [0][0] = 11.289376


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5583
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.985401
Layer 0 weight grad [0][0] = 59.564682


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5584
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.180517
Layer 0 weight grad [0][0] = 13.855412


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5585
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.906919
Layer 0 weight grad [0][0] = 9.752434


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5586
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.935518
Layer 0 weight grad [0][0] = 8.974569


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5587
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.918493
Layer 0 weight grad [0][0] = 8.566484


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5588
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.513419
Layer 0 weight grad [0][0] = 10.993211


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5589
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.021527
Layer 0 weight grad [0][0] = 88.412598


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5590
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7.176551
Layer 0 weight grad [0][0] = 9.007930


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5591
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.504798
Layer 0 weight grad [0][0] = 10.943513


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5592
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -37.434113
Layer 0 weight grad [0][0] = 13.170468


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5593
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.625959
Layer 0 weight grad [0][0] = 9.100840


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5594
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.734705
Layer 0 weight grad [0][0] = 15.277452


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5595
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.433573
Layer 0 weight grad [0][0] = 9.071176


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5596
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.476723
Layer 0 weight grad [0][0] = 12.719507


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5597
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.979825
Layer 0 weight grad [0][0] = 8.302164


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5598
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.435066
Layer 0 weight grad [0][0] = 8.262070


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5599
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.043441
Layer 0 weight grad [0][0] = 9.557020


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 5600
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.568352
Layer 0 weight grad [0][0] = 14.915520


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5601
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.496572
Layer 0 weight grad [0][0] = 8.818735


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5602
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.538584
Layer 0 weight grad [0][0] = 2.426394


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5603
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.567037
Layer 0 weight grad [0][0] = 10.760367


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5604
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 10.509630
Layer 0 weight grad [0][0] = 14.548667


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5605
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.536451
Layer 0 weight grad [0][0] = -0.492755


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5606
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.102122
Layer 0 weight grad [0][0] = 12.055266


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5607
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.129434
Layer 0 weight grad [0][0] = 11.324156


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5608
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.637102
Layer 0 weight grad [0][0] = 10.962214


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5609
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.653336
Layer 0 weight grad [0][0] = -20.584454


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5610
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -53.251434
Layer 0 weight grad [0][0] = 11.876240


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5611
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.881722
Layer 0 weight grad [0][0] = 10.341599


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5612
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -54.348450
Layer 0 weight grad [0][0] = 10.170483


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5613
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.427855
Layer 0 weight grad [0][0] = 9.739629


Training loss: 2.302585
Training accuracy: 0.437500

epoch: 5614
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.254414
Layer 0 weight grad [0][0] = 16.758266


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5615
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.731885
Layer 0 weight grad [0][0] = -16.421242


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5616
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.816919
Layer 0 weight grad [0][0] = 17.716995


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5617
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7.028092
Layer 0 weight grad [0][0] = 14.344976


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5618
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.312191
Layer 0 weight grad [0][0] = 14.369568


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5619
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.370386
Layer 0 weight grad [0][0] = 10.352790


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5620
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.360993
Layer 0 weight grad [0][0] = 10.747122


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5621
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 10.521496
Layer 0 weight grad [0][0] = 10.160718


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5622
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.927433
Layer 0 weight grad [0][0] = 63.774853


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5623
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.444614
Layer 0 weight grad [0][0] = 10.194168


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5624
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.478695
Layer 0 weight grad [0][0] = 21.581102


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5625
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 12.157442
Layer 0 weight grad [0][0] = 12.837069


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5626
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.588101
Layer 0 weight grad [0][0] = 11.920318


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5627
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.042889
Layer 0 weight grad [0][0] = 13.253967


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 5628
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 15.190037
Layer 0 weight grad [0][0] = 11.568345


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5629
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.093425
Layer 0 weight grad [0][0] = 13.029326


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5630
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -54.900875
Layer 0 weight grad [0][0] = 11.051319


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5631
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.949886
Layer 0 weight grad [0][0] = 11.473161


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5632
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.936244
Layer 0 weight grad [0][0] = 10.341332


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5633
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.494780
Layer 0 weight grad [0][0] = -1.619562


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5634
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.482119
Layer 0 weight grad [0][0] = 10.760935


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5635
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.045109
Layer 0 weight grad [0][0] = 7.869239


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5636
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 14.095366
Layer 0 weight grad [0][0] = 10.761153


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5637
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.527944
Layer 0 weight grad [0][0] = 11.052923


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5638
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.577129
Layer 0 weight grad [0][0] = 44.895927


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 5639
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.807633
Layer 0 weight grad [0][0] = 11.088268


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5640
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.149864
Layer 0 weight grad [0][0] = 10.551503


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5641
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.163590
Layer 0 weight grad [0][0] = 12.861912


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5642
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -64.165779
Layer 0 weight grad [0][0] = 11.395863


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5643
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.811937
Layer 0 weight grad [0][0] = 9.853972


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5644
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.659664
Layer 0 weight grad [0][0] = 9.498363


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5645
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.484529
Layer 0 weight grad [0][0] = 7.928510


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5646
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7.253142
Layer 0 weight grad [0][0] = 10.207775


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5647
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.585976
Layer 0 weight grad [0][0] = 24.443163


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5648
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -68.092049
Layer 0 weight grad [0][0] = 10.276708


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5649
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -68.434174
Layer 0 weight grad [0][0] = 9.468911


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5650
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 8.132458
Layer 0 weight grad [0][0] = 9.514577


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5651
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 8.170748
Layer 0 weight grad [0][0] = 9.656987


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5652
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -70.728561
Layer 0 weight grad [0][0] = 9.596084


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5653
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.054873
Layer 0 weight grad [0][0] = 9.145584


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5654
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.294421
Layer 0 weight grad [0][0] = 10.950665


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5655
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.629006
Layer 0 weight grad [0][0] = 10.016281


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5656
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.163493
Layer 0 weight grad [0][0] = 9.741879


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5657
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.169225
Layer 0 weight grad [0][0] = 8.696059


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5658
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.257739
Layer 0 weight grad [0][0] = 54.845627


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5659
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7.741535
Layer 0 weight grad [0][0] = 7.961102


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5660
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 8.564325
Layer 0 weight grad [0][0] = 8.912094


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5661
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 8.423450
Layer 0 weight grad [0][0] = 15.931359


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5662
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 8.300316
Layer 0 weight grad [0][0] = -1.113391


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 5663
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 8.863811
Layer 0 weight grad [0][0] = 20.778717


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5664
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -70.687157
Layer 0 weight grad [0][0] = 6.289961


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5665
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.643708
Layer 0 weight grad [0][0] = 1.136598


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5666
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.905621
Layer 0 weight grad [0][0] = 8.102348


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5667
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.228999
Layer 0 weight grad [0][0] = 6.735651


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5668
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -75.203522
Layer 0 weight grad [0][0] = 64.254013


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5669
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.085316
Layer 0 weight grad [0][0] = 5.560225


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5670
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.167963
Layer 0 weight grad [0][0] = 4.691483


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5671
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.205130
Layer 0 weight grad [0][0] = 7.743626


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5672
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.318160
Layer 0 weight grad [0][0] = 8.380167


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5673
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.382179
Layer 0 weight grad [0][0] = 18.969135


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5674
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -4.561260
Layer 0 weight grad [0][0] = 10.326766


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5675
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.870772
Layer 0 weight grad [0][0] = 64.167915


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5676
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 8.245689
Layer 0 weight grad [0][0] = 39.579300


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5677
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 8.297757
Layer 0 weight grad [0][0] = 10.356034


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5678
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 8.838781
Layer 0 weight grad [0][0] = 38.567215


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5679
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -56.089195
Layer 0 weight grad [0][0] = 9.819424


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5680
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 8.172845
Layer 0 weight grad [0][0] = -19.135962


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 5681
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 8.220515
Layer 0 weight grad [0][0] = 16.644682


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5682
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 8.787278
Layer 0 weight grad [0][0] = 14.016117


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5683
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 8.200568
Layer 0 weight grad [0][0] = 8.076731


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5684
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 8.287406
Layer 0 weight grad [0][0] = 9.463141


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5685
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 8.332314
Layer 0 weight grad [0][0] = 43.209160


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5686
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -4.218207
Layer 0 weight grad [0][0] = 8.900421


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5687
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 8.294570
Layer 0 weight grad [0][0] = 16.304062


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5688
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 8.402472
Layer 0 weight grad [0][0] = -25.233698


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5689
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 8.679774
Layer 0 weight grad [0][0] = 8.997835


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5690
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.070457
Layer 0 weight grad [0][0] = 9.352659


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5691
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 8.638627
Layer 0 weight grad [0][0] = 8.683965


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5692
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 8.699108
Layer 0 weight grad [0][0] = 7.888100


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5693
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 8.817320
Layer 0 weight grad [0][0] = 8.931563


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5694
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -74.824730
Layer 0 weight grad [0][0] = 8.200974


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5695
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.751320
Layer 0 weight grad [0][0] = 7.682795


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5696
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 10.374250
Layer 0 weight grad [0][0] = 18.572710


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5697
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.982656
Layer 0 weight grad [0][0] = 7.618535


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5698
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 10.033576
Layer 0 weight grad [0][0] = 14.707365


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5699
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 10.040774
Layer 0 weight grad [0][0] = -26.583965


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5700
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 10.132322
Layer 0 weight grad [0][0] = 7.407680


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5701
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 10.739749
Layer 0 weight grad [0][0] = 17.501892


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5702
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -84.407959
Layer 0 weight grad [0][0] = -31.475183


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5703
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 11.199672
Layer 0 weight grad [0][0] = 70.739540


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5704
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.931435
Layer 0 weight grad [0][0] = 17.177687


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5705
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 10.013590
Layer 0 weight grad [0][0] = 6.634487


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5706
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 10.130922
Layer 0 weight grad [0][0] = 14.289801


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5707
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 10.601674
Layer 0 weight grad [0][0] = 18.233154


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5708
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -77.896080
Layer 0 weight grad [0][0] = 11.564914


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5709
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 10.906784
Layer 0 weight grad [0][0] = 7.287381


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5710
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 11.535499
Layer 0 weight grad [0][0] = 17.009666


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5711
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 11.840551
Layer 0 weight grad [0][0] = 6.754995


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5712
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 11.231162
Layer 0 weight grad [0][0] = 28.004854


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5713
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 11.113299
Layer 0 weight grad [0][0] = 16.300085


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5714
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 11.031672
Layer 0 weight grad [0][0] = 57.739258


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5715
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 11.175415
Layer 0 weight grad [0][0] = 5.992002


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5716
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -4.512906
Layer 0 weight grad [0][0] = -35.678989


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5717
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2.176010
Layer 0 weight grad [0][0] = 6.199972


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5718
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 11.611842
Layer 0 weight grad [0][0] = 15.945231


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5719
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 10.993882
Layer 0 weight grad [0][0] = 36.005920


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 5720
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 8.981050
Layer 0 weight grad [0][0] = -26.722624


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5721
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 10.147117
Layer 0 weight grad [0][0] = -23.934277


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5722
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.734238
Layer 0 weight grad [0][0] = 5.278272


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5723
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 10.169744
Layer 0 weight grad [0][0] = -22.675953


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5724
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 10.044307
Layer 0 weight grad [0][0] = 4.656052


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5725
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.616771
Layer 0 weight grad [0][0] = -34.118607


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5726
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.786009
Layer 0 weight grad [0][0] = -33.487309


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5727
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.876002
Layer 0 weight grad [0][0] = 10.505754


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5728
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 10.489614
Layer 0 weight grad [0][0] = 68.915962


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5729
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 10.424811
Layer 0 weight grad [0][0] = 69.485909


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5730
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.826823
Layer 0 weight grad [0][0] = 13.749058


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5731
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 8.189261
Layer 0 weight grad [0][0] = 3.749354


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5732
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.606387
Layer 0 weight grad [0][0] = 14.543591


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5733
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.770169
Layer 0 weight grad [0][0] = 3.158870


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5734
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.902022
Layer 0 weight grad [0][0] = 5.058717


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 5735
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 10.503174
Layer 0 weight grad [0][0] = -34.065857


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5736
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 10.085361
Layer 0 weight grad [0][0] = -70.563637


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 5737
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -98.994019
Layer 0 weight grad [0][0] = 4.944216


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5738
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 11.484793
Layer 0 weight grad [0][0] = 7.550465


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5739
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 10.997834
Layer 0 weight grad [0][0] = 16.474598


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5740
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 12.117462
Layer 0 weight grad [0][0] = -26.417582


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5741
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 11.896496
Layer 0 weight grad [0][0] = 6.596514


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5742
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 11.780026
Layer 0 weight grad [0][0] = 6.237381


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5743
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 11.885423
Layer 0 weight grad [0][0] = 78.250946


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5744
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 10.839453
Layer 0 weight grad [0][0] = 80.912598


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5745
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 8.195747
Layer 0 weight grad [0][0] = 5.401072


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5746
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 8.828993
Layer 0 weight grad [0][0] = 14.836601


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5747
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 8.973287
Layer 0 weight grad [0][0] = 4.609204


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5748
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -88.151443
Layer 0 weight grad [0][0] = 4.426820


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5749
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 11.079291
Layer 0 weight grad [0][0] = 71.221931


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5750
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 10.683251
Layer 0 weight grad [0][0] = 14.047980


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5751
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.046933
Layer 0 weight grad [0][0] = 12.692937


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5752
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.939705
Layer 0 weight grad [0][0] = 3.910540


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5753
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 10.660843
Layer 0 weight grad [0][0] = 4.702765


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5754
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -99.596489
Layer 0 weight grad [0][0] = 81.766792


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5755
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 10.655208
Layer 0 weight grad [0][0] = 4.377197


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 5756
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 10.800546
Layer 0 weight grad [0][0] = 13.984508


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5757
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.512282
Layer 0 weight grad [0][0] = 4.496164


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5758
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.163716
Layer 0 weight grad [0][0] = 5.086174


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5759
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 10.244410
Layer 0 weight grad [0][0] = 64.236504


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5760
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 10.367617
Layer 0 weight grad [0][0] = -47.911633


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5761
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 10.490882
Layer 0 weight grad [0][0] = 86.541000


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5762
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 8.731004
Layer 0 weight grad [0][0] = 2.173294


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5763
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 8.835147
Layer 0 weight grad [0][0] = 97.038025


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 5764
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7.246103
Layer 0 weight grad [0][0] = 74.399750


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5765
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7.163833
Layer 0 weight grad [0][0] = -44.876606


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5766
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7.781848
Layer 0 weight grad [0][0] = 74.465439


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5767
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7.408672
Layer 0 weight grad [0][0] = 4.971016


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5768
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -79.641319
Layer 0 weight grad [0][0] = 7.539291


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5769
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 8.617243
Layer 0 weight grad [0][0] = 8.544323


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5770
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.294640
Layer 0 weight grad [0][0] = 52.472324


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5771
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.401779
Layer 0 weight grad [0][0] = 5.961375


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5772
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.949824
Layer 0 weight grad [0][0] = 10.732199


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5773
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.492521
Layer 0 weight grad [0][0] = 25.943865


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5774
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.366005
Layer 0 weight grad [0][0] = 8.452350


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5775
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.240384
Layer 0 weight grad [0][0] = 110.546387


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5776
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -75.333946
Layer 0 weight grad [0][0] = 48.880642


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5777
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.568647
Layer 0 weight grad [0][0] = 45.670063


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5778
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.093172
Layer 0 weight grad [0][0] = 4.922690


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5779
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.648798
Layer 0 weight grad [0][0] = 23.686718


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5780
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.384274
Layer 0 weight grad [0][0] = 7.723423


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5781
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.605719
Layer 0 weight grad [0][0] = 6.645608


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5782
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.497090
Layer 0 weight grad [0][0] = 6.623727


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5783
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.755728
Layer 0 weight grad [0][0] = 6.543300


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5784
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 10.133451
Layer 0 weight grad [0][0] = 5.436491


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5785
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.711993
Layer 0 weight grad [0][0] = -40.632523


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5786
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.794652
Layer 0 weight grad [0][0] = 44.445137


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5787
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 11.421823
Layer 0 weight grad [0][0] = 8.126533


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5788
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.584050
Layer 0 weight grad [0][0] = 88.549797


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5789
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 8.096452
Layer 0 weight grad [0][0] = 15.708943


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5790
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 17.202444
Layer 0 weight grad [0][0] = 4.968107


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5791
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 22.450089
Layer 0 weight grad [0][0] = 5.439482


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5792
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 8.221816
Layer 0 weight grad [0][0] = 9.133299


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5793
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 28.483547
Layer 0 weight grad [0][0] = 42.836510


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5794
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7.233687
Layer 0 weight grad [0][0] = -31.923321


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5795
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7.221729
Layer 0 weight grad [0][0] = 23.228109


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5796
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.964403
Layer 0 weight grad [0][0] = 83.396873


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5797
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -80.555901
Layer 0 weight grad [0][0] = 6.953734


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5798
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 21.407171
Layer 0 weight grad [0][0] = 77.508850


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5799
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -68.736328
Layer 0 weight grad [0][0] = 7.105700


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5800
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7.770313
Layer 0 weight grad [0][0] = -34.313625


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5801
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 11.772910
Layer 0 weight grad [0][0] = 6.102515


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5802
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7.162256
Layer 0 weight grad [0][0] = 18.803043


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5803
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.866593
Layer 0 weight grad [0][0] = 11.054404


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5804
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.943203
Layer 0 weight grad [0][0] = 6.032524


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5805
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.987767
Layer 0 weight grad [0][0] = 8.601030


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 5806
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7.528790
Layer 0 weight grad [0][0] = 11.001702


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5807
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7.753037
Layer 0 weight grad [0][0] = 34.201450


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5808
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7.588180
Layer 0 weight grad [0][0] = 35.469456


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5809
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7.064721
Layer 0 weight grad [0][0] = 9.577147


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5810
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7.137236
Layer 0 weight grad [0][0] = 9.291254


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5811
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.616006
Layer 0 weight grad [0][0] = 10.517008


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5812
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.652181
Layer 0 weight grad [0][0] = 9.556654


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5813
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7.739508
Layer 0 weight grad [0][0] = -43.216312


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5814
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.730849
Layer 0 weight grad [0][0] = 45.296265


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5815
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7.285916
Layer 0 weight grad [0][0] = 9.698271


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5816
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7.372293
Layer 0 weight grad [0][0] = 83.680756


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5817
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.867579
Layer 0 weight grad [0][0] = 7.485476


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5818
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -83.906654
Layer 0 weight grad [0][0] = 7.852352


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5819
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7.616073
Layer 0 weight grad [0][0] = 6.854231


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5820
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7.721009
Layer 0 weight grad [0][0] = 8.658862


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5821
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -87.957802
Layer 0 weight grad [0][0] = 8.690749


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5822
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.542325
Layer 0 weight grad [0][0] = 6.530581


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5823
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.832780
Layer 0 weight grad [0][0] = 8.811023


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5824
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.670521
Layer 0 weight grad [0][0] = 76.879494


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5825
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7.692604
Layer 0 weight grad [0][0] = 15.397306


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5826
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 8.263262
Layer 0 weight grad [0][0] = 9.325770


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5827
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 8.309917
Layer 0 weight grad [0][0] = 79.844521


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5828
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.772622
Layer 0 weight grad [0][0] = 18.158005


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5829
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -73.560860
Layer 0 weight grad [0][0] = 49.828278


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5830
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 8.590655
Layer 0 weight grad [0][0] = -64.690018


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5831
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 8.623723
Layer 0 weight grad [0][0] = 11.263987


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5832
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 8.654202
Layer 0 weight grad [0][0] = 58.035679


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5833
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7.244323
Layer 0 weight grad [0][0] = 10.318136


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5834
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7.800749
Layer 0 weight grad [0][0] = 11.167289


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5835
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7.338527
Layer 0 weight grad [0][0] = 19.928431


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5836
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.843983
Layer 0 weight grad [0][0] = 13.145080


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5837
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 12.778898
Layer 0 weight grad [0][0] = 20.486462


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5838
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7.668994
Layer 0 weight grad [0][0] = 63.592056


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5839
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.118321
Layer 0 weight grad [0][0] = 16.836451


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5840
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -68.061882
Layer 0 weight grad [0][0] = 16.165527


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5841
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7.842044
Layer 0 weight grad [0][0] = 17.187727


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5842
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7.713950
Layer 0 weight grad [0][0] = 15.999389


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5843
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7.747698
Layer 0 weight grad [0][0] = 16.550978


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5844
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 8.102242
Layer 0 weight grad [0][0] = 18.951942


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5845
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7.367410
Layer 0 weight grad [0][0] = 19.786385


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5846
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7.416866
Layer 0 weight grad [0][0] = 18.258224


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5847
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.875031
Layer 0 weight grad [0][0] = 17.901726


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5848
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7.957156
Layer 0 weight grad [0][0] = 17.112431


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5849
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.909247
Layer 0 weight grad [0][0] = 17.909737


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5850
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7.495364
Layer 0 weight grad [0][0] = 17.845240


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5851
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 8.051296
Layer 0 weight grad [0][0] = 17.919884


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5852
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7.564743
Layer 0 weight grad [0][0] = 38.849026


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5853
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 20.656368
Layer 0 weight grad [0][0] = 57.829426


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5854
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.506590
Layer 0 weight grad [0][0] = 22.096939


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5855
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.036716
Layer 0 weight grad [0][0] = 7.849465


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5856
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.587646
Layer 0 weight grad [0][0] = 58.209770


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5857
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.453970
Layer 0 weight grad [0][0] = 7.589636


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5858
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -66.326279
Layer 0 weight grad [0][0] = 16.685356


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5859
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.710378
Layer 0 weight grad [0][0] = 33.358513


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5860
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000022 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.925292
Layer 0 weight grad [0][0] = -0.869932


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5861
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.926728
Layer 0 weight grad [0][0] = -12.335775


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5862
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.442066
Layer 0 weight grad [0][0] = 19.042906


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5863
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.457427
Layer 0 weight grad [0][0] = 19.101978


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5864
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.933345
Layer 0 weight grad [0][0] = 21.477413


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5865
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.007901
Layer 0 weight grad [0][0] = 20.144970


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5866
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.995019
Layer 0 weight grad [0][0] = 34.747074


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5867
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -69.509407
Layer 0 weight grad [0][0] = -29.251972


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5868
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7.133304
Layer 0 weight grad [0][0] = 24.570152


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5869
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7.128809
Layer 0 weight grad [0][0] = 23.755257


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5870
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7.327263
Layer 0 weight grad [0][0] = 25.062565


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5871
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7.129774
Layer 0 weight grad [0][0] = 24.364227


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5872
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7.151124
Layer 0 weight grad [0][0] = 26.287643


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5873
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7.123831
Layer 0 weight grad [0][0] = 54.850342


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5874
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.587460
Layer 0 weight grad [0][0] = 26.012194


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5875
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.624611
Layer 0 weight grad [0][0] = 23.538986


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5876
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7.120640
Layer 0 weight grad [0][0] = 30.601633


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 5877
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 17.681030
Layer 0 weight grad [0][0] = 25.734447


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5878
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.928155
Layer 0 weight grad [0][0] = 46.525799


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5879
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.168941
Layer 0 weight grad [0][0] = 26.912779


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5880
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.654108
Layer 0 weight grad [0][0] = 31.542234


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5881
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.616190
Layer 0 weight grad [0][0] = 25.418457


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5882
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.392364
Layer 0 weight grad [0][0] = -101.130157


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5883
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.202659
Layer 0 weight grad [0][0] = 24.716837


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5884
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.698295
Layer 0 weight grad [0][0] = 24.452623


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5885
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.167379
Layer 0 weight grad [0][0] = 37.054897


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5886
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.973543
Layer 0 weight grad [0][0] = -29.409138


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5887
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.827102
Layer 0 weight grad [0][0] = 23.577890


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5888
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.365574
Layer 0 weight grad [0][0] = -34.344326


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5889
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.844979
Layer 0 weight grad [0][0] = 24.107735


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5890
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.805004
Layer 0 weight grad [0][0] = 23.625137


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5891
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.861250
Layer 0 weight grad [0][0] = 21.860861


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 5892
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.890083
Layer 0 weight grad [0][0] = 22.878645


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5893
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.860501
Layer 0 weight grad [0][0] = 22.676235


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5894
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.923517
Layer 0 weight grad [0][0] = -26.481644


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5895
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -76.408577
Layer 0 weight grad [0][0] = 21.191719


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5896
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -76.133194
Layer 0 weight grad [0][0] = 21.315271


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5897
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 12.792231
Layer 0 weight grad [0][0] = 51.204536


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5898
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.302921
Layer 0 weight grad [0][0] = 17.953066


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5899
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.342980
Layer 0 weight grad [0][0] = 33.869156


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5900
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.106705
Layer 0 weight grad [0][0] = 22.246910


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5901
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.339705
Layer 0 weight grad [0][0] = 18.102396


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5902
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.696617
Layer 0 weight grad [0][0] = 20.906342


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5903
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -73.157227
Layer 0 weight grad [0][0] = 22.245909


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5904
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7.634425
Layer 0 weight grad [0][0] = -27.341587


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 5905
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7.708769
Layer 0 weight grad [0][0] = 21.954010


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5906
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 11.360179
Layer 0 weight grad [0][0] = -34.570744


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5907
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7.325987
Layer 0 weight grad [0][0] = 25.109211


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5908
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.866165
Layer 0 weight grad [0][0] = -21.654875


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 5909
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -77.780563
Layer 0 weight grad [0][0] = 24.400738


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5910
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -77.113396
Layer 0 weight grad [0][0] = 34.363041


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5911
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.280469
Layer 0 weight grad [0][0] = 38.097397


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5912
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 8.995994
Layer 0 weight grad [0][0] = -39.786442


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5913
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -71.021477
Layer 0 weight grad [0][0] = 25.709698


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5914
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 10.438570
Layer 0 weight grad [0][0] = 39.484287


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5915
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 10.183491
Layer 0 weight grad [0][0] = 26.037197


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5916
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.654506
Layer 0 weight grad [0][0] = 25.030733


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5917
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 10.167422
Layer 0 weight grad [0][0] = 25.104298


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5918
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 10.433764
Layer 0 weight grad [0][0] = -49.810749


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5919
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 10.253499
Layer 0 weight grad [0][0] = -11.642029


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5920
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 10.278097
Layer 0 weight grad [0][0] = 36.521770


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5921
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 10.576665
Layer 0 weight grad [0][0] = 26.633165


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5922
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 10.081777
Layer 0 weight grad [0][0] = 36.325562


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5923
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.840670
Layer 0 weight grad [0][0] = 25.038307


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5924
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 10.024240
Layer 0 weight grad [0][0] = 28.082342


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5925
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.857114
Layer 0 weight grad [0][0] = -14.093143


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 5926
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 10.351314
Layer 0 weight grad [0][0] = 29.139263


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5927
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 10.067304
Layer 0 weight grad [0][0] = 13.773125


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5928
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.830256
Layer 0 weight grad [0][0] = 26.311266


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 5929
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.783041
Layer 0 weight grad [0][0] = 46.207676


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5930
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.421566
Layer 0 weight grad [0][0] = 26.171989


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5931
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -5.426239
Layer 0 weight grad [0][0] = -24.819395


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5932
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 8.748905
Layer 0 weight grad [0][0] = 27.764658


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5933
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 8.224020
Layer 0 weight grad [0][0] = 28.984785


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5934
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 8.213095
Layer 0 weight grad [0][0] = 26.595888


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5935
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 8.216602
Layer 0 weight grad [0][0] = 27.255365


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5936
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 8.254505
Layer 0 weight grad [0][0] = 25.636703


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5937
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 8.253604
Layer 0 weight grad [0][0] = 25.917532


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 5938
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -72.234467
Layer 0 weight grad [0][0] = 25.936462


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5939
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.765611
Layer 0 weight grad [0][0] = 45.911961


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5940
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.887831
Layer 0 weight grad [0][0] = 46.490742


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5941
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 8.998719
Layer 0 weight grad [0][0] = 29.597841


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5942
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 8.983560
Layer 0 weight grad [0][0] = -1.442127


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5943
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 8.933880
Layer 0 weight grad [0][0] = 29.255402


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5944
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.467435
Layer 0 weight grad [0][0] = 33.790283


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5945
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 8.938748
Layer 0 weight grad [0][0] = 47.610222


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5946
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 8.602757
Layer 0 weight grad [0][0] = 32.087231


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5947
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.065312
Layer 0 weight grad [0][0] = -89.560669


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5948
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.200150
Layer 0 weight grad [0][0] = 32.466240


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5949
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.455706
Layer 0 weight grad [0][0] = 41.191700


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5950
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7.356264
Layer 0 weight grad [0][0] = -4.252529


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5951
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -71.080254
Layer 0 weight grad [0][0] = 32.351334


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5952
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.527804
Layer 0 weight grad [0][0] = 33.365532


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5953
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.208733
Layer 0 weight grad [0][0] = -55.402943


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5954
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.953827
Layer 0 weight grad [0][0] = -55.575100


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5955
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.764283
Layer 0 weight grad [0][0] = 31.073071


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5956
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.576026
Layer 0 weight grad [0][0] = 47.833420


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5957
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.200987
Layer 0 weight grad [0][0] = 50.265419


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5958
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.338259
Layer 0 weight grad [0][0] = 47.708755


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5959
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -59.845455
Layer 0 weight grad [0][0] = 25.729290


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5960
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.094737
Layer 0 weight grad [0][0] = -15.609374


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5961
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.720020
Layer 0 weight grad [0][0] = 29.488083


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5962
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.750280
Layer 0 weight grad [0][0] = -15.237973


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5963
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.894897
Layer 0 weight grad [0][0] = 27.831791


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 5964
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 16.153214
Layer 0 weight grad [0][0] = 31.533169


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5965
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.780860
Layer 0 weight grad [0][0] = 18.135929


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 5966
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -52.471684
Layer 0 weight grad [0][0] = 30.567596


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5967
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.356824
Layer 0 weight grad [0][0] = 30.530811


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5968
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.294302
Layer 0 weight grad [0][0] = -79.344940


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5969
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.325132
Layer 0 weight grad [0][0] = 29.716557


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5970
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.254878
Layer 0 weight grad [0][0] = 23.904036


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5971
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.818493
Layer 0 weight grad [0][0] = 21.053543


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5972
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 15.931282
Layer 0 weight grad [0][0] = 28.721664


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 5973
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.014807
Layer 0 weight grad [0][0] = -35.894447


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 5974
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.462277
Layer 0 weight grad [0][0] = 29.364748


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5975
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.024599
Layer 0 weight grad [0][0] = -16.062305


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 5976
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.883611
Layer 0 weight grad [0][0] = -29.031013


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5977
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 26.439293
Layer 0 weight grad [0][0] = -65.905266


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5978
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 35.814831
Layer 0 weight grad [0][0] = 27.936787


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5979
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.932494
Layer 0 weight grad [0][0] = 55.983826


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5980
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 44.840992
Layer 0 weight grad [0][0] = 27.098339


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5981
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.451358
Layer 0 weight grad [0][0] = -30.306534


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5982
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -59.099419
Layer 0 weight grad [0][0] = 25.819918


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 5983
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.696322
Layer 0 weight grad [0][0] = 23.990152


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5984
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.208792
Layer 0 weight grad [0][0] = 24.679197


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5985
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 41.915783
Layer 0 weight grad [0][0] = 24.174101


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5986
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.242489
Layer 0 weight grad [0][0] = 21.642742


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5987
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.342555
Layer 0 weight grad [0][0] = 21.937664


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5988
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.405479
Layer 0 weight grad [0][0] = 20.997927


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5989
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.432790
Layer 0 weight grad [0][0] = 66.567841


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5990
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -58.430588
Layer 0 weight grad [0][0] = 20.949501


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5991
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.676145
Layer 0 weight grad [0][0] = -9.695111


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5992
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 40.210903
Layer 0 weight grad [0][0] = 1.580064


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5993
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.286749
Layer 0 weight grad [0][0] = 20.986622


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5994
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.361467
Layer 0 weight grad [0][0] = 25.020166


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5995
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.422729
Layer 0 weight grad [0][0] = 18.822765


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 5996
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.216150
Layer 0 weight grad [0][0] = -36.724228


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5997
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.767055
Layer 0 weight grad [0][0] = 24.377848


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 5998
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.279184
Layer 0 weight grad [0][0] = 23.444796


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 5999
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -65.795700
Layer 0 weight grad [0][0] = 36.884098


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6000
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.983730
Layer 0 weight grad [0][0] = 24.222660


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6001
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.842235
Layer 0 weight grad [0][0] = 24.078478


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6002
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 41.278305
Layer 0 weight grad [0][0] = -8.537574


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6003
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.328665
Layer 0 weight grad [0][0] = 23.492210


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6004
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.458490
Layer 0 weight grad [0][0] = 9.376242


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6005
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.625499
Layer 0 weight grad [0][0] = -57.037460


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6006
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.319261
Layer 0 weight grad [0][0] = -4.344194


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6007
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.490958
Layer 0 weight grad [0][0] = 50.375835


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6008
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -57.436523
Layer 0 weight grad [0][0] = -7.412945


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6009
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.607675
Layer 0 weight grad [0][0] = 3.503412


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6010
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 39.417976
Layer 0 weight grad [0][0] = 20.409334


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6011
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.690556
Layer 0 weight grad [0][0] = 17.910299


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6012
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -62.472328
Layer 0 weight grad [0][0] = -40.645401


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6013
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.828574
Layer 0 weight grad [0][0] = 20.056993


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6014
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.941524
Layer 0 weight grad [0][0] = -48.404461


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6015
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -62.768162
Layer 0 weight grad [0][0] = 22.562271


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6016
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.874165
Layer 0 weight grad [0][0] = 20.827404


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6017
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.017098
Layer 0 weight grad [0][0] = 25.438448


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6018
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 22.962725
Layer 0 weight grad [0][0] = 44.215614


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6019
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.305173
Layer 0 weight grad [0][0] = 29.688820


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6020
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.402687
Layer 0 weight grad [0][0] = 25.637743


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6021
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 37.240005
Layer 0 weight grad [0][0] = 26.257616


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 6022
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.180662
Layer 0 weight grad [0][0] = 25.970854


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6023
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -70.672943
Layer 0 weight grad [0][0] = 24.838139


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6024
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.450022
Layer 0 weight grad [0][0] = 24.924160


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6025
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.628192
Layer 0 weight grad [0][0] = 24.787802


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6026
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.248746
Layer 0 weight grad [0][0] = 23.461798


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 6027
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.578317
Layer 0 weight grad [0][0] = 23.390493


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 6028
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.481136
Layer 0 weight grad [0][0] = 24.376616


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6029
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.610799
Layer 0 weight grad [0][0] = 23.242001


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6030
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.758716
Layer 0 weight grad [0][0] = -8.045261


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6031
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.850401
Layer 0 weight grad [0][0] = -1.944986


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6032
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 41.356258
Layer 0 weight grad [0][0] = 32.727165


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6033
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.649502
Layer 0 weight grad [0][0] = 36.888599


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6034
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.095557
Layer 0 weight grad [0][0] = 36.913528


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6035
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.607915
Layer 0 weight grad [0][0] = 36.716953


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 6036
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 55.526382
Layer 0 weight grad [0][0] = -67.409470


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6037
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.209655
Layer 0 weight grad [0][0] = 60.820724


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6038
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -83.870628
Layer 0 weight grad [0][0] = 58.005085


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6039
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.240646
Layer 0 weight grad [0][0] = 57.885807


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6040
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.777242
Layer 0 weight grad [0][0] = 60.525265


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6041
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.394580
Layer 0 weight grad [0][0] = -76.500931


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6042
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.668442
Layer 0 weight grad [0][0] = 43.330948


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6043
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.490861
Layer 0 weight grad [0][0] = 45.131618


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6044
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.375599
Layer 0 weight grad [0][0] = 38.180046


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6045
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.655829
Layer 0 weight grad [0][0] = -73.880241


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6046
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.489069
Layer 0 weight grad [0][0] = -102.249825


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6047
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.029353
Layer 0 weight grad [0][0] = 8.278357


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6048
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.569813
Layer 0 weight grad [0][0] = 34.309406


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6049
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.625185
Layer 0 weight grad [0][0] = -46.868896


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6050
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.691316
Layer 0 weight grad [0][0] = 31.594954


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6051
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.766694
Layer 0 weight grad [0][0] = 33.036827


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6052
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.845796
Layer 0 weight grad [0][0] = 0.889699


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6053
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.677809
Layer 0 weight grad [0][0] = 27.007402


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6054
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 56.007324
Layer 0 weight grad [0][0] = 40.901909


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6055
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.498617
Layer 0 weight grad [0][0] = -15.345170


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6056
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.132813
Layer 0 weight grad [0][0] = 26.732080


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6057
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.184387
Layer 0 weight grad [0][0] = 24.019917


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6058
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.832814
Layer 0 weight grad [0][0] = -3.515155


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6059
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.926294
Layer 0 weight grad [0][0] = 25.809200


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6060
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.020475
Layer 0 weight grad [0][0] = -86.198677


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6061
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.119680
Layer 0 weight grad [0][0] = 42.808136


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6062
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.304597
Layer 0 weight grad [0][0] = 21.201448


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6063
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.860807
Layer 0 weight grad [0][0] = 20.440573


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 6064
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -85.721016
Layer 0 weight grad [0][0] = 26.006073


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6065
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 58.769272
Layer 0 weight grad [0][0] = 11.318689


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6066
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.951403
Layer 0 weight grad [0][0] = 11.066918


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6067
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.574608
Layer 0 weight grad [0][0] = 25.288548


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6068
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.655440
Layer 0 weight grad [0][0] = 23.906786


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6069
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.736601
Layer 0 weight grad [0][0] = 23.770761


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6070
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.264844
Layer 0 weight grad [0][0] = 21.183445


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6071
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.920656
Layer 0 weight grad [0][0] = 21.423183


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6072
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -91.524734
Layer 0 weight grad [0][0] = 23.053101


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6073
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.998960
Layer 0 weight grad [0][0] = 20.535858


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6074
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.638068
Layer 0 weight grad [0][0] = 23.725729


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6075
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.287128
Layer 0 weight grad [0][0] = 20.560907


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 6076
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.979970
Layer 0 weight grad [0][0] = 19.737482


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6077
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.626979
Layer 0 weight grad [0][0] = 20.190639


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6078
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.830906
Layer 0 weight grad [0][0] = 41.510189


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6079
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.060738
Layer 0 weight grad [0][0] = 19.811148


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6080
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.266903
Layer 0 weight grad [0][0] = 18.496035


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6081
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 60.994152
Layer 0 weight grad [0][0] = 34.354328


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6082
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.813517
Layer 0 weight grad [0][0] = 17.802511


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6083
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.483937
Layer 0 weight grad [0][0] = -11.998589


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6084
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.515267
Layer 0 weight grad [0][0] = -94.171722


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6085
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.945224
Layer 0 weight grad [0][0] = 15.599814


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6086
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.678851
Layer 0 weight grad [0][0] = 41.552132


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6087
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.870234
Layer 0 weight grad [0][0] = 17.433155


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6088
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.809313
Layer 0 weight grad [0][0] = 15.440749


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6089
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.825645
Layer 0 weight grad [0][0] = 15.155371


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6090
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -106.049179
Layer 0 weight grad [0][0] = 19.742968


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6091
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.378075
Layer 0 weight grad [0][0] = -84.798859


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6092
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.574454
Layer 0 weight grad [0][0] = 18.421801


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6093
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.780762
Layer 0 weight grad [0][0] = 25.569878


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6094
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 64.227745
Layer 0 weight grad [0][0] = 18.569319


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6095
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.774049
Layer 0 weight grad [0][0] = -79.621933


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6096
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.987008
Layer 0 weight grad [0][0] = 18.056284


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 6097
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.675066
Layer 0 weight grad [0][0] = 15.254189


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6098
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.462497
Layer 0 weight grad [0][0] = 14.594056


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6099
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.174091
Layer 0 weight grad [0][0] = -37.567318


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6100
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.483972
Layer 0 weight grad [0][0] = 62.384609


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6101
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.932936
Layer 0 weight grad [0][0] = 16.164707


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6102
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.186276
Layer 0 weight grad [0][0] = 123.396080


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6103
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -94.720261
Layer 0 weight grad [0][0] = -36.993179


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6104
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.775876
Layer 0 weight grad [0][0] = 13.097361


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6105
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.560967
Layer 0 weight grad [0][0] = 86.874580


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6106
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.781382
Layer 0 weight grad [0][0] = 34.620823


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6107
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 62.832809
Layer 0 weight grad [0][0] = 12.653581


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6108
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.054776
Layer 0 weight grad [0][0] = 33.298470


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6109
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.542866
Layer 0 weight grad [0][0] = 9.948046


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6110
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.642374
Layer 0 weight grad [0][0] = 61.912239


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6111
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.948590
Layer 0 weight grad [0][0] = 86.814720


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6112
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.750707
Layer 0 weight grad [0][0] = 87.743416


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6113
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.574911
Layer 0 weight grad [0][0] = 9.640702


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 6114
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -85.577705
Layer 0 weight grad [0][0] = 6.956609


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6115
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.898710
Layer 0 weight grad [0][0] = 29.195692


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6116
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2.791439
Layer 0 weight grad [0][0] = 6.210176


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6117
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.090217
Layer 0 weight grad [0][0] = 5.595586


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6118
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -92.035614
Layer 0 weight grad [0][0] = 26.044207


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6119
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.635326
Layer 0 weight grad [0][0] = 25.661264


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6120
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.033077
Layer 0 weight grad [0][0] = 24.265686


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6121
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.424088
Layer 0 weight grad [0][0] = 3.914114


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6122
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -91.914703
Layer 0 weight grad [0][0] = 21.897591


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6123
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7.072117
Layer 0 weight grad [0][0] = 163.374634


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6124
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -61.660072
Layer 0 weight grad [0][0] = 1.269945


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6125
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.435460
Layer 0 weight grad [0][0] = 1.237133


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6126
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 13.787350
Layer 0 weight grad [0][0] = 1.352138


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6127
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.503379
Layer 0 weight grad [0][0] = 2.159959


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6128
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -76.002426
Layer 0 weight grad [0][0] = 0.145722


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6129
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 8.295034
Layer 0 weight grad [0][0] = -1.968603


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6130
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.139464
Layer 0 weight grad [0][0] = 4.466393


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6131
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 8.984295
Layer 0 weight grad [0][0] = 4.033773


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6132
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.357197
Layer 0 weight grad [0][0] = 10.574443


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6133
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 10.243140
Layer 0 weight grad [0][0] = -97.349648


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6134
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -95.374496
Layer 0 weight grad [0][0] = 1.963249


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6135
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 11.781320
Layer 0 weight grad [0][0] = 4.208354


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6136
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -101.419479
Layer 0 weight grad [0][0] = 0.650336


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6137
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 14.759930
Layer 0 weight grad [0][0] = -104.542290


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6138
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 14.999784
Layer 0 weight grad [0][0] = 0.029494


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6139
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 14.919314
Layer 0 weight grad [0][0] = 109.556770


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6140
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 15.399619
Layer 0 weight grad [0][0] = -0.166948


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6141
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 15.841794
Layer 0 weight grad [0][0] = -61.946423


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6142
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 16.277966
Layer 0 weight grad [0][0] = -1.618020


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6143
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 16.694004
Layer 0 weight grad [0][0] = -2.184111


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6144
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 17.111401
Layer 0 weight grad [0][0] = 86.570244


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6145
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -8.996641
Layer 0 weight grad [0][0] = 7.853176


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6146
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 12.015315
Layer 0 weight grad [0][0] = -3.307196


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6147
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 13.534872
Layer 0 weight grad [0][0] = -100.738144


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6148
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 13.938302
Layer 0 weight grad [0][0] = 0.374640


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6149
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -116.029541
Layer 0 weight grad [0][0] = -1.695223


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6150
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 16.166431
Layer 0 weight grad [0][0] = 9.984951


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6151
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 16.019653
Layer 0 weight grad [0][0] = -1.543969


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6152
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 16.407248
Layer 0 weight grad [0][0] = -55.463474


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6153
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -129.988266
Layer 0 weight grad [0][0] = 11.634635


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6154
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -130.238831
Layer 0 weight grad [0][0] = -92.642761


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 6155
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 20.478426
Layer 0 weight grad [0][0] = -59.076126


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6156
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -26.848719
Layer 0 weight grad [0][0] = 158.566589


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6157
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 19.283175
Layer 0 weight grad [0][0] = -5.666233


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 6158
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 20.449690
Layer 0 weight grad [0][0] = -5.007582


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6159
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 20.426399
Layer 0 weight grad [0][0] = -5.596700


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6160
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 20.681786
Layer 0 weight grad [0][0] = -6.507735


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6161
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 21.162100
Layer 0 weight grad [0][0] = 10.328832


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6162
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 21.270761
Layer 0 weight grad [0][0] = -8.641921


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6163
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -163.239929
Layer 0 weight grad [0][0] = 111.894897


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6164
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 19.021353
Layer 0 weight grad [0][0] = 12.290211


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6165
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 20.015421
Layer 0 weight grad [0][0] = -8.326903


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6166
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 20.497105
Layer 0 weight grad [0][0] = -6.595229


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6167
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 21.014688
Layer 0 weight grad [0][0] = -69.510605


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6168
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 20.972458
Layer 0 weight grad [0][0] = -3.179378


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6169
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -26.791983
Layer 0 weight grad [0][0] = -97.074394


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6170
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 20.667269
Layer 0 weight grad [0][0] = 0.676630


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6171
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -154.881363
Layer 0 weight grad [0][0] = -0.311408


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6172
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -157.788910
Layer 0 weight grad [0][0] = 0.885126


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6173
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -34.381306
Layer 0 weight grad [0][0] = -0.413833


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6174
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 23.559139
Layer 0 weight grad [0][0] = 0.110336


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6175
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 24.070074
Layer 0 weight grad [0][0] = 0.671658


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6176
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -23.686541
Layer 0 weight grad [0][0] = -1.958017


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6177
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 23.993845
Layer 0 weight grad [0][0] = -4.180669


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6178
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -184.499435
Layer 0 weight grad [0][0] = 126.933945


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6179
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 25.654306
Layer 0 weight grad [0][0] = -66.399414


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6180
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 26.224430
Layer 0 weight grad [0][0] = 206.129669


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6181
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -22.272959
Layer 0 weight grad [0][0] = 0.802881


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6182
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -11.250121
Layer 0 weight grad [0][0] = 1.439586


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6183
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 21.636545
Layer 0 weight grad [0][0] = 87.012650


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 6184
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 17.448805
Layer 0 weight grad [0][0] = -1.705566


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6185
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 17.976778
Layer 0 weight grad [0][0] = -3.494283


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6186
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 18.571280
Layer 0 weight grad [0][0] = 13.639743


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6187
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 19.119387
Layer 0 weight grad [0][0] = 10.853390


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6188
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 19.710779
Layer 0 weight grad [0][0] = -99.764259


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6189
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 20.236664
Layer 0 weight grad [0][0] = -99.236435


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6190
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 20.992336
Layer 0 weight grad [0][0] = 0.775508


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6191
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 21.318737
Layer 0 weight grad [0][0] = -74.788994


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6192
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 21.798176
Layer 0 weight grad [0][0] = -1.501349


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 6193
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -173.777649
Layer 0 weight grad [0][0] = -63.470375


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6194
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 24.266157
Layer 0 weight grad [0][0] = 51.466427


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6195
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 23.687014
Layer 0 weight grad [0][0] = 2.098451


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6196
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 24.220352
Layer 0 weight grad [0][0] = 2.757998


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6197
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 24.765560
Layer 0 weight grad [0][0] = -175.999146


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6198
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -186.567291
Layer 0 weight grad [0][0] = 4.276731


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6199
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 26.093184
Layer 0 weight grad [0][0] = -52.468582


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6200
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 27.185999
Layer 0 weight grad [0][0] = -76.197159


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6201
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 27.267538
Layer 0 weight grad [0][0] = -106.763428


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6202
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 27.324209
Layer 0 weight grad [0][0] = 4.315990


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6203
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 28.469652
Layer 0 weight grad [0][0] = 3.235571


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6204
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 29.398998
Layer 0 weight grad [0][0] = 3.746823


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6205
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 30.604256
Layer 0 weight grad [0][0] = 6.079203


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6206
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 30.578583
Layer 0 weight grad [0][0] = -211.609650


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6207
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 31.273006
Layer 0 weight grad [0][0] = 4.089620


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6208
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -225.207611
Layer 0 weight grad [0][0] = 5.188737


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6209
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 32.295170
Layer 0 weight grad [0][0] = 2.070735


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6210
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -234.724472
Layer 0 weight grad [0][0] = 31.220173


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6211
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 33.112965
Layer 0 weight grad [0][0] = 25.871031


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6212
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 33.685646
Layer 0 weight grad [0][0] = 4.067629


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6213
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 34.161072
Layer 0 weight grad [0][0] = 7.951351


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6214
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 34.682697
Layer 0 weight grad [0][0] = 8.155972


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 6215
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -249.740051
Layer 0 weight grad [0][0] = 4.866964


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6216
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -254.236328
Layer 0 weight grad [0][0] = 3.926124


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6217
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 35.378799
Layer 0 weight grad [0][0] = 7.622215


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6218
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 35.990166
Layer 0 weight grad [0][0] = 6.153166


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6219
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -264.906982
Layer 0 weight grad [0][0] = 4.791369


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6220
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 37.092049
Layer 0 weight grad [0][0] = 279.813599


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6221
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 34.391415
Layer 0 weight grad [0][0] = 6.240871


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6222
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -31.128992
Layer 0 weight grad [0][0] = 50.386211


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6223
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 32.828762
Layer 0 weight grad [0][0] = -97.140892


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6224
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 33.394455
Layer 0 weight grad [0][0] = 6.424564


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6225
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000004 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 33.966072
Layer 0 weight grad [0][0] = 7.713809


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6226
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 34.687965
Layer 0 weight grad [0][0] = 6.419152


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6227
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 35.204830
Layer 0 weight grad [0][0] = 31.141306


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6228
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 35.607033
Layer 0 weight grad [0][0] = -71.295601


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6229
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 36.142391
Layer 0 weight grad [0][0] = 274.103699


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6230
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -33.474380
Layer 0 weight grad [0][0] = 3.834898


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6231
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 33.305401
Layer 0 weight grad [0][0] = 157.771042


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6232
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 33.596115
Layer 0 weight grad [0][0] = 78.464645


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6233
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -24.463770
Layer 0 weight grad [0][0] = 4.064246


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6234
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -12.043650
Layer 0 weight grad [0][0] = 153.482025


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6235
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 31.147705
Layer 0 weight grad [0][0] = 153.881042


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6236
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -253.179611
Layer 0 weight grad [0][0] = 3.826138


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6237
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 31.200201
Layer 0 weight grad [0][0] = -94.860092


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 6238
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 32.413971
Layer 0 weight grad [0][0] = 233.298462


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6239
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 31.916889
Layer 0 weight grad [0][0] = 23.572594


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6240
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 33.068504
Layer 0 weight grad [0][0] = 129.229736


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6241
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 31.599815
Layer 0 weight grad [0][0] = 5.893903


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6242
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 32.179264
Layer 0 weight grad [0][0] = 5.932726


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6243
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000014 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 32.786373
Layer 0 weight grad [0][0] = 159.064972


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6244
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -248.876236
Layer 0 weight grad [0][0] = 36.600300


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6245
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 32.569809
Layer 0 weight grad [0][0] = -109.297676


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6246
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 33.236149
Layer 0 weight grad [0][0] = 3.859731


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6247
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 34.618828
Layer 0 weight grad [0][0] = 4.573204


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6248
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -16.080770
Layer 0 weight grad [0][0] = 3.399667


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6249
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 32.699715
Layer 0 weight grad [0][0] = 24.366205


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6250
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 34.357292
Layer 0 weight grad [0][0] = 62.106594


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6251
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 33.239372
Layer 0 weight grad [0][0] = 62.149895


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6252
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 32.652748
Layer 0 weight grad [0][0] = -11.154798


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6253
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -236.448181
Layer 0 weight grad [0][0] = 160.248367


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6254
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -6.786162
Layer 0 weight grad [0][0] = 258.724731


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6255
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 27.543837
Layer 0 weight grad [0][0] = 5.041688


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6256
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 27.966694
Layer 0 weight grad [0][0] = -103.413048


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6257
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 29.135328
Layer 0 weight grad [0][0] = -85.774605


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6258
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 29.807737
Layer 0 weight grad [0][0] = 4.450392


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6259
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 30.015272
Layer 0 weight grad [0][0] = 5.225729


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6260
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 30.724901
Layer 0 weight grad [0][0] = 33.914616


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6261
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 31.417128
Layer 0 weight grad [0][0] = -80.271339


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6262
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 32.180592
Layer 0 weight grad [0][0] = -22.817265


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6263
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 31.767313
Layer 0 weight grad [0][0] = -128.759949


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6264
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 32.472912
Layer 0 weight grad [0][0] = 6.300782


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6265
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 33.705330
Layer 0 weight grad [0][0] = -75.051155


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6266
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 32.756042
Layer 0 weight grad [0][0] = 57.119987


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6267
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 32.338837
Layer 0 weight grad [0][0] = 5.841475


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6268
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 32.999088
Layer 0 weight grad [0][0] = 61.826210


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6269
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -226.561295
Layer 0 weight grad [0][0] = 132.505264


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6270
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 31.642450
Layer 0 weight grad [0][0] = -65.237144


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6271
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 32.941612
Layer 0 weight grad [0][0] = 5.923462


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6272
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 33.635361
Layer 0 weight grad [0][0] = 180.830856


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6273
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 34.249592
Layer 0 weight grad [0][0] = -117.631111


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6274
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 34.901268
Layer 0 weight grad [0][0] = -135.304794


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6275
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 35.247913
Layer 0 weight grad [0][0] = 7.285433


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6276
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 35.721527
Layer 0 weight grad [0][0] = 6.765299


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6277
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 36.379547
Layer 0 weight grad [0][0] = -124.672981


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6278
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 36.998024
Layer 0 weight grad [0][0] = 45.526691


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6279
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 37.719578
Layer 0 weight grad [0][0] = 154.341415


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6280
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 38.424545
Layer 0 weight grad [0][0] = 32.459557


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6281
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 38.998024
Layer 0 weight grad [0][0] = 7.472118


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6282
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -57.652481
Layer 0 weight grad [0][0] = 5.252651


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6283
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -41.370979
Layer 0 weight grad [0][0] = 229.780640


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6284
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 35.516052
Layer 0 weight grad [0][0] = 9.032038


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 6285
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 36.104183
Layer 0 weight grad [0][0] = 62.217880


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6286
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -34.234489
Layer 0 weight grad [0][0] = 8.650879


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6287
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -18.452982
Layer 0 weight grad [0][0] = 10.080391


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6288
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 32.983570
Layer 0 weight grad [0][0] = 59.068619


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6289
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 33.059090
Layer 0 weight grad [0][0] = -106.802353


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6290
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 32.627468
Layer 0 weight grad [0][0] = 32.203339


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6291
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 32.799049
Layer 0 weight grad [0][0] = 35.631191


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6292
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 33.494869
Layer 0 weight grad [0][0] = 5.956063


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6293
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 34.719212
Layer 0 weight grad [0][0] = 5.056167


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6294
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 34.948963
Layer 0 weight grad [0][0] = 143.045944


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6295
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -260.857788
Layer 0 weight grad [0][0] = 86.167801


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6296
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -14.945490
Layer 0 weight grad [0][0] = 4.763762


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6297
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 32.671158
Layer 0 weight grad [0][0] = 3.720805


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6298
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -264.767761
Layer 0 weight grad [0][0] = 152.564209


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6299
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4.547345
Layer 0 weight grad [0][0] = 2.363076


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6300
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 28.922640
Layer 0 weight grad [0][0] = -157.544342


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6301
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 29.570995
Layer 0 weight grad [0][0] = 4.266793


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6302
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 29.750185
Layer 0 weight grad [0][0] = 9.113661


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6303
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 27.794085
Layer 0 weight grad [0][0] = 25.364138


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6304
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -233.728867
Layer 0 weight grad [0][0] = -7.573227


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6305
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 14.249089
Layer 0 weight grad [0][0] = 2.466215


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6306
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 26.672050
Layer 0 weight grad [0][0] = 43.890846


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6307
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 26.387798
Layer 0 weight grad [0][0] = -175.667953


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6308
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 22.676228
Layer 0 weight grad [0][0] = 0.725849


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6309
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 25.921906
Layer 0 weight grad [0][0] = 0.517446


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6310
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 35.962223
Layer 0 weight grad [0][0] = -177.880157


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6311
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 26.053967
Layer 0 weight grad [0][0] = -177.520020


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6312
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 26.453924
Layer 0 weight grad [0][0] = -0.894927


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6313
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 27.021963
Layer 0 weight grad [0][0] = -3.300537


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6314
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 28.037724
Layer 0 weight grad [0][0] = 39.799782


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6315
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 28.835955
Layer 0 weight grad [0][0] = -3.596022


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6316
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 29.452291
Layer 0 weight grad [0][0] = -4.564460


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6317
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 30.776184
Layer 0 weight grad [0][0] = 184.381287


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6318
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 27.659651
Layer 0 weight grad [0][0] = -7.223654


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6319
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 28.314850
Layer 0 weight grad [0][0] = 198.889633


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6320
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 24.165049
Layer 0 weight grad [0][0] = 19.215488


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6321
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 25.087091
Layer 0 weight grad [0][0] = 108.882660


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6322
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 25.978384
Layer 0 weight grad [0][0] = -1.672158


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6323
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 26.858776
Layer 0 weight grad [0][0] = 15.556695


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6324
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 27.766155
Layer 0 weight grad [0][0] = -8.322104


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6325
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 29.203098
Layer 0 weight grad [0][0] = -6.601508


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6326
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 29.608387
Layer 0 weight grad [0][0] = 34.462059


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 6327
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 30.731091
Layer 0 weight grad [0][0] = 9.654623


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6328
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 31.506357
Layer 0 weight grad [0][0] = -9.672061


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6329
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 32.420708
Layer 0 weight grad [0][0] = 243.686844


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6330
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 27.935213
Layer 0 weight grad [0][0] = 17.593399


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6331
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 29.493196
Layer 0 weight grad [0][0] = 248.022339


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6332
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 24.336943
Layer 0 weight grad [0][0] = 99.034004


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6333
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 25.418295
Layer 0 weight grad [0][0] = -5.986217


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6334
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -191.553925
Layer 0 weight grad [0][0] = -9.488389


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6335
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 26.416256
Layer 0 weight grad [0][0] = -10.110917


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6336
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -15.774719
Layer 0 weight grad [0][0] = -10.613441


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 6337
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 26.420124
Layer 0 weight grad [0][0] = -9.065369


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6338
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 27.466999
Layer 0 weight grad [0][0] = -8.754644


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6339
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 29.046797
Layer 0 weight grad [0][0] = 18.365408


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6340
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -231.413101
Layer 0 weight grad [0][0] = 125.899162


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 6341
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 29.861746
Layer 0 weight grad [0][0] = 3.943144


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6342
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 30.343422
Layer 0 weight grad [0][0] = 2.547821


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6343
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -250.084610
Layer 0 weight grad [0][0] = 260.646149


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6344
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 25.734533
Layer 0 weight grad [0][0] = -14.285927


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6345
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 26.574131
Layer 0 weight grad [0][0] = 123.485603


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6346
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 27.619732
Layer 0 weight grad [0][0] = -8.268691


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6347
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 28.844055
Layer 0 weight grad [0][0] = 15.997881


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6348
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 29.648495
Layer 0 weight grad [0][0] = -12.505695


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6349
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 30.566828
Layer 0 weight grad [0][0] = -14.486736


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6350
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 31.611675
Layer 0 weight grad [0][0] = -207.004654


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6351
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 32.614162
Layer 0 weight grad [0][0] = -38.324276


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 6352
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 33.515770
Layer 0 weight grad [0][0] = -6.135197


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6353
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 34.280502
Layer 0 weight grad [0][0] = 72.765434


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6354
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 34.271481
Layer 0 weight grad [0][0] = -8.342502


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6355
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 35.149502
Layer 0 weight grad [0][0] = -10.447900


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6356
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -25.232100
Layer 0 weight grad [0][0] = -27.018202


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6357
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 35.186111
Layer 0 weight grad [0][0] = 245.232941


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6358
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 30.984112
Layer 0 weight grad [0][0] = -7.992218


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6359
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 31.361879
Layer 0 weight grad [0][0] = -186.576752


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6360
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 32.248302
Layer 0 weight grad [0][0] = -29.572107


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6361
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 33.174393
Layer 0 weight grad [0][0] = 23.796028


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6362
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 33.965382
Layer 0 weight grad [0][0] = 156.133057


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6363
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 34.712814
Layer 0 weight grad [0][0] = -10.450061


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 6364
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 35.491417
Layer 0 weight grad [0][0] = -30.310623


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6365
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 35.693737
Layer 0 weight grad [0][0] = -5.491636


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6366
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 36.935905
Layer 0 weight grad [0][0] = -9.919469


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6367
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 37.619915
Layer 0 weight grad [0][0] = -8.634730


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6368
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 37.884983
Layer 0 weight grad [0][0] = -143.751480


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6369
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 38.516697
Layer 0 weight grad [0][0] = -3.725765


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 6370
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -284.729645
Layer 0 weight grad [0][0] = -2.216966


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6371
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 39.438644
Layer 0 weight grad [0][0] = -2.245867


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6372
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -34.026382
Layer 0 weight grad [0][0] = 87.488586


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6373
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 38.462025
Layer 0 weight grad [0][0] = -3.906839


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6374
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 38.017784
Layer 0 weight grad [0][0] = 160.055618


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6375
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 38.755878
Layer 0 weight grad [0][0] = -0.803289


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6376
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -290.243134
Layer 0 weight grad [0][0] = 165.637009


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6377
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 40.351471
Layer 0 weight grad [0][0] = -2.534568


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6378
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 40.596638
Layer 0 weight grad [0][0] = -4.281311


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6379
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 41.021374
Layer 0 weight grad [0][0] = -4.761495


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6380
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 41.837994
Layer 0 weight grad [0][0] = -6.021498


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6381
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 42.960991
Layer 0 weight grad [0][0] = -6.105417


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6382
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 42.383415
Layer 0 weight grad [0][0] = -7.552048


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6383
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 43.795937
Layer 0 weight grad [0][0] = -322.773407


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6384
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 43.748116
Layer 0 weight grad [0][0] = 156.021515


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6385
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 45.469711
Layer 0 weight grad [0][0] = -8.814362


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6386
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -329.565460
Layer 0 weight grad [0][0] = -12.790651


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6387
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 46.433510
Layer 0 weight grad [0][0] = 199.239914


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6388
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -39.554245
Layer 0 weight grad [0][0] = -14.050865


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6389
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 45.052277
Layer 0 weight grad [0][0] = 149.991318


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6390
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 41.696293
Layer 0 weight grad [0][0] = 32.686707


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6391
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 43.157387
Layer 0 weight grad [0][0] = -4.958808


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6392
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 43.873081
Layer 0 weight grad [0][0] = 140.282303


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6393
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 45.129944
Layer 0 weight grad [0][0] = -127.044685


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6394
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 45.380169
Layer 0 weight grad [0][0] = 32.156212


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6395
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 46.406284
Layer 0 weight grad [0][0] = -13.353419


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6396
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -39.557407
Layer 0 weight grad [0][0] = 127.071434


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6397
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 46.389050
Layer 0 weight grad [0][0] = -113.090515


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6398
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 45.939713
Layer 0 weight grad [0][0] = 34.839069


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6399
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 47.188362
Layer 0 weight grad [0][0] = -11.532858


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6400
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -31.258501
Layer 0 weight grad [0][0] = -10.036922


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6401
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 47.583984
Layer 0 weight grad [0][0] = 30.476448


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6402
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 47.428825
Layer 0 weight grad [0][0] = -8.513619


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6403
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 47.590080
Layer 0 weight grad [0][0] = -11.212281


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6404
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 48.556007
Layer 0 weight grad [0][0] = 119.343208


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6405
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 49.588722
Layer 0 weight grad [0][0] = -166.828766


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6406
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 50.328217
Layer 0 weight grad [0][0] = 338.441711


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6407
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 45.438622
Layer 0 weight grad [0][0] = -16.301249


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6408
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 46.760517
Layer 0 weight grad [0][0] = -49.266212


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6409
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 47.496605
Layer 0 weight grad [0][0] = 212.438202


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6410
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 43.290367
Layer 0 weight grad [0][0] = 112.154800


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6411
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 44.066879
Layer 0 weight grad [0][0] = -20.419449


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6412
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 44.845306
Layer 0 weight grad [0][0] = 148.214508


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 6413
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -312.728088
Layer 0 weight grad [0][0] = -23.039816


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6414
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 45.265415
Layer 0 weight grad [0][0] = -21.115494


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6415
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -44.716839
Layer 0 weight grad [0][0] = -20.556534


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6416
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 45.423187
Layer 0 weight grad [0][0] = 14.367947


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6417
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 46.745754
Layer 0 weight grad [0][0] = -17.875271


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6418
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 46.919739
Layer 0 weight grad [0][0] = 190.886734


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6419
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 42.414104
Layer 0 weight grad [0][0] = 21.937229


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6420
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -40.362019
Layer 0 weight grad [0][0] = -18.847054


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6421
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 43.543781
Layer 0 weight grad [0][0] = -17.487108


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6422
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 44.266148
Layer 0 weight grad [0][0] = -161.921585


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6423
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 44.461578
Layer 0 weight grad [0][0] = -12.469708


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6424
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -330.790863
Layer 0 weight grad [0][0] = 141.263916


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6425
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 45.729721
Layer 0 weight grad [0][0] = -11.587280


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6426
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 46.690243
Layer 0 weight grad [0][0] = 231.978729


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6427
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 42.467419
Layer 0 weight grad [0][0] = -12.395702


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6428
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 43.066727
Layer 0 weight grad [0][0] = -14.958364


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6429
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -36.847759
Layer 0 weight grad [0][0] = -14.235668


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6430
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 43.131493
Layer 0 weight grad [0][0] = 149.320557


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6431
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 43.816990
Layer 0 weight grad [0][0] = -17.751102


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6432
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 44.484783
Layer 0 weight grad [0][0] = 79.938423


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 6433
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 45.327667
Layer 0 weight grad [0][0] = -14.765320


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6434
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 45.801903
Layer 0 weight grad [0][0] = -12.640491


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6435
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 46.461086
Layer 0 weight grad [0][0] = -0.015521


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6436
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 47.290970
Layer 0 weight grad [0][0] = -15.600705


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6437
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 47.974930
Layer 0 weight grad [0][0] = -18.018721


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6438
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -354.247437
Layer 0 weight grad [0][0] = 278.098907


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6439
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 43.540943
Layer 0 weight grad [0][0] = -154.355789


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6440
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 44.720482
Layer 0 weight grad [0][0] = 24.128807


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6441
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 44.916103
Layer 0 weight grad [0][0] = -21.090298


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6442
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 46.219440
Layer 0 weight grad [0][0] = 8.548576


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6443
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 45.770245
Layer 0 weight grad [0][0] = 209.154510


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6444
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 41.541935
Layer 0 weight grad [0][0] = 42.802998


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6445
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -291.530334
Layer 0 weight grad [0][0] = 75.158661


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6446
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -296.445190
Layer 0 weight grad [0][0] = 218.593307


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 6447
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 39.022629
Layer 0 weight grad [0][0] = -17.125986


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6448
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 39.011101
Layer 0 weight grad [0][0] = -14.559364


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6449
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 39.635723
Layer 0 weight grad [0][0] = 19.847464


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6450
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 40.669064
Layer 0 weight grad [0][0] = 154.366882


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6451
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 41.623943
Layer 0 weight grad [0][0] = 199.530945


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6452
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 37.026459
Layer 0 weight grad [0][0] = 149.358276


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6453
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 37.251907
Layer 0 weight grad [0][0] = 56.932247


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6454
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 38.645653
Layer 0 weight grad [0][0] = -80.934761


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6455
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 39.387947
Layer 0 weight grad [0][0] = -144.484848


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6456
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -64.847168
Layer 0 weight grad [0][0] = -17.055416


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6457
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 39.638638
Layer 0 weight grad [0][0] = -171.253937


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6458
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 40.381645
Layer 0 weight grad [0][0] = -18.487030


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6459
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 41.737396
Layer 0 weight grad [0][0] = -17.992336


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6460
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 41.995708
Layer 0 weight grad [0][0] = -6.513136


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6461
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 42.735928
Layer 0 weight grad [0][0] = -11.796549


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6462
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 43.326080
Layer 0 weight grad [0][0] = -13.264997


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6463
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 43.944332
Layer 0 weight grad [0][0] = -10.673379


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6464
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 44.452129
Layer 0 weight grad [0][0] = 17.330948


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6465
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 44.335526
Layer 0 weight grad [0][0] = -12.975064


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6466
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 45.088287
Layer 0 weight grad [0][0] = -161.695297


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6467
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -293.933167
Layer 0 weight grad [0][0] = -14.952151


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6468
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 46.262558
Layer 0 weight grad [0][0] = -15.401181


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6469
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 46.705025
Layer 0 weight grad [0][0] = -16.601559


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6470
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 46.806694
Layer 0 weight grad [0][0] = -12.700834


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6471
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 48.209354
Layer 0 weight grad [0][0] = -14.717905


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6472
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 48.139969
Layer 0 weight grad [0][0] = -9.417539


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 6473
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 48.816803
Layer 0 weight grad [0][0] = -16.800356


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6474
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 48.969357
Layer 0 weight grad [0][0] = -17.206818


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6475
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 50.372211
Layer 0 weight grad [0][0] = -17.236130


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6476
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -79.124535
Layer 0 weight grad [0][0] = 11.453349


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6477
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 49.669960
Layer 0 weight grad [0][0] = 10.679310


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6478
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 50.244316
Layer 0 weight grad [0][0] = -19.089285


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6479
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 50.469082
Layer 0 weight grad [0][0] = -17.758184


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6480
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 51.753525
Layer 0 weight grad [0][0] = -18.616472


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6481
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 52.023804
Layer 0 weight grad [0][0] = -12.823912


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6482
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 52.354553
Layer 0 weight grad [0][0] = -23.553802


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6483
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 53.778351
Layer 0 weight grad [0][0] = 133.324478


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6484
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 54.708286
Layer 0 weight grad [0][0] = 220.908173


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6485
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -311.251678
Layer 0 weight grad [0][0] = 104.624023


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6486
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 50.190613
Layer 0 weight grad [0][0] = -21.884211


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6487
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 50.322872
Layer 0 weight grad [0][0] = -21.806654


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6488
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 51.183277
Layer 0 weight grad [0][0] = -24.387577


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6489
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 52.280563
Layer 0 weight grad [0][0] = 23.699572


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6490
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 53.068501
Layer 0 weight grad [0][0] = 15.725463


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6491
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 53.099270
Layer 0 weight grad [0][0] = -24.339117


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6492
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 54.577839
Layer 0 weight grad [0][0] = -25.225779


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6493
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 55.046375
Layer 0 weight grad [0][0] = 96.089745


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6494
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 56.581451
Layer 0 weight grad [0][0] = 88.992371


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6495
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 57.275917
Layer 0 weight grad [0][0] = -25.035971


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6496
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 58.085014
Layer 0 weight grad [0][0] = -4.032407


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6497
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 59.100357
Layer 0 weight grad [0][0] = -24.681704


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6498
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 60.163918
Layer 0 weight grad [0][0] = -25.260763


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6499
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 61.217304
Layer 0 weight grad [0][0] = 16.828068


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6500
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 61.320423
Layer 0 weight grad [0][0] = -23.872379


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6501
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 62.874100
Layer 0 weight grad [0][0] = -19.944794


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6502
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 63.785789
Layer 0 weight grad [0][0] = -17.346802


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6503
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 64.137810
Layer 0 weight grad [0][0] = 97.226273


Training loss: 2.302585
Training accuracy: 0.375000

epoch: 6504
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 64.345039
Layer 0 weight grad [0][0] = 150.272949


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6505
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 65.321251
Layer 0 weight grad [0][0] = -402.359741


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6506
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -390.987122
Layer 0 weight grad [0][0] = 119.162308


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6507
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 61.749809
Layer 0 weight grad [0][0] = 22.556559


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6508
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -129.771317
Layer 0 weight grad [0][0] = 178.587921


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6509
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 60.939991
Layer 0 weight grad [0][0] = 31.193535


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6510
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 61.817844
Layer 0 weight grad [0][0] = -14.265759


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6511
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -122.992691
Layer 0 weight grad [0][0] = -12.267746


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6512
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 62.073406
Layer 0 weight grad [0][0] = -14.536015


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6513
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 61.938419
Layer 0 weight grad [0][0] = -180.690872


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6514
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 63.277012
Layer 0 weight grad [0][0] = -182.896133


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6515
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 64.285385
Layer 0 weight grad [0][0] = 195.901855


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6516
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 64.820206
Layer 0 weight grad [0][0] = -13.014220


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6517
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 65.645966
Layer 0 weight grad [0][0] = -194.524323


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6518
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 66.446259
Layer 0 weight grad [0][0] = -16.879007


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6519
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -405.079132
Layer 0 weight grad [0][0] = -11.628851


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6520
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 66.399063
Layer 0 weight grad [0][0] = -13.589627


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6521
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 66.710938
Layer 0 weight grad [0][0] = 159.109497


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6522
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 64.288292
Layer 0 weight grad [0][0] = 27.626631


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6523
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -130.482834
Layer 0 weight grad [0][0] = -17.858261


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6524
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 63.779133
Layer 0 weight grad [0][0] = -347.541473


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6525
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 65.259407
Layer 0 weight grad [0][0] = -14.200058


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6526
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 65.677689
Layer 0 weight grad [0][0] = 136.924500


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6527
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 66.694771
Layer 0 weight grad [0][0] = -19.760288


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6528
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 67.645844
Layer 0 weight grad [0][0] = -3.361572


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6529
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 68.660950
Layer 0 weight grad [0][0] = 136.499847


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 6530
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 69.776497
Layer 0 weight grad [0][0] = -20.186832


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 6531
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 70.536926
Layer 0 weight grad [0][0] = -216.979706


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6532
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -143.658478
Layer 0 weight grad [0][0] = 68.528603


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6533
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -427.961121
Layer 0 weight grad [0][0] = -24.101295


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6534
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 68.149002
Layer 0 weight grad [0][0] = -27.527357


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6535
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 69.442009
Layer 0 weight grad [0][0] = -28.396776


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6536
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -116.976151
Layer 0 weight grad [0][0] = 238.743393


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6537
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 63.943119
Layer 0 weight grad [0][0] = -25.715715


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6538
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 65.574013
Layer 0 weight grad [0][0] = -27.334320


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6539
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -116.898224
Layer 0 weight grad [0][0] = -23.776703


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6540
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -104.113594
Layer 0 weight grad [0][0] = -25.415480


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6541
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 65.445320
Layer 0 weight grad [0][0] = -27.911793


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6542
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 66.177170
Layer 0 weight grad [0][0] = -167.793655


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6543
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 68.226097
Layer 0 weight grad [0][0] = -169.534561


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6544
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 68.744255
Layer 0 weight grad [0][0] = 102.963242


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6545
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 69.936523
Layer 0 weight grad [0][0] = -27.768410


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6546
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 71.120369
Layer 0 weight grad [0][0] = -27.104853


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6547
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 72.849075
Layer 0 weight grad [0][0] = -29.178162


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6548
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 73.551971
Layer 0 weight grad [0][0] = -102.985474


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6549
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -123.457108
Layer 0 weight grad [0][0] = -26.219313


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6550
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 73.911011
Layer 0 weight grad [0][0] = -23.114309


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6551
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 75.140434
Layer 0 weight grad [0][0] = -23.231682


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6552
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 76.402802
Layer 0 weight grad [0][0] = -25.737913


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 6553
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -501.611725
Layer 0 weight grad [0][0] = -23.440235


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6554
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 75.531471
Layer 0 weight grad [0][0] = 48.598782


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6555
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -517.303406
Layer 0 weight grad [0][0] = -28.116772


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6556
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 74.381203
Layer 0 weight grad [0][0] = 44.647655


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6557
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 76.437683
Layer 0 weight grad [0][0] = -29.502485


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6558
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 77.911430
Layer 0 weight grad [0][0] = 38.787258


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6559
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 79.424164
Layer 0 weight grad [0][0] = 99.335938


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6560
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -551.925476
Layer 0 weight grad [0][0] = 50.188324


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6561
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 78.555229
Layer 0 weight grad [0][0] = -28.806128


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6562
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 79.782585
Layer 0 weight grad [0][0] = -30.920980


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6563
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 81.062172
Layer 0 weight grad [0][0] = 177.902847


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 6564
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -86.320923
Layer 0 weight grad [0][0] = -31.279139


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6565
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 80.503822
Layer 0 weight grad [0][0] = 101.476913


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6566
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 81.821648
Layer 0 weight grad [0][0] = -29.975653


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6567
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 82.684692
Layer 0 weight grad [0][0] = 49.383129


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6568
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 84.529495
Layer 0 weight grad [0][0] = -120.461166


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6569
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 85.553200
Layer 0 weight grad [0][0] = 98.431610


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6570
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 87.301277
Layer 0 weight grad [0][0] = -30.686026


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 6571
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 88.194641
Layer 0 weight grad [0][0] = -30.901888


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6572
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 89.567863
Layer 0 weight grad [0][0] = -25.481569


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6573
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 91.400040
Layer 0 weight grad [0][0] = 93.392357


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6574
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -622.063416
Layer 0 weight grad [0][0] = -24.535158


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6575
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 89.979202
Layer 0 weight grad [0][0] = -25.676699


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6576
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 91.435379
Layer 0 weight grad [0][0] = -662.319824


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6577
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 92.951981
Layer 0 weight grad [0][0] = -113.336075


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6578
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 95.030151
Layer 0 weight grad [0][0] = -29.073425


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6579
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 96.109444
Layer 0 weight grad [0][0] = -27.614794


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6580
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 97.722893
Layer 0 weight grad [0][0] = -27.736645


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6581
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -660.582031
Layer 0 weight grad [0][0] = -32.303493


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6582
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 97.478691
Layer 0 weight grad [0][0] = 316.284851


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6583
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 90.462509
Layer 0 weight grad [0][0] = -27.736454


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6584
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -127.754555
Layer 0 weight grad [0][0] = -22.207514


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6585
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 90.047874
Layer 0 weight grad [0][0] = -26.269789


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6586
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 91.752357
Layer 0 weight grad [0][0] = -20.144318


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6587
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 93.134033
Layer 0 weight grad [0][0] = -20.247749


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6588
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 94.619850
Layer 0 weight grad [0][0] = 30.389137


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6589
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 96.317574
Layer 0 weight grad [0][0] = -126.728760


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6590
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 98.010704
Layer 0 weight grad [0][0] = 75.021217


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6591
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 100.315269
Layer 0 weight grad [0][0] = 63.395176


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6592
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 101.466370
Layer 0 weight grad [0][0] = -16.973864


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6593
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 103.953041
Layer 0 weight grad [0][0] = -117.140877


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6594
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 104.432404
Layer 0 weight grad [0][0] = -117.101357


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 6595
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 106.740997
Layer 0 weight grad [0][0] = -21.391169


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6596
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 108.514656
Layer 0 weight grad [0][0] = -8.716979


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6597
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 109.812027
Layer 0 weight grad [0][0] = -21.305918


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6598
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 111.546783
Layer 0 weight grad [0][0] = 38.330547


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6599
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 113.275688
Layer 0 weight grad [0][0] = 52.244301


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6600
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 114.955917
Layer 0 weight grad [0][0] = -18.086874


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6601
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 116.587013
Layer 0 weight grad [0][0] = -17.917313


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6602
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 118.233650
Layer 0 weight grad [0][0] = -11.358559


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6603
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 119.825104
Layer 0 weight grad [0][0] = -11.377670


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6604
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 121.949226
Layer 0 weight grad [0][0] = -12.437198


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6605
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -222.625671
Layer 0 weight grad [0][0] = -17.814480


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6606
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 119.441811
Layer 0 weight grad [0][0] = -16.110836


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6607
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 121.012146
Layer 0 weight grad [0][0] = 103.243279


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6608
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 122.819168
Layer 0 weight grad [0][0] = -8.602811


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6609
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -796.074829
Layer 0 weight grad [0][0] = 358.587982


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6610
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 115.403709
Layer 0 weight grad [0][0] = -19.331741


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6611
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 117.545151
Layer 0 weight grad [0][0] = -13.804014


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6612
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 118.739319
Layer 0 weight grad [0][0] = 274.049866


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6613
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 112.172569
Layer 0 weight grad [0][0] = 34.610435


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 6614
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 113.856628
Layer 0 weight grad [0][0] = -11.748888


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6615
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -693.367126
Layer 0 weight grad [0][0] = -61.088097


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6616
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 115.311218
Layer 0 weight grad [0][0] = 9.849669


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6617
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 116.953651
Layer 0 weight grad [0][0] = -10.230645


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6618
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 118.963135
Layer 0 weight grad [0][0] = -12.049934


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6619
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -724.956909
Layer 0 weight grad [0][0] = -10.901904


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6620
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 118.827293
Layer 0 weight grad [0][0] = 19.501268


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6621
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 119.761078
Layer 0 weight grad [0][0] = 37.120384


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6622
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 121.813232
Layer 0 weight grad [0][0] = -77.138100


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6623
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 124.232368
Layer 0 weight grad [0][0] = -7.812366


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6624
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -758.541443
Layer 0 weight grad [0][0] = 113.698448


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6625
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 124.671898
Layer 0 weight grad [0][0] = -8.939386


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6626
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -238.791794
Layer 0 weight grad [0][0] = 7.431739


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6627
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -781.002014
Layer 0 weight grad [0][0] = -12.709213


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 6628
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 119.915161
Layer 0 weight grad [0][0] = -13.927874


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6629
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 121.979187
Layer 0 weight grad [0][0] = -16.495638


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6630
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 123.334618
Layer 0 weight grad [0][0] = -121.155441


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6631
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -803.298950
Layer 0 weight grad [0][0] = -15.552739


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6632
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 123.485962
Layer 0 weight grad [0][0] = -18.843924


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6633
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 124.455635
Layer 0 weight grad [0][0] = -733.819946


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6634
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 125.978134
Layer 0 weight grad [0][0] = -20.870438


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6635
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -824.133423
Layer 0 weight grad [0][0] = -17.407593


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6636
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 125.578812
Layer 0 weight grad [0][0] = -16.334318


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6637
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -831.024658
Layer 0 weight grad [0][0] = 148.206543


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6638
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 122.718575
Layer 0 weight grad [0][0] = 101.983498


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6639
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 123.386909
Layer 0 weight grad [0][0] = 170.183105


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6640
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 120.394730
Layer 0 weight grad [0][0] = -23.841610


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6641
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 122.232300
Layer 0 weight grad [0][0] = -123.051971


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6642
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 123.549591
Layer 0 weight grad [0][0] = 0.954073


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6643
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -789.651489
Layer 0 weight grad [0][0] = -26.405619


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6644
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 124.388794
Layer 0 weight grad [0][0] = 225.202591


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6645
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 120.287224
Layer 0 weight grad [0][0] = -178.146790


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6646
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 123.336143
Layer 0 weight grad [0][0] = -32.015167


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6647
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 124.237640
Layer 0 weight grad [0][0] = -129.575439


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6648
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 125.539986
Layer 0 weight grad [0][0] = -28.934946


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6649
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 126.131218
Layer 0 weight grad [0][0] = -27.388845


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 6650
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -768.892578
Layer 0 weight grad [0][0] = -28.232544


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6651
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -235.103699
Layer 0 weight grad [0][0] = 128.892258


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 6652
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 120.943001
Layer 0 weight grad [0][0] = -147.529572


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6653
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 122.118347
Layer 0 weight grad [0][0] = -185.094009


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6654
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -203.192749
Layer 0 weight grad [0][0] = -33.156193


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6655
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 119.640083
Layer 0 weight grad [0][0] = 149.420746


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6656
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -163.685684
Layer 0 weight grad [0][0] = 92.401367


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6657
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 110.335457
Layer 0 weight grad [0][0] = -106.365791


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6658
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 111.614548
Layer 0 weight grad [0][0] = -112.330963


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6659
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 112.894875
Layer 0 weight grad [0][0] = 160.882919


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6660
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 109.797516
Layer 0 weight grad [0][0] = 172.786011


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6661
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 106.531853
Layer 0 weight grad [0][0] = -34.421722


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6662
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 107.881950
Layer 0 weight grad [0][0] = 60.186390


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6663
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 109.765846
Layer 0 weight grad [0][0] = -136.835983


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6664
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -725.229431
Layer 0 weight grad [0][0] = -23.197239


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6665
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 113.234451
Layer 0 weight grad [0][0] = -33.269127


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6666
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 114.669220
Layer 0 weight grad [0][0] = 478.769073


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6667
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -179.829620
Layer 0 weight grad [0][0] = 82.944275


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6668
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 105.621674
Layer 0 weight grad [0][0] = -174.853638


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6669
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 109.393990
Layer 0 weight grad [0][0] = 73.968445


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6670
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 111.219078
Layer 0 weight grad [0][0] = 506.275879


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6671
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 108.027634
Layer 0 weight grad [0][0] = -67.109245


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6672
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -162.497635
Layer 0 weight grad [0][0] = -26.383307


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6673
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 103.588287
Layer 0 weight grad [0][0] = 89.561821


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6674
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -696.833862
Layer 0 weight grad [0][0] = 75.138069


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6675
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 99.422096
Layer 0 weight grad [0][0] = -81.279137


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6676
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 100.443108
Layer 0 weight grad [0][0] = -26.336187


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6677
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 101.685371
Layer 0 weight grad [0][0] = 170.843903


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6678
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 102.763245
Layer 0 weight grad [0][0] = -29.882298


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6679
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 103.619041
Layer 0 weight grad [0][0] = -29.320122


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6680
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -693.110413
Layer 0 weight grad [0][0] = 285.232880


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6681
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 102.316734
Layer 0 weight grad [0][0] = 63.322784


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6682
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -669.819214
Layer 0 weight grad [0][0] = 108.271355


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6683
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 95.155365
Layer 0 weight grad [0][0] = -123.281036


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6684
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 98.317535
Layer 0 weight grad [0][0] = -34.506042


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6685
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 100.012611
Layer 0 weight grad [0][0] = -68.211784


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6686
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 100.722733
Layer 0 weight grad [0][0] = -32.004749


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6687
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 102.150917
Layer 0 weight grad [0][0] = -33.044228


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6688
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 103.684517
Layer 0 weight grad [0][0] = -144.585754


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 6689
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 106.468300
Layer 0 weight grad [0][0] = -35.581051


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6690
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -175.461319
Layer 0 weight grad [0][0] = -99.952934


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6691
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 103.250755
Layer 0 weight grad [0][0] = -37.125084


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6692
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 104.506294
Layer 0 weight grad [0][0] = -37.638462


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6693
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 105.846771
Layer 0 weight grad [0][0] = -36.393547


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6694
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 107.347176
Layer 0 weight grad [0][0] = -92.839958


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6695
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 109.439049
Layer 0 weight grad [0][0] = -188.476898


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6696
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 111.158806
Layer 0 weight grad [0][0] = -27.916656


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6697
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 111.685295
Layer 0 weight grad [0][0] = -28.108963


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6698
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -721.589966
Layer 0 weight grad [0][0] = -30.504951


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6699
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 110.543739
Layer 0 weight grad [0][0] = -32.528225


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6700
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 111.729256
Layer 0 weight grad [0][0] = -32.522522


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6701
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 112.941818
Layer 0 weight grad [0][0] = -35.953178


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6702
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 114.595718
Layer 0 weight grad [0][0] = -36.138527


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6703
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 115.180885
Layer 0 weight grad [0][0] = 259.424591


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 6704
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 116.363091
Layer 0 weight grad [0][0] = -36.801178


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6705
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 118.032234
Layer 0 weight grad [0][0] = -38.922947


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6706
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 118.545952
Layer 0 weight grad [0][0] = -37.608685


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6707
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 120.108978
Layer 0 weight grad [0][0] = -83.635406


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6708
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -742.631287
Layer 0 weight grad [0][0] = 279.421997


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6709
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -207.201889
Layer 0 weight grad [0][0] = -113.181564


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6710
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -752.713623
Layer 0 weight grad [0][0] = -39.938057


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6711
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 111.670807
Layer 0 weight grad [0][0] = -40.438053


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6712
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -147.351227
Layer 0 weight grad [0][0] = -40.129013


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6713
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 107.701866
Layer 0 weight grad [0][0] = -42.656204


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6714
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 108.864136
Layer 0 weight grad [0][0] = 297.940735


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6715
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 110.007416
Layer 0 weight grad [0][0] = 91.666176


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6716
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 108.172638
Layer 0 weight grad [0][0] = -40.323040


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6717
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -738.447205
Layer 0 weight grad [0][0] = -36.887470


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6718
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 107.480118
Layer 0 weight grad [0][0] = -64.169624


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 6719
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 108.884621
Layer 0 weight grad [0][0] = 44.532085


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6720
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 110.687546
Layer 0 weight grad [0][0] = -60.244972


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6721
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 112.444717
Layer 0 weight grad [0][0] = -58.411594


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6722
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 114.136482
Layer 0 weight grad [0][0] = -39.606468


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6723
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 115.418327
Layer 0 weight grad [0][0] = 152.655518


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6724
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 112.490906
Layer 0 weight grad [0][0] = -39.750019


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6725
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 113.739182
Layer 0 weight grad [0][0] = 127.993202


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6726
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -174.598999
Layer 0 weight grad [0][0] = 137.094742


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6727
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 111.298332
Layer 0 weight grad [0][0] = -38.275219


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6728
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -757.944946
Layer 0 weight grad [0][0] = -38.981659


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6729
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 110.837898
Layer 0 weight grad [0][0] = 107.897469


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 6730
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 112.163361
Layer 0 weight grad [0][0] = -39.253262


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6731
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 113.320053
Layer 0 weight grad [0][0] = -36.637421


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6732
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 114.377747
Layer 0 weight grad [0][0] = 161.095245


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6733
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 111.836151
Layer 0 weight grad [0][0] = -45.906540


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6734
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 113.052338
Layer 0 weight grad [0][0] = -36.632374


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6735
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 113.787956
Layer 0 weight grad [0][0] = -39.051304


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6736
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 114.484047
Layer 0 weight grad [0][0] = -42.418526


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6737
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 116.788773
Layer 0 weight grad [0][0] = 191.686310


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6738
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 112.922417
Layer 0 weight grad [0][0] = -39.868980


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6739
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 113.594978
Layer 0 weight grad [0][0] = 114.589539


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6740
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 114.974388
Layer 0 weight grad [0][0] = 170.389450


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6741
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 116.455963
Layer 0 weight grad [0][0] = -44.679188


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6742
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 117.190147
Layer 0 weight grad [0][0] = -42.993240


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6743
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 119.022820
Layer 0 weight grad [0][0] = 161.666504


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6744
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -227.975616
Layer 0 weight grad [0][0] = 130.337280


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6745
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 112.988396
Layer 0 weight grad [0][0] = 282.867615


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6746
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -704.717346
Layer 0 weight grad [0][0] = -44.812042


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6747
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -183.753967
Layer 0 weight grad [0][0] = 43.337532


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6748
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 108.543556
Layer 0 weight grad [0][0] = -39.884380


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6749
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 109.779312
Layer 0 weight grad [0][0] = -439.102844


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6750
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 110.295761
Layer 0 weight grad [0][0] = -39.972298


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6751
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 111.965210
Layer 0 weight grad [0][0] = 115.745361


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6752
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 109.430817
Layer 0 weight grad [0][0] = 189.841263


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6753
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 110.401459
Layer 0 weight grad [0][0] = -42.924068


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6754
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 111.580124
Layer 0 weight grad [0][0] = -109.347481


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6755
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 109.918579
Layer 0 weight grad [0][0] = -45.051003


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6756
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 110.998505
Layer 0 weight grad [0][0] = 1.715816


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6757
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 111.641479
Layer 0 weight grad [0][0] = 210.917786


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6758
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 112.263725
Layer 0 weight grad [0][0] = 48.429050


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 6759
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 111.169884
Layer 0 weight grad [0][0] = 258.455322


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6760
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 112.253494
Layer 0 weight grad [0][0] = 249.661194


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6761
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 113.301109
Layer 0 weight grad [0][0] = -54.900738


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6762
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 114.351295
Layer 0 weight grad [0][0] = -55.635563


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6763
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 115.959084
Layer 0 weight grad [0][0] = 460.135559


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6764
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 114.632858
Layer 0 weight grad [0][0] = -51.938213


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6765
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 115.253876
Layer 0 weight grad [0][0] = -47.621758


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6766
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 116.634941
Layer 0 weight grad [0][0] = -47.158848


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6767
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 117.267906
Layer 0 weight grad [0][0] = -74.064598


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6768
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -664.368896
Layer 0 weight grad [0][0] = 201.959320


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6769
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 115.868118
Layer 0 weight grad [0][0] = -50.771038


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6770
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 117.530197
Layer 0 weight grad [0][0] = 185.378967


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6771
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 118.121231
Layer 0 weight grad [0][0] = -55.434246


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6772
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 119.781891
Layer 0 weight grad [0][0] = -55.020004


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6773
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 120.927170
Layer 0 weight grad [0][0] = 66.487976


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6774
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 121.559731
Layer 0 weight grad [0][0] = 99.701317


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6775
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 119.849846
Layer 0 weight grad [0][0] = 9.663612


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6776
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 119.266914
Layer 0 weight grad [0][0] = -56.811440


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6777
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 120.226944
Layer 0 weight grad [0][0] = 149.017456


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6778
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 121.388878
Layer 0 weight grad [0][0] = -57.094654


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6779
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 121.999985
Layer 0 weight grad [0][0] = 51.573425


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6780
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 123.740753
Layer 0 weight grad [0][0] = 127.413986


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6781
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 120.429214
Layer 0 weight grad [0][0] = 50.087437


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6782
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -336.432190
Layer 0 weight grad [0][0] = -60.981293


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6783
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 120.416939
Layer 0 weight grad [0][0] = 96.876373


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6784
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 122.312180
Layer 0 weight grad [0][0] = -62.470245


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 6785
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 122.753769
Layer 0 weight grad [0][0] = 15.631476


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6786
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 121.775162
Layer 0 weight grad [0][0] = 311.160217


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6787
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -653.612610
Layer 0 weight grad [0][0] = -61.001823


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6788
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -662.755371
Layer 0 weight grad [0][0] = 55.761589


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6789
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 119.162880
Layer 0 weight grad [0][0] = -64.343430


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6790
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -676.126343
Layer 0 weight grad [0][0] = -1.034355


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6791
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 115.993889
Layer 0 weight grad [0][0] = -67.004257


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6792
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 117.302567
Layer 0 weight grad [0][0] = -66.349159


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6793
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 118.642586
Layer 0 weight grad [0][0] = 47.747601


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6794
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 119.913773
Layer 0 weight grad [0][0] = -74.109505


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6795
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 121.170662
Layer 0 weight grad [0][0] = 6.854339


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6796
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 122.372482
Layer 0 weight grad [0][0] = -72.445877


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6797
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -698.168579
Layer 0 weight grad [0][0] = -367.591583


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6798
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -258.377228
Layer 0 weight grad [0][0] = -75.905792


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6799
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 118.267944
Layer 0 weight grad [0][0] = -77.852272


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6800
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 119.591240
Layer 0 weight grad [0][0] = -296.257843


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 6801
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 120.916779
Layer 0 weight grad [0][0] = -83.650620


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6802
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 122.639557
Layer 0 weight grad [0][0] = -86.258057


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6803
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 123.366020
Layer 0 weight grad [0][0] = -86.423981


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6804
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 125.101974
Layer 0 weight grad [0][0] = 414.026794


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6805
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 125.824776
Layer 0 weight grad [0][0] = -88.897552


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6806
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 127.089409
Layer 0 weight grad [0][0] = 77.167175


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6807
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 124.109070
Layer 0 weight grad [0][0] = 37.532448


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6808
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 125.912781
Layer 0 weight grad [0][0] = 419.573730


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 6809
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 127.169670
Layer 0 weight grad [0][0] = -90.695290


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6810
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 128.655533
Layer 0 weight grad [0][0] = -92.648949


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6811
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 129.726715
Layer 0 weight grad [0][0] = -91.127548


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6812
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 131.001007
Layer 0 weight grad [0][0] = -88.296692


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6813
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 132.147064
Layer 0 weight grad [0][0] = -88.517578


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6814
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 134.061630
Layer 0 weight grad [0][0] = -89.096405


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6815
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 135.083054
Layer 0 weight grad [0][0] = 395.073730


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6816
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 135.784927
Layer 0 weight grad [0][0] = 85.725861


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6817
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -350.918152
Layer 0 weight grad [0][0] = -87.985168


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6818
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 131.588348
Layer 0 weight grad [0][0] = 461.976044


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6819
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 131.217911
Layer 0 weight grad [0][0] = -12.895468


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6820
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 130.823242
Layer 0 weight grad [0][0] = -86.046272


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6821
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 132.051422
Layer 0 weight grad [0][0] = 109.531731


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 6822
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 129.094528
Layer 0 weight grad [0][0] = -82.536522


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6823
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 130.414780
Layer 0 weight grad [0][0] = -84.433449


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6824
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 131.750046
Layer 0 weight grad [0][0] = 88.924019


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6825
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -378.136688
Layer 0 weight grad [0][0] = -87.716194


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6826
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 130.392609
Layer 0 weight grad [0][0] = 31.186447


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6827
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 132.839294
Layer 0 weight grad [0][0] = 383.096375


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6828
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 133.695679
Layer 0 weight grad [0][0] = 16.259705


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6829
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 134.953125
Layer 0 weight grad [0][0] = -85.526146


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6830
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 136.245071
Layer 0 weight grad [0][0] = 183.992065


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6831
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -718.574158
Layer 0 weight grad [0][0] = -86.226067


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6832
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 135.716171
Layer 0 weight grad [0][0] = -44.738464


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6833
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 135.566772
Layer 0 weight grad [0][0] = 46.732738


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6834
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 136.877060
Layer 0 weight grad [0][0] = -37.595543


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6835
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 137.155960
Layer 0 weight grad [0][0] = -85.939507


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6836
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 137.936523
Layer 0 weight grad [0][0] = 76.129181


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6837
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 140.311829
Layer 0 weight grad [0][0] = -85.163071


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6838
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 141.079224
Layer 0 weight grad [0][0] = -79.125916


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6839
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 142.341751
Layer 0 weight grad [0][0] = -80.049202


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6840
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 143.729980
Layer 0 weight grad [0][0] = -82.360939


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6841
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 145.514923
Layer 0 weight grad [0][0] = 61.510586


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6842
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -417.871765
Layer 0 weight grad [0][0] = 456.920929


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6843
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 143.848572
Layer 0 weight grad [0][0] = -79.777939


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6844
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -762.099548
Layer 0 weight grad [0][0] = -80.941208


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6845
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -370.497284
Layer 0 weight grad [0][0] = 359.593658


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6846
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 138.952148
Layer 0 weight grad [0][0] = -75.248161


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6847
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 140.196899
Layer 0 weight grad [0][0] = -65.286934


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6848
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 141.412216
Layer 0 weight grad [0][0] = 100.760292


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 6849
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 142.106873
Layer 0 weight grad [0][0] = 2.898483


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6850
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 144.390747
Layer 0 weight grad [0][0] = -73.040314


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6851
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 145.114395
Layer 0 weight grad [0][0] = -70.555809


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6852
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 145.905685
Layer 0 weight grad [0][0] = -71.266830


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6853
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 147.925522
Layer 0 weight grad [0][0] = -70.681046


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6854
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 149.071594
Layer 0 weight grad [0][0] = -72.131294


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6855
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 150.894608
Layer 0 weight grad [0][0] = 163.109802


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6856
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 146.532547
Layer 0 weight grad [0][0] = -75.334282


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6857
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -767.595215
Layer 0 weight grad [0][0] = 74.165329


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6858
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 145.400650
Layer 0 weight grad [0][0] = 78.087296


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6859
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 147.255112
Layer 0 weight grad [0][0] = -22.869211


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6860
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 147.304016
Layer 0 weight grad [0][0] = -70.318657


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6861
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 149.034317
Layer 0 weight grad [0][0] = 223.388306


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 6862
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 150.143524
Layer 0 weight grad [0][0] = -66.479958


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6863
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -416.744598
Layer 0 weight grad [0][0] = 223.860001


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6864
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 149.997360
Layer 0 weight grad [0][0] = -8.485314


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6865
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -809.679626
Layer 0 weight grad [0][0] = 236.381058


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6866
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 142.345581
Layer 0 weight grad [0][0] = -20.203114


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6867
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 142.811539
Layer 0 weight grad [0][0] = 88.036240


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6868
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 144.977890
Layer 0 weight grad [0][0] = 88.134750


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6869
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 145.724808
Layer 0 weight grad [0][0] = 198.971481


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6870
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -777.047241
Layer 0 weight grad [0][0] = -14.195486


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6871
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 144.145309
Layer 0 weight grad [0][0] = -14.677416


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6872
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 144.574478
Layer 0 weight grad [0][0] = -14.191519


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6873
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 144.447403
Layer 0 weight grad [0][0] = 204.215668


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 6874
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 146.585648
Layer 0 weight grad [0][0] = -62.076172


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6875
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 148.633301
Layer 0 weight grad [0][0] = -62.232021


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6876
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 149.211975
Layer 0 weight grad [0][0] = -64.891914


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6877
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 151.592743
Layer 0 weight grad [0][0] = -863.671570


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6878
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 153.015961
Layer 0 weight grad [0][0] = 59.890244


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6879
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 154.600998
Layer 0 weight grad [0][0] = -486.608246


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6880
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 156.302231
Layer 0 weight grad [0][0] = 260.551056


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6881
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 150.467926
Layer 0 weight grad [0][0] = 228.806351


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6882
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 151.363693
Layer 0 weight grad [0][0] = 349.359192


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6883
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 151.761093
Layer 0 weight grad [0][0] = -60.282143


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6884
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -772.405518
Layer 0 weight grad [0][0] = -63.417267


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6885
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 150.364761
Layer 0 weight grad [0][0] = 187.930145


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6886
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -781.519470
Layer 0 weight grad [0][0] = 13.235999


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 6887
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 148.582855
Layer 0 weight grad [0][0] = 92.425568


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6888
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 150.049881
Layer 0 weight grad [0][0] = -60.895714


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6889
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 152.087326
Layer 0 weight grad [0][0] = -83.863449


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6890
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 153.104126
Layer 0 weight grad [0][0] = -495.838776


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6891
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 154.610565
Layer 0 weight grad [0][0] = -93.051361


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6892
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 156.686569
Layer 0 weight grad [0][0] = 172.072464


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 6893
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 157.550980
Layer 0 weight grad [0][0] = -19.388031


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6894
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 158.354492
Layer 0 weight grad [0][0] = -36.405590


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6895
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 159.252792
Layer 0 weight grad [0][0] = -73.436279


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6896
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 160.677368
Layer 0 weight grad [0][0] = -72.015778


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6897
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -861.848694
Layer 0 weight grad [0][0] = -5.301712


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6898
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 160.770065
Layer 0 weight grad [0][0] = -134.837524


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 6899
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 162.280212
Layer 0 weight grad [0][0] = 88.920532


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6900
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 163.759155
Layer 0 weight grad [0][0] = -70.899773


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 6901
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 164.617477
Layer 0 weight grad [0][0] = -73.818352


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6902
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 166.520081
Layer 0 weight grad [0][0] = -74.143456


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6903
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 168.220093
Layer 0 weight grad [0][0] = -76.372177


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6904
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -436.846375
Layer 0 weight grad [0][0] = -89.307281


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6905
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 169.066498
Layer 0 weight grad [0][0] = -67.052681


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6906
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 170.473160
Layer 0 weight grad [0][0] = 315.646362


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6907
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 172.612137
Layer 0 weight grad [0][0] = -61.658360


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6908
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 173.769485
Layer 0 weight grad [0][0] = -8.491717


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6909
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 174.826736
Layer 0 weight grad [0][0] = 96.847588


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6910
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -447.110291
Layer 0 weight grad [0][0] = 113.412743


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6911
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 175.893555
Layer 0 weight grad [0][0] = -109.121498


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6912
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 177.579330
Layer 0 weight grad [0][0] = -55.816807


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6913
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 179.288300
Layer 0 weight grad [0][0] = 123.641701


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6914
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -994.029663
Layer 0 weight grad [0][0] = 228.076447


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6915
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -416.993408
Layer 0 weight grad [0][0] = -63.509674


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6916
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 170.261200
Layer 0 weight grad [0][0] = 116.102829


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6917
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -411.817871
Layer 0 weight grad [0][0] = 257.714142


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6918
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 164.647446
Layer 0 weight grad [0][0] = 122.420601


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6919
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -915.809265
Layer 0 weight grad [0][0] = 239.960312


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6920
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 160.516434
Layer 0 weight grad [0][0] = 117.329605


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6921
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 162.695709
Layer 0 weight grad [0][0] = 165.936142


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6922
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 162.865952
Layer 0 weight grad [0][0] = -60.457413


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6923
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 164.890167
Layer 0 weight grad [0][0] = -8.218390


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6924
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 164.865356
Layer 0 weight grad [0][0] = -62.865784


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6925
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 166.507294
Layer 0 weight grad [0][0] = -65.174644


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6926
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 168.223816
Layer 0 weight grad [0][0] = -12.416614


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6927
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 168.513168
Layer 0 weight grad [0][0] = 98.126518


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6928
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 170.473465
Layer 0 weight grad [0][0] = -73.880074


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6929
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 171.483749
Layer 0 weight grad [0][0] = 156.143097


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6930
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 167.738998
Layer 0 weight grad [0][0] = -77.801826


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 6931
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -438.906891
Layer 0 weight grad [0][0] = 174.564850


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6932
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 167.435211
Layer 0 weight grad [0][0] = -25.419001


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6933
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -435.547333
Layer 0 weight grad [0][0] = 94.578667


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6934
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 167.466125
Layer 0 weight grad [0][0] = -67.390816


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6935
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 168.569092
Layer 0 weight grad [0][0] = 114.778816


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6936
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 169.895996
Layer 0 weight grad [0][0] = 402.037994


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6937
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -872.680786
Layer 0 weight grad [0][0] = 20.134825


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6938
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 160.640518
Layer 0 weight grad [0][0] = 102.484901


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6939
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 162.015320
Layer 0 weight grad [0][0] = -3.285318


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6940
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 162.098053
Layer 0 weight grad [0][0] = -61.559135


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6941
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 164.148529
Layer 0 weight grad [0][0] = -62.868782


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6942
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 164.568115
Layer 0 weight grad [0][0] = -62.901176


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6943
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 166.279465
Layer 0 weight grad [0][0] = -66.899544


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6944
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -896.622009
Layer 0 weight grad [0][0] = 72.933968


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6945
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 164.110397
Layer 0 weight grad [0][0] = 12.324076


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6946
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 164.731827
Layer 0 weight grad [0][0] = 73.467064


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6947
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 166.496170
Layer 0 weight grad [0][0] = -78.099167


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6948
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 168.227570
Layer 0 weight grad [0][0] = 135.264862


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6949
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 168.752258
Layer 0 weight grad [0][0] = 341.774536


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6950
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 165.246307
Layer 0 weight grad [0][0] = -51.036545


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6951
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 166.863403
Layer 0 weight grad [0][0] = -75.979156


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6952
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 168.213867
Layer 0 weight grad [0][0] = 73.438278


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6953
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 169.195251
Layer 0 weight grad [0][0] = -79.188362


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6954
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 169.342484
Layer 0 weight grad [0][0] = -81.813759


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6955
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -917.930725
Layer 0 weight grad [0][0] = -80.687096


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6956
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 167.408203
Layer 0 weight grad [0][0] = 310.680298


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6957
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 168.288101
Layer 0 weight grad [0][0] = 83.459389


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6958
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 169.891769
Layer 0 weight grad [0][0] = 267.618042


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6959
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 170.980637
Layer 0 weight grad [0][0] = 82.381981


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6960
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 171.581421
Layer 0 weight grad [0][0] = 68.667717


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6961
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 173.453247
Layer 0 weight grad [0][0] = -87.465858


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6962
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 173.937378
Layer 0 weight grad [0][0] = -89.669785


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6963
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -442.115540
Layer 0 weight grad [0][0] = 261.599030


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6964
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 174.787231
Layer 0 weight grad [0][0] = -92.451584


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6965
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 175.022064
Layer 0 weight grad [0][0] = 75.276260


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6966
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -967.288330
Layer 0 weight grad [0][0] = 117.070793


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6967
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -978.879761
Layer 0 weight grad [0][0] = 54.969158


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6968
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 169.071762
Layer 0 weight grad [0][0] = 111.609818


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6969
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 170.525146
Layer 0 weight grad [0][0] = 61.461048


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6970
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 171.984406
Layer 0 weight grad [0][0] = -89.942596


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6971
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 173.457886
Layer 0 weight grad [0][0] = -91.418945


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6972
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -380.094391
Layer 0 weight grad [0][0] = -97.391159


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6973
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -374.648041
Layer 0 weight grad [0][0] = -24.814829


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6974
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 174.038361
Layer 0 weight grad [0][0] = 271.025177


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6975
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 167.421494
Layer 0 weight grad [0][0] = -69.009727


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6976
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 169.518829
Layer 0 weight grad [0][0] = -106.550858


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6977
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 171.113464
Layer 0 weight grad [0][0] = 254.549545


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6978
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 172.001129
Layer 0 weight grad [0][0] = -109.831894


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6979
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 173.402435
Layer 0 weight grad [0][0] = -10.791551


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6980
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 174.839050
Layer 0 weight grad [0][0] = 101.543602


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6981
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 171.895432
Layer 0 weight grad [0][0] = -115.920013


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6982
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -419.882477
Layer 0 weight grad [0][0] = 17.395578


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6983
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 170.140900
Layer 0 weight grad [0][0] = -118.736397


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6984
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 170.711212
Layer 0 weight grad [0][0] = 24.401741


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 6985
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 168.531204
Layer 0 weight grad [0][0] = -127.360214


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6986
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 170.216202
Layer 0 weight grad [0][0] = -121.356346


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 6987
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 171.368210
Layer 0 weight grad [0][0] = -51.769676


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6988
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 169.993286
Layer 0 weight grad [0][0] = -120.140114


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6989
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 171.770020
Layer 0 weight grad [0][0] = -49.065624


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6990
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -911.291199
Layer 0 weight grad [0][0] = 50.316269


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 6991
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 167.189209
Layer 0 weight grad [0][0] = 498.310974


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6992
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 168.973831
Layer 0 weight grad [0][0] = -153.206940


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6993
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 169.145401
Layer 0 weight grad [0][0] = 143.550003


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6994
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 170.418442
Layer 0 weight grad [0][0] = -123.232803


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6995
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 172.244431
Layer 0 weight grad [0][0] = -116.095139


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6996
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 172.937820
Layer 0 weight grad [0][0] = -113.634872


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6997
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 174.819321
Layer 0 weight grad [0][0] = -113.470001


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 6998
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 176.224960
Layer 0 weight grad [0][0] = -28.469242


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 6999
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 174.362640
Layer 0 weight grad [0][0] = 87.340767


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7000
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 176.585129
Layer 0 weight grad [0][0] = 77.447617


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7001
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 177.195847
Layer 0 weight grad [0][0] = -117.388634


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7002
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 178.339935
Layer 0 weight grad [0][0] = 102.224022


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7003
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 178.862442
Layer 0 weight grad [0][0] = 91.423027


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7004
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 180.567688
Layer 0 weight grad [0][0] = 80.539291


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7005
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -491.539764
Layer 0 weight grad [0][0] = -120.692596


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7006
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 177.879868
Layer 0 weight grad [0][0] = 81.522682


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7007
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -497.103943
Layer 0 weight grad [0][0] = 178.538589


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7008
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 175.013412
Layer 0 weight grad [0][0] = -118.619606


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7009
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 176.316925
Layer 0 weight grad [0][0] = -124.382446


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7010
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -915.473328
Layer 0 weight grad [0][0] = -46.635574


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7011
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 173.290161
Layer 0 weight grad [0][0] = 542.526733


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7012
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -465.423615
Layer 0 weight grad [0][0] = 25.876116


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7013
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -929.334961
Layer 0 weight grad [0][0] = -129.980179


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7014
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 169.109772
Layer 0 weight grad [0][0] = -72.754150


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7015
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 168.897415
Layer 0 weight grad [0][0] = -129.840637


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7016
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 170.138519
Layer 0 weight grad [0][0] = -134.579620


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7017
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 170.976227
Layer 0 weight grad [0][0] = 493.919769


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7018
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 172.224548
Layer 0 weight grad [0][0] = -126.962456


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7019
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 172.831207
Layer 0 weight grad [0][0] = -126.355064


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7020
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 173.197372
Layer 0 weight grad [0][0] = 477.736267


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7021
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 174.603058
Layer 0 weight grad [0][0] = -129.334229


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7022
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 175.523529
Layer 0 weight grad [0][0] = 113.928200


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7023
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 175.332489
Layer 0 weight grad [0][0] = 60.345222


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7024
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -471.058380
Layer 0 weight grad [0][0] = 397.792603


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7025
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 175.821030
Layer 0 weight grad [0][0] = -138.949463


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7026
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 177.455887
Layer 0 weight grad [0][0] = 525.541931


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7027
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 178.507248
Layer 0 weight grad [0][0] = -41.791107


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7028
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 177.124191
Layer 0 weight grad [0][0] = 58.330139


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7029
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 179.014023
Layer 0 weight grad [0][0] = -39.494297


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7030
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -942.279297
Layer 0 weight grad [0][0] = -42.795288


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7031
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 174.457855
Layer 0 weight grad [0][0] = 29.442129


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7032
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -462.769531
Layer 0 weight grad [0][0] = -127.283447


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7033
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 176.406754
Layer 0 weight grad [0][0] = 278.047272


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7034
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 176.247925
Layer 0 weight grad [0][0] = 41.985146


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 7035
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 178.691589
Layer 0 weight grad [0][0] = -132.142303


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7036
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 179.130814
Layer 0 weight grad [0][0] = -43.330452


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 7037
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -963.688416
Layer 0 weight grad [0][0] = -128.845398


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7038
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -439.063934
Layer 0 weight grad [0][0] = 291.884247


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7039
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -980.827454
Layer 0 weight grad [0][0] = 25.206020


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7040
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 171.372726
Layer 0 weight grad [0][0] = 90.741264


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7041
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 173.980484
Layer 0 weight grad [0][0] = -126.624245


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7042
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 174.634674
Layer 0 weight grad [0][0] = 183.865845


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7043
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -935.947510
Layer 0 weight grad [0][0] = -127.097610


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7044
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 165.655975
Layer 0 weight grad [0][0] = -128.311996


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7045
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 167.211990
Layer 0 weight grad [0][0] = -126.918503


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7046
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 168.946396
Layer 0 weight grad [0][0] = 382.285645


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7047
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 162.872375
Layer 0 weight grad [0][0] = -126.887115


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7048
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 163.803268
Layer 0 weight grad [0][0] = -130.346436


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7049
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 165.511124
Layer 0 weight grad [0][0] = 177.111710


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7050
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 166.233932
Layer 0 weight grad [0][0] = -142.724380


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7051
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 167.725388
Layer 0 weight grad [0][0] = -143.281876


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 7052
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 169.323715
Layer 0 weight grad [0][0] = 30.055840


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7053
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 168.222763
Layer 0 weight grad [0][0] = -144.775574


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7054
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 169.510941
Layer 0 weight grad [0][0] = 250.571777


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7055
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -426.152039
Layer 0 weight grad [0][0] = -141.262024


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7056
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 172.033173
Layer 0 weight grad [0][0] = -136.364426


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7057
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 173.125931
Layer 0 weight grad [0][0] = -137.316101


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7058
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 174.113815
Layer 0 weight grad [0][0] = -138.748611


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7059
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -963.297546
Layer 0 weight grad [0][0] = -55.160408


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7060
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 170.073990
Layer 0 weight grad [0][0] = 22.890650


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7061
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 171.063110
Layer 0 weight grad [0][0] = -142.957077


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7062
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -965.271790
Layer 0 weight grad [0][0] = -147.894867


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7063
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 169.394470
Layer 0 weight grad [0][0] = -137.173416


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7064
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 169.921188
Layer 0 weight grad [0][0] = -1108.784058


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7065
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 170.772781
Layer 0 weight grad [0][0] = -135.630524


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 7066
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 170.796097
Layer 0 weight grad [0][0] = 634.232788


Training loss: 2.302585
Training accuracy: 0.375000

epoch: 7067
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 171.986938
Layer 0 weight grad [0][0] = -50.806431


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7068
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 170.697739
Layer 0 weight grad [0][0] = 621.179932


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 7069
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 171.345505
Layer 0 weight grad [0][0] = -129.658066


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7070
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -973.989319
Layer 0 weight grad [0][0] = 42.580151


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7071
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 168.541458
Layer 0 weight grad [0][0] = 719.830627


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7072
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 168.762543
Layer 0 weight grad [0][0] = 473.574341


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7073
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 168.555405
Layer 0 weight grad [0][0] = 461.004486


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7074
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 168.934845
Layer 0 weight grad [0][0] = -127.152611


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7075
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 169.382584
Layer 0 weight grad [0][0] = 766.283325


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7076
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 168.476715
Layer 0 weight grad [0][0] = 385.802612


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7077
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 168.588150
Layer 0 weight grad [0][0] = 662.120911


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7078
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 169.124832
Layer 0 weight grad [0][0] = -124.566917


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7079
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 169.359894
Layer 0 weight grad [0][0] = -40.682751


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7080
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 168.023911
Layer 0 weight grad [0][0] = 379.268188


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7081
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -943.423767
Layer 0 weight grad [0][0] = -30.486229


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7082
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 164.928711
Layer 0 weight grad [0][0] = -271.435455


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7083
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -950.429138
Layer 0 weight grad [0][0] = -131.664124


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7084
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 161.841797
Layer 0 weight grad [0][0] = 366.876923


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7085
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 161.955444
Layer 0 weight grad [0][0] = 225.286362


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7086
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 163.246704
Layer 0 weight grad [0][0] = -126.889694


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 7087
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 164.466919
Layer 0 weight grad [0][0] = -53.015392


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7088
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 163.416885
Layer 0 weight grad [0][0] = -49.723038


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7089
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -937.830811
Layer 0 weight grad [0][0] = -57.152576


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7090
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 158.587494
Layer 0 weight grad [0][0] = -33.977230


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7091
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 159.449509
Layer 0 weight grad [0][0] = 4.935563


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7092
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 157.553528
Layer 0 weight grad [0][0] = 317.876068


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7093
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -335.680908
Layer 0 weight grad [0][0] = 175.686432


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7094
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 159.327255
Layer 0 weight grad [0][0] = -161.486984


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7095
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 160.342850
Layer 0 weight grad [0][0] = -156.155685


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7096
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 161.349121
Layer 0 weight grad [0][0] = -160.124680


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7097
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 162.694901
Layer 0 weight grad [0][0] = -157.456833


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7098
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 164.136978
Layer 0 weight grad [0][0] = -150.483093


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7099
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 164.766510
Layer 0 weight grad [0][0] = 10.162759


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7100
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -358.167572
Layer 0 weight grad [0][0] = -140.083084


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7101
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 168.083450
Layer 0 weight grad [0][0] = -142.449539


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7102
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 169.399460
Layer 0 weight grad [0][0] = -130.946487


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7103
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 170.280899
Layer 0 weight grad [0][0] = 106.316734


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7104
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 171.399094
Layer 0 weight grad [0][0] = 69.679649


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7105
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -376.604004
Layer 0 weight grad [0][0] = -159.646439


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7106
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 174.264145
Layer 0 weight grad [0][0] = 83.791115


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7107
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 175.930344
Layer 0 weight grad [0][0] = -34.061050


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 7108
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 176.257645
Layer 0 weight grad [0][0] = 221.582626


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7109
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -394.108826
Layer 0 weight grad [0][0] = -158.472229


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7110
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 178.289810
Layer 0 weight grad [0][0] = 19.148115


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7111
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1030.871582
Layer 0 weight grad [0][0] = 16.154478


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7112
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 175.848892
Layer 0 weight grad [0][0] = 13.174146


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7113
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 176.882126
Layer 0 weight grad [0][0] = -71.765381


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7114
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -373.165771
Layer 0 weight grad [0][0] = 184.958679


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7115
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 179.049316
Layer 0 weight grad [0][0] = -155.953720


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 7116
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1061.846436
Layer 0 weight grad [0][0] = -170.238892


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7117
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1072.731934
Layer 0 weight grad [0][0] = 917.174500


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7118
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 174.720428
Layer 0 weight grad [0][0] = -16.781462


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7119
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 175.598724
Layer 0 weight grad [0][0] = -152.743271


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7120
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1091.632080
Layer 0 weight grad [0][0] = -148.143387


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7121
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 173.201828
Layer 0 weight grad [0][0] = -126.784088


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7122
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1095.581299
Layer 0 weight grad [0][0] = -153.230240


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7123
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 170.565933
Layer 0 weight grad [0][0] = -153.977234


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7124
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 170.791321
Layer 0 weight grad [0][0] = -156.744827


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 7125
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 171.483383
Layer 0 weight grad [0][0] = -91.759827


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7126
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 170.591385
Layer 0 weight grad [0][0] = -173.856735


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7127
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 171.438095
Layer 0 weight grad [0][0] = -167.046997


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 7128
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1105.653442
Layer 0 weight grad [0][0] = -125.473824


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7129
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 169.790771
Layer 0 weight grad [0][0] = -5.071962


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7130
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1089.263916
Layer 0 weight grad [0][0] = -4.296987


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7131
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 160.383530
Layer 0 weight grad [0][0] = -76.767677


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7132
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 160.877670
Layer 0 weight grad [0][0] = 60.609936


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7133
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 162.206451
Layer 0 weight grad [0][0] = -159.979538


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7134
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 163.030899
Layer 0 weight grad [0][0] = -69.659920


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7135
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 162.656540
Layer 0 weight grad [0][0] = -165.315979


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7136
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 163.708359
Layer 0 weight grad [0][0] = -181.564758


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7137
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 164.447205
Layer 0 weight grad [0][0] = -394.985687


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7138
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 165.433136
Layer 0 weight grad [0][0] = -184.327698


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7139
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 166.424255
Layer 0 weight grad [0][0] = -179.448929


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7140
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 167.546921
Layer 0 weight grad [0][0] = -169.090546


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7141
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 168.239548
Layer 0 weight grad [0][0] = -164.575607


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7142
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 169.559662
Layer 0 weight grad [0][0] = 910.639893


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7143
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 170.324799
Layer 0 weight grad [0][0] = -250.708038


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7144
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 172.455719
Layer 0 weight grad [0][0] = -155.038971


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7145
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 173.014709
Layer 0 weight grad [0][0] = -158.509750


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7146
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 173.630753
Layer 0 weight grad [0][0] = -161.763138


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7147
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 174.227905
Layer 0 weight grad [0][0] = -157.106125


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7148
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 174.625000
Layer 0 weight grad [0][0] = -151.579742


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7149
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -266.816864
Layer 0 weight grad [0][0] = 24.307240


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7150
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 175.366348
Layer 0 weight grad [0][0] = -133.376999


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7151
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 176.018234
Layer 0 weight grad [0][0] = -134.837906


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7152
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 175.603516
Layer 0 weight grad [0][0] = -133.834656


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7153
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1117.138916
Layer 0 weight grad [0][0] = -130.556992


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7154
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1117.935913
Layer 0 weight grad [0][0] = -132.042862


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7155
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -214.873123
Layer 0 weight grad [0][0] = 113.164177


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7156
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 167.236023
Layer 0 weight grad [0][0] = -57.353699


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7157
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1097.790771
Layer 0 weight grad [0][0] = -103.430313


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7158
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 160.988861
Layer 0 weight grad [0][0] = -154.401764


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7159
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 161.558823
Layer 0 weight grad [0][0] = 1008.598267


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 7160
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 161.718597
Layer 0 weight grad [0][0] = -150.681900


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7161
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -201.887711
Layer 0 weight grad [0][0] = -147.538696


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7162
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 161.796616
Layer 0 weight grad [0][0] = -141.456085


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7163
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1089.975952
Layer 0 weight grad [0][0] = 1034.739380


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7164
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 157.786102
Layer 0 weight grad [0][0] = -368.601044


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7165
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 162.690918
Layer 0 weight grad [0][0] = -326.281799


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7166
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 167.341614
Layer 0 weight grad [0][0] = -332.633759


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7167
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 171.673706
Layer 0 weight grad [0][0] = 95.169373


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7168
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1196.877686
Layer 0 weight grad [0][0] = -146.641113


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7169
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 167.355194
Layer 0 weight grad [0][0] = -124.550407


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7170
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -143.632156
Layer 0 weight grad [0][0] = 999.134155


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7171
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 167.601303
Layer 0 weight grad [0][0] = 994.690796


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7172
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -150.953949
Layer 0 weight grad [0][0] = -142.196594


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7173
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 167.424988
Layer 0 weight grad [0][0] = -140.699127


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7174
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 167.953262
Layer 0 weight grad [0][0] = -153.939240


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7175
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -160.943573
Layer 0 weight grad [0][0] = -155.727295


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7176
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 168.036942
Layer 0 weight grad [0][0] = -156.181091


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7177
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 167.973465
Layer 0 weight grad [0][0] = 80.896828


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7178
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 168.642715
Layer 0 weight grad [0][0] = 96.365707


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7179
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1178.974976
Layer 0 weight grad [0][0] = -168.015533


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7180
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 164.677597
Layer 0 weight grad [0][0] = -674.242126


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 7181
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 165.726974
Layer 0 weight grad [0][0] = 975.452820


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 7182
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1182.491089
Layer 0 weight grad [0][0] = -160.704895


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7183
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 161.792725
Layer 0 weight grad [0][0] = -158.106445


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7184
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 162.887756
Layer 0 weight grad [0][0] = -161.232193


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7185
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -118.146393
Layer 0 weight grad [0][0] = 992.852600


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7186
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 161.913605
Layer 0 weight grad [0][0] = -176.133286


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7187
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 163.170166
Layer 0 weight grad [0][0] = 263.399719


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7188
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 163.910797
Layer 0 weight grad [0][0] = -171.535950


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7189
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 164.563278
Layer 0 weight grad [0][0] = -165.093018


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7190
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 165.031204
Layer 0 weight grad [0][0] = -155.957550


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7191
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1177.889160
Layer 0 weight grad [0][0] = -149.518600


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7192
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 160.158524
Layer 0 weight grad [0][0] = 690.726685


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7193
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 159.562134
Layer 0 weight grad [0][0] = -468.523132


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7194
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 166.651093
Layer 0 weight grad [0][0] = 526.159485


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7195
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 166.128418
Layer 0 weight grad [0][0] = -579.669006


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7196
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 175.240585
Layer 0 weight grad [0][0] = 1016.441345


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7197
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1284.093628
Layer 0 weight grad [0][0] = 50.979870


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7198
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -80.152168
Layer 0 weight grad [0][0] = 6.675541


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7199
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 167.899689
Layer 0 weight grad [0][0] = -153.539902


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 7200
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 168.276260
Layer 0 weight grad [0][0] = -71.378281


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7201
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 168.150192
Layer 0 weight grad [0][0] = -160.703781


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7202
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 168.146194
Layer 0 weight grad [0][0] = 44.766994


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7203
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -101.103363
Layer 0 weight grad [0][0] = -158.544739


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7204
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 167.723312
Layer 0 weight grad [0][0] = -154.751160


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7205
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 167.108475
Layer 0 weight grad [0][0] = -575.125671


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7206
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 175.791306
Layer 0 weight grad [0][0] = -144.265518


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7207
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 175.343887
Layer 0 weight grad [0][0] = 891.551880


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7208
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 173.642960
Layer 0 weight grad [0][0] = 840.287903


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7209
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 172.963303
Layer 0 weight grad [0][0] = -634.055054


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7210
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 183.348114
Layer 0 weight grad [0][0] = 1048.741333


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7211
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 182.325317
Layer 0 weight grad [0][0] = 841.046509


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7212
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 181.715744
Layer 0 weight grad [0][0] = -178.239716


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7213
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 181.191742
Layer 0 weight grad [0][0] = -126.461067


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7214
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 180.717651
Layer 0 weight grad [0][0] = -557.027832


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7215
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 189.616638
Layer 0 weight grad [0][0] = 10.888010


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7216
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -129.055939
Layer 0 weight grad [0][0] = -409.395782


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7217
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 196.858154
Layer 0 weight grad [0][0] = -125.705849


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7218
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 196.432755
Layer 0 weight grad [0][0] = -115.663513


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7219
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 196.012573
Layer 0 weight grad [0][0] = -117.985535


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7220
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 195.906372
Layer 0 weight grad [0][0] = -119.058022


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 7221
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 195.346771
Layer 0 weight grad [0][0] = 964.042297


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7222
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -141.148590
Layer 0 weight grad [0][0] = -124.264572


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7223
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1413.564575
Layer 0 weight grad [0][0] = 543.271057


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7224
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 190.064545
Layer 0 weight grad [0][0] = -131.725464


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7225
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 189.792542
Layer 0 weight grad [0][0] = 669.391785


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7226
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000029 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -113.134903
Layer 0 weight grad [0][0] = -138.704498


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7227
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 196.299698
Layer 0 weight grad [0][0] = 59.962643


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7228
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 195.374512
Layer 0 weight grad [0][0] = -138.496582


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7229
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1435.521606
Layer 0 weight grad [0][0] = -139.014999


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7230
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -97.281258
Layer 0 weight grad [0][0] = -130.220566


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7231
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 190.422272
Layer 0 weight grad [0][0] = -130.060242


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 7232
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 190.077316
Layer 0 weight grad [0][0] = -128.500519


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7233
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 190.007950
Layer 0 weight grad [0][0] = -145.010895


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7234
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 189.520508
Layer 0 weight grad [0][0] = -120.749001


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7235
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 188.564972
Layer 0 weight grad [0][0] = -135.600113


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7236
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 188.189835
Layer 0 weight grad [0][0] = 12.307735


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7237
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 188.038483
Layer 0 weight grad [0][0] = -151.808014


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7238
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -131.306030
Layer 0 weight grad [0][0] = 769.330200


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7239
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 195.168488
Layer 0 weight grad [0][0] = 1119.856201


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7240
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -129.586792
Layer 0 weight grad [0][0] = -116.178391


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7241
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 192.938202
Layer 0 weight grad [0][0] = -145.656845


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7242
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 193.273132
Layer 0 weight grad [0][0] = -465.806763


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7243
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 200.503830
Layer 0 weight grad [0][0] = -145.982971


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7244
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 200.278076
Layer 0 weight grad [0][0] = -162.411636


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7245
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 199.555191
Layer 0 weight grad [0][0] = 509.131256


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7246
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 199.200806
Layer 0 weight grad [0][0] = -161.634216


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7247
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 199.483841
Layer 0 weight grad [0][0] = -7.600170


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7248
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 198.235489
Layer 0 weight grad [0][0] = -185.034805


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7249
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 198.626465
Layer 0 weight grad [0][0] = 478.943634


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7250
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 198.490662
Layer 0 weight grad [0][0] = -189.199417


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7251
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 198.341080
Layer 0 weight grad [0][0] = -197.192978


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7252
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 197.731979
Layer 0 weight grad [0][0] = -196.215714


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7253
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 198.213531
Layer 0 weight grad [0][0] = -776.260803


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7254
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 198.326401
Layer 0 weight grad [0][0] = -196.920868


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7255
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 197.804626
Layer 0 weight grad [0][0] = 1481.462036


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7256
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 198.377945
Layer 0 weight grad [0][0] = -190.427841


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7257
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 197.942078
Layer 0 weight grad [0][0] = -198.420776


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7258
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 198.044708
Layer 0 weight grad [0][0] = -185.033432


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7259
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 198.664764
Layer 0 weight grad [0][0] = 491.380310


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7260
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 198.040955
Layer 0 weight grad [0][0] = 393.959229


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7261
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 197.993958
Layer 0 weight grad [0][0] = -164.366745


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7262
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 197.986008
Layer 0 weight grad [0][0] = -181.102005


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7263
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -215.666092
Layer 0 weight grad [0][0] = -158.895340


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7264
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -212.636475
Layer 0 weight grad [0][0] = 79.457977


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7265
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -208.572174
Layer 0 weight grad [0][0] = 59.783066


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7266
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 195.747696
Layer 0 weight grad [0][0] = -151.815018


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7267
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 195.890854
Layer 0 weight grad [0][0] = -398.905731


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7268
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 198.522858
Layer 0 weight grad [0][0] = 1136.939941


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7269
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 198.737411
Layer 0 weight grad [0][0] = -237.686218


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7270
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 200.868423
Layer 0 weight grad [0][0] = -148.778549


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7271
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 201.764923
Layer 0 weight grad [0][0] = 170.212784


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7272
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 201.347412
Layer 0 weight grad [0][0] = -147.930206


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7273
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -228.706985
Layer 0 weight grad [0][0] = -147.336426


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7274
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 201.644989
Layer 0 weight grad [0][0] = 1194.760132


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7275
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 201.466476
Layer 0 weight grad [0][0] = -107.261421


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7276
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 201.616730
Layer 0 weight grad [0][0] = -124.926231


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7277
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -236.345444
Layer 0 weight grad [0][0] = 66.038689


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7278
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -234.180862
Layer 0 weight grad [0][0] = -136.843613


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7279
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 202.190521
Layer 0 weight grad [0][0] = -113.827080


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7280
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 201.739349
Layer 0 weight grad [0][0] = 1267.325439


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7281
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -239.709351
Layer 0 weight grad [0][0] = -27.380629


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7282
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 201.952164
Layer 0 weight grad [0][0] = 65.460342


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 7283
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 202.819870
Layer 0 weight grad [0][0] = -1510.081909


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7284
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 203.153656
Layer 0 weight grad [0][0] = 1297.017090


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7285
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 203.481430
Layer 0 weight grad [0][0] = -125.491875


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7286
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -251.507401
Layer 0 weight grad [0][0] = -126.744217


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7287
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 203.916214
Layer 0 weight grad [0][0] = 54.970097


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7288
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 203.356064
Layer 0 weight grad [0][0] = 1336.329712


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7289
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 203.828491
Layer 0 weight grad [0][0] = -141.210785


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7290
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 203.333572
Layer 0 weight grad [0][0] = 498.861908


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7291
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 203.516602
Layer 0 weight grad [0][0] = -130.901627


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7292
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 203.849930
Layer 0 weight grad [0][0] = -130.343735


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7293
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 202.418976
Layer 0 weight grad [0][0] = -66.499969


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7294
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1342.702393
Layer 0 weight grad [0][0] = -136.416168


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7295
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 198.853577
Layer 0 weight grad [0][0] = -136.156387


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7296
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -256.256805
Layer 0 weight grad [0][0] = -129.700775


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7297
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 197.723724
Layer 0 weight grad [0][0] = -161.595963


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7298
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 197.646713
Layer 0 weight grad [0][0] = -131.573685


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7299
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 197.797501
Layer 0 weight grad [0][0] = -395.968964


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7300
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1361.028076
Layer 0 weight grad [0][0] = 1267.443115


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7301
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 198.777893
Layer 0 weight grad [0][0] = 323.888153


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7302
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 199.200577
Layer 0 weight grad [0][0] = -134.945572


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7303
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 198.596741
Layer 0 weight grad [0][0] = 334.534424


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7304
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 197.978348
Layer 0 weight grad [0][0] = 303.741852


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7305
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 197.971420
Layer 0 weight grad [0][0] = -150.888550


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7306
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 198.450668
Layer 0 weight grad [0][0] = -135.869186


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7307
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1324.911865
Layer 0 weight grad [0][0] = -177.419388


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7308
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 194.944931
Layer 0 weight grad [0][0] = -142.963455


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7309
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 194.955978
Layer 0 weight grad [0][0] = -132.660294


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7310
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 195.489365
Layer 0 weight grad [0][0] = -274.834229


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7311
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1347.656738
Layer 0 weight grad [0][0] = -120.201614


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7312
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 194.907654
Layer 0 weight grad [0][0] = -111.466164


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7313
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 194.918640
Layer 0 weight grad [0][0] = -102.862663


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7314
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 195.069519
Layer 0 weight grad [0][0] = 139.906937


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7315
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -226.766586
Layer 0 weight grad [0][0] = -104.774605


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7316
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1331.018799
Layer 0 weight grad [0][0] = -218.851608


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7317
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 190.924881
Layer 0 weight grad [0][0] = -85.692795


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7318
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 190.423370
Layer 0 weight grad [0][0] = 48.899029


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7319
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 190.453812
Layer 0 weight grad [0][0] = 99.743568


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7320
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 190.553177
Layer 0 weight grad [0][0] = -90.086197


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7321
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 190.639542
Layer 0 weight grad [0][0] = -80.250465


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7322
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 190.810059
Layer 0 weight grad [0][0] = 1105.160278


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7323
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 190.571579
Layer 0 weight grad [0][0] = -185.688278


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7324
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 190.491913
Layer 0 weight grad [0][0] = -78.929756


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 7325
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 190.612381
Layer 0 weight grad [0][0] = -78.197937


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7326
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 190.056122
Layer 0 weight grad [0][0] = 134.914658


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7327
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -238.919357
Layer 0 weight grad [0][0] = -77.847176


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7328
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 188.108978
Layer 0 weight grad [0][0] = -92.878075


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7329
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 187.830231
Layer 0 weight grad [0][0] = -89.893616


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7330
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 187.426666
Layer 0 weight grad [0][0] = -76.941193


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7331
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -247.197388
Layer 0 weight grad [0][0] = -55.023659


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7332
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 184.939758
Layer 0 weight grad [0][0] = -205.358063


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7333
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -238.859573
Layer 0 weight grad [0][0] = -58.472210


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7334
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -229.206894
Layer 0 weight grad [0][0] = 124.032776


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7335
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 183.144562
Layer 0 weight grad [0][0] = -62.043747


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7336
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 182.560577
Layer 0 weight grad [0][0] = -64.360001


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7337
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 181.985382
Layer 0 weight grad [0][0] = -53.300671


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7338
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 181.617981
Layer 0 weight grad [0][0] = -63.260017


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7339
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 180.893921
Layer 0 weight grad [0][0] = -156.100113


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7340
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1250.188843
Layer 0 weight grad [0][0] = -59.400127


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7341
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 183.153244
Layer 0 weight grad [0][0] = -193.154358


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7342
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 188.122696
Layer 0 weight grad [0][0] = 24.246582


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7343
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 187.189255
Layer 0 weight grad [0][0] = 992.345032


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7344
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 186.246292
Layer 0 weight grad [0][0] = -44.805756


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7345
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -232.764282
Layer 0 weight grad [0][0] = -182.090454


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7346
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 184.279770
Layer 0 weight grad [0][0] = -100.700211


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7347
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 184.442474
Layer 0 weight grad [0][0] = -320.902252


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7348
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 189.445267
Layer 0 weight grad [0][0] = 943.772949


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7349
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -228.853806
Layer 0 weight grad [0][0] = 40.945797


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7350
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 186.701797
Layer 0 weight grad [0][0] = -48.730885


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7351
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1268.000366
Layer 0 weight grad [0][0] = -51.626335


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7352
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -206.627930
Layer 0 weight grad [0][0] = -30.496479


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7353
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 181.395645
Layer 0 weight grad [0][0] = -52.842087


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7354
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 180.464554
Layer 0 weight grad [0][0] = -1263.984497


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7355
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 180.671402
Layer 0 weight grad [0][0] = -419.057617


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 7356
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 184.576035
Layer 0 weight grad [0][0] = -73.816612


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7357
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 183.768692
Layer 0 weight grad [0][0] = 11.612220


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7358
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 184.585800
Layer 0 weight grad [0][0] = -49.228886


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7359
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 183.864746
Layer 0 weight grad [0][0] = -49.433750


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7360
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 183.699081
Layer 0 weight grad [0][0] = -49.627758


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7361
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 183.591187
Layer 0 weight grad [0][0] = 958.852478


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7362
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 185.609161
Layer 0 weight grad [0][0] = -51.735107


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7363
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -232.146637
Layer 0 weight grad [0][0] = -66.829803


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7364
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 183.436447
Layer 0 weight grad [0][0] = -52.930260


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7365
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 183.111679
Layer 0 weight grad [0][0] = 1181.592285


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7366
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 182.604050
Layer 0 weight grad [0][0] = -55.560429


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 7367
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 181.646927
Layer 0 weight grad [0][0] = 1085.446777


Training loss: 2.302585
Training accuracy: 0.375000

epoch: 7368
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 181.803619
Layer 0 weight grad [0][0] = -138.506699


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7369
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 183.692642
Layer 0 weight grad [0][0] = 44.055847


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7370
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 184.568085
Layer 0 weight grad [0][0] = -60.036003


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7371
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 184.246323
Layer 0 weight grad [0][0] = -73.729187


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7372
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 184.578735
Layer 0 weight grad [0][0] = 1105.864746


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7373
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 183.839890
Layer 0 weight grad [0][0] = -72.201416


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7374
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 183.653198
Layer 0 weight grad [0][0] = -12.363947


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7375
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 186.184570
Layer 0 weight grad [0][0] = -238.354050


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7376
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 189.806107
Layer 0 weight grad [0][0] = 54.513653


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7377
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 189.709869
Layer 0 weight grad [0][0] = -58.892319


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7378
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 189.852417
Layer 0 weight grad [0][0] = -71.365059


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7379
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 189.572983
Layer 0 weight grad [0][0] = -55.146820


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7380
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 189.582443
Layer 0 weight grad [0][0] = -76.894066


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7381
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 189.579315
Layer 0 weight grad [0][0] = 740.109558


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7382
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 194.142395
Layer 0 weight grad [0][0] = -75.161728


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7383
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 194.368256
Layer 0 weight grad [0][0] = -266.658325


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7384
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 197.996964
Layer 0 weight grad [0][0] = 907.334351


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7385
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 198.355438
Layer 0 weight grad [0][0] = 133.212906


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7386
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 197.899902
Layer 0 weight grad [0][0] = -66.536171


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7387
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 197.579834
Layer 0 weight grad [0][0] = -92.079773


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7388
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 197.454239
Layer 0 weight grad [0][0] = -233.488113


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7389
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 200.011948
Layer 0 weight grad [0][0] = -71.667015


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7390
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 200.538910
Layer 0 weight grad [0][0] = -73.100708


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7391
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 200.462677
Layer 0 weight grad [0][0] = -62.970074


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 7392
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 200.464722
Layer 0 weight grad [0][0] = -171.616135


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7393
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1291.316895
Layer 0 weight grad [0][0] = 1018.281250


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7394
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 200.489349
Layer 0 weight grad [0][0] = -66.042969


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7395
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 200.071854
Layer 0 weight grad [0][0] = -141.901840


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7396
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 202.317627
Layer 0 weight grad [0][0] = -55.669575


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7397
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 201.874893
Layer 0 weight grad [0][0] = -43.943352


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7398
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 202.421997
Layer 0 weight grad [0][0] = -130.776611


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7399
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 202.156158
Layer 0 weight grad [0][0] = 753.044495


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 7400
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 201.996353
Layer 0 weight grad [0][0] = -20.440998


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 7401
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1274.642822
Layer 0 weight grad [0][0] = -18.289934


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7402
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 199.011551
Layer 0 weight grad [0][0] = 6.676065


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7403
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -325.547455
Layer 0 weight grad [0][0] = -227.207306


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7404
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 201.116074
Layer 0 weight grad [0][0] = 45.688702


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7405
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 202.048477
Layer 0 weight grad [0][0] = -330.457550


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7406
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 201.662415
Layer 0 weight grad [0][0] = -22.878572


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7407
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 202.526199
Layer 0 weight grad [0][0] = -324.284973


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7408
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 202.464813
Layer 0 weight grad [0][0] = -22.034355


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7409
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 202.114883
Layer 0 weight grad [0][0] = 746.688171


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7410
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 202.370667
Layer 0 weight grad [0][0] = -31.748587


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7411
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 202.619293
Layer 0 weight grad [0][0] = 172.244217


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7412
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 203.363113
Layer 0 weight grad [0][0] = 38.889744


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7413
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 201.986786
Layer 0 weight grad [0][0] = -37.422794


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 7414
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1258.114746
Layer 0 weight grad [0][0] = -39.904785


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7415
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 199.368668
Layer 0 weight grad [0][0] = -44.571861


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7416
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 199.732040
Layer 0 weight grad [0][0] = 228.915054


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7417
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 199.879150
Layer 0 weight grad [0][0] = -224.978439


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7418
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 204.334702
Layer 0 weight grad [0][0] = -53.302647


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7419
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 205.045349
Layer 0 weight grad [0][0] = 208.141083


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7420
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 205.465790
Layer 0 weight grad [0][0] = 378.288910


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7421
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 205.338242
Layer 0 weight grad [0][0] = -50.031986


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7422
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 206.249405
Layer 0 weight grad [0][0] = -51.650162


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7423
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1273.724121
Layer 0 weight grad [0][0] = 671.425964


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7424
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 203.505096
Layer 0 weight grad [0][0] = 169.784225


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7425
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1273.288452
Layer 0 weight grad [0][0] = -247.890472


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7426
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1275.153809
Layer 0 weight grad [0][0] = 154.188553


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7427
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 197.868790
Layer 0 weight grad [0][0] = -51.704918


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7428
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 198.221436
Layer 0 weight grad [0][0] = -48.150692


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7429
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 198.362686
Layer 0 weight grad [0][0] = -47.601772


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7430
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 198.571808
Layer 0 weight grad [0][0] = -42.576538


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7431
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 198.561447
Layer 0 weight grad [0][0] = -38.593075


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7432
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 198.367477
Layer 0 weight grad [0][0] = -38.533718


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7433
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -344.457825
Layer 0 weight grad [0][0] = -41.837830


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7434
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 195.154556
Layer 0 weight grad [0][0] = 16.506624


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7435
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 198.151184
Layer 0 weight grad [0][0] = -25.201231


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7436
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 198.033417
Layer 0 weight grad [0][0] = -16.031321


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7437
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1244.031250
Layer 0 weight grad [0][0] = -23.570709


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7438
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 194.443237
Layer 0 weight grad [0][0] = -26.954668


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7439
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 194.116638
Layer 0 weight grad [0][0] = 468.518707


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7440
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 198.544846
Layer 0 weight grad [0][0] = -29.218643


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7441
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 198.488052
Layer 0 weight grad [0][0] = -38.042049


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7442
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 199.126648
Layer 0 weight grad [0][0] = 18.908237


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7443
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 198.363144
Layer 0 weight grad [0][0] = -76.940361


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7444
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 203.310089
Layer 0 weight grad [0][0] = 141.844223


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7445
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1280.973022
Layer 0 weight grad [0][0] = 131.782104


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7446
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -323.676544
Layer 0 weight grad [0][0] = -39.884987


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7447
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 197.122925
Layer 0 weight grad [0][0] = 317.529480


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7448
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 197.711716
Layer 0 weight grad [0][0] = 656.570374


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7449
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -313.596893
Layer 0 weight grad [0][0] = -133.219955


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7450
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1264.549194
Layer 0 weight grad [0][0] = -42.038460


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7451
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 191.878510
Layer 0 weight grad [0][0] = -356.794006


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7452
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 197.189896
Layer 0 weight grad [0][0] = -38.494328


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7453
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 197.198898
Layer 0 weight grad [0][0] = -42.607315


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7454
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -283.785553
Layer 0 weight grad [0][0] = 486.345734


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 7455
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 195.017609
Layer 0 weight grad [0][0] = -34.594528


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7456
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -266.159576
Layer 0 weight grad [0][0] = 153.514908


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7457
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 192.535507
Layer 0 weight grad [0][0] = 150.697708


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7458
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 192.370392
Layer 0 weight grad [0][0] = -262.492157


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7459
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1329.892090
Layer 0 weight grad [0][0] = -31.709341


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7460
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1328.092651
Layer 0 weight grad [0][0] = -37.124084


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7461
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -204.322815
Layer 0 weight grad [0][0] = -43.763264


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7462
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -179.488846
Layer 0 weight grad [0][0] = -5.390471


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7463
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 185.302994
Layer 0 weight grad [0][0] = -33.107716


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7464
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 184.698715
Layer 0 weight grad [0][0] = -717.151611


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 7465
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 184.613922
Layer 0 weight grad [0][0] = -104.978737


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7466
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -173.064941
Layer 0 weight grad [0][0] = -36.371746


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7467
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 183.407944
Layer 0 weight grad [0][0] = 512.519226


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7468
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1304.203613
Layer 0 weight grad [0][0] = -231.311111


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7469
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 183.987946
Layer 0 weight grad [0][0] = -232.268051


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7470
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 188.606125
Layer 0 weight grad [0][0] = -19.692097


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7471
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 187.935410
Layer 0 weight grad [0][0] = -15.115166


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7472
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 188.370361
Layer 0 weight grad [0][0] = -100.325371


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7473
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 190.832184
Layer 0 weight grad [0][0] = 96.402313


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7474
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 192.011932
Layer 0 weight grad [0][0] = 166.434326


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7475
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 192.517776
Layer 0 weight grad [0][0] = -77.834213


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7476
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 193.537903
Layer 0 weight grad [0][0] = 168.080307


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7477
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 193.403503
Layer 0 weight grad [0][0] = -236.233078


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7478
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 198.829239
Layer 0 weight grad [0][0] = -19.829409


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7479
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -179.884766
Layer 0 weight grad [0][0] = -241.353088


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7480
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 201.072540
Layer 0 weight grad [0][0] = -29.511175


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7481
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1443.398071
Layer 0 weight grad [0][0] = 226.000259


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7482
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 197.266602
Layer 0 weight grad [0][0] = -39.168236


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7483
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 197.426834
Layer 0 weight grad [0][0] = -45.259502


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7484
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 197.550522
Layer 0 weight grad [0][0] = -38.844257


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7485
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 197.980179
Layer 0 weight grad [0][0] = -31.113121


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7486
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 198.462479
Layer 0 weight grad [0][0] = -34.637272


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7487
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 198.686676
Layer 0 weight grad [0][0] = 173.036118


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7488
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 198.454605
Layer 0 weight grad [0][0] = -51.131767


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7489
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 203.993713
Layer 0 weight grad [0][0] = -35.773804


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7490
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -176.934586
Layer 0 weight grad [0][0] = 161.116760


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7491
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -157.123230
Layer 0 weight grad [0][0] = -30.024950


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7492
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 199.209641
Layer 0 weight grad [0][0] = -36.950611


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7493
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 199.976532
Layer 0 weight grad [0][0] = 252.585251


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7494
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 200.144379
Layer 0 weight grad [0][0] = -1332.257812


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7495
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 200.166260
Layer 0 weight grad [0][0] = 33.390755


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7496
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 199.335068
Layer 0 weight grad [0][0] = -33.518436


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7497
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1430.637451
Layer 0 weight grad [0][0] = 274.451660


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7498
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 195.275604
Layer 0 weight grad [0][0] = -14.068979


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7499
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -151.706863
Layer 0 weight grad [0][0] = -18.303869


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7500
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 193.857101
Layer 0 weight grad [0][0] = -23.330639


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7501
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -140.081253
Layer 0 weight grad [0][0] = -28.110195


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7502
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 191.523422
Layer 0 weight grad [0][0] = -220.021988


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7503
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1449.963501
Layer 0 weight grad [0][0] = 8.504338


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7504
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 194.633713
Layer 0 weight grad [0][0] = -15.324462


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7505
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 194.981888
Layer 0 weight grad [0][0] = -20.228138


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7506
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 194.735962
Layer 0 weight grad [0][0] = -26.535416


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7507
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1446.033325
Layer 0 weight grad [0][0] = -29.730556


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7508
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 194.184265
Layer 0 weight grad [0][0] = 197.216949


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7509
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -115.799271
Layer 0 weight grad [0][0] = -37.164722


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7510
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 187.942459
Layer 0 weight grad [0][0] = -5.182324


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7511
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 187.927383
Layer 0 weight grad [0][0] = 191.037949


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7512
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1406.754272
Layer 0 weight grad [0][0] = -0.724852


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7513
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 187.552734
Layer 0 weight grad [0][0] = 7.359658


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7514
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 187.920181
Layer 0 weight grad [0][0] = -29.476274


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 7515
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 193.250198
Layer 0 weight grad [0][0] = -220.133545


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7516
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 198.565079
Layer 0 weight grad [0][0] = -4.969802


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7517
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 199.656891
Layer 0 weight grad [0][0] = 319.116730


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7518
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 192.768997
Layer 0 weight grad [0][0] = 106.092438


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 7519
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 193.226624
Layer 0 weight grad [0][0] = -226.975586


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7520
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 198.439240
Layer 0 weight grad [0][0] = 106.591255


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7521
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 199.664886
Layer 0 weight grad [0][0] = 111.609909


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7522
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 200.489273
Layer 0 weight grad [0][0] = -14.435707


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7523
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 200.809891
Layer 0 weight grad [0][0] = -19.422871


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7524
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 202.160461
Layer 0 weight grad [0][0] = 417.547729


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 7525
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 193.715714
Layer 0 weight grad [0][0] = -24.333273


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7526
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1422.955811
Layer 0 weight grad [0][0] = -29.102055


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7527
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 192.964249
Layer 0 weight grad [0][0] = -33.557552


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7528
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 194.104645
Layer 0 weight grad [0][0] = -10.564487


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7529
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 194.840607
Layer 0 weight grad [0][0] = -29.217274


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7530
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 196.286224
Layer 0 weight grad [0][0] = 96.649086


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7531
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 196.868546
Layer 0 weight grad [0][0] = 158.234695


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7532
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 197.473495
Layer 0 weight grad [0][0] = -117.782616


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7533
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 199.161026
Layer 0 weight grad [0][0] = 137.696381


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7534
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -142.851425
Layer 0 weight grad [0][0] = -30.791582


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 7535
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -124.594193
Layer 0 weight grad [0][0] = -23.250473


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7536
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 197.584732
Layer 0 weight grad [0][0] = 166.647751


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 7537
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1476.916992
Layer 0 weight grad [0][0] = -30.188362


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7538
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -84.812012
Layer 0 weight grad [0][0] = 305.932404


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7539
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 186.283813
Layer 0 weight grad [0][0] = 78.042763


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7540
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 188.227203
Layer 0 weight grad [0][0] = -15.548272


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7541
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 188.651688
Layer 0 weight grad [0][0] = 154.858032


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7542
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 189.525818
Layer 0 weight grad [0][0] = -14.236094


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 7543
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 190.113113
Layer 0 weight grad [0][0] = -17.454582


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 7544
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 190.916656
Layer 0 weight grad [0][0] = 176.169983


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7545
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 191.794373
Layer 0 weight grad [0][0] = 173.924301


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7546
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1430.568604
Layer 0 weight grad [0][0] = -199.679901


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7547
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 194.533920
Layer 0 weight grad [0][0] = -203.092804


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7548
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 198.875290
Layer 0 weight grad [0][0] = -204.938416


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7549
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 203.947388
Layer 0 weight grad [0][0] = 265.381775


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 7550
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -91.091667
Layer 0 weight grad [0][0] = 320.676910


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7551
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -79.228142
Layer 0 weight grad [0][0] = -38.185898


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7552
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 193.685730
Layer 0 weight grad [0][0] = -16.259531


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7553
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 195.320084
Layer 0 weight grad [0][0] = 370.596466


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7554
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -79.922920
Layer 0 weight grad [0][0] = -24.779081


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7555
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 185.993484
Layer 0 weight grad [0][0] = 402.014526


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7556
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 178.609192
Layer 0 weight grad [0][0] = -18.157526


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7557
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 179.454361
Layer 0 weight grad [0][0] = -23.982082


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7558
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1357.861450
Layer 0 weight grad [0][0] = 414.403961


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7559
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 168.380524
Layer 0 weight grad [0][0] = -173.536041


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7560
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 172.985626
Layer 0 weight grad [0][0] = -122.605995


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7561
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -70.924339
Layer 0 weight grad [0][0] = -26.999804


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7562
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 177.071381
Layer 0 weight grad [0][0] = -21.364908


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 7563
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1363.608032
Layer 0 weight grad [0][0] = -34.616310


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7564
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1370.466064
Layer 0 weight grad [0][0] = -29.335487


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7565
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 174.044373
Layer 0 weight grad [0][0] = -32.806828


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7566
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 175.104721
Layer 0 weight grad [0][0] = 45.534367


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7567
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 176.218018
Layer 0 weight grad [0][0] = -23.451355


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7568
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 177.820847
Layer 0 weight grad [0][0] = -86.453453


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 7569
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 181.435425
Layer 0 weight grad [0][0] = -29.498716


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7570
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 183.067902
Layer 0 weight grad [0][0] = 233.250748


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7571
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 183.629089
Layer 0 weight grad [0][0] = -39.525997


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7572
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 184.075577
Layer 0 weight grad [0][0] = -793.066956


Training loss: 2.302585
Training accuracy: 0.375000

epoch: 7573
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 185.879715
Layer 0 weight grad [0][0] = -14.838022


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7574
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 186.742020
Layer 0 weight grad [0][0] = -43.750549


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7575
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 191.062622
Layer 0 weight grad [0][0] = 397.421387


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7576
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 182.455048
Layer 0 weight grad [0][0] = 71.689980


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7577
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 183.765228
Layer 0 weight grad [0][0] = 167.502945


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7578
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1416.110962
Layer 0 weight grad [0][0] = -104.831474


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 7579
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 183.963043
Layer 0 weight grad [0][0] = -26.932287


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7580
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -51.294788
Layer 0 weight grad [0][0] = -16.403152


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7581
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 184.787811
Layer 0 weight grad [0][0] = -310.488678


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7582
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 185.422867
Layer 0 weight grad [0][0] = 472.585724


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7583
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 176.465561
Layer 0 weight grad [0][0] = -387.925964


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7584
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 179.508743
Layer 0 weight grad [0][0] = 463.378906


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7585
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 169.676910
Layer 0 weight grad [0][0] = -27.545271


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7586
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 171.042191
Layer 0 weight grad [0][0] = -32.383755


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7587
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -70.849625
Layer 0 weight grad [0][0] = 46.620354


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7588
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 174.053619
Layer 0 weight grad [0][0] = -297.187439


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7589
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 177.877335
Layer 0 weight grad [0][0] = -24.608553


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7590
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1368.802124
Layer 0 weight grad [0][0] = -122.605003


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7591
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 179.316177
Layer 0 weight grad [0][0] = 53.298885


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7592
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 180.645065
Layer 0 weight grad [0][0] = 85.008362


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7593
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 181.538193
Layer 0 weight grad [0][0] = -27.709824


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7594
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 184.056290
Layer 0 weight grad [0][0] = -110.615013


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7595
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 187.205521
Layer 0 weight grad [0][0] = 74.384094


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7596
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 188.477798
Layer 0 weight grad [0][0] = -27.428617


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7597
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 189.963882
Layer 0 weight grad [0][0] = -35.366444


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7598
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 190.907867
Layer 0 weight grad [0][0] = -37.813656


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 7599
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 193.454987
Layer 0 weight grad [0][0] = 145.886185


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7600
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 194.975067
Layer 0 weight grad [0][0] = -12.103563


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7601
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 195.909348
Layer 0 weight grad [0][0] = -96.673141


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7602
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 199.040039
Layer 0 weight grad [0][0] = 463.070770


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7603
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 189.838669
Layer 0 weight grad [0][0] = 83.785049


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7604
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 191.464722
Layer 0 weight grad [0][0] = -30.250072


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7605
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 193.061249
Layer 0 weight grad [0][0] = -19.201694


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7606
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 194.342148
Layer 0 weight grad [0][0] = 67.455254


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7607
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 195.957138
Layer 0 weight grad [0][0] = -23.104788


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7608
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 197.296799
Layer 0 weight grad [0][0] = 65.994987


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7609
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1471.421875
Layer 0 weight grad [0][0] = 73.886749


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7610
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 195.663254
Layer 0 weight grad [0][0] = 470.968964


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7611
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 186.581848
Layer 0 weight grad [0][0] = 72.437485


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7612
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 188.216202
Layer 0 weight grad [0][0] = -17.208616


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7613
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 189.161072
Layer 0 weight grad [0][0] = -22.171518


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7614
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 191.240891
Layer 0 weight grad [0][0] = -254.140640


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7615
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 192.890198
Layer 0 weight grad [0][0] = 16.926186


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7616
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 194.644058
Layer 0 weight grad [0][0] = -65.635330


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7617
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 197.220428
Layer 0 weight grad [0][0] = -233.378952


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7618
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 199.786835
Layer 0 weight grad [0][0] = 193.921783


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7619
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1461.342896
Layer 0 weight grad [0][0] = 153.857422


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7620
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -92.749161
Layer 0 weight grad [0][0] = 149.757111


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7621
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 195.896729
Layer 0 weight grad [0][0] = 144.959488


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7622
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -89.642921
Layer 0 weight grad [0][0] = 601.813782


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 7623
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 187.393631
Layer 0 weight grad [0][0] = -93.601723


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7624
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 189.639450
Layer 0 weight grad [0][0] = 472.967010


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7625
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 180.014725
Layer 0 weight grad [0][0] = -61.057838


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7626
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 181.973724
Layer 0 weight grad [0][0] = -51.224190


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7627
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1342.027588
Layer 0 weight grad [0][0] = 978.582092


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7628
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 166.942215
Layer 0 weight grad [0][0] = 90.424469


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7629
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 168.862076
Layer 0 weight grad [0][0] = -373.446777


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7630
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 171.243362
Layer 0 weight grad [0][0] = -370.340729


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7631
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 172.560471
Layer 0 weight grad [0][0] = 357.538910


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7632
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 174.565948
Layer 0 weight grad [0][0] = -51.752060


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7633
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 176.158188
Layer 0 weight grad [0][0] = -53.275032


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7634
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 178.029388
Layer 0 weight grad [0][0] = -296.731201


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7635
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 179.688095
Layer 0 weight grad [0][0] = 133.411438


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7636
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 181.959915
Layer 0 weight grad [0][0] = 89.267708


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7637
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 171.726669
Layer 0 weight grad [0][0] = -403.067261


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7638
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 173.961258
Layer 0 weight grad [0][0] = 630.447144


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7639
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 165.108566
Layer 0 weight grad [0][0] = -57.763897


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7640
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1153.262695
Layer 0 weight grad [0][0] = 78.955818


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7641
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 161.726135
Layer 0 weight grad [0][0] = 113.188248


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7642
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 162.824921
Layer 0 weight grad [0][0] = -65.899773


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7643
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 165.702499
Layer 0 weight grad [0][0] = -68.057762


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7644
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 166.985565
Layer 0 weight grad [0][0] = -67.612617


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7645
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 168.863586
Layer 0 weight grad [0][0] = -71.016853


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7646
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 171.402161
Layer 0 weight grad [0][0] = -75.218102


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7647
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 172.528870
Layer 0 weight grad [0][0] = -167.785858


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7648
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 174.476349
Layer 0 weight grad [0][0] = -77.330795


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7649
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 175.894638
Layer 0 weight grad [0][0] = -67.202339


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7650
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 178.379349
Layer 0 weight grad [0][0] = -59.443546


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7651
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1262.416260
Layer 0 weight grad [0][0] = 408.101685


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 7652
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 175.765625
Layer 0 weight grad [0][0] = -51.019653


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7653
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 177.657990
Layer 0 weight grad [0][0] = 295.478271


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7654
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 179.637070
Layer 0 weight grad [0][0] = -76.605972


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7655
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 182.739838
Layer 0 weight grad [0][0] = -50.709240


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7656
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 184.299454
Layer 0 weight grad [0][0] = -56.165169


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7657
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 186.374069
Layer 0 weight grad [0][0] = -52.471245


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 7658
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 189.301605
Layer 0 weight grad [0][0] = -52.960503


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7659
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1356.018066
Layer 0 weight grad [0][0] = -641.479370


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7660
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 183.700073
Layer 0 weight grad [0][0] = 120.199745


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7661
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 186.066788
Layer 0 weight grad [0][0] = 128.194565


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7662
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 188.437256
Layer 0 weight grad [0][0] = 723.302368


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7663
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 190.802673
Layer 0 weight grad [0][0] = -48.544209


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7664
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 192.461990
Layer 0 weight grad [0][0] = -47.563904


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 7665
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 195.234680
Layer 0 weight grad [0][0] = 534.972107


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7666
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 184.687225
Layer 0 weight grad [0][0] = 77.680794


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 7667
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -164.454056
Layer 0 weight grad [0][0] = -59.977356


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7668
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 188.107208
Layer 0 weight grad [0][0] = -7.089259


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7669
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 189.524353
Layer 0 weight grad [0][0] = 565.215942


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7670
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 191.574799
Layer 0 weight grad [0][0] = -47.587914


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7671
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1369.652466
Layer 0 weight grad [0][0] = -35.283684


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7672
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 188.450104
Layer 0 weight grad [0][0] = -22.161901


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7673
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 190.218277
Layer 0 weight grad [0][0] = -1.230298


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7674
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 192.249664
Layer 0 weight grad [0][0] = -922.651855


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7675
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 194.450256
Layer 0 weight grad [0][0] = -939.272034


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7676
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 197.249115
Layer 0 weight grad [0][0] = 12.350838


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7677
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 199.983673
Layer 0 weight grad [0][0] = -16.221622


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7678
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 202.027740
Layer 0 weight grad [0][0] = -812.527710


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7679
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 203.600632
Layer 0 weight grad [0][0] = -23.971424


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7680
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 205.690033
Layer 0 weight grad [0][0] = 551.916992


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7681
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 207.726852
Layer 0 weight grad [0][0] = 16.879740


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7682
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 209.775757
Layer 0 weight grad [0][0] = 22.106430


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7683
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 211.831146
Layer 0 weight grad [0][0] = 24.384357


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7684
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 213.927261
Layer 0 weight grad [0][0] = -816.234558


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 7685
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 215.972275
Layer 0 weight grad [0][0] = 176.301331


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7686
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 217.979645
Layer 0 weight grad [0][0] = 150.300293


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7687
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 219.992905
Layer 0 weight grad [0][0] = -1284.283569


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7688
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 221.983200
Layer 0 weight grad [0][0] = 509.219269


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7689
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 214.394379
Layer 0 weight grad [0][0] = 166.639160


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7690
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1465.856934
Layer 0 weight grad [0][0] = 55.644787


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7691
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 210.547958
Layer 0 weight grad [0][0] = 299.891388


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7692
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 212.384155
Layer 0 weight grad [0][0] = 49.807556


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7693
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 213.588150
Layer 0 weight grad [0][0] = 367.469727


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7694
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1504.035767
Layer 0 weight grad [0][0] = 52.001854


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7695
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 211.902603
Layer 0 weight grad [0][0] = -1244.523682


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7696
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 212.863068
Layer 0 weight grad [0][0] = 574.314819


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7697
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 214.558197
Layer 0 weight grad [0][0] = 499.578735


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 7698
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1453.496948
Layer 0 weight grad [0][0] = 51.762394


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7699
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 202.040161
Layer 0 weight grad [0][0] = 58.004986


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7700
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 203.190384
Layer 0 weight grad [0][0] = 70.444862


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7701
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 204.806778
Layer 0 weight grad [0][0] = 65.333389


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7702
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 206.411575
Layer 0 weight grad [0][0] = 264.779572


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7703
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 208.682129
Layer 0 weight grad [0][0] = 54.135654


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7704
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 210.397659
Layer 0 weight grad [0][0] = 35.898193


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7705
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 211.623978
Layer 0 weight grad [0][0] = 75.254723


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7706
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1519.421387
Layer 0 weight grad [0][0] = 250.882339


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7707
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 208.656418
Layer 0 weight grad [0][0] = 252.319748


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7708
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -147.404892
Layer 0 weight grad [0][0] = -869.929199


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7709
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 211.160706
Layer 0 weight grad [0][0] = -1149.513184


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7710
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 214.767792
Layer 0 weight grad [0][0] = -1056.217285


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7711
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 216.992950
Layer 0 weight grad [0][0] = 37.663120


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7712
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 218.270172
Layer 0 weight grad [0][0] = 273.243225


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7713
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 219.919098
Layer 0 weight grad [0][0] = 587.795410


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7714
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1497.629639
Layer 0 weight grad [0][0] = 593.952759


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7715
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 193.716965
Layer 0 weight grad [0][0] = 33.415760


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7716
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 195.476959
Layer 0 weight grad [0][0] = 18.865032


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7717
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1417.816895
Layer 0 weight grad [0][0] = 624.372803


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7718
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -130.850296
Layer 0 weight grad [0][0] = 31.409988


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7719
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 180.435959
Layer 0 weight grad [0][0] = 23.322418


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7720
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 182.279221
Layer 0 weight grad [0][0] = 1015.481506


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7721
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 170.757080
Layer 0 weight grad [0][0] = -917.967773


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7722
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 172.620285
Layer 0 weight grad [0][0] = -70.703423


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7723
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 176.736237
Layer 0 weight grad [0][0] = 6.968193


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7724
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 178.027023
Layer 0 weight grad [0][0] = 537.254822


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7725
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1174.945557
Layer 0 weight grad [0][0] = 551.502319


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7726
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 164.932098
Layer 0 weight grad [0][0] = 2.436647


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7727
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 167.604156
Layer 0 weight grad [0][0] = -3.386324


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7728
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 169.248627
Layer 0 weight grad [0][0] = 336.863190


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7729
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 170.525528
Layer 0 weight grad [0][0] = -3.234343


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7730
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 172.302017
Layer 0 weight grad [0][0] = 0.694387


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7731
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 173.944763
Layer 0 weight grad [0][0] = -0.734132


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7732
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 175.459991
Layer 0 weight grad [0][0] = -0.557099


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7733
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 176.957382
Layer 0 weight grad [0][0] = 378.483856


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7734
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 170.026947
Layer 0 weight grad [0][0] = 381.481506


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7735
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 162.917587
Layer 0 weight grad [0][0] = 153.732697


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7736
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -202.960907
Layer 0 weight grad [0][0] = 151.993164


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7737
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -190.769821
Layer 0 weight grad [0][0] = 349.367584


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7738
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 163.848206
Layer 0 weight grad [0][0] = -22.191610


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7739
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 166.309448
Layer 0 weight grad [0][0] = -614.275391


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7740
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 167.330521
Layer 0 weight grad [0][0] = -33.225372


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7741
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1158.027710
Layer 0 weight grad [0][0] = 347.345734


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7742
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 157.862961
Layer 0 weight grad [0][0] = -40.376823


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7743
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 159.338150
Layer 0 weight grad [0][0] = 504.166473


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7744
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 151.788208
Layer 0 weight grad [0][0] = -394.984650


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7745
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -187.794205
Layer 0 weight grad [0][0] = -53.730106


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7746
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 152.913086
Layer 0 weight grad [0][0] = 266.706970


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7747
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 154.266022
Layer 0 weight grad [0][0] = -46.638702


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7748
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 155.565475
Layer 0 weight grad [0][0] = -45.397205


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7749
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1065.281860
Layer 0 weight grad [0][0] = -33.106178


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7750
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 154.437119
Layer 0 weight grad [0][0] = 408.286377


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7751
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -163.948151
Layer 0 weight grad [0][0] = 112.357819


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7752
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 154.789124
Layer 0 weight grad [0][0] = -28.714117


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7753
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 156.161102
Layer 0 weight grad [0][0] = -712.916931


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7754
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 158.245071
Layer 0 weight grad [0][0] = -703.713379


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7755
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 159.754150
Layer 0 weight grad [0][0] = -18.201811


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7756
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 160.771591
Layer 0 weight grad [0][0] = -41.693111


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7757
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 162.321548
Layer 0 weight grad [0][0] = -19.070385


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 7758
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -183.002457
Layer 0 weight grad [0][0] = -24.597868


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7759
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 163.918961
Layer 0 weight grad [0][0] = -798.940125


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7760
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -174.456390
Layer 0 weight grad [0][0] = 446.225006


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7761
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 164.977158
Layer 0 weight grad [0][0] = -31.692202


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7762
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 166.608307
Layer 0 weight grad [0][0] = -718.151733


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7763
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 168.316254
Layer 0 weight grad [0][0] = 131.113190


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7764
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 169.498566
Layer 0 weight grad [0][0] = -43.181496


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7765
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 171.788864
Layer 0 weight grad [0][0] = 121.470512


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7766
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 173.557709
Layer 0 weight grad [0][0] = -686.643982


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7767
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 175.475037
Layer 0 weight grad [0][0] = 362.352753


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7768
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 176.739975
Layer 0 weight grad [0][0] = 759.076538


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7769
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1142.289062
Layer 0 weight grad [0][0] = -252.035278


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7770
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 166.233658
Layer 0 weight grad [0][0] = -41.922253


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7771
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 167.581131
Layer 0 weight grad [0][0] = -179.845261


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7772
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 171.918121
Layer 0 weight grad [0][0] = -41.549664


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7773
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -193.220856
Layer 0 weight grad [0][0] = 89.961159


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7774
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 172.386581
Layer 0 weight grad [0][0] = -32.042141


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7775
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 173.335297
Layer 0 weight grad [0][0] = -23.936798


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7776
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 175.132538
Layer 0 weight grad [0][0] = 354.792114


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7777
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 177.101517
Layer 0 weight grad [0][0] = -32.868843


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7778
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1219.933472
Layer 0 weight grad [0][0] = -941.029358


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 7779
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -155.738556
Layer 0 weight grad [0][0] = -21.541712


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7780
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 175.778839
Layer 0 weight grad [0][0] = -729.994141


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7781
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1270.846680
Layer 0 weight grad [0][0] = 357.086884


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7782
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 172.003510
Layer 0 weight grad [0][0] = -19.371876


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7783
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 173.529449
Layer 0 weight grad [0][0] = -24.211971


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7784
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 174.649384
Layer 0 weight grad [0][0] = -29.657719


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7785
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 175.766632
Layer 0 weight grad [0][0] = 146.837509


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7786
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 176.685333
Layer 0 weight grad [0][0] = 329.681671


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7787
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 169.861710
Layer 0 weight grad [0][0] = 0.769286


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7788
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 171.440826
Layer 0 weight grad [0][0] = -732.744263


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7789
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 171.962189
Layer 0 weight grad [0][0] = -0.965308


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 7790
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1216.177490
Layer 0 weight grad [0][0] = -5.482370


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7791
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 168.518860
Layer 0 weight grad [0][0] = -10.950427


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7792
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 169.680557
Layer 0 weight grad [0][0] = -8.751705


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7793
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 170.263458
Layer 0 weight grad [0][0] = -502.266144


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7794
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 172.027466
Layer 0 weight grad [0][0] = 241.326859


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7795
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 173.210846
Layer 0 weight grad [0][0] = -20.590366


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7796
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 174.501068
Layer 0 weight grad [0][0] = -19.810844


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7797
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 176.296158
Layer 0 weight grad [0][0] = 260.231415


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7798
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 177.065063
Layer 0 weight grad [0][0] = -200.336456


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7799
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 182.204636
Layer 0 weight grad [0][0] = 391.699280


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7800
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 174.606537
Layer 0 weight grad [0][0] = 525.154968


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7801
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -201.836807
Layer 0 weight grad [0][0] = -562.236511


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7802
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 174.862061
Layer 0 weight grad [0][0] = -41.902390


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7803
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 176.224030
Layer 0 weight grad [0][0] = 129.261536


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7804
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -196.530380
Layer 0 weight grad [0][0] = -1.685575


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7805
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 176.150711
Layer 0 weight grad [0][0] = 129.338486


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7806
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 177.414322
Layer 0 weight grad [0][0] = 563.164856


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7807
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 178.216202
Layer 0 weight grad [0][0] = -34.618992


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7808
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 180.131500
Layer 0 weight grad [0][0] = -617.222229


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7809
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 181.469162
Layer 0 weight grad [0][0] = 49.682739


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7810
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 182.917725
Layer 0 weight grad [0][0] = 466.725708


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7811
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 173.819412
Layer 0 weight grad [0][0] = -1171.423706


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7812
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 175.612518
Layer 0 weight grad [0][0] = 427.316101


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7813
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 176.967590
Layer 0 weight grad [0][0] = 385.019104


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7814
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 178.957748
Layer 0 weight grad [0][0] = -102.776039


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7815
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 182.247177
Layer 0 weight grad [0][0] = -22.015621


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7816
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 184.436371
Layer 0 weight grad [0][0] = -27.866283


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7817
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 185.950195
Layer 0 weight grad [0][0] = 241.643509


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7818
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 189.613525
Layer 0 weight grad [0][0] = -42.415535


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7819
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 191.142380
Layer 0 weight grad [0][0] = 32.855488


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7820
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 197.309448
Layer 0 weight grad [0][0] = -32.924770


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7821
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 199.067154
Layer 0 weight grad [0][0] = -37.518616


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7822
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 201.604630
Layer 0 weight grad [0][0] = -46.299545


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7823
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1317.480591
Layer 0 weight grad [0][0] = -44.177628


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7824
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 197.497650
Layer 0 weight grad [0][0] = 171.217712


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7825
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 202.044861
Layer 0 weight grad [0][0] = 276.535034


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7826
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 204.186981
Layer 0 weight grad [0][0] = 471.783997


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7827
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -280.942963
Layer 0 weight grad [0][0] = 480.005432


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7828
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 195.783371
Layer 0 weight grad [0][0] = -67.591858


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7829
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 197.865067
Layer 0 weight grad [0][0] = 691.431885


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 7830
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -279.254517
Layer 0 weight grad [0][0] = 53.150120


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7831
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 201.740799
Layer 0 weight grad [0][0] = -57.797039


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7832
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1365.042725
Layer 0 weight grad [0][0] = -58.300930


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7833
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1379.844482
Layer 0 weight grad [0][0] = -45.034859


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7834
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 194.576004
Layer 0 weight grad [0][0] = 551.367249


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7835
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 183.005280
Layer 0 weight grad [0][0] = 625.891846


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7836
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 172.032135
Layer 0 weight grad [0][0] = -45.341408


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7837
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 173.978500
Layer 0 weight grad [0][0] = -32.720985


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7838
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 175.952744
Layer 0 weight grad [0][0] = -19.908997


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7839
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -227.053482
Layer 0 weight grad [0][0] = -22.636978


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7840
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 177.617462
Layer 0 weight grad [0][0] = -30.950882


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7841
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 179.167007
Layer 0 weight grad [0][0] = 142.075089


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7842
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 181.243759
Layer 0 weight grad [0][0] = 605.710388


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7843
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 182.885422
Layer 0 weight grad [0][0] = 766.366028


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 7844
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -249.453186
Layer 0 weight grad [0][0] = -41.559963


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 7845
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 185.166397
Layer 0 weight grad [0][0] = -34.552376


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7846
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 187.275482
Layer 0 weight grad [0][0] = -40.000309


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7847
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 189.322891
Layer 0 weight grad [0][0] = -677.731812


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7848
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 190.843826
Layer 0 weight grad [0][0] = 39.723778


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7849
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 193.420944
Layer 0 weight grad [0][0] = -48.765106


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7850
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 195.550232
Layer 0 weight grad [0][0] = -655.238708


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7851
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 197.676315
Layer 0 weight grad [0][0] = -45.791668


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7852
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 200.329941
Layer 0 weight grad [0][0] = -52.481033


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7853
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 202.088150
Layer 0 weight grad [0][0] = -616.997192


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7854
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 203.560425
Layer 0 weight grad [0][0] = -43.040115


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7855
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 205.026627
Layer 0 weight grad [0][0] = -32.966114


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7856
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 206.823303
Layer 0 weight grad [0][0] = -39.261906


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7857
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 209.127792
Layer 0 weight grad [0][0] = 643.705017


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7858
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1324.118530
Layer 0 weight grad [0][0] = -45.814766


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7859
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 206.134232
Layer 0 weight grad [0][0] = -45.620937


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7860
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1342.160156
Layer 0 weight grad [0][0] = 126.232246


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7861
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 202.684906
Layer 0 weight grad [0][0] = -41.676792


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7862
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 204.286301
Layer 0 weight grad [0][0] = -47.481880


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7863
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 206.887589
Layer 0 weight grad [0][0] = -56.411354


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7864
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 208.458984
Layer 0 weight grad [0][0] = -391.566406


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7865
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 217.852707
Layer 0 weight grad [0][0] = 247.286560


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7866
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 220.826691
Layer 0 weight grad [0][0] = -50.168571


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7867
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 222.229874
Layer 0 weight grad [0][0] = -56.898819


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7868
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000004 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 225.065704
Layer 0 weight grad [0][0] = 30.815426


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7869
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 209.630234
Layer 0 weight grad [0][0] = -421.778961


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7870
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 220.414917
Layer 0 weight grad [0][0] = -50.117771


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7871
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 223.055588
Layer 0 weight grad [0][0] = -45.530781


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7872
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1413.731934
Layer 0 weight grad [0][0] = -52.645248


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7873
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 216.448242
Layer 0 weight grad [0][0] = 462.705475


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7874
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -315.398682
Layer 0 weight grad [0][0] = -67.184067


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7875
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 216.842148
Layer 0 weight grad [0][0] = -73.591759


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7876
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 220.021744
Layer 0 weight grad [0][0] = -519.293518


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7877
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 221.756775
Layer 0 weight grad [0][0] = -85.650238


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7878
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 224.741333
Layer 0 weight grad [0][0] = 847.465332


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7879
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 211.771378
Layer 0 weight grad [0][0] = -445.366455


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7880
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 221.955551
Layer 0 weight grad [0][0] = -101.566628


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7881
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 224.585236
Layer 0 weight grad [0][0] = -396.117218


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 7882
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 234.014969
Layer 0 weight grad [0][0] = 727.076965


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7883
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 219.636429
Layer 0 weight grad [0][0] = 724.793396


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7884
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1338.474976
Layer 0 weight grad [0][0] = 444.379547


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7885
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 211.794647
Layer 0 weight grad [0][0] = -76.815842


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7886
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1367.117310
Layer 0 weight grad [0][0] = 125.689041


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7887
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1387.643311
Layer 0 weight grad [0][0] = 710.087280


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7888
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 174.683472
Layer 0 weight grad [0][0] = 416.285431


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7889
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 177.854355
Layer 0 weight grad [0][0] = -91.846458


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7890
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 180.745758
Layer 0 weight grad [0][0] = -391.558350


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7891
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 189.319168
Layer 0 weight grad [0][0] = 555.222473


Training loss: 2.302585
Training accuracy: 0.437500

epoch: 7892
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 192.239929
Layer 0 weight grad [0][0] = -321.491455


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7893
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 200.680573
Layer 0 weight grad [0][0] = -360.313171


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7894
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 203.532440
Layer 0 weight grad [0][0] = -445.567139


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7895
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 210.567917
Layer 0 weight grad [0][0] = -135.362869


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7896
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -251.600601
Layer 0 weight grad [0][0] = -137.703751


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7897
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 213.648941
Layer 0 weight grad [0][0] = 50.199306


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7898
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 216.656921
Layer 0 weight grad [0][0] = -144.665787


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7899
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 219.230316
Layer 0 weight grad [0][0] = -205.030640


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7900
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 222.296432
Layer 0 weight grad [0][0] = -151.525681


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7901
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 225.516174
Layer 0 weight grad [0][0] = 218.833801


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7902
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 227.372391
Layer 0 weight grad [0][0] = -142.770172


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7903
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 230.652649
Layer 0 weight grad [0][0] = -146.759506


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7904
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 233.289490
Layer 0 weight grad [0][0] = -496.550079


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7905
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1606.365479
Layer 0 weight grad [0][0] = -138.043823


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7906
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 233.133545
Layer 0 weight grad [0][0] = -126.387993


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7907
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 235.690582
Layer 0 weight grad [0][0] = 192.409668


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7908
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 237.857895
Layer 0 weight grad [0][0] = 177.519623


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7909
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 240.548935
Layer 0 weight grad [0][0] = -101.388588


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7910
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 243.351242
Layer 0 weight grad [0][0] = 838.385315


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7911
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 245.274567
Layer 0 weight grad [0][0] = -465.588623


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7912
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 247.751297
Layer 0 weight grad [0][0] = -634.932556


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7913
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 250.223938
Layer 0 weight grad [0][0] = -104.472504


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7914
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 252.222061
Layer 0 weight grad [0][0] = -104.967415


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7915
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 254.966095
Layer 0 weight grad [0][0] = 884.669189


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7916
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 258.267517
Layer 0 weight grad [0][0] = -110.645828


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7917
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 261.086700
Layer 0 weight grad [0][0] = 733.100708


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7918
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 245.981384
Layer 0 weight grad [0][0] = -102.589020


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7919
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 249.502594
Layer 0 weight grad [0][0] = 101.728569


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7920
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 252.515823
Layer 0 weight grad [0][0] = 97.931961


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7921
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1561.694336
Layer 0 weight grad [0][0] = -605.493103


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7922
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1588.009766
Layer 0 weight grad [0][0] = -604.018127


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7923
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1615.391357
Layer 0 weight grad [0][0] = 327.397339


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7924
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 214.213730
Layer 0 weight grad [0][0] = -132.452179


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7925
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 217.765167
Layer 0 weight grad [0][0] = -234.980392


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7926
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 221.410538
Layer 0 weight grad [0][0] = 1825.611694


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7927
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 206.235092
Layer 0 weight grad [0][0] = -1621.529907


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7928
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 210.370453
Layer 0 weight grad [0][0] = -149.270874


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7929
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 212.376541
Layer 0 weight grad [0][0] = 917.951111


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7930
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 216.185974
Layer 0 weight grad [0][0] = 60.027264


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7931
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1556.402466
Layer 0 weight grad [0][0] = -513.457703


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7932
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 207.996552
Layer 0 weight grad [0][0] = -158.874161


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7933
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 211.387756
Layer 0 weight grad [0][0] = 935.915710


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7934
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 214.525085
Layer 0 weight grad [0][0] = 16.752151


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7935
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 216.870514
Layer 0 weight grad [0][0] = -133.467087


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7936
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 220.359833
Layer 0 weight grad [0][0] = 726.427856


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7937
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 205.398041
Layer 0 weight grad [0][0] = -256.756958


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7938
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 216.110336
Layer 0 weight grad [0][0] = -410.778809


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7939
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1554.777588
Layer 0 weight grad [0][0] = 1865.853760


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7940
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 186.004532
Layer 0 weight grad [0][0] = -149.942932


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7941
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 190.423676
Layer 0 weight grad [0][0] = 723.931335


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 7942
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 174.125107
Layer 0 weight grad [0][0] = 1785.981689


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7943
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 158.194443
Layer 0 weight grad [0][0] = 887.981445


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7944
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 161.629745
Layer 0 weight grad [0][0] = -129.761490


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 7945
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1119.446777
Layer 0 weight grad [0][0] = -135.941849


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 7946
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -73.422592
Layer 0 weight grad [0][0] = -330.710785


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7947
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 151.888260
Layer 0 weight grad [0][0] = -150.505096


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7948
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 154.844910
Layer 0 weight grad [0][0] = -155.003983


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7949
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 158.055191
Layer 0 weight grad [0][0] = 945.238647


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7950
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1184.113037
Layer 0 weight grad [0][0] = 55.334358


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7951
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.088268
Layer 0 weight grad [0][0] = 985.829895


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7952
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1211.238525
Layer 0 weight grad [0][0] = -439.243164


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7953
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 134.504898
Layer 0 weight grad [0][0] = -104.419136


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7954
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 140.268478
Layer 0 weight grad [0][0] = -683.391113


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7955
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 146.745270
Layer 0 weight grad [0][0] = -413.915649


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 7956
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 150.163437
Layer 0 weight grad [0][0] = 1010.461487


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7957
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 152.561676
Layer 0 weight grad [0][0] = -956.319824


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7958
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 133.838028
Layer 0 weight grad [0][0] = -81.737671


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7959
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 150.015396
Layer 0 weight grad [0][0] = 57.735893


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7960
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 152.331116
Layer 0 weight grad [0][0] = -256.895996


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7961
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 143.199234
Layer 0 weight grad [0][0] = -75.820763


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7962
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 150.272766
Layer 0 weight grad [0][0] = -84.447014


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7963
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 166.727798
Layer 0 weight grad [0][0] = -72.262466


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7964
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 147.708435
Layer 0 weight grad [0][0] = -82.728951


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7965
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 184.982941
Layer 0 weight grad [0][0] = 60.756111


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7966
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 145.292313
Layer 0 weight grad [0][0] = 51.598198


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7967
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1385.084351
Layer 0 weight grad [0][0] = 933.835083


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7968
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 134.732101
Layer 0 weight grad [0][0] = 56.857021


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7969
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 136.617599
Layer 0 weight grad [0][0] = 16.816460


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7970
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 138.780548
Layer 0 weight grad [0][0] = -90.547501


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7971
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 140.111664
Layer 0 weight grad [0][0] = 27.998318


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7972
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 142.315613
Layer 0 weight grad [0][0] = 45.864044


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7973
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 144.637695
Layer 0 weight grad [0][0] = -927.278442


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7974
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 219.865219
Layer 0 weight grad [0][0] = 804.647400


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7975
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 160.668488
Layer 0 weight grad [0][0] = -703.067932


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7976
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 179.378632
Layer 0 weight grad [0][0] = -76.265388


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7977
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 181.544434
Layer 0 weight grad [0][0] = 788.120850


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7978
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 184.307449
Layer 0 weight grad [0][0] = -766.989380


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7979
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 202.102280
Layer 0 weight grad [0][0] = 549.836426


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7980
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 188.654755
Layer 0 weight grad [0][0] = -727.835449


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7981
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 204.944290
Layer 0 weight grad [0][0] = -60.521435


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7982
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 208.152725
Layer 0 weight grad [0][0] = -61.385239


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7983
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 209.937271
Layer 0 weight grad [0][0] = -75.607620


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7984
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 213.009354
Layer 0 weight grad [0][0] = 689.387756


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7985
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 214.782684
Layer 0 weight grad [0][0] = 738.511108


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7986
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 199.595230
Layer 0 weight grad [0][0] = -39.971039


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7987
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 201.670227
Layer 0 weight grad [0][0] = 756.226257


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7988
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 203.435303
Layer 0 weight grad [0][0] = 1598.983765


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7989
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 187.555969
Layer 0 weight grad [0][0] = 815.602417


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7990
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 171.013031
Layer 0 weight grad [0][0] = -23.463272


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 7991
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 172.126236
Layer 0 weight grad [0][0] = -1.847736


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7992
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 173.647400
Layer 0 weight grad [0][0] = -9.618287


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7993
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -173.858353
Layer 0 weight grad [0][0] = -16.796602


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7994
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 165.367340
Layer 0 weight grad [0][0] = -10.786717


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 7995
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 166.530304
Layer 0 weight grad [0][0] = -2.667451


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7996
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 168.136093
Layer 0 weight grad [0][0] = -0.907909


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 7997
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 169.926636
Layer 0 weight grad [0][0] = -6.881034


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 7998
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 171.006058
Layer 0 weight grad [0][0] = 787.713257


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 7999
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1125.319946
Layer 0 weight grad [0][0] = 242.076874


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8000
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1128.183105
Layer 0 weight grad [0][0] = -14.651356


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8001
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1131.786499
Layer 0 weight grad [0][0] = -1616.606201


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8002
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 148.837219
Layer 0 weight grad [0][0] = -28.272072


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8003
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 150.500183
Layer 0 weight grad [0][0] = -34.475754


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8004
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 151.887695
Layer 0 weight grad [0][0] = 142.652466


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8005
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 154.151718
Layer 0 weight grad [0][0] = 85.293556


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8006
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 155.923843
Layer 0 weight grad [0][0] = -34.194836


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8007
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 158.167160
Layer 0 weight grad [0][0] = -44.118950


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8008
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 75.771217
Layer 0 weight grad [0][0] = -49.380451


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8009
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 153.048691
Layer 0 weight grad [0][0] = -1458.846069


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8010
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 185.774719
Layer 0 weight grad [0][0] = -63.277542


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8011
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 188.010635
Layer 0 weight grad [0][0] = 1790.347412


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8012
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 169.678162
Layer 0 weight grad [0][0] = -74.438782


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8013
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1400.030884
Layer 0 weight grad [0][0] = -82.395737


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8014
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 153.887436
Layer 0 weight grad [0][0] = -89.208626


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8015
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 156.340393
Layer 0 weight grad [0][0] = 877.573547


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8016
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 158.470612
Layer 0 weight grad [0][0] = 417.833679


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8017
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 98.128090
Layer 0 weight grad [0][0] = 872.788757


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8018
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 132.535919
Layer 0 weight grad [0][0] = 411.724396


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8019
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 134.662552
Layer 0 weight grad [0][0] = 879.198547


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8020
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 115.276360
Layer 0 weight grad [0][0] = -126.150017


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8021
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 117.732231
Layer 0 weight grad [0][0] = -119.311180


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8022
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.847219
Layer 0 weight grad [0][0] = 842.217773


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 8023
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 114.656914
Layer 0 weight grad [0][0] = -121.114365


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8024
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 117.478004
Layer 0 weight grad [0][0] = -130.556824


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8025
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -954.716187
Layer 0 weight grad [0][0] = 840.619385


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8026
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 102.870033
Layer 0 weight grad [0][0] = 30.954870


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8027
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 105.646484
Layer 0 weight grad [0][0] = -35.168484


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8028
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 107.477432
Layer 0 weight grad [0][0] = -136.488953


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8029
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 110.401939
Layer 0 weight grad [0][0] = -29.978437


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8030
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 112.376556
Layer 0 weight grad [0][0] = -146.074997


Training loss: 2.302585
Training accuracy: 0.375000

epoch: 8031
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -951.194214
Layer 0 weight grad [0][0] = -143.101852


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 8032
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -968.427429
Layer 0 weight grad [0][0] = -152.848572


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8033
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 84.910065
Layer 0 weight grad [0][0] = -1191.144531


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8034
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1189.933716
Layer 0 weight grad [0][0] = -137.146515


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8035
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 93.456535
Layer 0 weight grad [0][0] = -126.913376


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8036
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 95.679466
Layer 0 weight grad [0][0] = -1097.356323


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8037
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 436.917480
Layer 0 weight grad [0][0] = 1872.790894


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8038
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 93.301086
Layer 0 weight grad [0][0] = -54.153820


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 8039
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 95.784676
Layer 0 weight grad [0][0] = -150.155991


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8040
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 99.263527
Layer 0 weight grad [0][0] = -1178.391235


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8041
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 125.603050
Layer 0 weight grad [0][0] = -126.225883


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8042
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 127.797188
Layer 0 weight grad [0][0] = -113.232285


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8043
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 130.680573
Layer 0 weight grad [0][0] = 849.064087


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8044
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1203.567017
Layer 0 weight grad [0][0] = -6.534382


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 8045
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 93.762383
Layer 0 weight grad [0][0] = -120.862122


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 8046
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 97.612389
Layer 0 weight grad [0][0] = -125.641960


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8047
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 100.254654
Layer 0 weight grad [0][0] = -108.782753


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8048
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 101.387993
Layer 0 weight grad [0][0] = -91.641144


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8049
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1209.125854
Layer 0 weight grad [0][0] = 6.486513


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8050
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 89.842163
Layer 0 weight grad [0][0] = -98.682014


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8051
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 92.601799
Layer 0 weight grad [0][0] = 422.739594


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8052
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1204.037964
Layer 0 weight grad [0][0] = -102.230896


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8053
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 79.606636
Layer 0 weight grad [0][0] = 930.051270


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 8054
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 82.541275
Layer 0 weight grad [0][0] = -334.068237


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8055
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 84.581932
Layer 0 weight grad [0][0] = 966.378418


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 8056
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 86.884842
Layer 0 weight grad [0][0] = 1002.429565


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8057
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 479.227844
Layer 0 weight grad [0][0] = -124.413330


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8058
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 84.504044
Layer 0 weight grad [0][0] = 1043.229248


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 8059
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 86.512932
Layer 0 weight grad [0][0] = 727.537659


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8060
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 88.332764
Layer 0 weight grad [0][0] = 1080.209717


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8061
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 90.645782
Layer 0 weight grad [0][0] = 688.208557


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8062
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 424.460297
Layer 0 weight grad [0][0] = 650.299683


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8063
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 69.539299
Layer 0 weight grad [0][0] = 1912.287720


Training loss: 2.302585
Training accuracy: 0.375000

epoch: 8064
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -848.293152
Layer 0 weight grad [0][0] = 1176.689453


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 8065
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 39.765121
Layer 0 weight grad [0][0] = -424.727081


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8066
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 41.208561
Layer 0 weight grad [0][0] = -1181.497192


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8067
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 65.972298
Layer 0 weight grad [0][0] = -130.323120


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8068
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 67.736862
Layer 0 weight grad [0][0] = -134.915161


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8069
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 69.566177
Layer 0 weight grad [0][0] = -114.410561


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8070
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 71.764214
Layer 0 weight grad [0][0] = 602.534912


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8071
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 57.716805
Layer 0 weight grad [0][0] = 1931.533813


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8072
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 43.288345
Layer 0 weight grad [0][0] = 1216.973999


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 8073
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 45.479698
Layer 0 weight grad [0][0] = -129.372818


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8074
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 46.470497
Layer 0 weight grad [0][0] = 727.059692


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8075
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 48.320343
Layer 0 weight grad [0][0] = -136.251923


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 8076
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 49.633503
Layer 0 weight grad [0][0] = -125.854515


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8077
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -674.615356
Layer 0 weight grad [0][0] = -129.900665


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8078
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 36.193626
Layer 0 weight grad [0][0] = 646.403870


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8079
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 362.199768
Layer 0 weight grad [0][0] = 653.090698


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 8080
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.407495
Layer 0 weight grad [0][0] = -138.421127


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8081
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.304528
Layer 0 weight grad [0][0] = -137.851059


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8082
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5.854284
Layer 0 weight grad [0][0] = -136.206543


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8083
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7.761098
Layer 0 weight grad [0][0] = -122.991577


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8084
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 10.411168
Layer 0 weight grad [0][0] = -108.735786


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8085
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 12.851229
Layer 0 weight grad [0][0] = -711.725769


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8086
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 15.483642
Layer 0 weight grad [0][0] = -207.763641


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8087
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 32.637920
Layer 0 weight grad [0][0] = 33.680313


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8088
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -342.295746
Layer 0 weight grad [0][0] = -123.641609


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8089
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.206092
Layer 0 weight grad [0][0] = -127.706230


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8090
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3.941626
Layer 0 weight grad [0][0] = -137.367752


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8091
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.009690
Layer 0 weight grad [0][0] = -111.657501


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 8092
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9.303979
Layer 0 weight grad [0][0] = -683.282410


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8093
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 10.537328
Layer 0 weight grad [0][0] = -130.684570


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8094
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -357.085632
Layer 0 weight grad [0][0] = -132.505768


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8095
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -3.010695
Layer 0 weight grad [0][0] = -561.916077


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8096
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.692486
Layer 0 weight grad [0][0] = 1136.228882


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 8097
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1.840296
Layer 0 weight grad [0][0] = 622.612122


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8098
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -365.481323
Layer 0 weight grad [0][0] = -129.490128


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8099
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 481.568542
Layer 0 weight grad [0][0] = -140.758957


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8100
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -15.755402
Layer 0 weight grad [0][0] = -115.225166


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8101
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -13.421124
Layer 0 weight grad [0][0] = 703.826355


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8102
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -29.126860
Layer 0 weight grad [0][0] = -128.872757


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8103
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -26.715746
Layer 0 weight grad [0][0] = 1171.919800


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8104
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 404.193115
Layer 0 weight grad [0][0] = -141.517471


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8105
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -26.205311
Layer 0 weight grad [0][0] = -1371.282104


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8106
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -6.512124
Layer 0 weight grad [0][0] = -157.788223


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8107
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -3.973408
Layer 0 weight grad [0][0] = -140.136871


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8108
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 377.208313
Layer 0 weight grad [0][0] = -130.546997


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8109
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -361.105865
Layer 0 weight grad [0][0] = 647.228577


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8110
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -376.268494
Layer 0 weight grad [0][0] = -143.322952


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8111
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -37.893414
Layer 0 weight grad [0][0] = -156.459686


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8112
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -35.475208
Layer 0 weight grad [0][0] = -155.002045


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8113
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -33.668385
Layer 0 weight grad [0][0] = 1134.533936


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8114
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -31.276495
Layer 0 weight grad [0][0] = -121.262100


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8115
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -28.789608
Layer 0 weight grad [0][0] = -537.708618


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8116
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -26.566839
Layer 0 weight grad [0][0] = 711.540405


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8117
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -42.086906
Layer 0 weight grad [0][0] = -115.638260


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8118
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -220.910004
Layer 0 weight grad [0][0] = 1136.786499


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8119
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -55.697079
Layer 0 weight grad [0][0] = -127.418350


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8120
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -53.015415
Layer 0 weight grad [0][0] = 1157.520752


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8121
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -50.392159
Layer 0 weight grad [0][0] = 282.652008


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8122
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -248.277481
Layer 0 weight grad [0][0] = -132.931076


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8123
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -63.410469
Layer 0 weight grad [0][0] = 2095.759277


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 8124
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 737.779053
Layer 0 weight grad [0][0] = -142.422806


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8125
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -80.921494
Layer 0 weight grad [0][0] = 1593.009033


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8126
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -98.270988
Layer 0 weight grad [0][0] = -131.966827


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8127
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -95.083229
Layer 0 weight grad [0][0] = -111.543236


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8128
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 70.277290
Layer 0 weight grad [0][0] = 394.357666


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8129
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -107.949440
Layer 0 weight grad [0][0] = -110.543411


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8130
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 54.743767
Layer 0 weight grad [0][0] = 818.113708


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8131
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 917.468689
Layer 0 weight grad [0][0] = -114.511642


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8132
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -143.511673
Layer 0 weight grad [0][0] = -102.525452


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8133
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -141.062256
Layer 0 weight grad [0][0] = -81.467323


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8134
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -138.643860
Layer 0 weight grad [0][0] = 1222.386475


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 8135
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 394.216888
Layer 0 weight grad [0][0] = 333.527130


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8136
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -172.614334
Layer 0 weight grad [0][0] = -1014.733398


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8137
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 198.779449
Layer 0 weight grad [0][0] = -101.209518


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8138
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -166.639679
Layer 0 weight grad [0][0] = -99.010979


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8139
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -163.789169
Layer 0 weight grad [0][0] = -85.986671


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8140
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -161.162155
Layer 0 weight grad [0][0] = -100.575409


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8141
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -159.510513
Layer 0 weight grad [0][0] = 825.715210


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8142
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -177.353149
Layer 0 weight grad [0][0] = -107.978081


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8143
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -174.861053
Layer 0 weight grad [0][0] = -845.057190


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8144
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -155.998688
Layer 0 weight grad [0][0] = -109.999611


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8145
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -153.636841
Layer 0 weight grad [0][0] = 409.821106


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8146
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 994.919250
Layer 0 weight grad [0][0] = 1130.140991


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8147
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -151.595169
Layer 0 weight grad [0][0] = -115.577858


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8148
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -148.808685
Layer 0 weight grad [0][0] = 314.571259


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 8149
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -145.652283
Layer 0 weight grad [0][0] = -236.975937


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8150
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -142.749435
Layer 0 weight grad [0][0] = -138.106400


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8151
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -140.446243
Layer 0 weight grad [0][0] = -149.458359


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8152
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -138.174133
Layer 0 weight grad [0][0] = -159.795456


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 8153
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -134.730621
Layer 0 weight grad [0][0] = 598.271240


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 8154
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 903.886841
Layer 0 weight grad [0][0] = -177.814117


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8155
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 50.763882
Layer 0 weight grad [0][0] = -596.159729


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8156
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1063.814209
Layer 0 weight grad [0][0] = 1098.850342


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8157
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -137.679077
Layer 0 weight grad [0][0] = -169.817886


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8158
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -135.408447
Layer 0 weight grad [0][0] = -144.634460


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8159
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -132.512024
Layer 0 weight grad [0][0] = -147.936111


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8160
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -129.500656
Layer 0 weight grad [0][0] = -665.267212


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8161
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -127.584892
Layer 0 weight grad [0][0] = -140.094116


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8162
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -125.679626
Layer 0 weight grad [0][0] = -127.688698


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8163
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -123.912735
Layer 0 weight grad [0][0] = -706.067749


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8164
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -122.464340
Layer 0 weight grad [0][0] = -145.300873


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8165
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 937.742615
Layer 0 weight grad [0][0] = -149.525558


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8166
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 14.443412
Layer 0 weight grad [0][0] = -154.495880


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8167
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1081.093872
Layer 0 weight grad [0][0] = -129.961380


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8168
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -138.750290
Layer 0 weight grad [0][0] = -117.772255


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 8169
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -136.548660
Layer 0 weight grad [0][0] = -148.960785


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8170
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -134.608276
Layer 0 weight grad [0][0] = -118.378143


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8171
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -132.772018
Layer 0 weight grad [0][0] = -127.507866


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8172
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -130.697891
Layer 0 weight grad [0][0] = 749.273499


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8173
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -147.238815
Layer 0 weight grad [0][0] = -1430.319336


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8174
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -128.210831
Layer 0 weight grad [0][0] = -129.893600


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8175
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 990.071655
Layer 0 weight grad [0][0] = -133.085068


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8176
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1012.579956
Layer 0 weight grad [0][0] = -109.992134


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8177
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6.722535
Layer 0 weight grad [0][0] = -1417.251099


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8178
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -118.082596
Layer 0 weight grad [0][0] = -93.176926


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8179
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1161.573730
Layer 0 weight grad [0][0] = -80.185867


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8180
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -120.842064
Layer 0 weight grad [0][0] = -71.264404


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8181
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -119.805595
Layer 0 weight grad [0][0] = 261.486176


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8182
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -137.258560
Layer 0 weight grad [0][0] = -141.448944


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8183
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -135.540176
Layer 0 weight grad [0][0] = -92.539940


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 8184
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -133.599533
Layer 0 weight grad [0][0] = 538.631287


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8185
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -132.358231
Layer 0 weight grad [0][0] = 824.555603


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8186
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -150.353271
Layer 0 weight grad [0][0] = -71.824959


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8187
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -148.777145
Layer 0 weight grad [0][0] = -1199.534912


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8188
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -123.115120
Layer 0 weight grad [0][0] = -74.497681


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 8189
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -45.013031
Layer 0 weight grad [0][0] = -76.029388


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8190
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -135.766769
Layer 0 weight grad [0][0] = -57.685520


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8191
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -133.944336
Layer 0 weight grad [0][0] = -44.711903


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8192
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1097.010742
Layer 0 weight grad [0][0] = -817.520386


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8193
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -137.381943
Layer 0 weight grad [0][0] = 1988.326538


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8194
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 160.158997
Layer 0 weight grad [0][0] = -41.860741


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8195
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -172.292908
Layer 0 weight grad [0][0] = -36.618954


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8196
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -170.479965
Layer 0 weight grad [0][0] = -865.565247


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8197
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -168.595993
Layer 0 weight grad [0][0] = -41.081161


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8198
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -166.273209
Layer 0 weight grad [0][0] = -36.810665


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8199
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -165.196930
Layer 0 weight grad [0][0] = -45.071964


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8200
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -163.639969
Layer 0 weight grad [0][0] = -1424.912598


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8201
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -51.684849
Layer 0 weight grad [0][0] = 1040.577271


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8202
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -147.913116
Layer 0 weight grad [0][0] = -794.111694


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8203
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -146.243515
Layer 0 weight grad [0][0] = -252.822311


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8204
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -115.033989
Layer 0 weight grad [0][0] = -75.728432


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8205
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1200.343872
Layer 0 weight grad [0][0] = -833.245544


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8206
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -119.122696
Layer 0 weight grad [0][0] = -74.652451


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8207
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -117.414574
Layer 0 weight grad [0][0] = -70.479347


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8208
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -114.994545
Layer 0 weight grad [0][0] = 1130.142700


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8209
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -114.047775
Layer 0 weight grad [0][0] = -91.986633


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8210
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -112.272011
Layer 0 weight grad [0][0] = -103.621597


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8211
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -110.352760
Layer 0 weight grad [0][0] = -523.993164


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8212
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -108.382553
Layer 0 weight grad [0][0] = -112.801796


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8213
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -106.369499
Layer 0 weight grad [0][0] = -121.430870


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8214
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -104.366241
Layer 0 weight grad [0][0] = -116.924507


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8215
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -75.005188
Layer 0 weight grad [0][0] = 852.650452


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8216
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -94.412880
Layer 0 weight grad [0][0] = -125.645988


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8217
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -93.034218
Layer 0 weight grad [0][0] = -587.740845


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8218
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -91.105659
Layer 0 weight grad [0][0] = -126.447701


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8219
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -88.394211
Layer 0 weight grad [0][0] = -129.185852


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 8220
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -86.520790
Layer 0 weight grad [0][0] = -132.535873


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8221
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -83.946678
Layer 0 weight grad [0][0] = 751.244629


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8222
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -82.400726
Layer 0 weight grad [0][0] = -129.286133


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8223
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -80.487648
Layer 0 weight grad [0][0] = -114.866455


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8224
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 830.981628
Layer 0 weight grad [0][0] = -102.513100


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8225
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -87.661392
Layer 0 weight grad [0][0] = -100.826859


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8226
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -86.268417
Layer 0 weight grad [0][0] = -93.975082


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 8227
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -84.783554
Layer 0 weight grad [0][0] = -563.892761


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8228
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -83.257179
Layer 0 weight grad [0][0] = -94.236862


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8229
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -150.234665
Layer 0 weight grad [0][0] = 704.045715


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8230
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -95.386406
Layer 0 weight grad [0][0] = 1058.568848


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8231
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -118.838745
Layer 0 weight grad [0][0] = 1907.126465


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8232
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -141.610611
Layer 0 weight grad [0][0] = -95.321243


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8233
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -140.216263
Layer 0 weight grad [0][0] = -642.265198


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8234
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -138.164368
Layer 0 weight grad [0][0] = -82.264938


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8235
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 738.092834
Layer 0 weight grad [0][0] = -84.026550


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8236
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -143.000122
Layer 0 weight grad [0][0] = 1094.086060


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8237
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -140.552155
Layer 0 weight grad [0][0] = -88.622490


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8238
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -138.516190
Layer 0 weight grad [0][0] = 260.708374


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8239
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -136.259750
Layer 0 weight grad [0][0] = -81.380417


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8240
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 375.606018
Layer 0 weight grad [0][0] = -1631.726196


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8241
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -113.600105
Layer 0 weight grad [0][0] = -94.078659


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8242
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 819.001221
Layer 0 weight grad [0][0] = -1585.722290


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8243
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -86.671959
Layer 0 weight grad [0][0] = -94.767334


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8244
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -215.554138
Layer 0 weight grad [0][0] = -29.599024


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8245
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -220.220352
Layer 0 weight grad [0][0] = -84.098419


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8246
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -105.785316
Layer 0 weight grad [0][0] = -1630.155640


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8247
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -70.383392
Layer 0 weight grad [0][0] = -75.722549


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8248
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -68.806450
Layer 0 weight grad [0][0] = 1127.440674


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8249
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -94.645981
Layer 0 weight grad [0][0] = -143.069122


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8250
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -94.453552
Layer 0 weight grad [0][0] = 785.674500


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8251
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -251.147766
Layer 0 weight grad [0][0] = -102.538551


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8252
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -97.695984
Layer 0 weight grad [0][0] = -99.591026


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8253
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -96.744514
Layer 0 weight grad [0][0] = -785.578674


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8254
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -63.354610
Layer 0 weight grad [0][0] = 720.780334


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8255
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1021.504456
Layer 0 weight grad [0][0] = -95.433006


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8256
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -69.343857
Layer 0 weight grad [0][0] = -786.526672


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8257
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -68.838890
Layer 0 weight grad [0][0] = -864.204956


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8258
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1067.968262
Layer 0 weight grad [0][0] = -94.029587


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8259
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -74.640594
Layer 0 weight grad [0][0] = -65.551483


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8260
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -73.611725
Layer 0 weight grad [0][0] = -99.773132


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8261
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -72.822968
Layer 0 weight grad [0][0] = -52.032928


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8262
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -528.412842
Layer 0 weight grad [0][0] = 1274.527466


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8263
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -264.112396
Layer 0 weight grad [0][0] = -135.588989


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8264
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1033.343384
Layer 0 weight grad [0][0] = 2366.515381


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8265
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.704892
Layer 0 weight grad [0][0] = -72.436157


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8266
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -129.770767
Layer 0 weight grad [0][0] = -77.170670


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8267
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -129.752457
Layer 0 weight grad [0][0] = -48.137455


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8268
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -129.350708
Layer 0 weight grad [0][0] = 429.223907


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8269
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -128.208130
Layer 0 weight grad [0][0] = -50.228840


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8270
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -128.259674
Layer 0 weight grad [0][0] = -181.790115


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8271
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -128.266556
Layer 0 weight grad [0][0] = 1263.945679


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8272
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -156.898666
Layer 0 weight grad [0][0] = -7.831329


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 8273
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -157.294891
Layer 0 weight grad [0][0] = 1314.483032


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8274
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 951.417236
Layer 0 weight grad [0][0] = 462.422333


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8275
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -195.106461
Layer 0 weight grad [0][0] = -989.200623


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8276
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -164.535950
Layer 0 weight grad [0][0] = -27.055109


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8277
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1056.503662
Layer 0 weight grad [0][0] = 995.370056


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8278
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -172.275238
Layer 0 weight grad [0][0] = -51.471481


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8279
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -172.821213
Layer 0 weight grad [0][0] = 539.623779


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8280
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 253.312347
Layer 0 weight grad [0][0] = -73.497833


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8281
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -163.314041
Layer 0 weight grad [0][0] = 525.687561


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8282
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -163.185196
Layer 0 weight grad [0][0] = 1012.496216


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8283
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -163.587326
Layer 0 weight grad [0][0] = -80.378380


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8284
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -164.400314
Layer 0 weight grad [0][0] = -73.862099


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8285
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -164.574493
Layer 0 weight grad [0][0] = -84.891663


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8286
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -164.672119
Layer 0 weight grad [0][0] = -54.129047


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8287
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1068.360107
Layer 0 weight grad [0][0] = -1241.054688


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 8288
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -147.702774
Layer 0 weight grad [0][0] = -58.603458


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8289
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -147.444382
Layer 0 weight grad [0][0] = -30.338947


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8290
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -147.235748
Layer 0 weight grad [0][0] = 1268.032227


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8291
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -175.541763
Layer 0 weight grad [0][0] = 1266.707275


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8292
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -204.391052
Layer 0 weight grad [0][0] = -27.323269


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8293
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -204.021088
Layer 0 weight grad [0][0] = -33.522797


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8294
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1132.505371
Layer 0 weight grad [0][0] = 984.131104


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8295
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1202.782104
Layer 0 weight grad [0][0] = 1054.045166


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8296
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1273.102417
Layer 0 weight grad [0][0] = -1293.821289


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8297
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -226.122223
Layer 0 weight grad [0][0] = -1088.627808


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8298
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -226.165527
Layer 0 weight grad [0][0] = -89.887527


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8299
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 461.237640
Layer 0 weight grad [0][0] = 994.071960


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8300
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -244.802002
Layer 0 weight grad [0][0] = -1078.958008


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8301
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1246.642090
Layer 0 weight grad [0][0] = 413.377716


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8302
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -251.111649
Layer 0 weight grad [0][0] = -58.591282


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8303
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -250.665222
Layer 0 weight grad [0][0] = -236.119461


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8304
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 689.476501
Layer 0 weight grad [0][0] = -75.455276


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8305
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -242.002563
Layer 0 weight grad [0][0] = -61.078865


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8306
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -242.983673
Layer 0 weight grad [0][0] = -35.755035


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8307
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -243.500504
Layer 0 weight grad [0][0] = -9.668157


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8308
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1250.704956
Layer 0 weight grad [0][0] = -1278.138794


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8309
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -224.141815
Layer 0 weight grad [0][0] = -10.845593


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8310
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 446.920898
Layer 0 weight grad [0][0] = -22.530167


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8311
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -212.747086
Layer 0 weight grad [0][0] = -1224.972534


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8312
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -186.851166
Layer 0 weight grad [0][0] = -40.512699


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8313
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 225.538712
Layer 0 weight grad [0][0] = 957.689331


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 8314
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -176.091949
Layer 0 weight grad [0][0] = -47.893120


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8315
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 241.386963
Layer 0 weight grad [0][0] = -125.147560


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8316
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -165.137390
Layer 0 weight grad [0][0] = -34.839642


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8317
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -165.511841
Layer 0 weight grad [0][0] = -1221.857666


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8318
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1096.106934
Layer 0 weight grad [0][0] = -16.680597


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8319
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -145.902908
Layer 0 weight grad [0][0] = -1182.812866


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 8320
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -120.696480
Layer 0 weight grad [0][0] = -1157.638184


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8321
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -120.491508
Layer 0 weight grad [0][0] = 391.731934


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8322
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -120.794556
Layer 0 weight grad [0][0] = -41.922009


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8323
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -120.236038
Layer 0 weight grad [0][0] = -1068.229980


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8324
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -120.717453
Layer 0 weight grad [0][0] = 1167.250732


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8325
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -147.021484
Layer 0 weight grad [0][0] = -177.181122


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8326
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -147.824051
Layer 0 weight grad [0][0] = -26.811472


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8327
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -147.463333
Layer 0 weight grad [0][0] = -31.217400


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8328
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -148.135468
Layer 0 weight grad [0][0] = -19.590137


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8329
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 24.270641
Layer 0 weight grad [0][0] = -27.412191


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8330
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1095.665283
Layer 0 weight grad [0][0] = -1333.994141


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8331
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -118.946793
Layer 0 weight grad [0][0] = -25.073565


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8332
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -118.316025
Layer 0 weight grad [0][0] = -147.529709


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8333
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -117.690659
Layer 0 weight grad [0][0] = -20.966413


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8334
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -117.973160
Layer 0 weight grad [0][0] = -10.988040


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 8335
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -117.346382
Layer 0 weight grad [0][0] = 12.399611


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8336
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1165.055786
Layer 0 weight grad [0][0] = -1270.233154


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8337
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -95.172226
Layer 0 weight grad [0][0] = 0.548410


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8338
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -94.964622
Layer 0 weight grad [0][0] = 384.909698


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8339
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -94.821152
Layer 0 weight grad [0][0] = 244.025681


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8340
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -94.564545
Layer 0 weight grad [0][0] = -2.594765


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8341
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -94.354233
Layer 0 weight grad [0][0] = 9.577192


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8342
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -478.007324
Layer 0 weight grad [0][0] = -36.016579


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8343
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -93.512421
Layer 0 weight grad [0][0] = 48.107018


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8344
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -92.835350
Layer 0 weight grad [0][0] = -48.757526


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8345
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -92.952774
Layer 0 weight grad [0][0] = 855.094116


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8346
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -93.289429
Layer 0 weight grad [0][0] = 927.470520


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8347
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -93.171211
Layer 0 weight grad [0][0] = 19.266685


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8348
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -436.651703
Layer 0 weight grad [0][0] = 13.414609


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8349
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -95.121346
Layer 0 weight grad [0][0] = 1331.809082


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8350
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1157.188721
Layer 0 weight grad [0][0] = 18.033922


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8351
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1206.987061
Layer 0 weight grad [0][0] = 1345.008423


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8352
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -164.324478
Layer 0 weight grad [0][0] = 16.229380


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8353
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -164.029205
Layer 0 weight grad [0][0] = -1686.768677


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8354
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -126.680618
Layer 0 weight grad [0][0] = 19.932083


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8355
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -127.487938
Layer 0 weight grad [0][0] = -993.959229


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8356
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -127.659546
Layer 0 weight grad [0][0] = -2625.000244


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8357
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -91.368050
Layer 0 weight grad [0][0] = 1485.983765


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8358
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -120.315506
Layer 0 weight grad [0][0] = -1649.575928


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8359
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -85.506210
Layer 0 weight grad [0][0] = 36.073547


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8360
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -85.311539
Layer 0 weight grad [0][0] = 1363.499878


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8361
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -113.342300
Layer 0 weight grad [0][0] = 327.037384


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8362
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -297.797974
Layer 0 weight grad [0][0] = -1095.724243


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8363
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -114.778465
Layer 0 weight grad [0][0] = 106.127457


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 8364
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -114.210068
Layer 0 weight grad [0][0] = 1398.085693


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8365
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -143.358765
Layer 0 weight grad [0][0] = 27.029005


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8366
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -143.021637
Layer 0 weight grad [0][0] = 41.219841


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8367
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -143.371613
Layer 0 weight grad [0][0] = -71.206238


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8368
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -143.634567
Layer 0 weight grad [0][0] = 52.611336


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8369
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -143.848419
Layer 0 weight grad [0][0] = 1430.758911


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8370
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 258.932800
Layer 0 weight grad [0][0] = 2.369139


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 8371
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 264.868317
Layer 0 weight grad [0][0] = 61.359009


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8372
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 270.225189
Layer 0 weight grad [0][0] = 1475.979126


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8373
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -192.253662
Layer 0 weight grad [0][0] = 772.506836


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 8374
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 549.159607
Layer 0 weight grad [0][0] = 49.860161


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8375
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 943.341248
Layer 0 weight grad [0][0] = -148.043365


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8376
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -191.967270
Layer 0 weight grad [0][0] = 603.314697


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8377
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -191.146683
Layer 0 weight grad [0][0] = 72.034401


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8378
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -190.765625
Layer 0 weight grad [0][0] = 84.164436


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8379
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -191.014374
Layer 0 weight grad [0][0] = -1399.626709


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8380
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -159.134766
Layer 0 weight grad [0][0] = 72.460045


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8381
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -159.925888
Layer 0 weight grad [0][0] = 1481.694702


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8382
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -191.144989
Layer 0 weight grad [0][0] = 73.024193


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8383
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -191.752396
Layer 0 weight grad [0][0] = 63.136765


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8384
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -192.163269
Layer 0 weight grad [0][0] = 1459.280884


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8385
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -223.905853
Layer 0 weight grad [0][0] = 53.695457


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8386
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -225.058060
Layer 0 weight grad [0][0] = 1440.011597


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8387
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -255.769791
Layer 0 weight grad [0][0] = -876.565308


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8388
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -222.753403
Layer 0 weight grad [0][0] = 29.640619


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8389
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 797.342529
Layer 0 weight grad [0][0] = 37.039299


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8390
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -216.483459
Layer 0 weight grad [0][0] = 713.939331


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8391
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -217.037186
Layer 0 weight grad [0][0] = 40.059002


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8392
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -217.115631
Layer 0 weight grad [0][0] = -1639.284546


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8393
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -184.193420
Layer 0 weight grad [0][0] = -1435.493774


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 8394
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 986.871643
Layer 0 weight grad [0][0] = 46.637501


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8395
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -157.597641
Layer 0 weight grad [0][0] = -1398.130493


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8396
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -59.557201
Layer 0 weight grad [0][0] = 34.536568


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 8397
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1052.190674
Layer 0 weight grad [0][0] = -72.520592


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8398
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -129.589569
Layer 0 weight grad [0][0] = 495.278168


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8399
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1095.574463
Layer 0 weight grad [0][0] = 68.029419


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8400
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -134.127518
Layer 0 weight grad [0][0] = 1460.814331


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8401
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -164.249680
Layer 0 weight grad [0][0] = -1635.384399


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8402
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -162.367538
Layer 0 weight grad [0][0] = 47.257572


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8403
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1086.187866
Layer 0 weight grad [0][0] = 65.911385


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8404
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -165.509537
Layer 0 weight grad [0][0] = 522.502136


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 8405
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -163.818176
Layer 0 weight grad [0][0] = 69.399338


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8406
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -162.670563
Layer 0 weight grad [0][0] = 89.642471


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8407
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -161.410294
Layer 0 weight grad [0][0] = 98.285164


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8408
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -160.466705
Layer 0 weight grad [0][0] = 1475.583374


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8409
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -190.038528
Layer 0 weight grad [0][0] = 313.411224


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8410
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -188.804916
Layer 0 weight grad [0][0] = 91.459496


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8411
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -188.883865
Layer 0 weight grad [0][0] = -1796.786011


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8412
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -188.359161
Layer 0 weight grad [0][0] = 441.414581


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8413
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -187.744659
Layer 0 weight grad [0][0] = 1517.659424


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 8414
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1016.852539
Layer 0 weight grad [0][0] = -1171.874390


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8415
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1081.652222
Layer 0 weight grad [0][0] = 91.088104


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8416
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -197.694031
Layer 0 weight grad [0][0] = -94.403625


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8417
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -196.218781
Layer 0 weight grad [0][0] = 110.321571


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8418
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -195.547150
Layer 0 weight grad [0][0] = 612.720337


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8419
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -194.941620
Layer 0 weight grad [0][0] = 103.765923


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8420
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -194.227356
Layer 0 weight grad [0][0] = 96.356911


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8421
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -193.185608
Layer 0 weight grad [0][0] = 428.570831


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8422
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1082.306641
Layer 0 weight grad [0][0] = 491.673096


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 8423
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -194.870911
Layer 0 weight grad [0][0] = 113.990189


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8424
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -194.458679
Layer 0 weight grad [0][0] = 1525.394653


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8425
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 717.180603
Layer 0 weight grad [0][0] = 427.802338


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8426
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -224.371552
Layer 0 weight grad [0][0] = -1790.007202


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8427
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -223.765686
Layer 0 weight grad [0][0] = 107.159492


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8428
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -222.394104
Layer 0 weight grad [0][0] = 119.666374


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8429
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -221.376343
Layer 0 weight grad [0][0] = 59.726448


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8430
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1067.507324
Layer 0 weight grad [0][0] = 101.541763


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8431
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -223.640564
Layer 0 weight grad [0][0] = 115.954742


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8432
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -223.076111
Layer 0 weight grad [0][0] = 1199.253662


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8433
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -222.277344
Layer 0 weight grad [0][0] = 104.658890


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8434
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1087.310181
Layer 0 weight grad [0][0] = 550.242981


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8435
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1128.820312
Layer 0 weight grad [0][0] = 107.303467


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 8436
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -230.551437
Layer 0 weight grad [0][0] = 1539.864624


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 8437
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -260.248474
Layer 0 weight grad [0][0] = 1271.124634


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8438
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -290.588104
Layer 0 weight grad [0][0] = 102.482841


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8439
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -289.612640
Layer 0 weight grad [0][0] = 125.676079


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8440
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -288.329926
Layer 0 weight grad [0][0] = -122.372711


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8441
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -287.681213
Layer 0 weight grad [0][0] = 112.891159


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8442
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -287.480652
Layer 0 weight grad [0][0] = 124.159424


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8443
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1081.938354
Layer 0 weight grad [0][0] = 135.335251


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8444
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -292.433167
Layer 0 weight grad [0][0] = -1755.846924


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8445
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -291.499512
Layer 0 weight grad [0][0] = -82.143875


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8446
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1124.883057
Layer 0 weight grad [0][0] = -148.309570


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8447
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -297.243011
Layer 0 weight grad [0][0] = 1584.262939


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8448
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -327.590240
Layer 0 weight grad [0][0] = 152.004791


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8449
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -327.293152
Layer 0 weight grad [0][0] = 142.029816


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8450
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -327.190002
Layer 0 weight grad [0][0] = 124.609802


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8451
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -326.815094
Layer 0 weight grad [0][0] = 141.076172


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8452
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1479.400269
Layer 0 weight grad [0][0] = 156.905502


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8453
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -324.662201
Layer 0 weight grad [0][0] = 2032.750122


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8454
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -354.975372
Layer 0 weight grad [0][0] = 133.940094


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8455
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -354.614471
Layer 0 weight grad [0][0] = 128.539642


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8456
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -352.939697
Layer 0 weight grad [0][0] = 123.058235


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 8457
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -352.098694
Layer 0 weight grad [0][0] = 117.014641


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8458
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -351.033539
Layer 0 weight grad [0][0] = 116.440903


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8459
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1733.303223
Layer 0 weight grad [0][0] = 109.170090


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8460
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -350.754364
Layer 0 weight grad [0][0] = 116.771423


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8461
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1067.838013
Layer 0 weight grad [0][0] = 1696.613281


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 8462
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -385.769440
Layer 0 weight grad [0][0] = -259.250000


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 8463
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -385.465332
Layer 0 weight grad [0][0] = 585.696167


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 8464
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1069.159058
Layer 0 weight grad [0][0] = 136.846359


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8465
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1113.492676
Layer 0 weight grad [0][0] = 128.215012


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 8466
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -394.355133
Layer 0 weight grad [0][0] = 522.986877


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8467
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -394.133972
Layer 0 weight grad [0][0] = 142.760986


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8468
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1994.002319
Layer 0 weight grad [0][0] = -1816.784790


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8469
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -389.945129
Layer 0 weight grad [0][0] = 1065.238525


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8470
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -390.680389
Layer 0 weight grad [0][0] = 170.767746


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8471
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -390.333527
Layer 0 weight grad [0][0] = -145.656509


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8472
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -390.842407
Layer 0 weight grad [0][0] = 157.535126


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8473
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -390.397858
Layer 0 weight grad [0][0] = 1825.623169


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8474
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -420.652161
Layer 0 weight grad [0][0] = 1058.458496


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8475
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -420.449249
Layer 0 weight grad [0][0] = 679.091125


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8476
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -420.543518
Layer 0 weight grad [0][0] = -1123.061035


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8477
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2012.637695
Layer 0 weight grad [0][0] = 805.703735


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8478
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -385.984161
Layer 0 weight grad [0][0] = 125.375206


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8479
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -385.169434
Layer 0 weight grad [0][0] = 118.309464


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8480
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -384.825745
Layer 0 weight grad [0][0] = 141.188538


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8481
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1058.841187
Layer 0 weight grad [0][0] = 135.405106


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8482
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -389.609741
Layer 0 weight grad [0][0] = 116.387535


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8483
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -389.544617
Layer 0 weight grad [0][0] = 860.435547


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8484
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -389.664856
Layer 0 weight grad [0][0] = 177.470901


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8485
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -391.078644
Layer 0 weight grad [0][0] = 171.826309


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8486
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -391.165070
Layer 0 weight grad [0][0] = -1365.660034


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8487
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -355.350769
Layer 0 weight grad [0][0] = 160.322845


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8488
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -356.221741
Layer 0 weight grad [0][0] = 430.138000


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8489
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -357.640289
Layer 0 weight grad [0][0] = 174.012268


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8490
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -358.384033
Layer 0 weight grad [0][0] = 194.927704


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8491
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -361.141632
Layer 0 weight grad [0][0] = -171.204971


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8492
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1754.117310
Layer 0 weight grad [0][0] = -1552.438354


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8493
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -311.073639
Layer 0 weight grad [0][0] = 14.223257


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8494
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1381.704468
Layer 0 weight grad [0][0] = 182.834686


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8495
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -306.703430
Layer 0 weight grad [0][0] = -1500.441406


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8496
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -309.048096
Layer 0 weight grad [0][0] = 345.479156


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 8497
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -310.254456
Layer 0 weight grad [0][0] = -1641.184814


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8498
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -312.846832
Layer 0 weight grad [0][0] = 222.184402


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8499
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1049.366211
Layer 0 weight grad [0][0] = 242.956070


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8500
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -319.899048
Layer 0 weight grad [0][0] = 254.059219


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8501
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -322.216339
Layer 0 weight grad [0][0] = 623.626709


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8502
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -324.409027
Layer 0 weight grad [0][0] = -1674.459229


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8503
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -326.233276
Layer 0 weight grad [0][0] = -2265.567627


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8504
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -273.153625
Layer 0 weight grad [0][0] = 431.627106


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8505
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -275.514252
Layer 0 weight grad [0][0] = -4281.545898


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8506
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1179.629150
Layer 0 weight grad [0][0] = 266.178131


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8507
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -228.487061
Layer 0 weight grad [0][0] = 544.667603


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8508
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -231.787582
Layer 0 weight grad [0][0] = 263.557465


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8509
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -233.994232
Layer 0 weight grad [0][0] = 1710.259766


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8510
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1163.083130
Layer 0 weight grad [0][0] = 248.140579


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8511
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -273.446655
Layer 0 weight grad [0][0] = 132.721985


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8512
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1176.470459
Layer 0 weight grad [0][0] = -1939.816284


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8513
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -280.549530
Layer 0 weight grad [0][0] = 264.324707


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8514
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -283.703857
Layer 0 weight grad [0][0] = 257.651672


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 8515
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -285.473602
Layer 0 weight grad [0][0] = 1205.169556


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8516
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -287.522400
Layer 0 weight grad [0][0] = 768.832825


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8517
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -290.413116
Layer 0 weight grad [0][0] = -4594.268066


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8518
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1220.395142
Layer 0 weight grad [0][0] = 597.546204


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8519
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -232.210434
Layer 0 weight grad [0][0] = 253.992996


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8520
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 662.354187
Layer 0 weight grad [0][0] = -1823.185669


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 8521
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1248.757202
Layer 0 weight grad [0][0] = -2092.858643


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8522
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -180.515533
Layer 0 weight grad [0][0] = 228.637787


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8523
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -182.800064
Layer 0 weight grad [0][0] = 1699.939697


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8524
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1284.062134
Layer 0 weight grad [0][0] = -4618.369629


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8525
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -158.025742
Layer 0 weight grad [0][0] = -1593.490723


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8526
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -161.331360
Layer 0 weight grad [0][0] = 198.572113


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8527
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -165.043671
Layer 0 weight grad [0][0] = 1316.707031


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8528
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -167.776154
Layer 0 weight grad [0][0] = 485.587158


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 8529
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -171.984344
Layer 0 weight grad [0][0] = 1537.078125


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8530
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -206.008240
Layer 0 weight grad [0][0] = 136.603622


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8531
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -209.549225
Layer 0 weight grad [0][0] = 145.343307


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8532
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -212.717041
Layer 0 weight grad [0][0] = 161.152206


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8533
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -215.888916
Layer 0 weight grad [0][0] = 173.571335


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 8534
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 439.688080
Layer 0 weight grad [0][0] = 179.753601


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8535
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1300.765381
Layer 0 weight grad [0][0] = 204.959061


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8536
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -226.828125
Layer 0 weight grad [0][0] = 213.141006


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 8537
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -228.725693
Layer 0 weight grad [0][0] = 1822.735352


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8538
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -265.960724
Layer 0 weight grad [0][0] = -7.784801


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 8539
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 888.191101
Layer 0 weight grad [0][0] = -29.810707


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8540
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 911.293030
Layer 0 weight grad [0][0] = 588.047119


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8541
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -273.793854
Layer 0 weight grad [0][0] = 243.548553


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8542
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -276.399139
Layer 0 weight grad [0][0] = 235.060043


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8543
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -280.118591
Layer 0 weight grad [0][0] = 209.194244


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8544
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -283.804382
Layer 0 weight grad [0][0] = 587.017944


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8545
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -286.675385
Layer 0 weight grad [0][0] = 209.215927


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 8546
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -290.392090
Layer 0 weight grad [0][0] = -1761.016479


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8547
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -293.961548
Layer 0 weight grad [0][0] = 215.399673


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8548
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1116.341797
Layer 0 weight grad [0][0] = 1777.437378


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8549
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -327.143341
Layer 0 weight grad [0][0] = 219.524170


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8550
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -329.948273
Layer 0 weight grad [0][0] = 232.301529


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8551
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -333.183868
Layer 0 weight grad [0][0] = -1908.967041


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8552
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -336.081482
Layer 0 weight grad [0][0] = 76.491539


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8553
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -339.456390
Layer 0 weight grad [0][0] = 249.416260


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8554
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -341.637634
Layer 0 weight grad [0][0] = 241.159576


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8555
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1557.759277
Layer 0 weight grad [0][0] = -105.444878


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8556
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -338.474396
Layer 0 weight grad [0][0] = -2259.858154


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8557
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -286.797821
Layer 0 weight grad [0][0] = 256.077820


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8558
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -289.422821
Layer 0 weight grad [0][0] = 248.865875


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8559
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -293.342712
Layer 0 weight grad [0][0] = 16.296808


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8560
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -296.660614
Layer 0 weight grad [0][0] = 1909.744751


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8561
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -335.366394
Layer 0 weight grad [0][0] = 247.669449


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8562
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -337.939484
Layer 0 weight grad [0][0] = -363.134827


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8563
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -376.371307
Layer 0 weight grad [0][0] = -2375.986816


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8564
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1857.393555
Layer 0 weight grad [0][0] = 256.723633


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8565
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -367.841400
Layer 0 weight grad [0][0] = -526.507202


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8566
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -406.474060
Layer 0 weight grad [0][0] = 248.159515


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8567
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -408.586792
Layer 0 weight grad [0][0] = 235.398193


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8568
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -412.067505
Layer 0 weight grad [0][0] = -2074.719238


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8569
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -414.744080
Layer 0 weight grad [0][0] = 247.899780


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8570
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -417.493866
Layer 0 weight grad [0][0] = 274.216370


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8571
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -420.450745
Layer 0 weight grad [0][0] = 283.986206


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8572
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -423.928711
Layer 0 weight grad [0][0] = 299.204376


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8573
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2300.257080
Layer 0 weight grad [0][0] = 300.043701


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8574
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -408.257629
Layer 0 weight grad [0][0] = 50.569885


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8575
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -411.817261
Layer 0 weight grad [0][0] = 508.202637


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8576
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -415.000519
Layer 0 weight grad [0][0] = 312.249023


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8577
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -418.156372
Layer 0 weight grad [0][0] = 1926.295776


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8578
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -459.161560
Layer 0 weight grad [0][0] = -2072.248779


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8579
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -461.759003
Layer 0 weight grad [0][0] = 298.547516


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8580
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 980.837219
Layer 0 weight grad [0][0] = -111.876999


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 8581
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2754.770752
Layer 0 weight grad [0][0] = 283.735840


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8582
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -449.910461
Layer 0 weight grad [0][0] = 278.179352


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8583
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2807.053223
Layer 0 weight grad [0][0] = 301.094086


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8584
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -424.958008
Layer 0 weight grad [0][0] = 0.149016


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8585
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -429.095001
Layer 0 weight grad [0][0] = -140.674805


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8586
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -433.385773
Layer 0 weight grad [0][0] = 277.464569


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8587
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -436.984833
Layer 0 weight grad [0][0] = 2017.134277


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8588
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -478.238342
Layer 0 weight grad [0][0] = 289.663818


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8589
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -481.681671
Layer 0 weight grad [0][0] = -2083.740234


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 8590
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -486.049835
Layer 0 weight grad [0][0] = 284.824860


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8591
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -490.125488
Layer 0 weight grad [0][0] = -123.537445


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8592
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -493.946808
Layer 0 weight grad [0][0] = -123.329422


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8593
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -497.937012
Layer 0 weight grad [0][0] = 323.539703


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 8594
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 720.386902
Layer 0 weight grad [0][0] = 250.624512


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8595
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -512.387024
Layer 0 weight grad [0][0] = -73.256668


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8596
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -517.394348
Layer 0 weight grad [0][0] = 1800.865845


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8597
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -555.811340
Layer 0 weight grad [0][0] = 265.160309


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8598
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3657.373779
Layer 0 weight grad [0][0] = 261.454407


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8599
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -532.056702
Layer 0 weight grad [0][0] = -368.390350


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8600
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -572.812012
Layer 0 weight grad [0][0] = 98.018333


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 8601
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 569.028442
Layer 0 weight grad [0][0] = 270.225891


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8602
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4049.262695
Layer 0 weight grad [0][0] = 1896.911255


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8603
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -590.759827
Layer 0 weight grad [0][0] = -1854.473999


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8604
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4427.329590
Layer 0 weight grad [0][0] = -9.340756


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8605
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -562.737610
Layer 0 weight grad [0][0] = -2597.346191


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8606
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 108.485596
Layer 0 weight grad [0][0] = 242.245316


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 8607
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -526.932556
Layer 0 weight grad [0][0] = 246.443832


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8608
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 207.966751
Layer 0 weight grad [0][0] = -1755.591553


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8609
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4045.531982
Layer 0 weight grad [0][0] = 1151.258789


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8610
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -51.052444
Layer 0 weight grad [0][0] = 253.612869


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8611
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4103.407227
Layer 0 weight grad [0][0] = -86.695000


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8612
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -518.522278
Layer 0 weight grad [0][0] = 1779.323486


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8613
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -556.919983
Layer 0 weight grad [0][0] = 227.150970


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8614
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -562.009766
Layer 0 weight grad [0][0] = 238.022079


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8615
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -566.960754
Layer 0 weight grad [0][0] = 221.859421


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8616
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -571.875183
Layer 0 weight grad [0][0] = 216.646393


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8617
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -576.114380
Layer 0 weight grad [0][0] = 1702.413574


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8618
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -613.324829
Layer 0 weight grad [0][0] = 207.100662


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8619
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -618.417358
Layer 0 weight grad [0][0] = 251.947479


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8620
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -621.939819
Layer 0 weight grad [0][0] = 205.082855


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8621
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5150.863281
Layer 0 weight grad [0][0] = 218.267593


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8622
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -593.224915
Layer 0 weight grad [0][0] = 213.637650


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8623
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5204.407227
Layer 0 weight grad [0][0] = 219.439514


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8624
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -564.974792
Layer 0 weight grad [0][0] = -1572.072876


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8625
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -569.337463
Layer 0 weight grad [0][0] = 774.920654


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8626
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -572.798340
Layer 0 weight grad [0][0] = 222.184937


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8627
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -577.962463
Layer 0 weight grad [0][0] = 175.511551


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8628
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -582.151428
Layer 0 weight grad [0][0] = 172.562515


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8629
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -587.122131
Layer 0 weight grad [0][0] = -2055.941895


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8630
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -543.102051
Layer 0 weight grad [0][0] = -242.445801


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8631
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -488.356689
Layer 0 weight grad [0][0] = 166.079376


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8632
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -556.056824
Layer 0 weight grad [0][0] = 172.555847


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8633
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -563.083496
Layer 0 weight grad [0][0] = 169.311676


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8634
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -568.795349
Layer 0 weight grad [0][0] = 171.964188


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8635
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -575.505737
Layer 0 weight grad [0][0] = -36.703850


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8636
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4927.037109
Layer 0 weight grad [0][0] = 166.706528


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8637
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -543.662354
Layer 0 weight grad [0][0] = 1602.625244


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8638
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -581.902710
Layer 0 weight grad [0][0] = 170.603973


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8639
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -588.774414
Layer 0 weight grad [0][0] = 174.507462


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8640
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -595.708923
Layer 0 weight grad [0][0] = 159.702972


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8641
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5318.836914
Layer 0 weight grad [0][0] = 1306.967407


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8642
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -872.032227
Layer 0 weight grad [0][0] = 1510.473999


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8643
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -886.238647
Layer 0 weight grad [0][0] = 150.056015


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 8644
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5421.576660
Layer 0 weight grad [0][0] = -435.067657


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8645
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5482.298828
Layer 0 weight grad [0][0] = 160.306473


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8646
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -488.580139
Layer 0 weight grad [0][0] = 167.666687


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8647
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5562.241699
Layer 0 weight grad [0][0] = 201.380112


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8648
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -454.351715
Layer 0 weight grad [0][0] = -1091.055420


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8649
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -408.394928
Layer 0 weight grad [0][0] = -1405.301758


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8650
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1837.852173
Layer 0 weight grad [0][0] = -1047.063110


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8651
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -417.643555
Layer 0 weight grad [0][0] = 207.361389


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8652
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -425.052185
Layer 0 weight grad [0][0] = -251.882629


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8653
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5224.003418
Layer 0 weight grad [0][0] = 178.275284


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8654
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -391.693542
Layer 0 weight grad [0][0] = 146.227997


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8655
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -400.003967
Layer 0 weight grad [0][0] = 291.378876


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 8656
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -435.805908
Layer 0 weight grad [0][0] = -4.539411


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8657
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -442.933044
Layer 0 weight grad [0][0] = -25.902365


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8658
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -450.833099
Layer 0 weight grad [0][0] = -176.758698


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8659
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -458.122223
Layer 0 weight grad [0][0] = 1671.564331


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8660
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -496.635315
Layer 0 weight grad [0][0] = 207.167999


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8661
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -503.558533
Layer 0 weight grad [0][0] = -263.285767


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8662
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -510.234711
Layer 0 weight grad [0][0] = 220.272064


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8663
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1823.668457
Layer 0 weight grad [0][0] = 718.705994


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8664
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -517.722778
Layer 0 weight grad [0][0] = 761.892273


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8665
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -524.551086
Layer 0 weight grad [0][0] = -1081.880493


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8666
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -531.128845
Layer 0 weight grad [0][0] = 243.526215


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8667
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -537.617737
Layer 0 weight grad [0][0] = 1680.337646


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8668
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -576.344177
Layer 0 weight grad [0][0] = 158.631317


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8669
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -583.001953
Layer 0 weight grad [0][0] = 1805.327759


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8670
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -624.044067
Layer 0 weight grad [0][0] = -331.199524


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8671
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -630.711914
Layer 0 weight grad [0][0] = 198.021088


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8672
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -636.971741
Layer 0 weight grad [0][0] = 197.436905


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8673
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -643.756592
Layer 0 weight grad [0][0] = 1871.619995


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8674
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -685.994263
Layer 0 weight grad [0][0] = 223.667221


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8675
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -691.720703
Layer 0 weight grad [0][0] = -139.587677


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8676
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -698.649536
Layer 0 weight grad [0][0] = 254.650452


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8677
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -703.888123
Layer 0 weight grad [0][0] = -3357.509277


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8678
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -661.058899
Layer 0 weight grad [0][0] = 191.301987


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8679
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -666.892151
Layer 0 weight grad [0][0] = 186.770599


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8680
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -672.352295
Layer 0 weight grad [0][0] = 218.617249


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8681
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -677.973816
Layer 0 weight grad [0][0] = 235.649689


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8682
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6600.810547
Layer 0 weight grad [0][0] = -1017.184326


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8683
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6652.359375
Layer 0 weight grad [0][0] = 220.694443


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8684
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6706.398438
Layer 0 weight grad [0][0] = -969.895569


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8685
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -559.522461
Layer 0 weight grad [0][0] = -934.722717


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8686
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -565.766296
Layer 0 weight grad [0][0] = -2609.871826


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8687
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -522.583374
Layer 0 weight grad [0][0] = -7.009356


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8688
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2092.062988
Layer 0 weight grad [0][0] = -927.853394


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8689
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -532.074280
Layer 0 weight grad [0][0] = 2079.632812


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8690
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -577.964844
Layer 0 weight grad [0][0] = -1967.338257


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8691
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -535.671997
Layer 0 weight grad [0][0] = -211.840775


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8692
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1916.327637
Layer 0 weight grad [0][0] = 302.910248


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8693
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -547.754333
Layer 0 weight grad [0][0] = 298.276215


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 8694
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -555.742920
Layer 0 weight grad [0][0] = 247.466583


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8695
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6272.261230
Layer 0 weight grad [0][0] = 257.791229


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8696
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -509.965698
Layer 0 weight grad [0][0] = 265.223846


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8697
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -516.646851
Layer 0 weight grad [0][0] = -216.976334


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8698
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -523.771057
Layer 0 weight grad [0][0] = 215.000290


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8699
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -531.570923
Layer 0 weight grad [0][0] = 221.474564


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8700
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2056.916748
Layer 0 weight grad [0][0] = 253.733215


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8701
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -544.351929
Layer 0 weight grad [0][0] = 1786.475586


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8702
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -585.378967
Layer 0 weight grad [0][0] = 271.506500


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8703
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -591.934631
Layer 0 weight grad [0][0] = 1210.536743


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8704
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -629.956238
Layer 0 weight grad [0][0] = 258.794434


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8705
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -637.600281
Layer 0 weight grad [0][0] = 259.992737


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8706
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -644.041016
Layer 0 weight grad [0][0] = 267.980957


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8707
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -651.807800
Layer 0 weight grad [0][0] = 207.926743


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8708
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -658.691101
Layer 0 weight grad [0][0] = 425.370331


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 8709
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -666.303528
Layer 0 weight grad [0][0] = 259.030304


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8710
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -674.070740
Layer 0 weight grad [0][0] = -335.842957


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8711
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -680.756042
Layer 0 weight grad [0][0] = 259.235748


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8712
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -687.856445
Layer 0 weight grad [0][0] = 233.387955


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8713
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -694.669922
Layer 0 weight grad [0][0] = 240.933624


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8714
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7080.628906
Layer 0 weight grad [0][0] = 195.825668


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8715
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -653.021118
Layer 0 weight grad [0][0] = 205.190826


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8716
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -660.007324
Layer 0 weight grad [0][0] = 203.058899


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8717
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7170.794434
Layer 0 weight grad [0][0] = -2625.703369


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8718
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -570.768616
Layer 0 weight grad [0][0] = -875.771912


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8719
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2195.873779
Layer 0 weight grad [0][0] = 231.188553


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8720
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -589.404053
Layer 0 weight grad [0][0] = -408.815552


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8721
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6858.191895
Layer 0 weight grad [0][0] = -358.593475


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8722
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -546.079651
Layer 0 weight grad [0][0] = -291.360718


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8723
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -554.229736
Layer 0 weight grad [0][0] = -1305.581787


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8724
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -516.158020
Layer 0 weight grad [0][0] = -217.481339


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8725
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -524.942749
Layer 0 weight grad [0][0] = 297.438721


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8726
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -532.469360
Layer 0 weight grad [0][0] = -1210.489624


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8727
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -540.213074
Layer 0 weight grad [0][0] = 325.274139


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8728
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -547.674438
Layer 0 weight grad [0][0] = 287.054749


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8729
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6653.406738
Layer 0 weight grad [0][0] = 346.980377


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8730
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -507.218628
Layer 0 weight grad [0][0] = 363.392334


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 8731
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -515.053406
Layer 0 weight grad [0][0] = -1072.591187


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8732
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -522.584473
Layer 0 weight grad [0][0] = -90.228447


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8733
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -529.834595
Layer 0 weight grad [0][0] = 163.974548


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8734
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -536.759705
Layer 0 weight grad [0][0] = -2.665904


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8735
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -543.092590
Layer 0 weight grad [0][0] = 473.221375


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8736
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -550.307739
Layer 0 weight grad [0][0] = 483.017517


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8737
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -556.805420
Layer 0 weight grad [0][0] = 508.680054


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8738
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -563.071228
Layer 0 weight grad [0][0] = -1473.868652


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8739
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -569.619751
Layer 0 weight grad [0][0] = -1856.276855


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8740
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -577.050476
Layer 0 weight grad [0][0] = 549.458374


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8741
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -583.314880
Layer 0 weight grad [0][0] = 258.289337


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8742
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -590.160767
Layer 0 weight grad [0][0] = 445.245880


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8743
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -598.272461
Layer 0 weight grad [0][0] = -1390.481323


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8744
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -562.815369
Layer 0 weight grad [0][0] = 6027.120605


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8745
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -570.417542
Layer 0 weight grad [0][0] = 576.232971


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8746
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6564.537598
Layer 0 weight grad [0][0] = -641.436584


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8747
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -524.741150
Layer 0 weight grad [0][0] = 584.718262


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8748
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -530.769836
Layer 0 weight grad [0][0] = -818.550110


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8749
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -537.178040
Layer 0 weight grad [0][0] = -1297.698364


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 8750
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -543.438538
Layer 0 weight grad [0][0] = 629.218750


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8751
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -549.307373
Layer 0 weight grad [0][0] = 652.642029


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8752
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -556.405396
Layer 0 weight grad [0][0] = 1538.862427


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 8753
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -582.718994
Layer 0 weight grad [0][0] = -1563.461426


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8754
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -589.231506
Layer 0 weight grad [0][0] = 662.378845


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8755
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -595.700134
Layer 0 weight grad [0][0] = 680.741333


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8756
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -602.014038
Layer 0 weight grad [0][0] = 690.684692


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8757
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -607.279602
Layer 0 weight grad [0][0] = 689.909607


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8758
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -614.590698
Layer 0 weight grad [0][0] = 678.894592


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8759
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6950.099121
Layer 0 weight grad [0][0] = 678.977661


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8760
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -569.271057
Layer 0 weight grad [0][0] = 1516.572754


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8761
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -594.356628
Layer 0 weight grad [0][0] = 884.349548


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8762
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -620.363525
Layer 0 weight grad [0][0] = 624.337402


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8763
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -626.614807
Layer 0 weight grad [0][0] = 615.888733


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8764
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -633.268921
Layer 0 weight grad [0][0] = 495.027313


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8765
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -639.181763
Layer 0 weight grad [0][0] = 632.164246


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 8766
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -645.977051
Layer 0 weight grad [0][0] = 629.185303


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8767
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -652.841187
Layer 0 weight grad [0][0] = 639.686096


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8768
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7461.441406
Layer 0 weight grad [0][0] = -1207.377686


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8769
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -615.252258
Layer 0 weight grad [0][0] = 677.251343


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8770
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -621.955994
Layer 0 weight grad [0][0] = 687.726440


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8771
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -629.017151
Layer 0 weight grad [0][0] = 705.984802


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8772
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -636.469116
Layer 0 weight grad [0][0] = 168.008942


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8773
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -643.605164
Layer 0 weight grad [0][0] = -505.923615


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8774
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -663.699097
Layer 0 weight grad [0][0] = -1054.672852


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8775
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -631.291199
Layer 0 weight grad [0][0] = 711.590881


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8776
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2312.325195
Layer 0 weight grad [0][0] = -972.200684


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8777
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -650.322876
Layer 0 weight grad [0][0] = -1636.968506


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 8778
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7450.069336
Layer 0 weight grad [0][0] = -1344.233276


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8779
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -613.945129
Layer 0 weight grad [0][0] = 743.285156


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8780
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -620.572510
Layer 0 weight grad [0][0] = -1301.393433


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8781
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -627.028748
Layer 0 weight grad [0][0] = 708.093384


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8782
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -633.389648
Layer 0 weight grad [0][0] = 723.768738


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8783
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -639.669983
Layer 0 weight grad [0][0] = 725.290588


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8784
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -646.953491
Layer 0 weight grad [0][0] = 741.041321


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8785
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -654.144226
Layer 0 weight grad [0][0] = 759.203247


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8786
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -661.258972
Layer 0 weight grad [0][0] = 1718.367554


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8787
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -688.997742
Layer 0 weight grad [0][0] = 1730.736206


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8788
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 8041.685547
Layer 0 weight grad [0][0] = -822.215088


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8789
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -671.810913
Layer 0 weight grad [0][0] = 710.303406


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8790
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -678.680054
Layer 0 weight grad [0][0] = 1885.147461


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 8791
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -709.183899
Layer 0 weight grad [0][0] = -3740.507080


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8792
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -674.072144
Layer 0 weight grad [0][0] = 448.435486


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 8793
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -679.812866
Layer 0 weight grad [0][0] = -897.400513


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8794
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -711.465576
Layer 0 weight grad [0][0] = 768.517456


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8795
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -717.418945
Layer 0 weight grad [0][0] = -1436.689697


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8796
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 8246.452148
Layer 0 weight grad [0][0] = 816.047363


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8797
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -674.469177
Layer 0 weight grad [0][0] = 824.184998


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8798
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -680.315125
Layer 0 weight grad [0][0] = 762.177917


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8799
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -686.578186
Layer 0 weight grad [0][0] = -1492.498169


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8800
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2792.807129
Layer 0 weight grad [0][0] = 862.768738


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 8801
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -711.069458
Layer 0 weight grad [0][0] = 906.736816


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8802
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -716.707031
Layer 0 weight grad [0][0] = 950.357239


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8803
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -722.986938
Layer 0 weight grad [0][0] = 735.131348


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8804
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -728.631958
Layer 0 weight grad [0][0] = -4287.819824


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8805
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -698.620667
Layer 0 weight grad [0][0] = 969.500366


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8806
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -703.931824
Layer 0 weight grad [0][0] = -1559.218018


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8807
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2407.418945
Layer 0 weight grad [0][0] = 1018.253235


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8808
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -729.781555
Layer 0 weight grad [0][0] = 992.508606


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8809
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -735.172180
Layer 0 weight grad [0][0] = 7567.745117


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8810
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -740.300049
Layer 0 weight grad [0][0] = -1731.735840


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8811
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -746.111755
Layer 0 weight grad [0][0] = 956.839783


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8812
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -751.576355
Layer 0 weight grad [0][0] = -2161.503418


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8813
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2107.504395
Layer 0 weight grad [0][0] = 924.216370


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8814
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -781.937561
Layer 0 weight grad [0][0] = 952.440735


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8815
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -787.023438
Layer 0 weight grad [0][0] = 949.802551


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8816
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -792.610535
Layer 0 weight grad [0][0] = 958.914368


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8817
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -798.022949
Layer 0 weight grad [0][0] = 927.362915


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8818
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -803.233459
Layer 0 weight grad [0][0] = 2089.918213


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 8819
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -808.034363
Layer 0 weight grad [0][0] = -2676.353760


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8820
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1771.109619
Layer 0 weight grad [0][0] = -878.639343


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8821
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -798.270569
Layer 0 weight grad [0][0] = -1702.582886


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8822
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -764.405518
Layer 0 weight grad [0][0] = -3301.330566


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8823
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1456.229980
Layer 0 weight grad [0][0] = 801.531982


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8824
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -793.115356
Layer 0 weight grad [0][0] = 831.836853


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8825
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -797.532471
Layer 0 weight grad [0][0] = 861.249573


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 8826
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1208.956909
Layer 0 weight grad [0][0] = -2690.996338


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8827
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -822.234436
Layer 0 weight grad [0][0] = -2105.923584


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8828
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -827.227051
Layer 0 weight grad [0][0] = -754.873352


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8829
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7320.149414
Layer 0 weight grad [0][0] = 885.468445


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8830
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -754.783264
Layer 0 weight grad [0][0] = 881.354736


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8831
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -760.065247
Layer 0 weight grad [0][0] = -2536.825195


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8832
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -765.048035
Layer 0 weight grad [0][0] = -2161.072021


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8833
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1259.941895
Layer 0 weight grad [0][0] = 829.393250


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8834
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -791.595459
Layer 0 weight grad [0][0] = -2774.876221


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8835
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -795.611755
Layer 0 weight grad [0][0] = 874.992798


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8836
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1044.883911
Layer 0 weight grad [0][0] = 894.730774


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8837
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -821.860046
Layer 0 weight grad [0][0] = -2372.835693


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8838
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -825.637085
Layer 0 weight grad [0][0] = -2656.555664


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8839
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -829.048096
Layer 0 weight grad [0][0] = 973.962219


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8840
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -832.195862
Layer 0 weight grad [0][0] = 959.539917


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8841
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -836.046265
Layer 0 weight grad [0][0] = 993.168152


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8842
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -838.612000
Layer 0 weight grad [0][0] = -651.221680


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8843
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -805.735962
Layer 0 weight grad [0][0] = 1000.490906


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8844
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7174.067383
Layer 0 weight grad [0][0] = 1022.526550


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8845
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -769.726807
Layer 0 weight grad [0][0] = 947.661682


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8846
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -773.242371
Layer 0 weight grad [0][0] = -619.880554


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8847
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -743.033203
Layer 0 weight grad [0][0] = -746.480225


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8848
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -712.824646
Layer 0 weight grad [0][0] = 902.550476


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8849
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -717.004395
Layer 0 weight grad [0][0] = 873.320801


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8850
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -719.995300
Layer 0 weight grad [0][0] = 682.373535


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8851
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -723.375061
Layer 0 weight grad [0][0] = -4718.614258


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8852
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -697.031921
Layer 0 weight grad [0][0] = -3279.538330


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8853
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -699.354675
Layer 0 weight grad [0][0] = 847.383423


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8854
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -702.425842
Layer 0 weight grad [0][0] = -3204.800049


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8855
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -704.870300
Layer 0 weight grad [0][0] = 2174.312500


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8856
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -738.349792
Layer 0 weight grad [0][0] = 89.413506


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8857
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -741.672058
Layer 0 weight grad [0][0] = 850.277771


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8858
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -745.231995
Layer 0 weight grad [0][0] = 209.197647


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8859
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -626.974243
Layer 0 weight grad [0][0] = -3391.399902


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8860
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -771.508667
Layer 0 weight grad [0][0] = -331.545135


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8861
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -748.814209
Layer 0 weight grad [0][0] = 882.493103


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8862
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -331.235870
Layer 0 weight grad [0][0] = -3185.702148


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8863
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -777.350403
Layer 0 weight grad [0][0] = 931.858276


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8864
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -780.701355
Layer 0 weight grad [0][0] = -3043.036865


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8865
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -785.533569
Layer 0 weight grad [0][0] = 916.802246


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8866
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -789.703369
Layer 0 weight grad [0][0] = -366.397217


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8867
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -794.372131
Layer 0 weight grad [0][0] = -2917.910889


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8868
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -799.169678
Layer 0 weight grad [0][0] = -3305.004639


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8869
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -803.829529
Layer 0 weight grad [0][0] = -265.218170


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8870
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -780.641846
Layer 0 weight grad [0][0] = 191.610321


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8871
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -785.243103
Layer 0 weight grad [0][0] = 4306.133789


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8872
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6120.668945
Layer 0 weight grad [0][0] = 926.595032


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 8873
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6178.287109
Layer 0 weight grad [0][0] = 184.144684


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8874
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -682.613708
Layer 0 weight grad [0][0] = 938.026672


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8875
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -686.926941
Layer 0 weight grad [0][0] = 974.215698


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8876
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -690.705566
Layer 0 weight grad [0][0] = -42.548359


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8877
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -672.424316
Layer 0 weight grad [0][0] = 976.557251


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8878
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -676.497986
Layer 0 weight grad [0][0] = 1004.232422


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8879
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -680.430542
Layer 0 weight grad [0][0] = 759.408569


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8880
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -684.634277
Layer 0 weight grad [0][0] = 976.143127


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8881
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -688.314087
Layer 0 weight grad [0][0] = 658.035217


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8882
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -692.488892
Layer 0 weight grad [0][0] = 970.211060


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8883
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -696.057068
Layer 0 weight grad [0][0] = 1002.845825


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8884
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6023.551758
Layer 0 weight grad [0][0] = 985.302307


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8885
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -644.018188
Layer 0 weight grad [0][0] = -3193.183838


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8886
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -647.382751
Layer 0 weight grad [0][0] = 382.507751


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8887
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -650.452698
Layer 0 weight grad [0][0] = 936.804932


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8888
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -653.586731
Layer 0 weight grad [0][0] = -140.958572


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8889
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -656.366333
Layer 0 weight grad [0][0] = 910.172363


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8890
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -660.049255
Layer 0 weight grad [0][0] = -3688.993408


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8891
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -663.366699
Layer 0 weight grad [0][0] = 913.870422


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8892
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -666.486206
Layer 0 weight grad [0][0] = -2940.154541


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8893
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -669.445862
Layer 0 weight grad [0][0] = 1888.824951


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8894
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -694.834412
Layer 0 weight grad [0][0] = 914.636353


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8895
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -698.440186
Layer 0 weight grad [0][0] = 422.182922


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8896
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -701.533447
Layer 0 weight grad [0][0] = -169.020798


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8897
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -705.435913
Layer 0 weight grad [0][0] = 906.217773


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8898
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -708.477539
Layer 0 weight grad [0][0] = 925.017273


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8899
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -710.797424
Layer 0 weight grad [0][0] = 908.340881


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8900
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -713.969666
Layer 0 weight grad [0][0] = 929.064941


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8901
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -716.435913
Layer 0 weight grad [0][0] = 868.763611


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8902
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6141.601074
Layer 0 weight grad [0][0] = 904.252747


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8903
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -853.723633
Layer 0 weight grad [0][0] = -16.688881


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8904
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -690.885559
Layer 0 weight grad [0][0] = 1232.890625


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8905
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -716.751770
Layer 0 weight grad [0][0] = 899.053101


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8906
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -721.403625
Layer 0 weight grad [0][0] = -946.898743


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8907
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -723.861877
Layer 0 weight grad [0][0] = 147.402222


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8908
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -727.151978
Layer 0 weight grad [0][0] = 172.266190


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8909
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -730.763550
Layer 0 weight grad [0][0] = 878.048096


Training loss: 2.302585
Training accuracy: 0.375000

epoch: 8910
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -733.860352
Layer 0 weight grad [0][0] = 908.723083


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8911
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -736.676941
Layer 0 weight grad [0][0] = -111.145737


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8912
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -718.655823
Layer 0 weight grad [0][0] = 834.945435


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8913
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -336.586182
Layer 0 weight grad [0][0] = 829.314514


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8914
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -738.015930
Layer 0 weight grad [0][0] = 127.714333


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8915
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -741.794067
Layer 0 weight grad [0][0] = 794.630859


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8916
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -745.418884
Layer 0 weight grad [0][0] = 2252.550293


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8917
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -780.328796
Layer 0 weight grad [0][0] = 808.571289


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8918
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -783.345886
Layer 0 weight grad [0][0] = 840.942627


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8919
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2.932811
Layer 0 weight grad [0][0] = 862.713135


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8920
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -804.935547
Layer 0 weight grad [0][0] = 894.436584


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8921
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -808.897705
Layer 0 weight grad [0][0] = 265.022400


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 8922
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -796.333801
Layer 0 weight grad [0][0] = 1012.559387


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8923
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -799.517517
Layer 0 weight grad [0][0] = 194.143814


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8924
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 372.475342
Layer 0 weight grad [0][0] = 869.863464


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8925
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 565.957886
Layer 0 weight grad [0][0] = 826.647217


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 8926
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -830.647888
Layer 0 weight grad [0][0] = 814.634705


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8927
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -833.955017
Layer 0 weight grad [0][0] = 444.501495


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 8928
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -838.130676
Layer 0 weight grad [0][0] = -367.018555


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8929
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5664.505371
Layer 0 weight grad [0][0] = 726.866882


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 8930
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -762.289246
Layer 0 weight grad [0][0] = 1910.153442


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8931
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -792.114197
Layer 0 weight grad [0][0] = -54.444317


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8932
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -795.929016
Layer 0 weight grad [0][0] = -2638.609131


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8933
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -801.586731
Layer 0 weight grad [0][0] = 735.483704


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8934
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -807.398315
Layer 0 weight grad [0][0] = -67.138992


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8935
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5883.598633
Layer 0 weight grad [0][0] = 774.063171


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8936
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -750.404297
Layer 0 weight grad [0][0] = -2717.910645


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8937
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -756.941589
Layer 0 weight grad [0][0] = 769.778564


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8938
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5915.891113
Layer 0 weight grad [0][0] = -569.016479


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8939
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -672.266052
Layer 0 weight grad [0][0] = 782.926331


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8940
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -263.906158
Layer 0 weight grad [0][0] = 386.437103


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8941
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -673.584900
Layer 0 weight grad [0][0] = 756.788025


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8942
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -236.428833
Layer 0 weight grad [0][0] = 773.389648


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8943
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -671.918030
Layer 0 weight grad [0][0] = 790.960999


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8944
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -680.341125
Layer 0 weight grad [0][0] = -4532.051758


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8945
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -687.435181
Layer 0 weight grad [0][0] = 798.112732


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8946
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -694.916260
Layer 0 weight grad [0][0] = 816.390198


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8947
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -13.820699
Layer 0 weight grad [0][0] = 838.135803


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8948
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -58.212730
Layer 0 weight grad [0][0] = 826.292114


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8949
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5616.717773
Layer 0 weight grad [0][0] = 718.235779


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8950
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -621.888062
Layer 0 weight grad [0][0] = -608.466248


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8951
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -598.333801
Layer 0 weight grad [0][0] = 832.658325


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8952
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -606.246582
Layer 0 weight grad [0][0] = 2812.327637


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8953
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -661.889771
Layer 0 weight grad [0][0] = 353.039154


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8954
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -364.403137
Layer 0 weight grad [0][0] = 879.870605


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8955
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -661.971130
Layer 0 weight grad [0][0] = 880.928162


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8956
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -670.057068
Layer 0 weight grad [0][0] = -2693.203369


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8957
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -678.754578
Layer 0 weight grad [0][0] = 864.700134


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8958
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -687.086731
Layer 0 weight grad [0][0] = 859.311707


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8959
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -695.235107
Layer 0 weight grad [0][0] = 880.389893


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8960
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -703.537048
Layer 0 weight grad [0][0] = 900.866699


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8961
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -713.168274
Layer 0 weight grad [0][0] = 1118.455200


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8962
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -722.377319
Layer 0 weight grad [0][0] = 869.195557


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8963
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -731.411072
Layer 0 weight grad [0][0] = 6378.593262


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8964
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -740.027954
Layer 0 weight grad [0][0] = 888.316956


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8965
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -748.930603
Layer 0 weight grad [0][0] = 2278.100098


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8966
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 536.194214
Layer 0 weight grad [0][0] = -3082.738037


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8967
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -780.481384
Layer 0 weight grad [0][0] = 895.037476


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8968
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -789.619202
Layer 0 weight grad [0][0] = 858.813538


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8969
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 625.292175
Layer 0 weight grad [0][0] = 923.703857


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8970
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -790.619446
Layer 0 weight grad [0][0] = 912.254395


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8971
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -799.112976
Layer 0 weight grad [0][0] = -1402.901367


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8972
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -843.547729
Layer 0 weight grad [0][0] = 886.002197


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8973
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6055.974121
Layer 0 weight grad [0][0] = 874.467651


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8974
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -786.938660
Layer 0 weight grad [0][0] = 823.093689


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8975
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -794.691223
Layer 0 weight grad [0][0] = 336.261902


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8976
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -802.591309
Layer 0 weight grad [0][0] = 2356.240234


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8977
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 381.064941
Layer 0 weight grad [0][0] = 804.524292


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8978
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6362.818359
Layer 0 weight grad [0][0] = 855.628113


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8979
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -776.260559
Layer 0 weight grad [0][0] = 843.741211


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8980
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -783.272095
Layer 0 weight grad [0][0] = 831.256287


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8981
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -790.609802
Layer 0 weight grad [0][0] = -4484.952637


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8982
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6381.218750
Layer 0 weight grad [0][0] = 798.949646


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8983
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -733.514709
Layer 0 weight grad [0][0] = -546.881287


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8984
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -710.867493
Layer 0 weight grad [0][0] = 99.328781


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8985
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -717.941406
Layer 0 weight grad [0][0] = 800.429504


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8986
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -725.201843
Layer 0 weight grad [0][0] = -2310.577393


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8987
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -248.441925
Layer 0 weight grad [0][0] = 46.389767


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8988
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -723.586609
Layer 0 weight grad [0][0] = 794.199585


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 8989
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -731.812195
Layer 0 weight grad [0][0] = 782.591492


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8990
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -739.542358
Layer 0 weight grad [0][0] = 685.966492


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8991
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -748.086609
Layer 0 weight grad [0][0] = 775.258484


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8992
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -756.316589
Layer 0 weight grad [0][0] = 1694.889893


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8993
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -784.271057
Layer 0 weight grad [0][0] = 1728.674194


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8994
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -813.772217
Layer 0 weight grad [0][0] = -22.069950


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 8995
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -821.943787
Layer 0 weight grad [0][0] = 826.196899


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8996
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -829.808105
Layer 0 weight grad [0][0] = 9338.992188


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 8997
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6658.818848
Layer 0 weight grad [0][0] = -1962.674805


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8998
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -808.929260
Layer 0 weight grad [0][0] = -709.138855


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 8999
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -842.297729
Layer 0 weight grad [0][0] = 1223.320801


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9000
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -850.628662
Layer 0 weight grad [0][0] = 821.812134


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9001
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6934.301270
Layer 0 weight grad [0][0] = 241.626190


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9002
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -809.061829
Layer 0 weight grad [0][0] = 26.935099


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9003
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -817.150452
Layer 0 weight grad [0][0] = 1038.614624


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9004
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -825.226074
Layer 0 weight grad [0][0] = -676.939941


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9005
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -288.776703
Layer 0 weight grad [0][0] = -1283.723755


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9006
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -375.805145
Layer 0 weight grad [0][0] = -4745.077637


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9007
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -784.911316
Layer 0 weight grad [0][0] = 864.543213


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9008
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -794.657776
Layer 0 weight grad [0][0] = -1221.177979


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9009
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -804.119019
Layer 0 weight grad [0][0] = 869.910645


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9010
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -813.190186
Layer 0 weight grad [0][0] = 1228.893555


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9011
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -832.634766
Layer 0 weight grad [0][0] = 769.444275


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9012
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -842.702820
Layer 0 weight grad [0][0] = 785.531433


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9013
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -851.647766
Layer 0 weight grad [0][0] = 791.402466


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9014
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.718360
Layer 0 weight grad [0][0] = 784.993896


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9015
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -849.422485
Layer 0 weight grad [0][0] = -989.996277


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9016
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6600.610352
Layer 0 weight grad [0][0] = -4799.623047


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9017
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -778.748901
Layer 0 weight grad [0][0] = 833.260132


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9018
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6680.433105
Layer 0 weight grad [0][0] = 826.692078


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9019
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -746.062561
Layer 0 weight grad [0][0] = 7513.541016


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9020
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -756.552673
Layer 0 weight grad [0][0] = 823.380737


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9021
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -767.416382
Layer 0 weight grad [0][0] = 843.099243


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9022
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -778.924683
Layer 0 weight grad [0][0] = 852.688843


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9023
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -487.164673
Layer 0 weight grad [0][0] = -952.161987


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9024
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -735.218689
Layer 0 weight grad [0][0] = 856.064209


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9025
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -746.650146
Layer 0 weight grad [0][0] = -4788.499512


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9026
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -756.603271
Layer 0 weight grad [0][0] = 840.577026


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 9027
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -766.406494
Layer 0 weight grad [0][0] = -4564.193848


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9028
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -778.536011
Layer 0 weight grad [0][0] = 776.298340


Training loss: 2.302585
Training accuracy: 0.375000

epoch: 9029
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -788.544739
Layer 0 weight grad [0][0] = 881.529663


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9030
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -799.324158
Layer 0 weight grad [0][0] = 2139.728516


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 9031
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -810.088318
Layer 0 weight grad [0][0] = 535.533936


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9032
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -821.013184
Layer 0 weight grad [0][0] = 846.265198


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9033
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -833.660095
Layer 0 weight grad [0][0] = -944.042236


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9034
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -806.977051
Layer 0 weight grad [0][0] = 865.399536


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9035
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 166.575546
Layer 0 weight grad [0][0] = -195.791794


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9036
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -802.696838
Layer 0 weight grad [0][0] = 876.416077


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9037
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -815.251038
Layer 0 weight grad [0][0] = 75.660599


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9038
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -828.534058
Layer 0 weight grad [0][0] = 904.971313


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9039
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -839.835571
Layer 0 weight grad [0][0] = 842.858215


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9040
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -851.288025
Layer 0 weight grad [0][0] = 631.819275


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9041
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -863.136353
Layer 0 weight grad [0][0] = -0.510808


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9042
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -875.716492
Layer 0 weight grad [0][0] = -931.736877


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9043
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -848.137756
Layer 0 weight grad [0][0] = 889.998901


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9044
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -860.404602
Layer 0 weight grad [0][0] = 881.124329


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9045
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -873.068909
Layer 0 weight grad [0][0] = -4503.335938


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9046
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -885.583130
Layer 0 weight grad [0][0] = -584.983459


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9047
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6380.186035
Layer 0 weight grad [0][0] = 922.064697


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9048
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -852.492920
Layer 0 weight grad [0][0] = 970.578918


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9049
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -865.569031
Layer 0 weight grad [0][0] = 914.316406


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9050
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -878.543823
Layer 0 weight grad [0][0] = 904.867981


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9051
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -891.044922
Layer 0 weight grad [0][0] = 927.171448


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 9052
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -903.177551
Layer 0 weight grad [0][0] = 948.653259


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9053
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -914.977966
Layer 0 weight grad [0][0] = -672.223572


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9054
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -890.918579
Layer 0 weight grad [0][0] = 960.153809


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9055
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -902.425171
Layer 0 weight grad [0][0] = -5857.726074


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9056
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 908.122375
Layer 0 weight grad [0][0] = 980.003906


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9057
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -906.269958
Layer 0 weight grad [0][0] = 913.583862


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9058
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -917.695251
Layer 0 weight grad [0][0] = 662.490723


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9059
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -929.283997
Layer 0 weight grad [0][0] = -6452.646973


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9060
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -941.184631
Layer 0 weight grad [0][0] = 951.698669


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9061
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -954.332275
Layer 0 weight grad [0][0] = 943.376038


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9062
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -968.331604
Layer 0 weight grad [0][0] = -874.478638


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9063
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -941.806458
Layer 0 weight grad [0][0] = 881.936279


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9064
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -955.835815
Layer 0 weight grad [0][0] = 1023.084961


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9065
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -969.598572
Layer 0 weight grad [0][0] = 512.773621


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9066
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -971.866577
Layer 0 weight grad [0][0] = 1067.180298


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9067
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -984.557251
Layer 0 weight grad [0][0] = 573.188660


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9068
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -986.491089
Layer 0 weight grad [0][0] = -6112.622070


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9069
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -999.526978
Layer 0 weight grad [0][0] = 1046.948730


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9070
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1011.499268
Layer 0 weight grad [0][0] = -415.268646


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9071
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1024.432251
Layer 0 weight grad [0][0] = 1027.254517


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9072
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1036.413818
Layer 0 weight grad [0][0] = 1079.642334


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9073
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1968.679443
Layer 0 weight grad [0][0] = 1114.948486


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9074
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1041.695923
Layer 0 weight grad [0][0] = 1153.514893


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9075
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1055.259399
Layer 0 weight grad [0][0] = 1151.354004


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9076
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1067.909546
Layer 0 weight grad [0][0] = 1141.710571


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9077
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1081.523804
Layer 0 weight grad [0][0] = 1129.891846


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9078
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1094.560669
Layer 0 weight grad [0][0] = 1169.516846


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9079
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1108.335205
Layer 0 weight grad [0][0] = -252.759598


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9080
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1122.053955
Layer 0 weight grad [0][0] = -1784.753906


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9081
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1102.286865
Layer 0 weight grad [0][0] = 1179.223999


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9082
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1117.043091
Layer 0 weight grad [0][0] = 1225.425659


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9083
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6623.988281
Layer 0 weight grad [0][0] = 757.664307


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9084
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1091.891479
Layer 0 weight grad [0][0] = -4919.633301


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9085
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1104.662354
Layer 0 weight grad [0][0] = 1242.633057


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9086
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2106.982910
Layer 0 weight grad [0][0] = 1232.758667


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9087
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1117.058228
Layer 0 weight grad [0][0] = 1254.818970


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9088
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2083.996582
Layer 0 weight grad [0][0] = 1240.689331


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9089
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1130.347168
Layer 0 weight grad [0][0] = -1252.447632


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9090
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6802.293457
Layer 0 weight grad [0][0] = -1092.695068


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9091
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1043.472046
Layer 0 weight grad [0][0] = -928.258118


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9092
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1029.417969
Layer 0 weight grad [0][0] = 1124.578613


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9093
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1040.694580
Layer 0 weight grad [0][0] = 1111.485840


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9094
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1052.288818
Layer 0 weight grad [0][0] = 1161.594238


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 9095
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1063.593506
Layer 0 weight grad [0][0] = 1200.973389


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 9096
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1075.644043
Layer 0 weight grad [0][0] = 1248.395996


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9097
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1087.338745
Layer 0 weight grad [0][0] = -4887.704102


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9098
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1099.769775
Layer 0 weight grad [0][0] = 1275.877319


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9099
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1112.946899
Layer 0 weight grad [0][0] = 1285.573975


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9100
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6849.580566
Layer 0 weight grad [0][0] = -1064.013916


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9101
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1090.950439
Layer 0 weight grad [0][0] = 596.353333


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9102
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1104.744263
Layer 0 weight grad [0][0] = -4821.604980


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9103
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1117.538940
Layer 0 weight grad [0][0] = 1308.385742


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 9104
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1132.065796
Layer 0 weight grad [0][0] = -2195.208252


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9105
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1145.787842
Layer 0 weight grad [0][0] = -2145.732178


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9106
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1134.239746
Layer 0 weight grad [0][0] = 57.952797


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9107
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1147.682495
Layer 0 weight grad [0][0] = -809.319275


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9108
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1161.342407
Layer 0 weight grad [0][0] = 1292.812256


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9109
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1175.644653
Layer 0 weight grad [0][0] = 1300.758423


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9110
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1189.152100
Layer 0 weight grad [0][0] = -1880.348267


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9111
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1133.525269
Layer 0 weight grad [0][0] = 1290.473267


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9112
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1146.770264
Layer 0 weight grad [0][0] = 1237.353516


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9113
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1160.129272
Layer 0 weight grad [0][0] = -4936.520020


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9114
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1172.285889
Layer 0 weight grad [0][0] = -4836.857422


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9115
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1185.555176
Layer 0 weight grad [0][0] = 1248.655884


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 9116
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2321.822510
Layer 0 weight grad [0][0] = 1247.002441


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9117
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2351.005371
Layer 0 weight grad [0][0] = -5775.554199


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9118
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1223.568115
Layer 0 weight grad [0][0] = 1252.281616


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9119
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1235.810303
Layer 0 weight grad [0][0] = 1253.962402


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9120
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1248.794922
Layer 0 weight grad [0][0] = 1242.420776


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9121
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1260.785156
Layer 0 weight grad [0][0] = -860.843750


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9122
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1274.588379
Layer 0 weight grad [0][0] = -1775.802246


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9123
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7191.008789
Layer 0 weight grad [0][0] = 1308.935425


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9124
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1202.660889
Layer 0 weight grad [0][0] = 1234.588501


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9125
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1215.048218
Layer 0 weight grad [0][0] = 63.601078


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9126
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1201.630737
Layer 0 weight grad [0][0] = 1686.718872


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9127
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1212.900757
Layer 0 weight grad [0][0] = 1245.917480


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9128
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1225.509644
Layer 0 weight grad [0][0] = 1305.116821


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9129
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1237.875488
Layer 0 weight grad [0][0] = -1580.867676


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9130
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7307.085449
Layer 0 weight grad [0][0] = -5054.978516


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9131
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1212.956787
Layer 0 weight grad [0][0] = 1349.153320


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9132
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2304.992432
Layer 0 weight grad [0][0] = 662.448425


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9133
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1233.098145
Layer 0 weight grad [0][0] = 1297.111206


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9134
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1245.225830
Layer 0 weight grad [0][0] = -4987.221680


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9135
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7748.470703
Layer 0 weight grad [0][0] = -287.126007


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9136
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2112.922852
Layer 0 weight grad [0][0] = 1265.979004


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9137
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2106.670898
Layer 0 weight grad [0][0] = -2045.803223


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9138
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1167.033325
Layer 0 weight grad [0][0] = 1303.117920


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 9139
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1179.170044
Layer 0 weight grad [0][0] = 1351.441284


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9140
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1191.032959
Layer 0 weight grad [0][0] = 933.702881


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9141
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2216.051514
Layer 0 weight grad [0][0] = -2231.581543


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9142
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1133.931152
Layer 0 weight grad [0][0] = -2480.775146


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9143
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1126.808838
Layer 0 weight grad [0][0] = 927.504150


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9144
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1139.184326
Layer 0 weight grad [0][0] = 1392.246094


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9145
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1151.483398
Layer 0 weight grad [0][0] = 1378.166992


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9146
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6930.414551
Layer 0 weight grad [0][0] = 1365.542236


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9147
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1143.751343
Layer 0 weight grad [0][0] = 1314.483276


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9148
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1156.731934
Layer 0 weight grad [0][0] = 1312.979858


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9149
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1170.073486
Layer 0 weight grad [0][0] = 877.196045


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9150
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1183.658325
Layer 0 weight grad [0][0] = 1327.970947


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9151
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1197.945801
Layer 0 weight grad [0][0] = 1380.410400


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9152
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7476.094238
Layer 0 weight grad [0][0] = -1039.231201


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9153
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1184.085327
Layer 0 weight grad [0][0] = 1383.580322


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9154
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1200.827148
Layer 0 weight grad [0][0] = 1431.111572


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9155
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 1923.447021
Layer 0 weight grad [0][0] = 321.506439


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9156
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1225.984009
Layer 0 weight grad [0][0] = 1468.980347


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9157
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1241.730347
Layer 0 weight grad [0][0] = -2384.130371


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9158
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1172.364502
Layer 0 weight grad [0][0] = 1402.930908


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9159
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2065.895752
Layer 0 weight grad [0][0] = -2807.800293


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9160
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1105.422974
Layer 0 weight grad [0][0] = -2774.829834


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9161
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1029.925903
Layer 0 weight grad [0][0] = 1430.324829


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9162
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6073.166992
Layer 0 weight grad [0][0] = -1512.439087


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9163
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1010.387573
Layer 0 weight grad [0][0] = 1081.317139


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 9164
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1027.840088
Layer 0 weight grad [0][0] = -1855.053223


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9165
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1044.462769
Layer 0 weight grad [0][0] = -1709.666870


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9166
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1062.283813
Layer 0 weight grad [0][0] = -3333.587891


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 9167
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -974.295532
Layer 0 weight grad [0][0] = 611.081055


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9168
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -971.439392
Layer 0 weight grad [0][0] = 1536.061157


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9169
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2205.535645
Layer 0 weight grad [0][0] = 1552.338135


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9170
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1002.117859
Layer 0 weight grad [0][0] = -5075.508301


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9171
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1000.619934
Layer 0 weight grad [0][0] = -4172.500000


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9172
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1017.128845
Layer 0 weight grad [0][0] = -2535.571289


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9173
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1034.357056
Layer 0 weight grad [0][0] = 1611.855103


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9174
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6066.902344
Layer 0 weight grad [0][0] = 1632.833740


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9175
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1016.515869
Layer 0 weight grad [0][0] = 1564.817139


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9176
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1033.617798
Layer 0 weight grad [0][0] = 1586.116577


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9177
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1050.861694
Layer 0 weight grad [0][0] = -4208.989258


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9178
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1068.286377
Layer 0 weight grad [0][0] = 1607.001953


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9179
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1086.671997
Layer 0 weight grad [0][0] = 1612.988525


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9180
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1104.601196
Layer 0 weight grad [0][0] = -2359.889160


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9181
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1122.961914
Layer 0 weight grad [0][0] = 1599.961182


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9182
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1141.545166
Layer 0 weight grad [0][0] = 1624.958130


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9183
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2270.691406
Layer 0 weight grad [0][0] = 1671.251465


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9184
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1172.680054
Layer 0 weight grad [0][0] = -3929.930176


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9185
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1192.810303
Layer 0 weight grad [0][0] = 1740.294922


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9186
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1212.640381
Layer 0 weight grad [0][0] = 1745.587769


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9187
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1232.401733
Layer 0 weight grad [0][0] = 1760.875244


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9188
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1252.752808
Layer 0 weight grad [0][0] = 673.790649


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9189
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1249.845825
Layer 0 weight grad [0][0] = 1666.005493


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9190
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1271.080566
Layer 0 weight grad [0][0] = 1652.721558


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9191
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1290.968750
Layer 0 weight grad [0][0] = -4122.658203


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9192
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1311.755371
Layer 0 weight grad [0][0] = 1461.962891


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9193
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1330.897339
Layer 0 weight grad [0][0] = -3490.195801


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9194
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1239.811768
Layer 0 weight grad [0][0] = 706.025757


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9195
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1239.608032
Layer 0 weight grad [0][0] = 1625.825317


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9196
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1259.364624
Layer 0 weight grad [0][0] = 1579.075928


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9197
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1278.620728
Layer 0 weight grad [0][0] = 1844.577637


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9198
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1299.027466
Layer 0 weight grad [0][0] = -3675.809570


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9199
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1320.073242
Layer 0 weight grad [0][0] = 1598.276978


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9200
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1341.759277
Layer 0 weight grad [0][0] = 1595.766602


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9201
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1364.030273
Layer 0 weight grad [0][0] = 1644.737915


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9202
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3404.705811
Layer 0 weight grad [0][0] = -5330.836426


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9203
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000014 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1372.836792
Layer 0 weight grad [0][0] = 943.896790


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9204
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1394.065918
Layer 0 weight grad [0][0] = 1656.187988


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9205
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1415.956177
Layer 0 weight grad [0][0] = -3037.835938


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9206
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3547.813477
Layer 0 weight grad [0][0] = 1723.773193


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9207
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1451.696655
Layer 0 weight grad [0][0] = 1771.990601


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9208
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1472.681641
Layer 0 weight grad [0][0] = 1760.788330


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9209
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1494.876709
Layer 0 weight grad [0][0] = -4495.205566


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9210
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1516.782471
Layer 0 weight grad [0][0] = -3647.080811


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9211
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3874.369873
Layer 0 weight grad [0][0] = 1712.415283


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9212
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1433.840210
Layer 0 weight grad [0][0] = 1701.966187


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9213
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1455.518433
Layer 0 weight grad [0][0] = -3494.340332


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9214
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1363.352539
Layer 0 weight grad [0][0] = 1680.811890


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9215
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1384.626587
Layer 0 weight grad [0][0] = -3414.862549


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9216
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1295.268799
Layer 0 weight grad [0][0] = 5461.059570


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9217
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1316.457642
Layer 0 weight grad [0][0] = 1714.024414


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9218
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1336.777100
Layer 0 weight grad [0][0] = 1754.232178


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9219
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1358.896606
Layer 0 weight grad [0][0] = -3617.118164


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9220
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1379.973755
Layer 0 weight grad [0][0] = 1700.782104


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9221
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1400.519287
Layer 0 weight grad [0][0] = 1698.397583


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9222
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6752.680176
Layer 0 weight grad [0][0] = 1628.347900


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9223
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1373.205566
Layer 0 weight grad [0][0] = -3730.937988


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9224
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7036.684570
Layer 0 weight grad [0][0] = 1658.106567


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9225
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1345.244385
Layer 0 weight grad [0][0] = 1710.596436


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9226
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1366.288208
Layer 0 weight grad [0][0] = 1765.481323


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9227
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1388.815918
Layer 0 weight grad [0][0] = 427.994202


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9228
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1411.089844
Layer 0 weight grad [0][0] = 469.265320


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9229
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1435.149658
Layer 0 weight grad [0][0] = 1810.052979


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9230
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1458.411621
Layer 0 weight grad [0][0] = 1800.358521


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9231
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1481.557983
Layer 0 weight grad [0][0] = 1790.056641


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9232
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1504.503052
Layer 0 weight grad [0][0] = 1780.227051


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9233
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 8280.821289
Layer 0 weight grad [0][0] = -5135.255859


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9234
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1467.870728
Layer 0 weight grad [0][0] = 1776.399170


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9235
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1489.625732
Layer 0 weight grad [0][0] = 798.869263


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9236
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1489.380737
Layer 0 weight grad [0][0] = 1771.439331


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9237
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1510.469360
Layer 0 weight grad [0][0] = -11661.139648


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9238
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1401.215698
Layer 0 weight grad [0][0] = 638.373413


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9239
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1422.281860
Layer 0 weight grad [0][0] = 1689.411987


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9240
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1442.899170
Layer 0 weight grad [0][0] = 967.057556


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9241
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1464.262085
Layer 0 weight grad [0][0] = -1849.894287


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9242
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1485.131836
Layer 0 weight grad [0][0] = 1763.114746


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9243
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1504.926880
Layer 0 weight grad [0][0] = 1793.401489


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9244
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 8230.110352
Layer 0 weight grad [0][0] = 1783.179443


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9245
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1501.399536
Layer 0 weight grad [0][0] = -2791.364258


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9246
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1521.022705
Layer 0 weight grad [0][0] = 1802.801025


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9247
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1539.365112
Layer 0 weight grad [0][0] = -4181.687500


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9248
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1559.245850
Layer 0 weight grad [0][0] = -4069.123779


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9249
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1450.107788
Layer 0 weight grad [0][0] = -4113.297363


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9250
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1468.519165
Layer 0 weight grad [0][0] = -3963.604492


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9251
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3990.222656
Layer 0 weight grad [0][0] = 673.988831


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9252
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1378.938232
Layer 0 weight grad [0][0] = -4213.346191


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9253
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1397.338257
Layer 0 weight grad [0][0] = -4309.629395


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 9254
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1283.465210
Layer 0 weight grad [0][0] = -4274.459961


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9255
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1169.498657
Layer 0 weight grad [0][0] = 579.390991


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9256
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1165.879761
Layer 0 weight grad [0][0] = 1773.807129


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 9257
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4357.828125
Layer 0 weight grad [0][0] = -210.842392


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9258
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1179.237671
Layer 0 weight grad [0][0] = 359.098816


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9259
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1197.099121
Layer 0 weight grad [0][0] = 599.642334


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9260
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1190.069702
Layer 0 weight grad [0][0] = -1558.568726


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9261
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1208.991089
Layer 0 weight grad [0][0] = 1727.937500


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9262
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1227.965454
Layer 0 weight grad [0][0] = -3750.707520


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9263
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1247.127075
Layer 0 weight grad [0][0] = 1763.133423


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9264
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1265.793213
Layer 0 weight grad [0][0] = -5035.977539


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9265
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5499.281250
Layer 0 weight grad [0][0] = 1742.288452


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9266
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1243.020874
Layer 0 weight grad [0][0] = 1729.600586


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9267
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1261.897827
Layer 0 weight grad [0][0] = -3718.842285


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9268
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1282.181519
Layer 0 weight grad [0][0] = 1753.337036


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9269
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4344.055176
Layer 0 weight grad [0][0] = 373.905792


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9270
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1291.339111
Layer 0 weight grad [0][0] = 1676.470459


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9271
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6087.592285
Layer 0 weight grad [0][0] = 538.000671


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 9272
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1294.514282
Layer 0 weight grad [0][0] = 1611.927490


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9273
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4112.795898
Layer 0 weight grad [0][0] = 1673.139038


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9274
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1332.106323
Layer 0 weight grad [0][0] = -4434.453613


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9275
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1218.701294
Layer 0 weight grad [0][0] = 1648.691162


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9276
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1237.259888
Layer 0 weight grad [0][0] = 1614.484009


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9277
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4288.879395
Layer 0 weight grad [0][0] = -7500.011719


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9278
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1135.815308
Layer 0 weight grad [0][0] = -4691.903320


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9279
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1016.397278
Layer 0 weight grad [0][0] = -3746.131348


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9280
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3684.051270
Layer 0 weight grad [0][0] = -4585.558105


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9281
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4523.361328
Layer 0 weight grad [0][0] = 1678.439209


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9282
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -914.231995
Layer 0 weight grad [0][0] = 1694.977417


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9283
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -933.661682
Layer 0 weight grad [0][0] = 1714.165649


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9284
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -952.313538
Layer 0 weight grad [0][0] = -3452.615967


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9285
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -971.189758
Layer 0 weight grad [0][0] = 1747.922974


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9286
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -990.500122
Layer 0 weight grad [0][0] = 1758.380249


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9287
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1009.558105
Layer 0 weight grad [0][0] = 1768.294556


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9288
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1027.757080
Layer 0 weight grad [0][0] = -1048.552856


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9289
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1047.084961
Layer 0 weight grad [0][0] = -1470.073975


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9290
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4616.099609
Layer 0 weight grad [0][0] = -1676.059937


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9291
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1089.192749
Layer 0 weight grad [0][0] = 5846.859375


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9292
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1106.912231
Layer 0 weight grad [0][0] = -11.502590


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9293
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4337.146973
Layer 0 weight grad [0][0] = 1847.117432


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9294
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1112.865845
Layer 0 weight grad [0][0] = 1831.728516


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9295
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1130.684448
Layer 0 weight grad [0][0] = 1718.413086


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9296
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1151.441528
Layer 0 weight grad [0][0] = 684.065918


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9297
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1171.087036
Layer 0 weight grad [0][0] = 1814.456787


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9298
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1191.003540
Layer 0 weight grad [0][0] = -988.045105


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9299
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5224.020020
Layer 0 weight grad [0][0] = 1583.444214


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9300
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1193.582031
Layer 0 weight grad [0][0] = 1844.381348


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9301
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1213.611328
Layer 0 weight grad [0][0] = 1782.136963


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9302
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1232.604492
Layer 0 weight grad [0][0] = 1527.386353


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9303
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1250.740479
Layer 0 weight grad [0][0] = 620.082275


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9304
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4202.999023
Layer 0 weight grad [0][0] = 643.977356


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9305
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1268.873413
Layer 0 weight grad [0][0] = -4026.536621


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9306
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1286.079102
Layer 0 weight grad [0][0] = -10045.967773


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9307
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1170.460693
Layer 0 weight grad [0][0] = 1769.403931


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9308
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1187.701294
Layer 0 weight grad [0][0] = -1910.914307


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 9309
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1204.686523
Layer 0 weight grad [0][0] = 1715.927490


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9310
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1221.323730
Layer 0 weight grad [0][0] = 1307.054321


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9311
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1236.947510
Layer 0 weight grad [0][0] = -4335.376465


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9312
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1124.111450
Layer 0 weight grad [0][0] = 724.572815


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9313
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1139.606201
Layer 0 weight grad [0][0] = 1581.410889


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9314
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1154.862427
Layer 0 weight grad [0][0] = 441.752411


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9315
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1170.084351
Layer 0 weight grad [0][0] = 1631.450806


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9316
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1185.637329
Layer 0 weight grad [0][0] = -3852.833496


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9317
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1200.658447
Layer 0 weight grad [0][0] = 1630.485229


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9318
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1215.508057
Layer 0 weight grad [0][0] = 1617.687378


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9319
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1230.406372
Layer 0 weight grad [0][0] = 1628.227905


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9320
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1244.894897
Layer 0 weight grad [0][0] = 1670.399414


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9321
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5675.853516
Layer 0 weight grad [0][0] = 1604.492310


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9322
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1266.975830
Layer 0 weight grad [0][0] = -3876.977539


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9323
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4863.548340
Layer 0 weight grad [0][0] = 1550.173096


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9324
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1161.322754
Layer 0 weight grad [0][0] = 1527.276489


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9325
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1176.800171
Layer 0 weight grad [0][0] = 401.402130


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9326
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1166.934448
Layer 0 weight grad [0][0] = -3783.027832


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9327
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1182.222046
Layer 0 weight grad [0][0] = 475.161499


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9328
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1174.219116
Layer 0 weight grad [0][0] = 6535.952637


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9329
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4307.070801
Layer 0 weight grad [0][0] = 1552.576294


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9330
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5311.846680
Layer 0 weight grad [0][0] = 1539.965576


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 9331
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1206.866211
Layer 0 weight grad [0][0] = 1553.591431


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9332
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1221.441162
Layer 0 weight grad [0][0] = 1590.488770


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9333
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1235.679443
Layer 0 weight grad [0][0] = 400.248352


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9334
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1224.344849
Layer 0 weight grad [0][0] = -3330.533203


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 9335
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1237.595215
Layer 0 weight grad [0][0] = -4322.117188


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9336
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1251.136719
Layer 0 weight grad [0][0] = -3285.895752


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 9337
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1264.471680
Layer 0 weight grad [0][0] = 1533.038940


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9338
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1277.325806
Layer 0 weight grad [0][0] = 1521.449341


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9339
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1290.010620
Layer 0 weight grad [0][0] = 1555.551880


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 9340
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1303.376221
Layer 0 weight grad [0][0] = 1263.605591


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 9341
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1316.468750
Layer 0 weight grad [0][0] = -4070.929932


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9342
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6470.720703
Layer 0 weight grad [0][0] = 1593.591309


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9343
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1325.462158
Layer 0 weight grad [0][0] = 464.855042


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9344
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1338.499756
Layer 0 weight grad [0][0] = 1660.140381


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9345
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1352.446533
Layer 0 weight grad [0][0] = -3579.200195


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9346
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1366.197021
Layer 0 weight grad [0][0] = -3335.177490


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9347
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1379.737061
Layer 0 weight grad [0][0] = 1707.390625


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9348
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1392.912354
Layer 0 weight grad [0][0] = -3761.012451


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9349
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1405.655762
Layer 0 weight grad [0][0] = 1754.812134


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9350
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1419.114380
Layer 0 weight grad [0][0] = 468.318787


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9351
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1404.148315
Layer 0 weight grad [0][0] = 1724.216553


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9352
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7373.541016
Layer 0 weight grad [0][0] = 1708.771729


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9353
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7490.877930
Layer 0 weight grad [0][0] = -3798.362793


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9354
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1426.289185
Layer 0 weight grad [0][0] = -2747.864990


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9355
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1438.175903
Layer 0 weight grad [0][0] = 349.896118


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 9356
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7831.002930
Layer 0 weight grad [0][0] = 1718.196167


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9357
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1457.675415
Layer 0 weight grad [0][0] = -3869.598877


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 9358
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1367.353149
Layer 0 weight grad [0][0] = 1762.352417


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9359
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1380.045410
Layer 0 weight grad [0][0] = -3354.783447


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9360
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1393.558350
Layer 0 weight grad [0][0] = -5261.588379


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9361
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1378.938110
Layer 0 weight grad [0][0] = 3115.720703


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9362
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1392.244751
Layer 0 weight grad [0][0] = 1863.488525


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9363
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1404.052734
Layer 0 weight grad [0][0] = 1845.104126


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9364
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1416.445679
Layer 0 weight grad [0][0] = 1811.167603


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9365
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1428.301025
Layer 0 weight grad [0][0] = -4468.980469


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9366
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1440.255249
Layer 0 weight grad [0][0] = -2994.842041


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9367
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1349.053223
Layer 0 weight grad [0][0] = 1697.812378


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9368
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1361.755005
Layer 0 weight grad [0][0] = -6056.483887


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9369
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1372.842529
Layer 0 weight grad [0][0] = 1712.528687


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9370
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1384.614258
Layer 0 weight grad [0][0] = -1368.921021


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9371
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1373.369751
Layer 0 weight grad [0][0] = -4901.199219


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9372
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1385.324707
Layer 0 weight grad [0][0] = 1644.029785


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9373
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1397.009155
Layer 0 weight grad [0][0] = -3207.495117


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9374
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1314.637329
Layer 0 weight grad [0][0] = -2882.190186


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9375
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3737.291260
Layer 0 weight grad [0][0] = 1591.387451


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9376
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3786.021973
Layer 0 weight grad [0][0] = 492.740448


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9377
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1361.360474
Layer 0 weight grad [0][0] = -5368.767090


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9378
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1352.479614
Layer 0 weight grad [0][0] = 1542.473022


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9379
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1363.408569
Layer 0 weight grad [0][0] = 1631.853516


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9380
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1375.218872
Layer 0 weight grad [0][0] = 1629.942993


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9381
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7280.341309
Layer 0 weight grad [0][0] = -4033.382080


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9382
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1292.942261
Layer 0 weight grad [0][0] = 1600.782593


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9383
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1305.348267
Layer 0 weight grad [0][0] = 1677.304565


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9384
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1318.683228
Layer 0 weight grad [0][0] = 1716.541504


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9385
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1331.644287
Layer 0 weight grad [0][0] = -3979.459473


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9386
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1344.331543
Layer 0 weight grad [0][0] = 1687.843384


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9387
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1356.901245
Layer 0 weight grad [0][0] = -2920.491943


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9388
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1268.319702
Layer 0 weight grad [0][0] = 1713.413208


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9389
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1279.154175
Layer 0 weight grad [0][0] = 1698.870728


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9390
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6446.625977
Layer 0 weight grad [0][0] = -7502.071777


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9391
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1195.445923
Layer 0 weight grad [0][0] = -3628.196533


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9392
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5771.966309
Layer 0 weight grad [0][0] = -3678.960938


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9393
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1210.956055
Layer 0 weight grad [0][0] = 1737.139648


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9394
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3791.762695
Layer 0 weight grad [0][0] = 1238.084229


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9395
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1229.247192
Layer 0 weight grad [0][0] = 1705.776123


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9396
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1240.195312
Layer 0 weight grad [0][0] = 1689.500977


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9397
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3815.048340
Layer 0 weight grad [0][0] = -3161.500488


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9398
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1266.489502
Layer 0 weight grad [0][0] = 1661.925171


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9399
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1276.690308
Layer 0 weight grad [0][0] = 5556.156738


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9400
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1288.300171
Layer 0 weight grad [0][0] = -3163.647705


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9401
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1191.329956
Layer 0 weight grad [0][0] = -493.115967


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9402
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1202.450439
Layer 0 weight grad [0][0] = 1762.048340


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9403
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1213.337280
Layer 0 weight grad [0][0] = 1742.687378


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9404
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1223.442749
Layer 0 weight grad [0][0] = 1725.303711


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9405
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1233.751709
Layer 0 weight grad [0][0] = -1435.169434


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9406
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1243.721191
Layer 0 weight grad [0][0] = -175.934937


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9407
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1254.139526
Layer 0 weight grad [0][0] = -3383.579834


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9408
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1154.455688
Layer 0 weight grad [0][0] = 1702.492065


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9409
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1163.894043
Layer 0 weight grad [0][0] = 935.654724


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9410
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5579.391602
Layer 0 weight grad [0][0] = -272.415070


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9411
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1178.341553
Layer 0 weight grad [0][0] = 1658.991455


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9412
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1191.047119
Layer 0 weight grad [0][0] = 1683.361572


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 9413
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1203.996216
Layer 0 weight grad [0][0] = 863.791504


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9414
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1199.703003
Layer 0 weight grad [0][0] = 1070.427246


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9415
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1212.103271
Layer 0 weight grad [0][0] = 473.914337


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9416
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1226.162720
Layer 0 weight grad [0][0] = 1768.888062


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9417
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1242.172241
Layer 0 weight grad [0][0] = 1644.818237


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9418
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1258.621460
Layer 0 weight grad [0][0] = 1680.337158


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9419
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1275.488770
Layer 0 weight grad [0][0] = 1023.736694


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9420
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1278.578247
Layer 0 weight grad [0][0] = 1651.819092


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9421
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1296.300537
Layer 0 weight grad [0][0] = 1569.139038


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9422
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1313.019409
Layer 0 weight grad [0][0] = 1656.787109


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9423
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1331.897827
Layer 0 weight grad [0][0] = 1642.062256


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9424
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1348.382080
Layer 0 weight grad [0][0] = -3725.139160


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9425
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1367.227905
Layer 0 weight grad [0][0] = -3695.200928


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9426
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1386.012573
Layer 0 weight grad [0][0] = 1659.822144


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9427
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1403.453369
Layer 0 weight grad [0][0] = -436.810608


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9428
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1421.999390
Layer 0 weight grad [0][0] = -157.033203


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 9429
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7429.950684
Layer 0 weight grad [0][0] = 1574.811279


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9430
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1401.338135
Layer 0 weight grad [0][0] = 1597.969727


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9431
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1418.765015
Layer 0 weight grad [0][0] = 7283.196777


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9432
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1435.163940
Layer 0 weight grad [0][0] = 843.154724


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9433
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1452.687256
Layer 0 weight grad [0][0] = 1573.375610


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9434
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1469.134277
Layer 0 weight grad [0][0] = 5760.736328


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 9435
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1485.248535
Layer 0 weight grad [0][0] = 1624.403809


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9436
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1502.174316
Layer 0 weight grad [0][0] = 1704.337646


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9437
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1518.947632
Layer 0 weight grad [0][0] = 224.541122


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9438
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1536.616333
Layer 0 weight grad [0][0] = 1658.012817


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9439
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1553.640503
Layer 0 weight grad [0][0] = -3409.631836


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9440
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4093.389160
Layer 0 weight grad [0][0] = 1632.732788


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9441
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1474.946411
Layer 0 weight grad [0][0] = -3421.121582


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9442
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1491.833740
Layer 0 weight grad [0][0] = -8280.298828


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9443
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1402.180542
Layer 0 weight grad [0][0] = -1857.436646


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9444
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1417.287231
Layer 0 weight grad [0][0] = 1580.354492


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9445
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1433.666138
Layer 0 weight grad [0][0] = 1404.889893


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 9446
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1445.457764
Layer 0 weight grad [0][0] = 1606.232300


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9447
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1462.018311
Layer 0 weight grad [0][0] = -5784.401367


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9448
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4594.563477
Layer 0 weight grad [0][0] = 1541.390503


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9449
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6516.225098
Layer 0 weight grad [0][0] = -3348.437012


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9450
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1347.982178
Layer 0 weight grad [0][0] = 1519.832031


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9451
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1364.198364
Layer 0 weight grad [0][0] = 1557.162720


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9452
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1381.687866
Layer 0 weight grad [0][0] = 1619.854614


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9453
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4268.085938
Layer 0 weight grad [0][0] = -1506.619507


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9454
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1415.129761
Layer 0 weight grad [0][0] = 4527.805664


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9455
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1433.112183
Layer 0 weight grad [0][0] = 5065.797363


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9456
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1451.849731
Layer 0 weight grad [0][0] = -4463.980469


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9457
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1468.543579
Layer 0 weight grad [0][0] = 1709.322632


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9458
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1486.557739
Layer 0 weight grad [0][0] = 1684.212891


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9459
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1504.079224
Layer 0 weight grad [0][0] = 1690.730225


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9460
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1522.729614
Layer 0 weight grad [0][0] = 1716.779053


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9461
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1540.960815
Layer 0 weight grad [0][0] = -2165.447754


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9462
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1559.456177
Layer 0 weight grad [0][0] = 1732.258911


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9463
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1575.912964
Layer 0 weight grad [0][0] = 1720.348633


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9464
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1594.723389
Layer 0 weight grad [0][0] = 1795.714600


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9465
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1613.923096
Layer 0 weight grad [0][0] = -1113.331665


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 9466
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1633.076538
Layer 0 weight grad [0][0] = -3147.187744


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9467
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1651.483032
Layer 0 weight grad [0][0] = 1743.528198


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9468
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1669.243408
Layer 0 weight grad [0][0] = -2401.752441


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9469
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1672.952148
Layer 0 weight grad [0][0] = 1719.554565


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9470
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1690.316162
Layer 0 weight grad [0][0] = 1760.843506


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9471
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1707.849243
Layer 0 weight grad [0][0] = 10500.267578


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9472
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1726.130493
Layer 0 weight grad [0][0] = -1452.609009


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9473
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1745.484131
Layer 0 weight grad [0][0] = -7334.046875


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9474
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1628.739990
Layer 0 weight grad [0][0] = 1020.442566


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9475
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1632.122925
Layer 0 weight grad [0][0] = 1801.034302


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9476
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1651.859131
Layer 0 weight grad [0][0] = -4287.271484


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9477
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5400.093262
Layer 0 weight grad [0][0] = -4235.857910


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9478
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1437.087769
Layer 0 weight grad [0][0] = 267.474701


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9479
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1455.134888
Layer 0 weight grad [0][0] = -1080.670044


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9480
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1474.021362
Layer 0 weight grad [0][0] = 1751.363403


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9481
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1492.394531
Layer 0 weight grad [0][0] = 7413.525391


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 9482
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1510.321899
Layer 0 weight grad [0][0] = 1754.000488


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9483
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1527.962769
Layer 0 weight grad [0][0] = 1708.993042


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9484
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5760.822754
Layer 0 weight grad [0][0] = 1695.414429


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9485
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1577.204834
Layer 0 weight grad [0][0] = -1001.199951


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9486
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 6837.522949
Layer 0 weight grad [0][0] = -813.721558


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9487
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1570.567139
Layer 0 weight grad [0][0] = -1089.718628


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9488
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1588.347900
Layer 0 weight grad [0][0] = 1701.794922


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 9489
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1605.732422
Layer 0 weight grad [0][0] = 1686.944458


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9490
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1623.062866
Layer 0 weight grad [0][0] = 1709.890137


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9491
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1641.549438
Layer 0 weight grad [0][0] = 1183.068604


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9492
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1647.639160
Layer 0 weight grad [0][0] = -175.256775


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9493
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1667.519897
Layer 0 weight grad [0][0] = -613.170349


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9494
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7854.896973
Layer 0 weight grad [0][0] = 1822.214722


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9495
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1673.433105
Layer 0 weight grad [0][0] = 7023.286621


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9496
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1691.789062
Layer 0 weight grad [0][0] = -846.406860


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9497
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 8314.921875
Layer 0 weight grad [0][0] = -1004.977844


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9498
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1700.998901
Layer 0 weight grad [0][0] = -1621.251465


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9499
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1717.624390
Layer 0 weight grad [0][0] = 1796.351074


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9500
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1734.033936
Layer 0 weight grad [0][0] = 1781.374390


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9501
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1750.902832
Layer 0 weight grad [0][0] = 219.495850


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9502
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1768.533691
Layer 0 weight grad [0][0] = 395.270294


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9503
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1786.298096
Layer 0 weight grad [0][0] = 1028.776123


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9504
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1786.248901
Layer 0 weight grad [0][0] = -3843.735107


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9505
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1804.767578
Layer 0 weight grad [0][0] = -572.313477


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9506
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1823.972290
Layer 0 weight grad [0][0] = 1837.605469


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9507
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1841.425781
Layer 0 weight grad [0][0] = -100.148567


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9508
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1859.598389
Layer 0 weight grad [0][0] = -369.928284


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9509
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5120.227539
Layer 0 weight grad [0][0] = -472.331390


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9510
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1902.308350
Layer 0 weight grad [0][0] = 1742.602661


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9511
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1918.703491
Layer 0 weight grad [0][0] = 1738.298218


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 9512
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1935.524902
Layer 0 weight grad [0][0] = 1075.027588


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9513
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1938.804443
Layer 0 weight grad [0][0] = 421.666504


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9514
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1954.205078
Layer 0 weight grad [0][0] = -4407.773926


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9515
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9380.810547
Layer 0 weight grad [0][0] = 1598.051392


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9516
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 5176.505371
Layer 0 weight grad [0][0] = -188.320877


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9517
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1859.008057
Layer 0 weight grad [0][0] = -217.545944


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9518
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9780.386719
Layer 0 weight grad [0][0] = 1660.539307


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9519
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9934.917969
Layer 0 weight grad [0][0] = 1702.336060


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9520
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1863.343262
Layer 0 weight grad [0][0] = -3382.436768


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9521
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1879.968262
Layer 0 weight grad [0][0] = 1811.309937


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9522
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 10357.980469
Layer 0 weight grad [0][0] = 1799.189697


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9523
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1897.158936
Layer 0 weight grad [0][0] = 1789.353638


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9524
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1914.641113
Layer 0 weight grad [0][0] = -4296.436523


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9525
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1799.067505
Layer 0 weight grad [0][0] = -3522.494873


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9526
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1817.100342
Layer 0 weight grad [0][0] = -3023.050049


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 9527
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1811.295288
Layer 0 weight grad [0][0] = 673.193298


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9528
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1827.659302
Layer 0 weight grad [0][0] = -26.437492


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9529
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1844.844482
Layer 0 weight grad [0][0] = 1775.593018


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9530
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1862.673584
Layer 0 weight grad [0][0] = -246.424103


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9531
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1880.489746
Layer 0 weight grad [0][0] = -2194.652344


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9532
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1896.742432
Layer 0 weight grad [0][0] = -191.286957


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9533
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1912.748901
Layer 0 weight grad [0][0] = 1668.852051


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9534
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1929.737793
Layer 0 weight grad [0][0] = 1656.119141


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9535
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1945.940186
Layer 0 weight grad [0][0] = 31.343212


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9536
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1962.766968
Layer 0 weight grad [0][0] = 1649.563843


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9537
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1978.765137
Layer 0 weight grad [0][0] = 1645.089233


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9538
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1995.647583
Layer 0 weight grad [0][0] = -375.011688


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9539
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2012.246948
Layer 0 weight grad [0][0] = -3155.119141


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9540
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1922.287231
Layer 0 weight grad [0][0] = 1666.658203


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9541
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 10407.750977
Layer 0 weight grad [0][0] = 636.306885


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9542
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1902.473633
Layer 0 weight grad [0][0] = 460.871948


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9543
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1917.113525
Layer 0 weight grad [0][0] = 1637.877197


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9544
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1931.956543
Layer 0 weight grad [0][0] = 1687.271973


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9545
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1946.692993
Layer 0 weight grad [0][0] = 1733.480347


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9546
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 4919.424316
Layer 0 weight grad [0][0] = 1778.268311


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9547
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1977.446289
Layer 0 weight grad [0][0] = -897.467041


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9548
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 10974.033203
Layer 0 weight grad [0][0] = -663.255493


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9549
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1983.578125
Layer 0 weight grad [0][0] = 1939.632446


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9550
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 11248.048828
Layer 0 weight grad [0][0] = 1927.086060


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9551
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1984.899658
Layer 0 weight grad [0][0] = 1915.647217


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9552
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2002.349976
Layer 0 weight grad [0][0] = 1424.430054


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9553
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 11668.468750
Layer 0 weight grad [0][0] = 1888.755859


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9554
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1995.152954
Layer 0 weight grad [0][0] = 1928.890991


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9555
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 11960.510742
Layer 0 weight grad [0][0] = 1922.600342


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9556
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1988.625977
Layer 0 weight grad [0][0] = 2035.524414


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9557
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3803.593994
Layer 0 weight grad [0][0] = -204.495209


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9558
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2005.258789
Layer 0 weight grad [0][0] = -3103.399902


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9559
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2025.249146
Layer 0 weight grad [0][0] = 2168.186523


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9560
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 12459.592773
Layer 0 weight grad [0][0] = 173.016113


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9561
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2018.815430
Layer 0 weight grad [0][0] = -4374.539062


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9562
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1896.185913
Layer 0 weight grad [0][0] = 316.409698


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9563
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1918.843018
Layer 0 weight grad [0][0] = 2197.495361


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9564
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1942.891968
Layer 0 weight grad [0][0] = -4998.455078


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9565
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1809.678833
Layer 0 weight grad [0][0] = 252.702377


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9566
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1832.776733
Layer 0 weight grad [0][0] = 1143.623291


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9567
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1832.047485
Layer 0 weight grad [0][0] = 387.264526


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9568
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 10813.144531
Layer 0 weight grad [0][0] = -9867.541992


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9569
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1672.777954
Layer 0 weight grad [0][0] = 2167.559326


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9570
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3735.231445
Layer 0 weight grad [0][0] = -2797.763916


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9571
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9955.763672
Layer 0 weight grad [0][0] = 2128.172607


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9572
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1683.402466
Layer 0 weight grad [0][0] = 2201.840576


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9573
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 10309.342773
Layer 0 weight grad [0][0] = 2237.578369


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9574
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 10512.700195
Layer 0 weight grad [0][0] = 2224.918945


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9575
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1630.264038
Layer 0 weight grad [0][0] = 2301.019287


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9576
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 10855.519531
Layer 0 weight grad [0][0] = 2290.501953


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9577
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1617.113403
Layer 0 weight grad [0][0] = 1458.763672


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 9578
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1639.454346
Layer 0 weight grad [0][0] = -4562.059082


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9579
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2077.869141
Layer 0 weight grad [0][0] = -353.723724


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9580
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1542.045288
Layer 0 weight grad [0][0] = 2286.031006


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9581
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1563.699219
Layer 0 weight grad [0][0] = 1156.990479


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9582
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1559.375366
Layer 0 weight grad [0][0] = 2372.997803


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9583
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1581.948608
Layer 0 weight grad [0][0] = 707.605530


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9584
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1605.159546
Layer 0 weight grad [0][0] = 2285.111084


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 9585
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1627.388428
Layer 0 weight grad [0][0] = -4478.267578


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9586
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2339.010498
Layer 0 weight grad [0][0] = -3249.214111


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9587
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1645.823486
Layer 0 weight grad [0][0] = 2246.261963


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9588
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1666.217773
Layer 0 weight grad [0][0] = 2265.094482


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9589
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1689.057129
Layer 0 weight grad [0][0] = 2223.941162


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9590
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1711.049683
Layer 0 weight grad [0][0] = 2283.116699


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9591
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1732.267944
Layer 0 weight grad [0][0] = -5906.539551


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9592
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1574.901489
Layer 0 weight grad [0][0] = 2388.102051


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9593
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1597.379883
Layer 0 weight grad [0][0] = 2501.541504


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9594
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1622.226440
Layer 0 weight grad [0][0] = 1292.193604


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9595
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1619.785522
Layer 0 weight grad [0][0] = -4585.381348


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9596
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2597.497314
Layer 0 weight grad [0][0] = 2447.433350


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9597
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1669.051025
Layer 0 weight grad [0][0] = 911.685669


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9598
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1692.384766
Layer 0 weight grad [0][0] = 1214.592896


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9599
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 10869.041016
Layer 0 weight grad [0][0] = 2474.082275


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9600
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1693.811523
Layer 0 weight grad [0][0] = 2495.940186


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9601
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1717.497681
Layer 0 weight grad [0][0] = 2492.827637


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9602
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1741.262085
Layer 0 weight grad [0][0] = 2479.035400


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9603
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1764.767944
Layer 0 weight grad [0][0] = -4358.570312


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9604
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1787.627441
Layer 0 weight grad [0][0] = 2388.530762


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9605
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1809.884277
Layer 0 weight grad [0][0] = 2439.884277


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9606
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2381.796631
Layer 0 weight grad [0][0] = 2103.675537


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9607
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1853.925537
Layer 0 weight grad [0][0] = 2412.986816


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9608
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1875.765259
Layer 0 weight grad [0][0] = -4219.148438


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9609
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1897.039429
Layer 0 weight grad [0][0] = 1812.725464


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9610
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2291.368408
Layer 0 weight grad [0][0] = -5080.238770


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9611
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1938.164185
Layer 0 weight grad [0][0] = -5847.467285


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9612
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2420.610596
Layer 0 weight grad [0][0] = 916.299255


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9613
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1770.842651
Layer 0 weight grad [0][0] = 2210.653564


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9614
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1789.706421
Layer 0 weight grad [0][0] = 2207.181641


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9615
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1808.633057
Layer 0 weight grad [0][0] = 2093.661621


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9616
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1826.975464
Layer 0 weight grad [0][0] = -13023.820312


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9617
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1660.188843
Layer 0 weight grad [0][0] = 2220.366699


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9618
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1681.156982
Layer 0 weight grad [0][0] = 1692.053589


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9619
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1701.718262
Layer 0 weight grad [0][0] = 2565.246826


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9620
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1722.873535
Layer 0 weight grad [0][0] = -6027.377930


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9621
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2385.602051
Layer 0 weight grad [0][0] = 836.028198


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9622
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1764.504150
Layer 0 weight grad [0][0] = -4345.151855


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 9623
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1783.948853
Layer 0 weight grad [0][0] = 558.110413


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9624
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1803.548950
Layer 0 weight grad [0][0] = -4758.899902


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9625
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1823.898071
Layer 0 weight grad [0][0] = -14306.912109


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9626
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1652.656128
Layer 0 weight grad [0][0] = 2260.909424


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9627
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1672.887451
Layer 0 weight grad [0][0] = 2250.671387


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9628
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1692.388306
Layer 0 weight grad [0][0] = 2710.251221


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9629
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1711.828125
Layer 0 weight grad [0][0] = -5286.015137


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9630
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1730.708618
Layer 0 weight grad [0][0] = 2148.740723


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9631
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1748.700317
Layer 0 weight grad [0][0] = 2109.045654


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9632
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1766.799561
Layer 0 weight grad [0][0] = 2053.930664


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9633
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1784.588623
Layer 0 weight grad [0][0] = -6480.996094


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9634
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1628.162476
Layer 0 weight grad [0][0] = -5895.333984


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9635
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1475.443115
Layer 0 weight grad [0][0] = 1979.082520


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 9636
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1492.928223
Layer 0 weight grad [0][0] = 570.016418


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9637
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1512.039551
Layer 0 weight grad [0][0] = 541.130920


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9638
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1530.011719
Layer 0 weight grad [0][0] = 1985.574341


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9639
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1547.451294
Layer 0 weight grad [0][0] = -6721.689453


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9640
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1537.277466
Layer 0 weight grad [0][0] = -53.030598


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9641
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1527.649292
Layer 0 weight grad [0][0] = 1793.199707


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9642
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1544.338867
Layer 0 weight grad [0][0] = 1740.393433


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9643
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1560.089111
Layer 0 weight grad [0][0] = 736.337402


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9644
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1554.493164
Layer 0 weight grad [0][0] = 1863.827637


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9645
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 10419.807617
Layer 0 weight grad [0][0] = 1766.834839


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9646
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 10577.558594
Layer 0 weight grad [0][0] = 1758.519775


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9647
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1640.824707
Layer 0 weight grad [0][0] = 1758.924683


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9648
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1658.117188
Layer 0 weight grad [0][0] = 12537.899414


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9649
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 11072.827148
Layer 0 weight grad [0][0] = 1723.258423


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9650
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1712.235474
Layer 0 weight grad [0][0] = 1791.237061


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9651
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 11391.666992
Layer 0 weight grad [0][0] = 4668.476074


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9652
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1754.893677
Layer 0 weight grad [0][0] = 1724.656128


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9653
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1772.104370
Layer 0 weight grad [0][0] = 544.440430


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9654
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2474.265625
Layer 0 weight grad [0][0] = 4867.911621


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9655
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1783.562134
Layer 0 weight grad [0][0] = 1678.710571


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9656
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1802.464600
Layer 0 weight grad [0][0] = 1721.169189


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9657
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1821.181274
Layer 0 weight grad [0][0] = 3890.938477


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9658
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1841.058594
Layer 0 weight grad [0][0] = 1776.388916


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9659
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1861.174927
Layer 0 weight grad [0][0] = 1771.913208


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9660
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1880.648315
Layer 0 weight grad [0][0] = 1818.907349


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9661
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 12703.782227
Layer 0 weight grad [0][0] = 1757.135986


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9662
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1893.625732
Layer 0 weight grad [0][0] = 1657.465454


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9663
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000036 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2282.824707
Layer 0 weight grad [0][0] = 1698.299072


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9664
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1929.383301
Layer 0 weight grad [0][0] = -4440.640625


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9665
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1816.071777
Layer 0 weight grad [0][0] = 1558.298706


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9666
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1834.604492
Layer 0 weight grad [0][0] = -3123.252686


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9667
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1852.950806
Layer 0 weight grad [0][0] = 1553.273804


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9668
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1870.634277
Layer 0 weight grad [0][0] = 1081.613770


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9669
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1889.112915
Layer 0 weight grad [0][0] = 1550.477417


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9670
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1907.192139
Layer 0 weight grad [0][0] = -5593.334961


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9671
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2514.555420
Layer 0 weight grad [0][0] = 559.444092


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9672
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1924.223511
Layer 0 weight grad [0][0] = 1696.324585


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9673
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1944.637329
Layer 0 weight grad [0][0] = -204.951477


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9674
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1964.836548
Layer 0 weight grad [0][0] = -7136.303223


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9675
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1985.645630
Layer 0 weight grad [0][0] = 1660.367676


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9676
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2006.169189
Layer 0 weight grad [0][0] = 4268.939941


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9677
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2699.253174
Layer 0 weight grad [0][0] = 363.463013


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9678
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2014.990234
Layer 0 weight grad [0][0] = -6210.253906


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9679
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2008.159912
Layer 0 weight grad [0][0] = 1608.759888


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9680
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2029.217163
Layer 0 weight grad [0][0] = 1607.410278


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9681
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2049.337646
Layer 0 weight grad [0][0] = 1605.650146


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 9682
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2069.147217
Layer 0 weight grad [0][0] = -5240.678223


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9683
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2089.892334
Layer 0 weight grad [0][0] = 1539.736084


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9684
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2109.986816
Layer 0 weight grad [0][0] = -3666.798584


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9685
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2017.125122
Layer 0 weight grad [0][0] = -5092.983398


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 9686
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3206.197266
Layer 0 weight grad [0][0] = 6119.568848


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9687
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2034.956543
Layer 0 weight grad [0][0] = -5705.318848


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9688
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2054.468750
Layer 0 weight grad [0][0] = -5539.717773


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9689
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2073.439209
Layer 0 weight grad [0][0] = 8383.860352


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9690
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2091.741211
Layer 0 weight grad [0][0] = 1505.243286


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9691
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2111.781738
Layer 0 weight grad [0][0] = -7119.852051


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9692
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1989.831055
Layer 0 weight grad [0][0] = -4080.889160


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9693
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2011.260620
Layer 0 weight grad [0][0] = 4205.002441


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9694
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2034.328247
Layer 0 weight grad [0][0] = 1683.023804


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9695
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2057.759277
Layer 0 weight grad [0][0] = -3878.805908


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9696
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2081.042480
Layer 0 weight grad [0][0] = 1772.585083


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9697
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2104.416260
Layer 0 weight grad [0][0] = 6260.299805


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9698
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2126.255615
Layer 0 weight grad [0][0] = -4922.809082


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9699
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2128.599121
Layer 0 weight grad [0][0] = 1726.803345


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9700
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2150.012939
Layer 0 weight grad [0][0] = 841.807556


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9701
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2151.900146
Layer 0 weight grad [0][0] = -6851.743652


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9702
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2029.491577
Layer 0 weight grad [0][0] = 1562.609985


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9703
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2049.399658
Layer 0 weight grad [0][0] = -3959.583984


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 9704
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2070.347168
Layer 0 weight grad [0][0] = -4043.417480


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9705
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2092.394043
Layer 0 weight grad [0][0] = 158.888000


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 9706
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2112.397461
Layer 0 weight grad [0][0] = 5821.629395


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9707
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2133.058594
Layer 0 weight grad [0][0] = 1487.777710


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9708
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2151.764404
Layer 0 weight grad [0][0] = 1377.262085


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9709
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2170.415039
Layer 0 weight grad [0][0] = 1317.427124


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9710
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 13330.922852
Layer 0 weight grad [0][0] = 6774.409180


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9711
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2174.556152
Layer 0 weight grad [0][0] = -3832.113525


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9712
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3909.375488
Layer 0 weight grad [0][0] = 1223.588501


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9713
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2210.707764
Layer 0 weight grad [0][0] = 1314.666504


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9714
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3935.946533
Layer 0 weight grad [0][0] = 1321.700439


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9715
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3946.870605
Layer 0 weight grad [0][0] = 822.838562


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9716
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 14149.851562
Layer 0 weight grad [0][0] = 6698.220703


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9717
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2244.549805
Layer 0 weight grad [0][0] = 673.798889


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9718
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2246.207031
Layer 0 weight grad [0][0] = -6150.818848


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9719
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2264.340088
Layer 0 weight grad [0][0] = 1390.732910


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9720
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2280.849854
Layer 0 weight grad [0][0] = -13384.548828


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9721
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 13379.371094
Layer 0 weight grad [0][0] = 1473.330322


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 9722
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2143.229736
Layer 0 weight grad [0][0] = 1475.373779


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9723
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2161.947998
Layer 0 weight grad [0][0] = 1405.165039


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9724
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3618.757324
Layer 0 weight grad [0][0] = 1216.320068


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9725
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2197.148193
Layer 0 weight grad [0][0] = 1143.032104


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9726
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 14049.789062
Layer 0 weight grad [0][0] = 1070.506226


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9727
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2194.148926
Layer 0 weight grad [0][0] = -556.611023


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9728
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2209.844482
Layer 0 weight grad [0][0] = -3795.929932


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9729
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2120.624756
Layer 0 weight grad [0][0] = 6205.330078


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9730
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2121.820557
Layer 0 weight grad [0][0] = -6056.632812


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9731
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2136.926270
Layer 0 weight grad [0][0] = 1065.981201


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9732
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2153.920898
Layer 0 weight grad [0][0] = -2612.818359


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9733
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2172.687256
Layer 0 weight grad [0][0] = -3240.178711


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9734
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2179.416748
Layer 0 weight grad [0][0] = -5585.435547


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9735
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2186.389404
Layer 0 weight grad [0][0] = 982.008850


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9736
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2203.709473
Layer 0 weight grad [0][0] = 800.062439


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9737
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2220.281006
Layer 0 weight grad [0][0] = -4164.258301


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9738
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2236.655518
Layer 0 weight grad [0][0] = 769.338318


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9739
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2252.220459
Layer 0 weight grad [0][0] = -1427.116699


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9740
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3678.450195
Layer 0 weight grad [0][0] = 690.638855


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9741
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2290.222412
Layer 0 weight grad [0][0] = 696.549622


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9742
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2304.990479
Layer 0 weight grad [0][0] = -4734.357910


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9743
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2199.967041
Layer 0 weight grad [0][0] = 6885.918457


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9744
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2213.868408
Layer 0 weight grad [0][0] = 7461.230469


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9745
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2227.382324
Layer 0 weight grad [0][0] = 19728.621094


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9746
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2240.513428
Layer 0 weight grad [0][0] = 7722.937012


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9747
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2253.998047
Layer 0 weight grad [0][0] = -6437.510742


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9748
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2160.856445
Layer 0 weight grad [0][0] = 657.767639


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9749
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2173.039551
Layer 0 weight grad [0][0] = 365.785492


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9750
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3991.833984
Layer 0 weight grad [0][0] = 697.873291


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9751
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2198.936279
Layer 0 weight grad [0][0] = 704.044922


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9752
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 13608.875977
Layer 0 weight grad [0][0] = -5068.188965


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9753
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2205.434814
Layer 0 weight grad [0][0] = -5276.733887


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9754
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2204.593262
Layer 0 weight grad [0][0] = 6976.384277


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9755
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2215.068115
Layer 0 weight grad [0][0] = -3611.856201


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9756
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2134.298828
Layer 0 weight grad [0][0] = 811.504883


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9757
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2144.929932
Layer 0 weight grad [0][0] = 642.040283


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9758
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 13255.412109
Layer 0 weight grad [0][0] = -5160.411621


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9759
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2067.834229
Layer 0 weight grad [0][0] = 727.295776


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 9760
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 12677.143555
Layer 0 weight grad [0][0] = 621.636597


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9761
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2070.959473
Layer 0 weight grad [0][0] = 7175.587402


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9762
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2081.903809
Layer 0 weight grad [0][0] = -3726.523438


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9763
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2092.162598
Layer 0 weight grad [0][0] = 482.964996


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9764
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 13053.629883
Layer 0 weight grad [0][0] = -3301.340576


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9765
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2098.784424
Layer 0 weight grad [0][0] = -2726.961914


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9766
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2110.036621
Layer 0 weight grad [0][0] = 506.173950


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9767
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2121.702881
Layer 0 weight grad [0][0] = 542.637085


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9768
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2131.816162
Layer 0 weight grad [0][0] = 678.217651


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9769
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2145.254395
Layer 0 weight grad [0][0] = -4237.916992


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9770
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 12719.303711
Layer 0 weight grad [0][0] = 684.824890


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9771
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2052.225342
Layer 0 weight grad [0][0] = 816.436768


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9772
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2065.897705
Layer 0 weight grad [0][0] = -8218.684570


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9773
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1960.195923
Layer 0 weight grad [0][0] = -4606.253906


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9774
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1855.742188
Layer 0 weight grad [0][0] = 763.121216


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9775
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1869.611206
Layer 0 weight grad [0][0] = 800.849915


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9776
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1882.018677
Layer 0 weight grad [0][0] = -4356.629883


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9777
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1782.273193
Layer 0 weight grad [0][0] = 7322.287109


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9778
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1794.534912
Layer 0 weight grad [0][0] = -4254.216797


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9779
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1808.325562
Layer 0 weight grad [0][0] = -4212.288086


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9780
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 10743.462891
Layer 0 weight grad [0][0] = -5164.744141


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 9781
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1825.452637
Layer 0 weight grad [0][0] = 901.657471


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9782
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1838.648315
Layer 0 weight grad [0][0] = 4611.982910


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9783
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1853.891602
Layer 0 weight grad [0][0] = 1210.342285


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9784
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1871.174683
Layer 0 weight grad [0][0] = 991.092712


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9785
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 11444.515625
Layer 0 weight grad [0][0] = 1102.075928


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9786
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1899.867798
Layer 0 weight grad [0][0] = 1044.269287


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9787
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 11754.591797
Layer 0 weight grad [0][0] = 1112.635376


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9788
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1931.629150
Layer 0 weight grad [0][0] = 1109.680054


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9789
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1947.173706
Layer 0 weight grad [0][0] = 1108.642334


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 9790
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1963.304199
Layer 0 weight grad [0][0] = 1104.759033


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9791
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1978.898560
Layer 0 weight grad [0][0] = 1102.390625


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9792
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1994.418579
Layer 0 weight grad [0][0] = 1106.619873


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9793
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2008.257690
Layer 0 weight grad [0][0] = -2887.158936


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9794
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2023.207886
Layer 0 weight grad [0][0] = 1104.350342


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9795
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 12951.214844
Layer 0 weight grad [0][0] = -5008.896973


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9796
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3393.413086
Layer 0 weight grad [0][0] = -2900.919922


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9797
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1935.984985
Layer 0 weight grad [0][0] = -1918.605591


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9798
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1925.242920
Layer 0 weight grad [0][0] = 1174.154663


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9799
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1940.973389
Layer 0 weight grad [0][0] = 1133.945923


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 9800
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1956.290649
Layer 0 weight grad [0][0] = -858.732605


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9801
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3437.800049
Layer 0 weight grad [0][0] = -4564.876465


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9802
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1875.577515
Layer 0 weight grad [0][0] = -4483.153320


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9803
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1769.666504
Layer 0 weight grad [0][0] = -4433.834473


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9804
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1765.781006
Layer 0 weight grad [0][0] = 1034.718262


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9805
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3794.066162
Layer 0 weight grad [0][0] = 5156.447754


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9806
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1808.928345
Layer 0 weight grad [0][0] = -3082.930176


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9807
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 10687.134766
Layer 0 weight grad [0][0] = 1032.505981


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9808
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3731.499512
Layer 0 weight grad [0][0] = 1107.876709


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9809
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1848.176758
Layer 0 weight grad [0][0] = -3036.843994


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9810
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1862.390503
Layer 0 weight grad [0][0] = 1066.299927


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9811
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1876.464600
Layer 0 weight grad [0][0] = 5038.559082


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9812
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1891.971069
Layer 0 weight grad [0][0] = 1037.766846


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9813
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1905.891479
Layer 0 weight grad [0][0] = 4739.395508


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9814
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000030 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 11564.250977
Layer 0 weight grad [0][0] = 1049.554565


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9815
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1915.000366
Layer 0 weight grad [0][0] = 2631.051270


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9816
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1891.438721
Layer 0 weight grad [0][0] = -3663.462158


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9817
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 11596.601562
Layer 0 weight grad [0][0] = -905.842957


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9818
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1902.073975
Layer 0 weight grad [0][0] = -833.622742


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9819
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1915.627319
Layer 0 weight grad [0][0] = -2838.539795


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9820
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1928.249146
Layer 0 weight grad [0][0] = 949.958069


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9821
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 12072.963867
Layer 0 weight grad [0][0] = -2785.003906


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9822
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1942.711670
Layer 0 weight grad [0][0] = 924.909546


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9823
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1953.791504
Layer 0 weight grad [0][0] = -4454.364258


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9824
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1966.044312
Layer 0 weight grad [0][0] = 915.731995


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9825
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1976.870483
Layer 0 weight grad [0][0] = -7864.343262


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9826
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1894.829712
Layer 0 weight grad [0][0] = -1014.821899


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9827
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1863.049683
Layer 0 weight grad [0][0] = -277.872131


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9828
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1876.762085
Layer 0 weight grad [0][0] = -2853.420898


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9829
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1888.686768
Layer 0 weight grad [0][0] = 890.879089


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9830
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1900.163818
Layer 0 weight grad [0][0] = -2810.221191


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9831
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1912.436401
Layer 0 weight grad [0][0] = -2879.929199


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9832
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1840.950439
Layer 0 weight grad [0][0] = -7681.928223


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9833
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3419.007568
Layer 0 weight grad [0][0] = -1206.707520


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9834
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1751.936157
Layer 0 weight grad [0][0] = 932.038818


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9835
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1762.847900
Layer 0 weight grad [0][0] = 4536.229492


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9836
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1774.260132
Layer 0 weight grad [0][0] = -700.503845


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9837
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1787.705078
Layer 0 weight grad [0][0] = -3524.520264


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9838
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1710.615723
Layer 0 weight grad [0][0] = 687.431458


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9839
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1724.225708
Layer 0 weight grad [0][0] = 1068.948120


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9840
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1738.078369
Layer 0 weight grad [0][0] = 1168.799683


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9841
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1753.300537
Layer 0 weight grad [0][0] = 1207.202271


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9842
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1768.691162
Layer 0 weight grad [0][0] = 1301.362305


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9843
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1786.619995
Layer 0 weight grad [0][0] = 332.880402


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9844
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1803.488892
Layer 0 weight grad [0][0] = -2789.878418


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9845
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3555.788086
Layer 0 weight grad [0][0] = 1341.551636


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9846
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1852.915527
Layer 0 weight grad [0][0] = 1309.032959


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9847
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 11281.691406
Layer 0 weight grad [0][0] = -4293.958008


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9848
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1862.552734
Layer 0 weight grad [0][0] = 996.760925


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9849
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1880.479736
Layer 0 weight grad [0][0] = 2876.313232


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9850
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1897.764404
Layer 0 weight grad [0][0] = 1469.783813


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9851
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1916.605713
Layer 0 weight grad [0][0] = -3861.358154


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9852
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3403.074219
Layer 0 weight grad [0][0] = 1444.242920


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9853
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3520.189453
Layer 0 weight grad [0][0] = 4625.884766


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9854
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2000.260498
Layer 0 weight grad [0][0] = 1422.081421


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9855
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2017.379883
Layer 0 weight grad [0][0] = 1400.592896


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9856
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2033.921143
Layer 0 weight grad [0][0] = -4160.821289


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9857
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2050.510010
Layer 0 weight grad [0][0] = 1437.843384


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9858
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000013 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2066.869873
Layer 0 weight grad [0][0] = -10663.791992


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9859
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1939.041992
Layer 0 weight grad [0][0] = -2431.744385


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9860
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1912.176025
Layer 0 weight grad [0][0] = -5773.304688


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9861
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1929.844971
Layer 0 weight grad [0][0] = 1458.346924


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 9862
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1946.740479
Layer 0 weight grad [0][0] = 1419.312866


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9863
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1964.565063
Layer 0 weight grad [0][0] = 1413.711914


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9864
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1982.468506
Layer 0 weight grad [0][0] = 538.698853


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 9865
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1999.246338
Layer 0 weight grad [0][0] = 1373.640503


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9866
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2016.651978
Layer 0 weight grad [0][0] = 4702.707520


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9867
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2035.118164
Layer 0 weight grad [0][0] = 1483.818359


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9868
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2053.638916
Layer 0 weight grad [0][0] = 1517.854614


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9869
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3439.284180
Layer 0 weight grad [0][0] = 1585.071167


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9870
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2105.431152
Layer 0 weight grad [0][0] = -3841.465820


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9871
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2122.692627
Layer 0 weight grad [0][0] = 4141.503418


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9872
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2140.905762
Layer 0 weight grad [0][0] = -559.594666


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9873
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2156.966797
Layer 0 weight grad [0][0] = 1232.917236


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9874
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 13973.796875
Layer 0 weight grad [0][0] = 1682.898071


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9875
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2198.323486
Layer 0 weight grad [0][0] = -3986.229248


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9876
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2218.027832
Layer 0 weight grad [0][0] = -330.535706


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9877
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 14140.757812
Layer 0 weight grad [0][0] = -308.794250


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9878
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2179.573975
Layer 0 weight grad [0][0] = 1749.038330


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9879
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2197.801270
Layer 0 weight grad [0][0] = 1739.280762


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9880
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2217.339600
Layer 0 weight grad [0][0] = 1814.070190


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9881
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2238.223633
Layer 0 weight grad [0][0] = 1781.787231


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9882
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2259.714844
Layer 0 weight grad [0][0] = -334.943573


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9883
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2284.393555
Layer 0 weight grad [0][0] = -3672.254883


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9884
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2308.435547
Layer 0 weight grad [0][0] = 1715.685669


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9885
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2332.747314
Layer 0 weight grad [0][0] = 1720.555664


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9886
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 15497.306641
Layer 0 weight grad [0][0] = 1731.069214


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9887
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2324.628174
Layer 0 weight grad [0][0] = 1697.079956


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9888
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2351.806885
Layer 0 weight grad [0][0] = 1694.056152


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9889
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2379.387695
Layer 0 weight grad [0][0] = -4360.211426


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9890
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 16312.660156
Layer 0 weight grad [0][0] = -4910.323730


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9891
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2364.895264
Layer 0 weight grad [0][0] = 1757.979004


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 9892
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2392.822998
Layer 0 weight grad [0][0] = -6631.908203


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9893
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2236.486084
Layer 0 weight grad [0][0] = 1792.654297


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9894
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2262.958008
Layer 0 weight grad [0][0] = 1701.645142


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9895
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2289.129883
Layer 0 weight grad [0][0] = 1696.668945


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9896
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2316.702393
Layer 0 weight grad [0][0] = -5076.196777


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9897
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2342.983887
Layer 0 weight grad [0][0] = 1700.341187


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 9898
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2370.652832
Layer 0 weight grad [0][0] = 1664.053711


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9899
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2717.583252
Layer 0 weight grad [0][0] = -2735.750488


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9900
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2438.375977
Layer 0 weight grad [0][0] = -2696.395752


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9901
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2464.250244
Layer 0 weight grad [0][0] = 2531.640137


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9902
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2447.296875
Layer 0 weight grad [0][0] = 4547.939453


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9903
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2471.769531
Layer 0 weight grad [0][0] = -6989.102051


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9904
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 16962.630859
Layer 0 weight grad [0][0] = -5361.093750


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9905
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2308.524170
Layer 0 weight grad [0][0] = -5034.193848


Training loss: 2.302585
Training accuracy: 0.375000

epoch: 9906
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2332.288330
Layer 0 weight grad [0][0] = 1668.077637


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9907
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2355.016357
Layer 0 weight grad [0][0] = -3200.519287


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9908
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2377.857178
Layer 0 weight grad [0][0] = 5339.777832


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9909
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2402.502686
Layer 0 weight grad [0][0] = 1775.962769


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9910
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2749.634033
Layer 0 weight grad [0][0] = -5743.314941


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9911
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3003.949951
Layer 0 weight grad [0][0] = 3819.360596


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9912
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2289.313477
Layer 0 weight grad [0][0] = 34.216843


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9913
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2274.076660
Layer 0 weight grad [0][0] = -71.825569


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9914
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2259.975098
Layer 0 weight grad [0][0] = 1624.996948


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9915
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2281.975586
Layer 0 weight grad [0][0] = 5191.626953


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9916
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2303.499023
Layer 0 weight grad [0][0] = 7254.602051


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 9917
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 15355.719727
Layer 0 weight grad [0][0] = 1455.122192


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9918
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2312.373291
Layer 0 weight grad [0][0] = 3372.056396


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9919
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2331.740723
Layer 0 weight grad [0][0] = -4889.091797


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9920
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2212.193359
Layer 0 weight grad [0][0] = -4074.454346


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9921
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2231.652344
Layer 0 weight grad [0][0] = 5786.895508


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9922
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2252.433594
Layer 0 weight grad [0][0] = -3186.832520


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9923
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2274.844482
Layer 0 weight grad [0][0] = 1585.152222


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9924
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2300.043457
Layer 0 weight grad [0][0] = 1578.580688


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9925
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2322.912354
Layer 0 weight grad [0][0] = 1573.762939


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9926
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2346.829590
Layer 0 weight grad [0][0] = 91.992218


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 9927
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2337.780518
Layer 0 weight grad [0][0] = 119.214867


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9928
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 15563.740234
Layer 0 weight grad [0][0] = 1568.360352


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9929
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2338.036133
Layer 0 weight grad [0][0] = 1479.924927


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9930
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2360.960449
Layer 0 weight grad [0][0] = 3615.560303


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9931
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2894.376709
Layer 0 weight grad [0][0] = 1605.809204


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9932
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 16372.861328
Layer 0 weight grad [0][0] = 327.967133


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9933
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2407.629395
Layer 0 weight grad [0][0] = 6095.529297


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9934
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2432.985840
Layer 0 weight grad [0][0] = 1607.504028


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9935
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2458.227539
Layer 0 weight grad [0][0] = -7529.733887


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9936
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2234.390625
Layer 0 weight grad [0][0] = 1743.915771


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9937
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2260.798828
Layer 0 weight grad [0][0] = -3738.571045


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9938
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2287.733643
Layer 0 weight grad [0][0] = 1682.039429


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 9939
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2312.529785
Layer 0 weight grad [0][0] = -2796.547852


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9940
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2336.937744
Layer 0 weight grad [0][0] = -2474.734863


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9941
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2363.215088
Layer 0 weight grad [0][0] = 1726.568115


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9942
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2388.171875
Layer 0 weight grad [0][0] = -4347.333984


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9943
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2416.032471
Layer 0 weight grad [0][0] = -2654.277832


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9944
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2441.098877
Layer 0 weight grad [0][0] = 1684.644653


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9945
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2466.072266
Layer 0 weight grad [0][0] = -814.416870


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9946
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2490.641602
Layer 0 weight grad [0][0] = -457.169495


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9947
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2515.200684
Layer 0 weight grad [0][0] = 7913.125488


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9948
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2538.750244
Layer 0 weight grad [0][0] = -4862.471680


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9949
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 2606.392822
Layer 0 weight grad [0][0] = -3406.134521


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9950
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2590.927979
Layer 0 weight grad [0][0] = -8212.293945


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9951
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2397.209473
Layer 0 weight grad [0][0] = 1637.194214


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9952
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2419.249023
Layer 0 weight grad [0][0] = -8711.011719


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9953
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2228.960205
Layer 0 weight grad [0][0] = -4585.178711


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9954
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2248.806641
Layer 0 weight grad [0][0] = -12348.068359


Training loss: 2.302585
Training accuracy: 0.312500

epoch: 9955
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2060.973145
Layer 0 weight grad [0][0] = 1364.130615


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9956
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -2080.914307
Layer 0 weight grad [0][0] = -12273.192383


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9957
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1895.078857
Layer 0 weight grad [0][0] = 1242.486816


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9958
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1913.963745
Layer 0 weight grad [0][0] = -2526.041504


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9959
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1919.169312
Layer 0 weight grad [0][0] = 1082.260864


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9960
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1936.997559
Layer 0 weight grad [0][0] = -8019.998535


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9961
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3159.046387
Layer 0 weight grad [0][0] = 1130.361572


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9962
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1777.406738
Layer 0 weight grad [0][0] = 1258.165894


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9963
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1796.623535
Layer 0 weight grad [0][0] = -2071.420166


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9964
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1816.066650
Layer 0 weight grad [0][0] = -8528.208984


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9965
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 9799.333008
Layer 0 weight grad [0][0] = 1238.156006


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9966
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1680.608154
Layer 0 weight grad [0][0] = 499.904297


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9967
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1700.440308
Layer 0 weight grad [0][0] = 814.153931


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9968
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3361.040283
Layer 0 weight grad [0][0] = 1333.706299


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9969
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1727.444702
Layer 0 weight grad [0][0] = 1467.277100


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9970
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1747.679077
Layer 0 weight grad [0][0] = 1564.613892


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9971
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000006 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1771.710449
Layer 0 weight grad [0][0] = 8887.634766


Training loss: inf
Training accuracy: 0.062500

epoch: 9972
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000006 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1795.245850
Layer 0 weight grad [0][0] = 5676.361328


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 9973
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000005 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1818.253784
Layer 0 weight grad [0][0] = -2879.520508


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9974
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000006 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1841.404663
Layer 0 weight grad [0][0] = 1480.169189


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9975
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000004 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1862.368042
Layer 0 weight grad [0][0] = 28.553631


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 9976
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000006 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1884.279541
Layer 0 weight grad [0][0] = 1415.907715


Training loss: 2.302585
Training accuracy: 0.375000

epoch: 9977
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000005 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1908.242188
Layer 0 weight grad [0][0] = -10090.350586


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9978
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000005 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1678.865112
Layer 0 weight grad [0][0] = -10054.730469


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9979
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000004 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3237.544434
Layer 0 weight grad [0][0] = 1477.789673


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9980
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1486.296021
Layer 0 weight grad [0][0] = 1556.657959


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9981
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000004 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 8846.530273
Layer 0 weight grad [0][0] = 1468.873779


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9982
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000004 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1520.696533
Layer 0 weight grad [0][0] = 1589.381470


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9983
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000004 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1547.824341
Layer 0 weight grad [0][0] = -3387.270752


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9984
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000004 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1575.499756
Layer 0 weight grad [0][0] = -11125.390625


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9985
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000004 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1323.962280
Layer 0 weight grad [0][0] = -11107.352539


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9986
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1072.585083
Layer 0 weight grad [0][0] = 1696.769409


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9987
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000004 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1100.069092
Layer 0 weight grad [0][0] = 1694.252563


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9988
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000004 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1127.371216
Layer 0 weight grad [0][0] = -3514.106445


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9989
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000004 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1155.717896
Layer 0 weight grad [0][0] = 1598.552490


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9990
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3427.095459
Layer 0 weight grad [0][0] = 1522.569946


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9991
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000004 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1214.634644
Layer 0 weight grad [0][0] = 1607.190430


Training loss: 2.302585
Training accuracy: 0.062500

epoch: 9992
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3400.162354
Layer 0 weight grad [0][0] = -4631.145996


Training loss: 2.302585
Training accuracy: 0.250000

epoch: 9993
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 3405.803467
Layer 0 weight grad [0][0] = 1619.422485


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9994
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1305.067505
Layer 0 weight grad [0][0] = 1605.283081


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9995
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 7276.039551
Layer 0 weight grad [0][0] = 1686.808105


Training loss: 2.302585
Training accuracy: 0.125000

epoch: 9996
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1376.198608
Layer 0 weight grad [0][0] = 1672.022217


Training loss: 2.302585
Training accuracy: 0.187500

epoch: 9997
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000004 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1400.556763
Layer 0 weight grad [0][0] = 1659.834839


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9998
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1427.847168
Layer 0 weight grad [0][0] = 467.201813


Training loss: 2.302585
Training accuracy: 0.000000

epoch: 9999
remainder_m = 0, remainder_n = 2
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1453.579834
Layer 0 weight grad [0][0] = 1764.960205


Training loss: 2.302585
Training accuracy: 0.187500

saving in file: /home/rickojn/coding/cf-mlp/models/model_20260209_221732_h8.mdl
Error opening file /home/rickojn/coding/cf-mlp/models/remainder_m = 0, remainder_n = 2
Test loss after training: inf
Test accuracy after training: 0.098000
