rows: 28, cols: 28
Number of training images: 60000
rows: 28, cols: 28
Number of test images: 10000
model layers = 0
Model created with 2 layers
Layer 0: 784 inputs, 8 neurons
Layer 1: 8 inputs, 10 neurons
Number of parameters: 6370
Batch size: 16
Error opening directory /home/rickojn/coding/cf-mlp/models/No model found, training from scratch
relu forward ...
Time spent in relu_forward: 0.000147 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000561 seconds
Test loss before training: 2.322339
Test accuracy before training: 0.099200


training loop:

epoch: 0
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000001 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.594582
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.184118


Training loss: 2.319504
Training accuracy: 0.125000

epoch: 1
relu forward ...
Time spent in relu_forward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000001 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.034513
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = -0.347446


Training loss: 2.304832
Training accuracy: 0.312500

epoch: 2
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.481559
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.000000


Training loss: 2.316247
Training accuracy: 0.125000

epoch: 3
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000001 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.367916
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.007008


Training loss: 2.307064
Training accuracy: 0.187500

epoch: 4
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000001 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.485625
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = -0.276628


Training loss: 2.266833
Training accuracy: 0.062500

epoch: 5
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.377724
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.000000


Training loss: 2.278826
Training accuracy: 0.125000

epoch: 6
relu forward ...
Time spent in relu_forward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.036741
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.000000


Training loss: 2.357383
Training accuracy: 0.062500

epoch: 7
relu forward ...
Time spent in relu_forward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.398734
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.155437


Training loss: 2.344934
Training accuracy: 0.000000

epoch: 8
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000001 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.070504
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.000000


Training loss: 2.308985
Training accuracy: 0.125000

epoch: 9
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.038177
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.091530


Training loss: 2.345540
Training accuracy: 0.125000

epoch: 10
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.043790
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.250138


Training loss: 2.240722
Training accuracy: 0.062500

epoch: 11
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000001 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.518499
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.000000


Training loss: 2.338700
Training accuracy: 0.000000

epoch: 12
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000001 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.512040
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.000000


Training loss: 2.313500
Training accuracy: 0.062500

epoch: 13
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.038581
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.000000


Training loss: 2.282691
Training accuracy: 0.250000

epoch: 14
relu forward ...
Time spent in relu_forward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.040942
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.076938


Training loss: 2.350564
Training accuracy: 0.125000

epoch: 15
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.518311
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.085546


Training loss: 2.268906
Training accuracy: 0.125000

epoch: 16
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000001 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.673805
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = -0.110318


Training loss: 2.322007
Training accuracy: 0.187500

epoch: 17
relu forward ...
Time spent in relu_forward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.196821
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.000000


Training loss: 2.341656
Training accuracy: 0.000000

epoch: 18
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.104837
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.000000


Training loss: 2.326498
Training accuracy: 0.125000

epoch: 19
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.041419
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.000000


Training loss: 2.274022
Training accuracy: 0.125000

epoch: 20
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.038200
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.053867


Training loss: 2.326596
Training accuracy: 0.125000

epoch: 21
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.060925
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.000000


Training loss: 2.265544
Training accuracy: 0.125000

epoch: 22
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000001 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.038520
relu backward ...
Time spent in relu_backward: 0.000002 seconds
Layer 0 weight grad [0][0] = 0.000000


Training loss: 2.317890
Training accuracy: 0.062500

epoch: 23
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.308758
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = -0.032843


Training loss: 2.297474
Training accuracy: 0.062500

epoch: 24
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000001 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.024995
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.103841


Training loss: 2.262258
Training accuracy: 0.125000

epoch: 25
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.034503
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = -0.175352


Training loss: 2.274046
Training accuracy: 0.062500

epoch: 26
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.434617
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.237134


Training loss: 2.343460
Training accuracy: 0.062500

epoch: 27
relu forward ...
Time spent in relu_forward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.023675
relu backward ...
Time spent in relu_backward: 0.000002 seconds
Layer 0 weight grad [0][0] = 0.000000


Training loss: 2.256108
Training accuracy: 0.125000

epoch: 28
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -1.069159
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.000000


Training loss: 2.246725
Training accuracy: 0.187500

epoch: 29
relu forward ...
Time spent in relu_forward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000003 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.492066
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.000000


Training loss: 2.299158
Training accuracy: 0.062500

epoch: 30
relu forward ...
Time spent in relu_forward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.024915
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.000000


Training loss: 2.283576
Training accuracy: 0.125000

epoch: 31
relu forward ...
Time spent in relu_forward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.025896
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.139043


Training loss: 2.374954
Training accuracy: 0.187500

epoch: 32
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.422837
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.000000


Training loss: 2.275295
Training accuracy: 0.062500

epoch: 33
relu forward ...
Time spent in relu_forward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.036253
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.000000


Training loss: 2.328517
Training accuracy: 0.062500

epoch: 34
relu forward ...
Time spent in relu_forward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.278578
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.000000


Training loss: 2.357376
Training accuracy: 0.062500

epoch: 35
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.015871
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = -0.605521


Training loss: 2.279911
Training accuracy: 0.125000

epoch: 36
relu forward ...
Time spent in relu_forward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000003 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.315439
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.000000


Training loss: 2.324623
Training accuracy: 0.062500

epoch: 37
relu forward ...
Time spent in relu_forward: 0.000004 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000004 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.760825
relu backward ...
Time spent in relu_backward: 0.000002 seconds
Layer 0 weight grad [0][0] = -0.133698


Training loss: 2.292902
Training accuracy: 0.250000

epoch: 38
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.010514
relu backward ...
Time spent in relu_backward: 0.000002 seconds
Layer 0 weight grad [0][0] = 0.095702


Training loss: 2.347455
Training accuracy: 0.000000

epoch: 39
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.052321
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.000000


Training loss: 2.326439
Training accuracy: 0.000000

epoch: 40
relu forward ...
Time spent in relu_forward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.025991
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.181042


Training loss: 2.365731
Training accuracy: 0.062500

epoch: 41
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.017084
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.000000


Training loss: 2.282447
Training accuracy: 0.125000

epoch: 42
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.038047
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.000000


Training loss: 2.317134
Training accuracy: 0.125000

epoch: 43
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.047454
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.000000


Training loss: 2.321020
Training accuracy: 0.000000

epoch: 44
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000001 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.059092
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.159456


Training loss: 2.310730
Training accuracy: 0.125000

epoch: 45
relu forward ...
Time spent in relu_forward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000001 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.754601
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.000000


Training loss: 2.292182
Training accuracy: 0.125000

epoch: 46
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.689925
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.000000


Training loss: 2.373522
Training accuracy: 0.250000

epoch: 47
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.034240
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = -0.050403


Training loss: 2.285264
Training accuracy: 0.062500

epoch: 48
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000001 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.275672
relu backward ...
Time spent in relu_backward: 0.000000 seconds
Layer 0 weight grad [0][0] = 0.000000


Training loss: 2.302113
Training accuracy: 0.125000

epoch: 49
relu forward ...
Time spent in relu_forward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.039692
relu backward ...
Time spent in relu_backward: 0.000002 seconds
Layer 0 weight grad [0][0] = 0.000000


Training loss: 2.313430
Training accuracy: 0.125000

epoch: 50
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000001 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.034490
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.000000


Training loss: 2.345099
Training accuracy: 0.000000

epoch: 51
relu forward ...
Time spent in relu_forward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.053189
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.000000


Training loss: 2.348331
Training accuracy: 0.000000

epoch: 52
relu forward ...
Time spent in relu_forward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.050946
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.832635


Training loss: 2.258857
Training accuracy: 0.062500

epoch: 53
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.055818
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.000000


Training loss: 2.271495
Training accuracy: 0.000000

epoch: 54
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.052564
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = -0.743474


Training loss: 2.354370
Training accuracy: 0.062500

epoch: 55
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.046614
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.000000


Training loss: 2.320678
Training accuracy: 0.000000

epoch: 56
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.003904
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.000000


Training loss: 2.291700
Training accuracy: 0.062500

epoch: 57
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.771180
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = -0.894870


Training loss: 2.297542
Training accuracy: 0.187500

epoch: 58
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.295487
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.000000


Training loss: 2.389148
Training accuracy: 0.125000

epoch: 59
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.074840
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.000000


Training loss: 2.300998
Training accuracy: 0.000000

epoch: 60
relu forward ...
Time spent in relu_forward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000004 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.040793
relu backward ...
Time spent in relu_backward: 0.000002 seconds
Layer 0 weight grad [0][0] = -0.281149


Training loss: 2.327878
Training accuracy: 0.125000

epoch: 61
relu forward ...
Time spent in relu_forward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.075909
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.000000


Training loss: 2.446007
Training accuracy: 0.187500

epoch: 62
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.046638
relu backward ...
Time spent in relu_backward: 0.000002 seconds
Layer 0 weight grad [0][0] = 0.000000


Training loss: 2.329131
Training accuracy: 0.062500

epoch: 63
relu forward ...
Time spent in relu_forward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.428723
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.000000


Training loss: 2.229429
Training accuracy: 0.125000

epoch: 64
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.066000
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.000000


Training loss: 2.265466
Training accuracy: 0.062500

epoch: 65
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.095816
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.208701


Training loss: 2.301559
Training accuracy: 0.125000

epoch: 66
relu forward ...
Time spent in relu_forward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.306795
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.000000


Training loss: 2.320100
Training accuracy: 0.000000

epoch: 67
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.629050
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.000000


Training loss: 2.267140
Training accuracy: 0.062500

epoch: 68
relu forward ...
Time spent in relu_forward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.317141
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.000000


Training loss: 2.424332
Training accuracy: 0.000000

epoch: 69
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000001 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.056971
relu backward ...
Time spent in relu_backward: 0.000000 seconds
Layer 0 weight grad [0][0] = 0.000000


Training loss: 2.321815
Training accuracy: 0.000000

epoch: 70
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.060987
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.000000


Training loss: 2.332885
Training accuracy: 0.000000

epoch: 71
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000001 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.343111
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.618585


Training loss: 2.258836
Training accuracy: 0.062500

epoch: 72
relu forward ...
Time spent in relu_forward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.051032
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.000000


Training loss: 2.310760
Training accuracy: 0.125000

epoch: 73
relu forward ...
Time spent in relu_forward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.065716
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.053515


Training loss: 2.348363
Training accuracy: 0.375000

epoch: 74
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.083430
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.000000


Training loss: 2.320611
Training accuracy: 0.125000

epoch: 75
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.463101
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.000000


Training loss: 2.412499
Training accuracy: 0.000000

epoch: 76
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.053737
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = -0.574928


Training loss: 2.444229
Training accuracy: 0.062500

epoch: 77
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.057105
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.000000


Training loss: 2.270489
Training accuracy: 0.125000

epoch: 78
relu forward ...
Time spent in relu_forward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000001 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.484624
relu backward ...
Time spent in relu_backward: 0.000002 seconds
Layer 0 weight grad [0][0] = 0.000000


Training loss: 2.307711
Training accuracy: 0.062500

epoch: 79
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000001 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.022282
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.000000


Training loss: 2.315024
Training accuracy: 0.000000

epoch: 80
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.557660
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.066015


Training loss: 2.335429
Training accuracy: 0.000000

epoch: 81
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.121546
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.097890


Training loss: 2.393645
Training accuracy: 0.000000

epoch: 82
relu forward ...
Time spent in relu_forward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.046012
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = -0.526618


Training loss: 2.266663
Training accuracy: 0.125000

epoch: 83
relu forward ...
Time spent in relu_forward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000003 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.057421
relu backward ...
Time spent in relu_backward: 0.000002 seconds
Layer 0 weight grad [0][0] = 0.000000


Training loss: 2.392811
Training accuracy: 0.000000

epoch: 84
relu forward ...
Time spent in relu_forward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.115028
relu backward ...
Time spent in relu_backward: 0.000002 seconds
Layer 0 weight grad [0][0] = 0.000000


Training loss: 2.382136
Training accuracy: 0.062500

epoch: 85
relu forward ...
Time spent in relu_forward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.487125
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.000000


Training loss: 2.319043
Training accuracy: 0.125000

epoch: 86
relu forward ...
Time spent in relu_forward: 0.000003 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000006 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.094693
relu backward ...
Time spent in relu_backward: 0.000002 seconds
Layer 0 weight grad [0][0] = 0.000000


Training loss: 2.375851
Training accuracy: 0.000000

epoch: 87
relu forward ...
Time spent in relu_forward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.490274
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.106434


Training loss: 2.317930
Training accuracy: 0.250000

epoch: 88
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.042799
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.000000


Training loss: 2.298406
Training accuracy: 0.125000

epoch: 89
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.412481
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = -0.892955


Training loss: 2.243228
Training accuracy: 0.187500

epoch: 90
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.789623
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.000000


Training loss: 2.225108
Training accuracy: 0.187500

epoch: 91
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.047266
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.741977


Training loss: 2.321109
Training accuracy: 0.125000

epoch: 92
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000001 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.522822
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.000000


Training loss: 2.314414
Training accuracy: 0.125000

epoch: 93
relu forward ...
Time spent in relu_forward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.100083
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.000000


Training loss: 2.324824
Training accuracy: 0.125000

epoch: 94
relu forward ...
Time spent in relu_forward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.459245
relu backward ...
Time spent in relu_backward: 0.000002 seconds
Layer 0 weight grad [0][0] = 0.000000


Training loss: 2.360779
Training accuracy: 0.125000

epoch: 95
relu forward ...
Time spent in relu_forward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.027874
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.000000


Training loss: 2.303455
Training accuracy: 0.125000

epoch: 96
relu forward ...
Time spent in relu_forward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.030218
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.628182


Training loss: 2.249481
Training accuracy: 0.125000

epoch: 97
relu forward ...
Time spent in relu_forward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = 0.535648
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.134225


Training loss: 2.340869
Training accuracy: 0.000000

epoch: 98
relu forward ...
Time spent in relu_forward: 0.000002 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.030209
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = -0.889056


Training loss: 2.327146
Training accuracy: 0.000000

epoch: 99
relu forward ...
Time spent in relu_forward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000002 seconds
loss softmax backward ...
Time spent in loss_softmax_backward: 0.000001 seconds
remainder_m = 0, remainder_n = 2
remainder_m = 0, remainder_n = 2
Layer 1 weight grad [0][0] = -0.031981
relu backward ...
Time spent in relu_backward: 0.000001 seconds
Layer 0 weight grad [0][0] = 0.000000


Training loss: 2.297527
Training accuracy: 0.250000

saving in file: /home/rickojn/coding/cf-mlp/models/model_20260123_223020_h8.mdl
Error opening file /home/rickojn/coding/cf-mlp/models/relu forward ...
Time spent in relu_forward: 0.000190 seconds
remainder_m = 0, remainder_n = 2
softmax forward ...
Time spent in softmax_forward: 0.000560 seconds
Test loss after training: 2.329839
Test accuracy after training: 0.100700
